{"category": "政策计划", "title": "印尼计划削减煤炭产量以稳定国际价格", "short_summary": "印尼为保收入稳煤价，计划于2026年将年产量降至7亿吨以下。", "detailed_summary": "印尼为保收入稳煤价，计划于2026年将年产量降至7亿吨以下。\n(1) 印尼政府为防止供大于求抑制煤价，计划实施煤炭产量削减措施。\n(2) 目标为2025年产量降至7.5亿吨，2026年进一步降至7亿吨以下。\n(3) 此举旨在优化价格，确保国家收入，尽管预计需求至2027年仍将增长。\n(4) 2024年基准数据显示产量8.36亿吨，其中出口量为5.55亿吨。", "raw_content": "印尼要大幅减产煤炭。 现在国际上的需求有些偏弱，供应如果还比较充裕的话，将直接影响印尼的国家收入。 印尼能矿部煤炭矿业开发司司长苏里亚·赫尔朱纳(Surya Herjuna)表示，为了保持国家收入的增加，需要在煤炭生产阶段采取措施进行价格优化。从市场角度看，印尼政府认为煤炭需求到2027年仍将保持上升，预计增长约5%-10%。但是，政府却并不希望这种需求增长反而带来过度生产，导致抑制印尼煤炭在全球市场的价格。他总结道，“(印尼)政府正试图防止煤炭生产和销售的差距扩大，即防止出现供大于求的趋势。” 印尼能源与矿产资源部计划于2026年实施煤炭产量削减措施，以稳定并提振持续下跌的国际煤炭价格。 2024年，印尼煤炭产量8.36亿吨，其中2.33亿吨用于国内市场义务，4800万吨用作国家储备，出口量5.55亿吨。 2025年，印尼煤炭产量计划下降至7.5亿吨。 2026年，印尼煤炭产量计划下降到7亿吨以下。", "release_time": "2025-11-18", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1196279-1.html"}
{"category": "研究前沿", "title": "量子时钟测量能耗远超运行成本，牛津团队揭示计时熵源", "short_summary": "量子时钟测量能耗比运行高十亿倍，颠覆传统认知并指向更高效计时方案。", "detailed_summary": "量子时钟测量能耗比运行高十亿倍，颠覆传统认知并指向更高效计时方案。\n(1) 牛津大学团队发现量子计时中测量行为是主要熵来源，相关成果发表于《物理评论快报》；\n(2) 通过双量子点电子跳跃实验，对比电流与射频两种测量技术能耗；\n(3) 测量能耗可达时钟运行能耗的十亿倍，揭示观测行为赋予时间方向性；\n(4) 研究颠覆\"优化量子元件提升时钟性能\"的传统思路；\n(5) 为高效量子传感器、自主导航设备及时间箭头本质研究提供新路径。", "raw_content": "A team led by the University of Oxford has uncovered an unexpected contributor to entropy in quantum timekeeping: the act of measurement itself. In findings published on November 14 in Physical Review Letters, the researchers show that the energy required to read a quantum clock is far greater than the energy needed to run it. Their results point to new challenges and opportunities for developing next-generation quantum technologies.  Traditional clocks, from pendulums to atomic oscillators, depend on irreversible processes to track time. At the quantum level, these processes become extremely weak or may barely occur at all, which makes reliable timekeeping far more complicated. Devices such as quantum sensors and navigation systems, which rely on precise timing, will need internal clocks that use energy sparingly. Until now, the thermodynamic behavior of these systems has remained largely unknown. Investigating the Real Energy Cost of Time The researchers set out to determine the true thermodynamic burden of keeping time in the quantum realm and to separate how much of that cost is caused by the act of measurement. To explore this, they built a tiny clock that uses single electrons hopping between two nanoscale regions (known as a double quantum dot). Each hop serves as a clock-like tick. The team then monitored these ticks using two different techniques; one measured extremely small electric currents, while the other used radio waves to detect subtle changes in the system. In both approaches, the detectors convert quantum events (electron jumps) into classical information that can be recorded: a quantum-to-classical transition. A Billion-Fold Measurement Energy Surprise The team calculated the entropy (amount of energy dissipated) generated both by the clock itself (i.e., the double quantum dot) and by the measurement devices. They found that the energy required to read the quantum clock (i.e., to convert its tiny signals into something measurable) can be up to a billion times larger than the energy used by the clockwork. This result challenges the long-held belief that measurement costs in quantum physics are negligible. It also reveals something striking: observation introduces irreversibility, which is what gives time its forward direction.  This finding overturns the usual expectation that improving quantum clocks requires better quantum components. Instead, the researchers argue that future progress depends on designing measurement methods that gather information more efficiently. Rethinking Efficiency in Quantum Clock Design Lead author Professor Natalia Ares (Department of Engineering Science, University of Oxford) said: \"Quantum clocks running at the smallest scales were expected to lower the energy cost of timekeeping, but our new experiment reveals a surprising twist. Instead, in quantum clocks the quantum ticks far exceed that of the clockwork itself.\" According to the researchers, this imbalance might actually offer an advantage. The additional energy used during measurement can provide richer information about the clock's behavior, not only counting ticks but capturing every minor fluctuation. This could make it possible to build highly precise clocks that operate more efficiently. Co-author Vivek Wadhia (PhD student, Department of Engineering Science) said: \"Our results suggest that the entropy produced by the amplification and measurement of a clock's ticks, which has often been ignored in the literature, is the most important and fundamental thermodynamic cost of timekeeping at the quantum scale. The next step is to understand the principles governing efficiency in nanoscale devices so that we can design autonomous devices that compute and keep time far more efficiently, as nature does.\" Co-author Florian Meier (PhD student, Technische Universität Wien) said: \"Beyond quantum clocks, the research touches on deep questions in physics, including why time flows in one direction. By showing that it is the act of measuring -- not just the ticking itself -- that gives time its forward direction, these new findings draw a powerful connection between the physics of energy and the science of information.\" The study also involved researchers from TU Wien and Trinity College Dublin.", "release_time": "2025-11-18", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251117091138.htm"}
{"category": "政策计划", "title": "IAEA与圣裘德合作制定儿科放疗标准化课程", "short_summary": "国际机构联手制定儿科放疗标准化课程，旨在强化全球医疗队伍能力。", "detailed_summary": "国际机构联手制定儿科放疗标准化课程，旨在强化全球医疗队伍能力。\n（1）国际原子能机构（IAEA）与圣裘德儿童研究医院合作，召集近20名全球放疗专家召开为期一周的咨询会议。\n（2）会议核心目标是制定适用于儿科放射治疗专业人员的标准化教育课程，这是计划中的首个全球公共产品。\n（3）专家们明确了课程应侧重的核心能力、儿科放疗培训的最低要求以及使用先进技术的熟练度基准。\n（4）会议成果将直接用于新课程开发，经外部评审后作为IAEA出版物发布，以补充现有指南。\n（5）此举旨在加强全球知识库，培养训练有素的放射肿瘤学人才，为全球数百万癌症儿童提供解决方案。", "raw_content": "Developing Curricula for Paediatric Radiotherapy Professionals  As the first global good, the IAEA and St. Jude aim to create standardized educational curricula. Nearly 20 radiotherapy experts from across the globe, including from the Rays of Hope Anchor Centre in Argentina, joined specialists from both organizations for a week-long consultancy meeting to outline an effective framework for these curricula. By sharing their experience in treating paediatric cancer patients within their national and regional contexts, participants were able to clarify the core competencies these curricula should emphasize. They also articulated the minimum requirements for paediatric radiotherapy training, identified proficiency benchmarks for the use of advanced technologies and explored strategies to tailor curricula to learning-related needs at the local level.  Insights from their consultancy meeting will directly inform the new curricula. Following further external review, these curricula will be released as an IAEA publication and will supplement existing guidance.  “For the millions of children with cancer, these new curricula are part of the solution. In strengthening the global knowledge base, they will help to realise a well-trained radiation oncology workforce,” said May Abdel-Wahab, Director of the IAEA Division of Human Health. “Together with St. Jude, the IAEA will build on the forthcoming paediatric radiotherapy curricula by creating standardized education programmes as the next global public good.”", "release_time": "2025-11-19", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/strengthening-childhood-cancer-care-iaea-and-st-jude-begin-development-of-radiotherapy-curricula"}
{"category": "产业应用", "title": "雪佛龙考虑收购卢克石油重叠海外资产", "short_summary": "雪佛龙研究收购受制裁俄企卢克石油部分重叠海外资产方案。", "detailed_summary": "雪佛龙研究收购受制裁俄企卢克石油部分重叠海外资产方案。\n（1）雪佛龙公司正在研究收购受制裁的俄罗斯卢克石油公司海外资产的方案；\n（2）收购目标限定为两家公司业务有重叠的特定资产，而非卢克石油全部海外资产组合；\n（3）雪佛龙强调遵守相关法律和监管规定，并对商业事务不予评论。", "raw_content": "知情人士称，雪佛龙正在研究收购受制裁的俄罗斯石油企业卢克石油公司（Lukoil）海外资产的方案。    雪佛龙考虑收购两家公司业务有重叠的资产，而非卢克石油的全部海外资产组合。   雪佛龙表示，公司遵守适用于其业务的法律和监管规定，不对商业事务置评。", "release_time": "2025-11-18", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1196273-1.html"}
{"category": "产业应用", "title": "氢能材料试验六项团体标准通过立项评估", "short_summary": "氢能材料试验标准立项会召开，六项标准通过评估，推动产业规范化发展。", "detailed_summary": "氢能材料试验标准立项会召开，六项标准通过评估，推动产业规范化发展。\n（1）2025年11月6日，CSTM氢能材料试验标准化分技术委员会在上海应用物理研究所召开标准立项评审会。\n（2）会议采用线上线下结合方式，对《水和二氧化碳共电解反应固体氧化物单电解池电化学性能测试方法》等6项团体标准进行立项评估。\n（3）7位专家及20余名代表参会，专家组听取汇报并质询，最终六项标准一致通过立项。\n（4）标准覆盖电解水制氢关键材料与方法的测试，解决行业性能评价不统一、数据可比性差的问题。\n（5）标准制定将满足氢能产业急迫需求，为技术规范化、规模化发展提供坚实支撑。", "raw_content": "CSTM/FC98/TC10/SC01团体标准立项评估会成功召开                                    发布日期：2025/11/17  [ 大 中 小 ] [ 打印 ] [ 关闭 ]    2025年11月06日，中国材料与试验标准化委员会科学试验标准化领域委员会氢能材料试验标准化技术委员会电解水制氢材料试验标准化分技术委员会(CSTM/FC98/TC10/SC01)标准立项评审会在中国科学院上海应用物理研究所成功召开。会议采用线上线下相结合的方式进行，对《水和二氧化碳共电解反应  固体氧化物单电解池  电化学性能测试方法》等6项团体标准进行了立项评估（见表1）。会议由卓尚军研究员主持，来自中关村材料试验技术联盟、国家计量认证中科院评审组、中国科学院化学研究所、中国科学院理化技术研究所和中国科学院上海硅酸盐研究所的7位专家出席了会议。标准起草单位中关村材料试验技术联盟代表佟艳春主任以及电解水制氢材料试验标准化分技术委员会秘书处等20余人参加了此次立项评估。会上，专家组听取了起草单位对申报标准的情况汇报，包括标准制定的必要性和可行性，标准技术水平的先进性和创新性，标准前期技术准备工作，标准的应用前景以及工作组构成等方面。与会专家对标准的技术内容及与现有标准的关系进行了质询，并提出了意见和建议。最后，六项标准一致通过了立项评估，建议标准编制组参考会议提出的意见尽快修改，形成征求意见稿。此六项氢能材料试验标准的提出与制定，实现了对电解水制氢关键技术环节（从固体氧化物电解池、阴离子交换膜、膜电极、碱性隔膜等关键材料到重水分析、电极过程表征等先进方法）测试方法的全面覆盖，解决了行业内相关材料性能评价与表征方法不统一、数据可比性差的迫切问题，满足了氢能产业快速发展对材料试验标准化提出的急迫需求，将为推动我国氢能技术的规范化、规模化和高质量发展提供坚实的技术支撑。(能源材料与化学研究部  供稿)", "release_time": "2025-11-18", "source_institution": "上海应用物理研究所", "url": "http://www.sinap.cas.cn/xwzx/kydt/202511/t20251117_8012823.html"}
{"category": "研究前沿", "title": "东京大学研发出宽动态范围无标记显微镜", "short_summary": "新型显微镜可同时检测微纳尺度细胞活动，助力生命科学研究和药物开发。", "detailed_summary": "新型显微镜可同时检测微纳尺度细胞活动，助力生命科学研究和药物开发。\n（1）东京大学研究团队开发出新型显微镜，动态范围比标准仪器宽14倍；\n（2）技术结合定量相位显微镜和干涉散射显微镜优势，可同时采集前向和后向散射光；\n（3）实现无标记成像，细胞在长期观察中保持完好，适用于制药和生物技术领域；\n（4）成功分离微米级细胞结构和纳米级粒子信号，并能估算粒子尺寸和折射率；\n（5）未来将研究外泌体和病毒等更小粒子，探索细胞死亡动态过程。", "raw_content": "Researchers Kohki Horie, Keiichiro Toda, Takuma Nakamura, and Takuro Ideguchi at the University of Tokyo have created a microscope capable of detecting signals across an intensity range fourteen times broader than that of standard instruments. The system also works label-free, meaning it does not rely on added dyes. This gentle approach allows cells to remain unharmed during long-term imaging, which could benefit testing and quality control in pharmaceutical and biotechnology settings. The study appears in Nature Communications.  Microscopes have driven scientific progress since the 16th century, but major improvements have often required increasingly specialized tools. As techniques became more advanced, they also faced tradeoffs in what they could measure. Quantitative phase microscopy (QPM) uses forward-scattered light to visualize structures at the microscale (in this study, over 100 nanometers), which makes it useful for capturing still images of complex cell features. However, QPM cannot detect very small particles. Interferometric scattering (iSCAT) microscopy works differently by capturing back-scattered light and can detect structures as tiny as single proteins. While iSCAT enables researchers to \"track\" individual particles and observe rapid changes inside cells, it lacks the wider view offered by QPM. Capturing Two Directions of Light at Once \"I would like to understand dynamic processes inside living cells using non-invasive methods,\" says Horie, one of the first authors. Motivated by this goal, the team examined whether collecting light from both directions at the same time could bridge the gap and reveal activity across a broad range of sizes and motions in a single image. To explore the idea and confirm that their microscope performed as expected, they observed how cells behaved during cell death. In one experiment, they captured an image that contained information from both forward- and backward-traveling light. Separating Overlapping Signals \"Our biggest challenge,\" Toda, another first author, explains, \"was cleanly separating two kinds of signals from a single image while keeping noise low and avoiding mixing between them.\" The researchers succeeded in identifying the movement of larger cell structures (micro) as well as much smaller particles (nano). By comparing the patterns in forward- and back-scattered light, they could estimate each particle's size and its refractive index, which describes how strongly light bends or scatters when it passes through a material. Future Applications for Smaller Particles \"We plan to study even smaller particles,\" Toda says, already thinking about future research, \"such as exosomes and viruses, and to estimate their size and refractive index in different samples. We also want to reveal how living cells move toward death by controlling their state and double-checking our results with other techniques.\"", "release_time": "2025-11-18", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251117091134.htm"}
{"category": "研究前沿", "title": "科学家发现新型电子晶体与量子弹球相", "short_summary": "佛州立大学团队发现广义维格纳晶体及兼具绝缘与导电特性的量子弹球相。", "detailed_summary": "佛州立大学团队发现广义维格纳晶体及兼具绝缘与导电特性的量子弹球相。\n（1）佛州立大学物理学家团队确定了形成广义维格纳晶体的特定条件，该电子晶体可呈现条纹或蜂窝状等不同晶格形状。\n（2）研究过程中意外发现一种新的物质状态——量子弹球相，其中部分电子固定形成绝缘晶体，部分电子自由移动导电。\n（3）团队利用精确对角化、张量网络计算等先进计算工具模拟电子行为，验证了理论发现。\n（4）此项发现深化了对量子物质状态的理解，通过调控“量子旋钮”可实现物相转变。\n（5）研究成果有望推动量子计算、自旋电子学等未来量子技术的发展与创新。", "raw_content": "Electricity keeps modern life running, from cars and phones to computers and nearly every device we rely on. It works through the movement of electrons traveling through a circuit. Although these particles are far too small to see, the electric current they produce flows through wires in a way that resembles water moving through a pipe.  In some materials, however, this steady flow can suddenly lock into organized, crystal-like patterns. When electrons settle into these rigid arrangements, the material undergoes a shift in its state of matter and stops conducting electricity. Instead of acting like a metal, it behaves as an insulator. This unusual behavior provides scientists with valuable insight into how electrons interact and has opened the door to advances in quantum computing, high-performance superconductors used in energy and medical imaging, innovative lighting systems, and extremely precise atomic clocks. A group of physicists at Florida State University, including National High Magnetic Field Laboratory Dirac Postdoctoral Fellow Aman Kumar, Associate Professor Hitesh Changlani, and Assistant Professor Cyprian Lewandowski, has now identified the specific conditions that allow a special kind of electron crystal to form. In this state, electrons arrange themselves in a solid lattice yet can also shift into a more fluid form. This hybrid phase is called a generalized Wigner crystal, and the team's findings appear in npj Quantum Materials, a Nature publication. How Electron Crystals Form Scientists have long known that electrons in thin, two-dimensional materials can solidify into Wigner crystals, a concept first proposed in 1934. Experiments in recent years have detected these structures, but researchers had not fully understood how they arise once additional quantum effects are considered. \"In our study, we determined which 'quantum knobs' to turn to trigger this phase transition and achieve a generalized Wigner crystal, which uses a 2D moiré system and allows different crystalline shapes to form, like stripes or honeycomb crystals, unlike traditional Wigner crystals that only show a triangular lattice crystal,\" Changlani said. To explore these conditions, the team relied on advanced computational tools at FSU's Research Computing Center, an academic service unit of Information Technology Services, as well as the National Science Foundation's ACCESS program (an advanced computing and data resource under the Office of Advanced Cyberinfrastructure). They used methods such as exact diagonalization, density matrix renormalization group, and Monte Carlo simulations to test how electrons behave under various scenarios.  Processing Enormous Amounts of Quantum Data Quantum mechanics assigns two pieces of information to every electron, and when hundreds or thousands of electrons interact, the total amount of data becomes extremely large. The researchers used sophisticated algorithms to compress and organize this overwhelming information into networks that could be examined and interpreted. \"We're able to mimic experimental findings via our theoretical understanding of the state of matter,\" Kumar said. \"We conduct precise theoretical calculations using state-of-the-art tensor network calculations and exact diagonalization, a powerful numerical technique used in physics to collect details about a quantum Hamiltonian, which represents the total quantum energy in a system. Through this, we can provide a picture for how the crystal states came about and why they're favored in comparison to other energetically competitive states.\" A New Hybrid: The Quantum Pinball Phase While studying the generalized Wigner crystal, the team uncovered another surprising state of matter. In this newly identified phase, electrons show both insulating and conducting behavior at the same time. Some electrons remain anchored in place within the crystal lattice, while others break free and move throughout the material. Their motion resembles a pinball ricocheting between stationary posts. \"This pinball phase is a very exciting phase of matter that we observed while researching the generalized Wigner crystal,\" Lewandowski said. \"Some electrons want to freeze and others want to float around, which means that some are insulating and some are conducting electricity. This is the first time this unique quantum mechanical effect has been observed and reported for the electron density we studied in our work.\" Why These Discoveries Matter  These results expand scientists' ability to understand and control how matter behaves at the quantum level. \"What causes something to be insulating, conducting or magnetic? Can we transmute something into a different state?\" Lewandowski said. \"We're looking to predict where certain phases of matter exist and how one state can transition to another -- when you think of turning a liquid into gas, you picture turning up a heat knob to get water to boil into steam. Here, it turns out there are other quantum knobs we can play with to manipulate states of matter, which can lead to impressive advances in experimental research.\" By adjusting these quantum knobs, or energy scales, researchers can push electrons from solid to liquid phases within these materials. Understanding Wigner crystals and their related states may shape the future of quantum technologies, including quantum computing and spintronics -- a rapidly evolving area of condensed-matter physics that promises faster, more efficient nano-electronic devices with lower energy use and reduced manufacturing costs. The team aims to further explore how electrons cooperate and influence one another in complex systems. Their goal is to address fundamental questions that could ultimately drive innovations in quantum, superconducting, and atomic technologies.", "release_time": "2025-11-18", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251116105625.htm"}
{"category": "研究前沿", "title": "美F-22与MQ-20无人机成功演示有人-无人协同作战", "short_summary": "F-22指挥MQ-20无人机完成编队飞行测试，验证新型无线电数据链与开放任务系统。", "detailed_summary": "F-22指挥MQ-20无人机完成编队飞行测试，验证新型无线电数据链与开放任务系统。\n(1) 2025年10月21日，通用原子、洛克希德·马丁和L3Harris公司联合完成F-22与MQ-20复仇者无人机协同飞行测试。\n(2) 测试成功演示了有人-无人编队技术，F-22通过新型软件定义无线电和数据链实现对无人机的指挥控制。\n(3) 关键技术包括L3Harris的BANSHEE战术数据链、Pantera软件定义无线电和洛克希德·马丁的开放无线电架构。\n(4) 测试在内华达试验训练场进行，展示了非专有、美国政府拥有的通信能力及开放任务系统的互操作性。\n(5) 此次演示是系列测试的一部分，旨在探索有人与无人平台协同作战的潜力，推动基于技能的无人自主生态系统发展。", "raw_content": "Flight Features F-22 and MQ-20 Avenger® UAS with Pantera and Banshee Radios SAN DIEGO – 17 November 2025 – On October 21, 2025, General Atomics Aeronautical Systems, Inc. (GA-ASI), Lockheed Martin, and L3Harris Technologies (NYSE:LHX) collaborated on a flight test that successfully demonstrated Crewed-Uncrewed Teaming using an F-22 Raptor fighter jet and a GA-ASI MQ-20 Avenger® unmanned jet. The effort integrated L3Harris’ BANSHEE™ Advanced Tactical Datalinks with its Pantera software-defined radios (SDRs) via Lockheed Martin’s open radio architectures, all integrated and shared from an F-22 Raptor. Two L3Harris Software‑Defined Radios (SDRs) supported the demonstration. The first SDR was installed into the General Atomics MQ‑20 Avenger, and the second was integrated in the Lockheed Martin F‑22 Raptor. Through the Pilot Vehicle Interface (PVI) tablet and the F‑22’s GRACE module, the system provided end‑to‑end communications, enabling the F‑22 command and control of the MQ‑20 in flight. The collaborative demonstration showcased non-proprietary, U.S. government-owned communications capabilities and the ability to fly, transition, and re-fly flight hardware that is core to the Open Mission Systems and skills based unmanned autonomy ecosystem. The demonstration took place at the Nevada Test and Training Range and is part of an ongoing series of flight demonstrations performed using internal research and development funding to showcase “the art of the possible” between manned and unmanned teaming. About GA-ASI General Atomics Aeronautical Systems, Inc., is the world’s foremost builder of Unmanned Aircraft Systems (UAS). Logging more than 9 million flight hours, the Predator® line of UAS has flown for over 30 years and includes MQ-9A Reaper®, MQ-1C Gray Eagle®, MQ-20 Avenger®, and MQ-9B SkyGuardian®/SeaGuardian®. The company is dedicated to providing long-endurance, multi-mission solutions that deliver persistent situational awareness and rapid strike. For more information, visit www.ga-asi.com      Avenger, EagleEye, Gray Eagle, Lynx, Predator, Reaper, SeaGuardian, and SkyGuardian are trademarks of General Atomics Aeronautical Systems, Inc. registered in the United States and/or other countries.", "release_time": "2025-11-18", "source_institution": "通用原子能公司", "url": "http://www.ga.com/ga-asi-lockheed-martin-and-l3harris-collaborate-on-crewed-uncrewed-teaming-flight-test"}
{"category": "研究前沿", "title": "广州能源所举办“新能源·新青年”学术交流会", "short_summary": "广州能源所举办研究生学术交流会，26名学子展示新能源研究成果。", "detailed_summary": "广州能源所举办研究生学术交流会，26名学子展示新能源研究成果。\n（1）11月11日，中国科学院广州能源研究所举办“新能源·新青年”研究生学术交流会；\n（2）孙永明副所长致辞强调学术平台对学风建设和学科交叉的重要性；\n（3）来自多所高校的专家担任评委，14名博士和12名硕士进行口头报告；\n（4）会议设置墙报展示环节，促进师生深入交流；\n（5）宋达、郑桐君分获博士组和硕士组口头报告一等奖；\n（6）活动由所青促会支持，为研究生提供高水平学术交流平台。", "raw_content": "11月11日，为加强研究生的学术素养，传承研究所优良的科研学风，中国科学院广州能源研究所（中国科学技术大学能源科学与技术学院）举办“新能源．新青年”研究生学术交流会。中国科学技术大学特任教授李满、王其梁，华南农业大学魏国强副教授，华南师范大学特聘副研究员何嘉荣特，中山大学王立国副教授及广州能源所李德念、汪小憨研究员、杜晓蕊副研究员等担任评委，广州能源所副所长、所学位评定委员会委员孙永明研究员出席并致辞。孙永明在致辞中指出，“湾区讲坛”“青促会开讲啦”“研究生学术交流会”是研究所三个重要的学术交流平台，为研究所营造了积极良好的学风和学术交流氛围，对增进多学科交叉、推动学术交流与建设具有十分重要的意义。他希望同学们赓续优良传统，切实增强科技创新青年后备军的使命感责任感，争取在新能源与可再生能源领域做出自身的贡献。14名博士研究生和12名硕士研究生就各自的研究工作进行了深入细致的报告，通过丰富的数据和详实的案例，展示了研究成果和创新点。报告涵盖了能源领域的多个研究方向，内容新颖、观点独到，体现了报告人扎实的学术功底和勇于探索、敢于创新的科研精神。会议期间，墙报展示吸引了大量师生的关注。墙报以图文并茂的形式生动地展示了研究成果，并详细介绍了研究背景、研究方法、实验结果和结论等关键信息。与会人员驻足观看，并与墙报作者进行了深入交流和探讨，现场气氛热烈。最终，新兴固废高值循环研究中心2024级博士研究生宋达获得口头报告博士组一等奖，海上能源研究中心2023级硕士研究生郑桐君获得硕士组一等奖。此次学术交流会得到广州能源所青年创新促进会小组的支持，为研究生搭建了深层次、高水平的学术交流平台，提供了展示自我、共同进步的机会，也展示了研究生们在新能源与可再生能源领域的最新研究成果，促进在全所范围内营造浓厚的学术氛围。活动现场", "release_time": "2025-11-18", "source_institution": "广州能源研究所", "url": "http://www.giec.cas.cn/xshd2016/202511/t20251117_8012824.html"}
{"category": "研究前沿", "title": "科学家首次在室温高压下发现第21种冰相", "short_summary": "韩国团队利用超快压缩技术，在室温下观测到水反复相变并发现新型冰晶体Ice XXI。", "detailed_summary": "韩国团队利用超快压缩技术，在室温下观测到水反复相变并发现新型冰晶体Ice XXI。\n（1）韩国标准科学研究院首次在2吉帕以上高压、室温条件下观测到水微秒级快速冻结融化现象；\n（2）实验使用自主研发的动态金刚石压砧技术，将压缩时间缩短至10毫秒以避免提前结晶；\n（3）通过欧洲XFEL激光设施精准捕捉结晶过程，发现第21种冰晶体Ice XXI并解析其扁平矩形结构；\n（4）Ice XXI密度与木星土星冰卫星内部高压冰层相近，为地外生命探索提供新线索；\n（5）该研究由多国团队合作完成，成果发表于《自然·材料》期刊，推动高压物理与行星科学发展。", "raw_content": "The Korea Research Institute of Standards and Science (KRISS, President Lee Ho Seong) has captured the first-ever observation of water repeatedly freezing and melting at ultrahigh pressures above 2 gigapascals (2 GPa) while remaining at room temperature. These rapid changes were recorded on a microsecond (μs, one-millionth of a second) timescale.  This achievement led to the identification of a completely new crystallization pathway for water and the discovery of a previously unknown ice phase. The newly recognized structure has been named Ice XXI, making it the 21st crystalline form of ice. How High Pressure Creates New Forms of Ice Water typically turns into ice when its temperature drops below 0 °C, but pressure can also drive crystallization. Under the right pressure conditions, ice can form at room temperature or even at temperatures higher than its usual boiling point. For example, water compressed beyond 0.96 GPa at room temperature transforms into Ice VI. During freezing, the hydrogen-bonded network among water molecules becomes distorted and reorganized in complex ways. These shifts produce a wide range of ice structures depending on the surrounding pressure and temperature. A more detailed understanding of how these molecular rearrangements occur, and the ability to control them under extreme conditions, could pave the way for creating entirely new materials that do not exist naturally on Earth. A Century of Ice Research Reaches a New Milestone Over the past 100 years, scientists have identified 20 distinct crystalline ice phases* by adjusting pressure and temperature. These phases appear across a massive range of more than 2,000 K in temperature and over 100 GPa in pressure. The zone between ambient pressure (0 GPa) and 2 GPa is considered one of the most complex regions of water's phase diagram, where more than ten different ice phases cluster together.  The Space Metrology Group at KRISS managed to create a supercompressed liquid state in which water remained liquid at room temperature despite being pressurized to more than 2 GPa, which is over twice the pressure normally required for crystallization. This was made possible with a dynamic diamond anvil cell (dDAC**), a high-pressure instrument developed at KRISS. Conventional diamond anvil cells (DACs) increase pressure by tightening bolts, a process that often introduces pressure gradients and mechanical disturbances that trigger premature nucleation. The KRISS dDAC minimizes these issues by reducing mechanical shock and cutting the compression time from tens of seconds to only 10 milliseconds (ms). This allowed water to be pushed deeply into the Ice VI pressure range while remaining liquid. Capturing the Birth of a New Ice Phase In collaboration with international partners, KRISS scientists used the dDAC together with the European XFEL (the world's largest X-ray free-electron laser facility) to monitor the crystallization of supercompressed water with microsecond precision. These observations revealed complex, previously unseen crystallization pathways at room temperature. The transitions occurred through a new ice phase, Ice XXI, marking the first global identification of the 21st crystalline form of ice. The researchers also determined the detailed structure of Ice XXI and mapped the various pathways leading to its formation. Ice XXI shows an unusually large and intricate unit cell compared to other known phases. The crystal's geometry is a flattened rectangular lattice in which the two base edges are identical in length. A Large International Collaboration This discovery involved 33 researchers from South Korea, Germany, Japan, the USA, and England, along with scientists at the European XFEL and DESY. The project was proposed and led by KRISS under the direction of Dr. Lee Geun Woo, who served as principal investigator (PI).  The KRISS team included Dr. Kim Jin Kyun (co-first author, postdoctoral researcher at KRISS), Dr. Kim Yong-Jae (co-first author, formerly postdoctoral researcher at KRISS and now at Lawrence Livermore National Laboratory), Dr. Lee Yun-Hee (co-first author, Principal Research Scientist), Dr. Kim Minju (co-author, Postdoctoral Researcher), Dr. Cho Yong Chan (co-author, Principal Research Scientist), and Dr. Lee Geun Woo (corresponding author, Principal Research Scientist). They led the experimental design, data collection, and structural analysis that enabled the first identification of Ice XXI. Their work represents a major advancement for high-pressure physics and planetary science. Dr. Lee Yun-Hee said, \"The density of Ice XXI is comparable to the high-pressure ice layers inside the icy moons of Jupiter and Saturn. This discovery may provide new clues for exploring the origins of life under extreme conditions in space.\" Dr. Lee Geun Woo added, \"By combining our in-house developed dDAC technology with the XFEL, we were able to capture fleeting moments that had been inaccessible with conventional instruments. Continued research into ultrahigh-pressure and other extreme environments will open new frontiers in science.\" Notes * Previously, ice phases from Ice I to Ice XX had been reported. Ice I appears in two structural forms: the hexagonal Ice Ih and the cubic Ice Ic. ** The dDAC is a high-pressure device that uses a pair of diamonds and piezoelectric actuators to dynamically control and observe pressure changes in a microscopic water sample. This research was supported by the 4000 K-class Rocket Engine Ultra-High Temperature Materials and Measurement Technologies Development Project of the National Research Council of Science & Technology (NST). The results were published in Nature Materials (Impact Factor: 38.5) in October.", "release_time": "2025-11-17", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251115100051.htm"}
{"category": "研究前沿", "title": "南航研发漂浮式水滴发电机实现高效能量收集", "short_summary": "新型水滴发电机利用水体作电极，实现轻量化高效发电，可驱动LED等小型设备。", "detailed_summary": "新型水滴发电机利用水体作电极，实现轻量化高效发电，可驱动LED等小型设备。\n（1）南京航空航天大学团队开发漂浮式水滴发电机，以自然水体替代传统金属电极和固体基底；\n（2）该设计使设备重量降低约80%，成本减少50%，单滴水滴可产生250伏峰值电压；\n（3）利用水的不可压缩性和表面张力增强水滴铺展效果，离子导电特性确保电极稳定性；\n（4）系统在温差、盐度及自然湖水环境中保持耐用，通过排水孔设计防止积水干扰；\n（5）0.3平方米集成装置可同时点亮50个LED，未来可部署于湖泊海域实现无土地发电。", "raw_content": "Raindrops are more than a source of fresh water. They also carry mechanical energy that reaches the ground for free, and scientists have been exploring how to turn that energy into electricity for years. Traditional droplet electricity generators, however, often struggle with low efficiency, heavy components, and limited potential for scaling up. A research team from Nanjing University of Aeronautics and Astronautics has now developed a new solution: a floating droplet electricity generator that uses natural water as part of its structure. The result is a lighter, more affordable, and more sustainable way to collect clean energy. The work is described in National Science Review.  Most droplet electricity generators use a solid platform and a metal bottom electrode. When a raindrop hits the dielectric film on top, the impact produces an electrical signal. Although this approach can generate hundreds of volts, it relies on rigid, costly materials that limit widespread deployment. The new design takes a different approach by allowing the device to float on a water surface. In this setup, the water itself acts as the supporting base and also serves as the conductive electrode. This nature-integrated configuration cuts the device's weight by about 80 percent and lowers cost by about 50 percent while maintaining similar electrical output compared to conventional systems. How Water Improves Energy Generation When a raindrop lands on the floating dielectric film, the water beneath it provides the strength needed to absorb the impact because of its incompressibility and surface tension. This lets the droplet spread more effectively across the surface. At the same time, ions in the water act as charge carriers, allowing the water layer to operate as a dependable electrode. These combined effects enable the floating generator to deliver high peak voltages of around 250 volts per droplet, a performance level comparable to devices that rely on metal components and solid substrates. Durability is a major advantage of the new system. Tests showed that the W-DEG continued to function under a wide range of temperatures and salt levels, and even when exposed to natural lake water containing biofouling. Many energy-harvesting devices degrade in such environments, but this generator remained stable because its dielectric layer is chemically inert and its water-based structure is naturally resilient. To improve reliability further, the team used water's strong surface tension to design drainage holes that let water move downward but not upward. This creates a self-regulating way to remove excess droplets and helps prevent water buildup that could interfere with performance. Scalable Design for Large-Area Energy Collection Scalability is a promising aspect of this technology. The researchers created an integrated device measuring 0.3 square meters, which is much larger than most previous droplet generators, and demonstrated that it could power 50 light-emitting diodes (LEDs) at the same time. The system also charged capacitors to useful voltages within minutes, showing its potential for powering small electronics and wireless sensors. With continued development, similar systems could be deployed on lakes, reservoirs, or coastal waters, providing renewable electricity without using any land-based space.  \"By letting water itself play both structural and electrical roles, we've unlocked a new strategy for droplet electricity generation that is lightweight, cost-effective, and scalable,\" said Prof. Wanlin Guo, a corresponding author of the study. \"This opens the door to land-free hydrovoltaic systems that can complement other renewable technologies like solar and wind.\" Broader Applications and Future Possibilities The impact of this research goes beyond capturing energy from rainfall. Because the generator floats naturally on water, it could support environmental monitoring systems in diverse aquatic settings, including sensors for water quality, salinity, or pollution. In areas with frequent rain, the technology could offer a distributed source of clean power for local grids or act as a resource for off-grid needs. The \"nature-integrated design\" approach, which uses abundant natural materials like water as essential working components, may also inspire future advances in sustainable technology. Although the laboratory results are encouraging, the researchers emphasize that additional work is necessary before the technology can be deployed at large scales. Real raindrops vary in both size and speed, and these differences could influence power generation. Maintaining the durability of large dielectric films in dynamic outdoor conditions will also require further engineering. Even so, the successful demonstration of a stable, efficient, and scalable prototype represents an important step toward practical applications.", "release_time": "2025-11-17", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251114041228.htm"}
{"category": "研究前沿", "title": "MQ-9B无人机完成12万小时全尺寸疲劳测试", "short_summary": "通用原子MQ-9B完成第三寿命周期疲劳测试，累计达12万小时，验证机体结构完整性。", "detailed_summary": "通用原子MQ-9B完成第三寿命周期疲劳测试，累计达12万小时，验证机体结构完整性。\n(1)通用原子航空系统公司于2025年10月31日完成MQ-9B无人机的第三次全尺寸疲劳测试。\n(2)测试累计达12万小时，验证了机体结构完整性，是获得北约STANAG 4671标准认证的关键步骤。\n(3)测试在美国威奇托州立大学进行，旨在识别潜在结构缺陷并为制定检查维护计划提供依据。\n(4)MQ-9B是该公司最先进无人机型号，已获多国采购合同，包括英国、比利时、日本等。", "raw_content": "MQ-9B’s Third Lifetime Test Completes the FSF Testing Process With a Total of 120,000 Hours  DUBAI AIRSHOW – 17 November 2025 – On October 31, 2025, General Atomics Aeronautical Systems, Inc. (GA-ASI) completed its “third lifetime” of full-scale fatigue (FSF) testing for the MQ-9B Remotely Piloted Aircraft (RPA). Completion of FSF testing for the third and final lifetime includes a total of 120,000 operating hours (40,000+ flight hours per aircraft life) for the RPA and is a key milestone in validating the design of the airframe. The testing verifies the airframe structural integrity in support of certification to the NATO STANAG 4671 standard. The aim of the testing is to identify any potential structural deficiencies ahead of fleet usage and assist in developing inspection and maintenance schedules for the airframe. Test results will be used as documentation for certification and will form the basis for in-service inspections of structural components. “The completion of our full-scale fatigue test validates years of GA-ASI design and analysis efforts,” said GA-ASI President David R. Alexander. “The first two lifetimes simulated the operation of the aircraft under normal conditions, and the third intentionally inflicted damage to the airframe’s critical components to demonstrate its ability to tolerate operational damage that could occur over the lifetime of the aircraft.” Testing was conducted from December 13, 2022, through October 31, 2025, at Wichita State University’s National Institute for Aviation Research in Wichita, Kansas. The airframe tested was a production airframe purpose-built to support the test campaign. MQ-9B is GA-ASI’s most advanced RPA and includes the SkyGuardian® and SeaGuardian® models as well as the new Protector RG Mk1 that is currently being delivered to the United Kingdom’s Royal Air Force (RAF). In addition to the RAF, GA-ASI has MQ-9B procurement contracts with Belgium, Canada, Japan, Taiwan, Poland, India, Denmark, and the U.S. Air Force in support of the Special Operations Command. MQ-9B has also been featured in various U.S. Navy exercises, including Northern Edge, Integrated Battle Problem, RIMPAC, and Group Sail. About GA-ASI General Atomics Aeronautical Systems, Inc., is the world’s foremost builder of Unmanned Aircraft Systems (UAS). Logging more than 9 million flight hours, the Predator® line of UAS has flown for over 30 years and includes MQ-9A Reaper®, MQ-1C Gray Eagle®, MQ-20 Avenger®, and MQ-9B SkyGuardian®/SeaGuardian®. The company is dedicated to providing long-endurance, multi-mission solutions that deliver persistent situational awareness and rapid strike. For more information, visit www.ga-asi.com      Avenger, EagleEye, Gray Eagle, Lynx, Predator, Reaper, SeaGuardian, and SkyGuardian are trademarks of General Atomics Aeronautical Systems, Inc., registered in the United States and/or other countries.", "release_time": "2025-11-17", "source_institution": "通用原子能公司", "url": "http://www.ga.com/ga-asi-completes-full-scale-fatigue-test-on-mq-9b"}
{"category": "产业应用", "title": "通用原子YFQ-42A无人战斗机模型亮相迪拜航展", "short_summary": "GA-ASI在迪拜展示YFQ-42A全尺寸模型，该机具备半自主空战能力并计划快速量产。", "detailed_summary": "GA-ASI在迪拜展示YFQ-42A全尺寸模型，该机具备半自主空战能力并计划快速量产。\n（1）通用原子航空系统公司在迪拜航展展示YFQ-42A协同作战飞机全尺寸模型；\n（2）该无人战斗机专注于空对空半自主作战，设计用于快速大规模生产；\n（3）基于Gambit系列无人机衍生，可配合F-35等有人战机提升作战能力；\n（4）模型还将在2026年卡塔尔多哈DIMDEX和沙特利雅得世界防务展展出；\n（5）展示活动反映全球对协同作战飞机技术的高度关注和产业应用前景。", "raw_content": "Full-Size YFQ-42A CCA Model Anchors GA-ASI’s Dubai Stand Model Will Also Be Featured at Upcoming DIMDEX and World Defense Show  DUBAI AIRSHOW – 17 November 2025 – A full-size model of the YFQ-42A Collaborative Combat Aircraft (CCA) produced by General Atomics Aeronautical Systems, Inc. (GA-ASI) for the U.S. Air Force will be on display November 17−21 at the Dubai Airshow in stand #1280. The exciting new unmanned fighter jet has captured the attention of the global military aviation community as it continues through flight testing as part of an accelerated development schedule. The YFQ-42A is focused on air-to-air, semi-autonomous operations, and it’s being designed for rapid production, in large quantities, at an affordable price. “Global interest in CCA and our YFQ-42A is very high,” said GA-ASI President David R. Alexander. “We’re excited to have the aircraft and our overall CCA development effort on display at a major international industry event like the Dubai Airshow.” The YFQ-42A is a derivative of GA-ASI’s Gambit Series of unmanned combat air vehicles. Gambit is made up of multiple CCA variants that can be rapidly reconfigured from a common core, which enables substantial commonality for rapid and affordable production at scale. Based on the original Gambit 2 concept, the YFQ-42A is designed to complement human-crewed fighters like the F-35 and Next-Generation Air Dominance (NGAD) systems, expanding sensing, weapons capacity, and survivability in contested airspace. Following the Dubai Airshow, the CCA model will be featured at two other major regional events in early 2026: at DIMDEX January 19−22 in Doha, Qatar; and at the World Defense Show in Riyadh, Saudi Arabia, February 8−12. About GA-ASI General Atomics Aeronautical Systems, Inc., is the world’s foremost builder of Unmanned Aircraft Systems (UAS). Logging more than 9 million flight hours, the Predator® line of UAS has flown for over 30 years and includes MQ-9A Reaper®, MQ-1C Gray Eagle®, MQ-20 Avenger®, and MQ-9B SkyGuardian®/SeaGuardian®. The company is dedicated to providing long-endurance, multi-mission solutions that deliver persistent situational awareness and rapid strike. For more information, visit www.ga-asi.com      Avenger, EagleEye, Gray Eagle, Lynx, Predator, Reaper, SeaGuardian, and SkyGuardian are trademarks of General Atomics Aeronautical Systems, Inc., registered in the United States and/or other countries.", "release_time": "2025-11-17", "source_institution": "通用原子能公司", "url": "http://www.ga.com/ga-asi-showcases-collaborative-combat-aircraft-at-dubai-airshow"}
{"category": "产业应用", "title": "通用原子与萨博合作演示无人机预警系统", "short_summary": "两巨头为MQ-9B集成预警能力，2026年演示，提升持久监视与威胁防御。", "detailed_summary": "两巨头为MQ-9B集成预警能力，2026年演示，提升持久监视与威胁防御。\n（1）通用原子航空系统公司与萨博公司宣布合作，为MQ-9B无人机平台集成空中预警与控制系统能力。\n（2）计划于2026年夏季在加利福尼亚州沙漠地平线飞行操作设施进行演示验证。\n（3）将萨博的AEW传感器与长航时MQ-9B无人机结合，实现持久空中监视。\n（4）新能力可防御巡航导弹、无人机群等多种威胁，特别适用于缺乏或负担不起传统预警系统的区域。\n（5）作为无人平台，MQ-9B具有高作战可用性且无需机组人员冒险。", "raw_content": "Two Aerospace Leaders Are Bringing Airborne Early Warning and Control to UAS DUBAI AIRSHOW – 17 November 2025 – Following their announcement to bring Airborne Early Warning and Control (AEW&C) capability to the world’s leading Remotely Piloted Aircraft (RPA) platform, General Atomics Aeronautical Systems, Inc. (GA-ASI) and Saab will now team up to demonstrate the capability in the summer of 2026. The demo will be conducted at GA-ASI’s Desert Horizon flight operations facility in Southern California using a GA-ASI MQ-9B equipped with AEW&C supplied by Saab. In partnership with Saab, a leading company in AEW&C systems, GA-ASI is pairing Saab’s AEW sensors with the world’s longest-range, highest-endurance RPA, the MQ-9B. At sea or over land, adding AEW capabilities on MQ-9B enables persistent air surveillance and enables AEW in areas of the world where it doesn’t currently exist or is unaffordable, such as for navy aircraft carriers at sea. “Adding AEW&C to the MQ-9B brings a critical new capability to our platform,” said GA-ASI President David R. Alexander. “We want to deliver a persistent AEW&C solution to our global operators that will protect them against sophisticated cruise missiles as well as simple but dangerous drone swarms.” MQ-9B models include the SkyGuardian® and SeaGuardian®, the United Kingdom’s MQ-9B variant known as Protector, and the new MQ-9B STOL (Short Takeoff and Landing) configuration currently in development. The AEW solution for MQ-9B will offer critical aloft sensing to defend against tactical air munitions, guided missiles, drones, fighter and bomber aircraft, and other threats.  Operational availability for a medium-altitude, long-endurance UAS is the highest of any military aircraft, and as an unmanned platform, its aircrews are not put into harm’s way. GA-ASI and Saab’s AEW offering will span a wide range of applications, including early detection and warning; long-range detection and tracking; and simultaneous target tracking and flexible combat system integration — all over line-of-sight and SATCOM connectivity. About GA-ASI General Atomics Aeronautical Systems, Inc., is the world’s foremost builder of Unmanned Aircraft Systems (UAS). Logging more than 9 million flight hours, the Predator® line of UAS has flown for over 30 years and includes MQ-9A Reaper®, MQ-1C Gray Eagle®, MQ-20 Avenger®, and MQ-9B SkyGuardian®/SeaGuardian®. The company is dedicated to providing long-endurance, multi-mission solutions that deliver persistent situational awareness and rapid strike. For more information, visit www.ga-asi.com      Avenger, EagleEye, Gray Eagle, Lynx, Predator, Reaper, SeaGuardian, and SkyGuardian are trademarks of General Atomics Aeronautical Systems, Inc., registered in the United States and/or other countries.", "release_time": "2025-11-17", "source_institution": "通用原子能公司", "url": "http://www.ga.com/ga-asi-and-saab-will-demonstrate-aew-c-on-mq-9b-in-2026"}
{"category": "研究前沿", "title": "高超音速湍流研究获突破，验证Morkovin假说", "short_summary": "研究证实高超音速湍流行为与低速相似，有望简化未来超音速飞行器设计。", "detailed_summary": "研究证实高超音速湍流行为与低速相似，有望简化未来超音速飞行器设计。\n（1）高超音速飞行（如马赫10）可将悉尼至洛杉矶航程缩短至1小时，但极端速度下的湍流和热量是主要挑战；\n（2）Morkovin假说提出高超音速（马赫5-6）与低速湍流行为基本一致，但长期缺乏实验验证；\n（3）研究团队通过向风洞注入氪气并用激光电离，耗时11年首次在马赫6条件下直接观测湍流；\n（4）实验发现高超音速湍流行为与低速不可压缩流非常接近，支持假说；\n（5）验证假说可大幅简化高超音速飞行器设计计算，并有望变革太空进入方式。", "raw_content": "If it ever becomes achievable, hypersonic flight could dramatically reshape international travel. What currently requires an entire day could become a short trip lasting no more than a feature length movie. A route such as Sydney to Los Angeles, which now takes about 15 hours, might be reduced to only one hour.  \"It really shrinks the planet,\" says Professor Nicholaus Parziale, whose work centers on turning hypersonic travel from aspiration into reality. Parziale recently received the Presidential Early Career Award for Scientists and Engineers in recognition of his research into fluid mechanics at extreme speeds. \"It will make travel faster, easier and more enjoyable.\" The Challenges of Flying at Mach 10 Covering half the world in just one hour may seem impossible, yet the technology is not as far away as it appears. Some military aircraft already reach speeds of Mach 2 or Mach 3, which means two or three times the speed of sound. Mach 1 equals about 760 miles per hour. To travel from Los Angeles to Sydney in sixty minutes, an aircraft would need to reach Mach 10. The major obstacles are the extraordinary turbulence and heat produced during flight at these extreme speeds. There is a fundamental difference between how air behaves around an aircraft at lower speeds and how it behaves at higher speeds. Engineers describe these conditions as incompressible flow and compressible flow. In incompressible flow, which occurs at lower speeds (below about Mach 0.3 or 225 miles per hour), the density of the air stays nearly the same. This consistency simplifies aeronautical design. Once an aircraft moves faster than the speed of sound, the airflow becomes compressible instead. \"That's because a gas can 'squish,'\" Parziale explains, meaning it can compress. Why Airflow Behavior Matters for Hypersonic Design When air compresses, its density changes in response to variations in both pressure and temperature. These shifts influence how an aircraft interacts with the air around it. \"Compressibility affects how the airflow goes around the body and that can change things like lift, drag, and thrust required to take off or stay airborne.\" All of these factors play a major role in aircraft design.  Engineers already understand airflow fairly well for aircraft that fly below or near the speed of sound, a range called \"low Mach\" numbers. Creating hypersonic aircraft requires a much deeper understanding of how air behaves at Mach 5, Mach 6, or even Mach 10. Much of that behavior is still uncertain, except for guidance provided by Morkovin's hypothesis. Morkovin's Hypothesis and the Mystery of Hypersonic Turbulence Developed by Mark Morkovin in the mid 20th century, the hypothesis proposes that when air moves around Mach 5 or Mach 6, the fundamental nature of turbulence remains surprisingly similar to turbulence at lower speeds. Although high-speed airflow involves larger shifts in temperature and density, Morkovin suggested that the general pattern of turbulent motion stays mostly consistent. \"Basically, the Morkovin's hypothesis means that the way the turbulent air moves at low and high speeds isn't that different,\" Parziale says. \"If the hypothesis is correct, it means that we don't need a whole new way to understand turbulence at these higher speeds. We can use the same concepts we use for the slower flows.\" This also suggests that future hypersonic aircraft may not require a completely different design philosophy. Despite its importance, the hypothesis has lacked solid experimental validation. That gap led to Parziale's recent research, described in his study Hypersonic Turbulent Quantities in Support of Morkovin's Hypothesis, published in Nature Communications on November 12, 2025. A Laser and Krypton Experiment Eleven Years in the Making In the study, Parziale's team introduced krypton gas into a wind tunnel and used lasers to ionize it. This process briefly created a straight, glowing line formed by the krypton atoms. High-resolution cameras then captured how this illuminated line bent, twisted, and distorted as it moved through the airflow, similar to how a leaf drifts and spins within small swirling currents in a river.\"As that line moves with the gas, you can see crinkles and structure in the flow, and from that, we can learn a lot about turbulence,\" Parziale says. He notes that developing the experimental setup required 11 years of effort. \"And what we found was that at Mach 6, the turbulence behavior is pretty close to the incompressible flow.\" Parziale's group received early support from the Air Force Office of Scientific Research Young Investigator Research Program (YIP) in 2016 and from the Office of Naval Research (ONR) YIP in 2020, with the latest work also funded by ONR.  What the Findings Mean for Future Flight and Space Access While Morkovin's hypothesis is not yet completely proven, the new results move scientists closer to understanding how to design aircraft that can withstand hypersonic speeds. The findings indicate that engineers may not need to reinvent the fundamental approach to aircraft design for these extreme conditions, which simplifies the challenge significantly. \"Today, we must use computers to design an airplane, and the computational resources to design a plane that will fly at Mach 6, simulating all the tiny, fine, little details would be impossible,\" Parziale explains. \"The Morkovin's hypothesis allows us to make simplifying assumptions so that the computational demands to design hypersonic vehicles can become more doable.\" Parziale adds that the same principles could transform future access to space. \"If we can build planes that fly at hypersonic speed, we can also fly them into space, rather than launching rockets, which would make transportation to and from low Earth orbit easier,\" he says. \"It will be a game-changer for transportation not only on earth, but also in low orbit.\"", "release_time": "2025-11-17", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251114091854.htm"}
{"category": "研究前沿", "title": "暗物质行为研究新突破：遵循已知物理法则", "short_summary": "日内瓦大学研究显示暗物质运动符合欧拉方程，未排除微弱新相互作用可能性。", "detailed_summary": "日内瓦大学研究显示暗物质运动符合欧拉方程，未排除微弱新相互作用可能性。\n（1）日内瓦大学牵头研究暗物质是否遵循普通物质的四种基本力作用规则；\n（2）通过比较星系运动速度与宇宙引力阱深度分析暗物质行为；\n（3）研究发现暗物质落入引力阱的方式与普通物质一致，符合欧拉方程；\n（4）目前未能完全排除存在强度不超过重力7%的第五种力的可能性；\n（5）未来LSST和DESI等实验将探测弱至重力2%的新型相互作用。", "raw_content": "Does dark matter behave according to the same physical rules that apply to ordinary matter? This question remains one of the major puzzles in modern cosmology, since this invisible form of matter (which neither emits nor reflects any light) is still hypothetical and extremely difficult to study directly. Researchers from the University of Geneva (UNIGE) and collaborating institutions aimed to see whether dark matter follows familiar behavior on the largest scales, or whether other forces might influence it. Their study, published in Nature Communications, indicates that dark matter appears to act much like ordinary matter, although they cannot yet rule out the possibility of an additional, previously unknown interaction. Because dark matter is thought to be five times more common than ordinary matter, even a small new insight helps clarify its role in shaping the Universe.  Ordinary matter is affected by four known fundamental forces: gravity, electromagnetism, and the strong and weak forces within atoms. The question is whether dark matter responds to the same set of forces. While dark matter is invisible and difficult to detect, it may still follow these familiar laws or possibly be influenced by a fifth force that scientists have not yet identified. Investigating How Dark Matter Moves Through Gravitational Wells To explore this possibility, the UNIGE-led team examined whether dark matter sinks into gravitational wells the way ordinary matter does on cosmic scales. Massive objects distort the structure of space, forming these wells. Ordinary matter -- planets, stars and galaxies -- falls into them according to established physical principles that include Einstein's general relativity and Euler's equations. The team wanted to know whether dark matter behaves in the same predictable way. \"To answer this question, we compared the velocities of galaxies across the Universe with the depth of gravitational wells,\" explains Camille Bonvin, associate professor in the Department of Theoretical Physics at UNIGE's Faculty of Science and co-author of the study. \"If dark matter is not subject to a fifth force, then galaxies -- which are mostly made of dark matter -- will fall into these wells like ordinary matter, governed solely by gravity. On the other hand, if a fifth force acts on dark matter, it will influence the motion of galaxies, which would then fall into the wells differently. By comparing the depth of the wells with the galaxies' velocities, we can therefore test for the presence of such a force.\" Dark Matter Appears to Follow Euler's Equations Using this method on modern cosmological data, the researchers found that dark matter moves into gravitational wells in the same manner as ordinary matter, meaning it is consistent with Euler's equations. \"At this stage, however, these conclusions do not yet rule out the presence of an unknown force. But if such a fifth force exists, it cannot exceed 7% of the strength of gravity -- otherwise it would already have appeared in our analyses,\" says Nastassia Grimm first author of the study and former postdoctoral researcher at the Department of Theoretical Physics at UNIGE's Faculty of Science who has recently joined the Institute of Cosmology and Gravitation at the University of Portsmouth. What Comes Next in the Search for New Physics These early findings represent an important step in refining our understanding of dark matter. The next key objective is to determine whether a subtle fifth force truly affects it. \"Upcoming data from the newest experiments, such as LSST and DESI, will be sensitive to forces as weak as 2% of gravity. They should therefore allow us to learn even more about the behavior of dark matter,\" concludes Isaac Tutusaus, researcher at ICE-CSIC and IEEC and associate professor at IRAP, Midi-Pyrénées observatory, University of Toulouse, co-author of the study.", "release_time": "2025-11-17", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251115095924.htm"}
{"category": "产业应用", "title": "拉美风能潜力巨大，供应链建设成关键挑战", "short_summary": "报告预测拉美陆上风电将超120GW，但供应链瓶颈可能制约发展。", "detailed_summary": "报告预测拉美陆上风电将超120GW，但供应链瓶颈可能制约发展。\n（1）全球风能理事会报告预测拉丁美洲陆上风电容量2035年将超120GW，并安装首批海上风电；\n（2）当前供应链高度集中于巴西和墨西哥，存在政策不确定性、基础设施薄弱等八大挑战；\n（3）报告提出六大建议，包括加强监管确定性、改善基础设施和促进区域合作；\n（4）拉美拥有全球25%的清洁能源关键矿物，具备战略优势；\n（5）强化供应链对确保区域能源转型公平、快速至关重要，可推动拉美成为全球风能制造中心。", "raw_content": "14 November 2025, Belem, Brazil | Latin America could more than double its onshore wind capacity by 2035, surpassing 120 GW, and install its first gigawatts of offshore wind within the same decade, according to a new report from the Global Wind Energy Council. But this growth will only be possible if governments and industry strengthen the region’s fragmented supply chain, currently heavily concentrated in Brazil and Mexico, to meet rising demand across the continent.     Mission Critical: Building the LAC Wind Energy Supply Chain for a Clean and Just Energy Transition highlights that while Latin America and the Caribbean (LAC) have vast wind potential and an expanding pipeline of projects - 1GW is projected by end of 2032 for LAC,  6 GW OFW by 2035,  19,6 GW OFW by 2040, and reaching 40,6GW by 2045 - policy uncertainty, weak infrastructure and supply chain bottlenecks could prevent the region from realising its full opportunity in the global energy transition.    Download The Report     Ben Backwell, CEO of the Global Wind Energy Council, said: \"The growth of renewable energy is an energy transition success story - 92.5% of all new capacity additions in 2024 came from renewable sources. But this success must get bigger, and quickly.    The sector needs to achieve a 16.6% growth rate for the rest of this decade to reach the tripling goal set at COP28. Wind needs to step up. GWEC's new report details how the Latin America and Caribbean region can deliver on its potential by building a supply chain that will unlock the region's wind energy potential.    A strong supply chain can deliver long-term jobs and a local manufacturing base. Renewed ports and infrastructure can transform regional economies, and strong regional cooperation can be built on strategic integration with regional natural resources. Wind energy can be the driver of an energy transition that creates jobs, growth and security for all.\"    A Decisive Decade for Wind Energy in Latin America   With COP30 taking place in Belém, Brazil, the report comes at a pivotal moment for the region. Global leaders have committed to tripling renewable energy capacity by 2030, yet progress remains off track. Wind energy is a cornerstone of the clean energy transition, with 1,136 GW of installed capacity globally at the end of 2024, and on course to grow to 2,100 GW by 2030. But to stay aligned with climate goals, global installations must accelerate sharply and Latin America will play a crucial role in that.    GWEC’s analysis, developed with our project partner ERM, sets out that the LAC region’s onshore wind industry has established industrial bases in Brazil and Mexico, with complementary capabilities in Argentina and emerging markets in Chile and Colombia. However, the region remains dependent on imports for critical components such as gearboxes, and currently lacks local capacity for offshore assembly, specialized vessels, and transmission infrastructure.    A Call for Coordinated Action  The report highlights the key role regional cooperation, investment, and industrial strategy will play in unlocking this opportunity, especially for offshore wind. Building resilient local supply chains will not only secure energy independence and reduce import exposure but also create high-quality jobs and industrial value across the region.  Key Findings and Challenges  The report identifies eight key challenges hindering the region’s ability to scale wind power and industrial capacity, including:   Political volatility and instability in market demand are hindering the Latin American wind industry’s ability to adjust and scale its production capacity.     Transmission infrastructure limitations and the absence of flexible grid solutions.    Structural vulnerabilities, such as dependence on imports for key components and materials.    The development of the offshore segment remains incipient, with few projects at an advanced stage and several regulatory, financial and logistical barriers.    The current port and logistics infrastructure is insufficient to support large-scale offshore projects.     Latin America lacks specialized vessels and shipyard capacity to support offshore wind deployment.    The region faces a critical shortage of qualified professionals for offshore wind and limited local capacity for research, development, and manufacturing of complex components.    Over-reliance on Asian suppliers and lack of regional collaboration undermine local supply chain development and expose the region to geopolitical and price volatility risks.     There are opportunities for the LAC region in the global market as well, for example the region holds 25% of the world’s critical minerals needed for the clean energy transition, including copper, lithium, and rare earths, which give it a strategic advantage for industrial growth and technology integration.    Six Recommendations for Action   Build regulatory certainty to unlock wind energy and supply chain investment.  Strengthen transmission and port infrastructure to support the region’s energy transition  Accelerate local manufacturing and industrial development for wind energy supply chains  Implement financial mechanisms and tax incentives to reduce the cost of capital and make large scale projects viable Promote technology transfer and integration with strategic natural resources  Strengthen regional cooperation and energy integration to scale up the supply chain and build competitiveness    A Regional Vision for a Just Energy Transition  The report concludes that strengthening the LAC wind energy supply chain is mission critical for ensuring that the region’s clean energy transition is not only fast and secure, but also fair. Strategic investment in local industry could transform Latin America into a global hub for wind manufacturing — boosting resilience, lowering costs, and positioning the region as a leader in clean industrialization.", "release_time": "2025-11-17", "source_institution": "全球风能理事会", "url": "https://www.gwec.net/gwec-news/latin-america-must-strengthen-its-wind-energy-supply-chain-to-capture-a-once-in-a-generation-growth-opportunity-finds-new-gwec-report"}
{"category": "研究前沿", "title": "等离子体平衡重构不确定度研究获新进展", "short_summary": "研究量化托卡马克平衡计算不确定度，为聚变装置精准控制与物理分析提供关键支撑。", "detailed_summary": "研究量化托卡马克平衡计算不确定度，为聚变装置精准控制与物理分析提供关键支撑。\n(1) 等离子体所团队在托卡马克平衡重构不确定度量化研究方面取得重要进展，成果发表于《Nuclear Fusion》。\n(2) 研究构建了基于多项式混沌展开与拉丁超立方采样的不确定性评估框架，处理EAST实验输入参数。\n(3) 关键发现包括：等离子体芯部q剖面不确定度约2.17%，边界q剖面约4.32%；环向磁场在内/外侧中平面不确定度显著（31.09%/80.74%）。\n(4) 研究明确了各参数对平衡计算结果的影响程度，如等离子体形状不确定度受外中平面等位置影响约为1%-10%。\n(5) 该成果可识别误差来源，优化等离子体控制参数，提升聚变实验结果的准确性与鲁棒性。", "raw_content": "等离子体所在等离子体平衡重构不确定度研究方面取得新进展  2025-11-14 | 作者：文/袁舒智 图/袁舒智 |【大 中 小】【打印】【关闭】   近日，等离子体所刘海庆研究员团队在托卡马克平衡重构不确定度研究中取得新进展。该团队通过深入分析自由边界平衡求解中的不确定度传播，评估平衡重构结果不确定度以及平衡输入参数对计算结果分布的影响。相关成果以“The uncertainty quantification of the free boundary G-S plasma equilibrium calculation on Experimental Advanced Superconducting Tokamak (EAST)”为题发表于核聚变领域核心期刊《Nuclear Fusion》。等离子体平衡计算是托卡马克运行、物理分析的重要基础。等离子体约束、控制、稳态运行以及部分关键诊断系统数据处理都基于平衡的计算结果。其计算的各项参数的不确定度分布直接影响后续的物理、诊断数据处理以及实验分析。在等离子体平衡不确定性量化评估过程中，平衡求解器的输入参数采用了EAST实验数据。这些输入参数及其分布随后通过基于多项式混沌展开与拉丁超立方采样方法的编码器、解码器和分析器构成的不确定性评估框架进行处理。通过该不确定性量化评估可获得平衡输出量的不确定度及输出参数分布与对应输入分布的敏感性分析。研究表明，要获得精确的平衡重构结果，输入参数（如磁探针、纵场）必须控制在3%误差范围内。如果能够提供精确的内/外中平面位置，可计算更为精确的平衡。等离子体芯部区域q剖面计算受到纵场和初始输入等离子体电流的影响较大，不确定度约为2.17%；而等离子体边界q剖面则依赖于X点和外中平面的精确数据，其不确定度约为4.32%。等离子体形状不确定度主要受外中平面、打击点和X点位置影响，其不确定度范围根据位置不同约为1%-10%。环向磁场不确定性量化评估显示，存在两个不确定度显著的区域：内侧中平面（31.09%）与外侧中平面（80.74%），而其他区域（无论等离子体内部或外部）的环向磁场计算最大不确定度均低于1%。等离子体压强分布，受环向电流和X点Z坐标的影响，且二者的影响呈现此消彼长的形式。零维参数不确定度（如极向比压、等离子体体积等）主要源于外中平面位置，而环向比压则主要取决于环向电流的精确度。磁轴垂直方向误差源自打击点和X点的R坐标。通过分析等离子体平衡计算中的不确定度量级，可识别误差来源以支持后续诊断与物理分析，从而提升最终结果的准确性与鲁棒性。参数影响研究能为优化等离子体控制参数提供重要参考，助力搭建具有特定参数的等离子体放电实验平台。本论文由刘海庆研究员协助指导的博士生袁舒智为论文的第一作者。该研究受到国家磁约束核聚变能发展研究专项、ITER专项、安徽省重大科技专项项目等项目的资助。论文链接：https://doi.org/10.1088/1741-4326/ae1307  图2 安全因子q的不确定度量化（1）及敏感性指数分布（2）图3 磁轴压强不确定度分布（1）和敏感性指数分布（2）", "release_time": "2025-11-18", "source_institution": "等离子体物理研究所", "url": "http://www.ipp.ac.cn/xwdt/kydt/202511/t20251114_797549.html"}
{"category": "研究前沿", "title": "中德合作离子技术暑期学校促前沿科研交流", "short_summary": "中德暑期学校聚焦离子技术与精密测量，促进青年学者交流与合作。", "detailed_summary": "中德暑期学校聚焦离子技术与精密测量，促进青年学者交流与合作。\n（1）暑期学校由中科院与德国马普学会共同主办，于惠州举办，系中德合作50周年庆典活动之一；\n（2）汇聚中德25名国际学员和近60名国内学员，围绕离子技术、精密测量等八大前沿方向开展系列讲座；\n（3）学术活动包括系统课程、学员报告和海报展示，并举办公众科普讲座促进跨学科交流；\n（4）注重科学与文化融合，组织体育友谊赛、科研设施参观和博物馆访问等文体交流；\n（5）活动搭建了中德青年学者合作平台，为未来科研合作奠定基础，获多方资助支持。", "raw_content": "11月2日至12日，由中国科学院与德国马克斯-普朗克学会（以下简称“马普学会”）共同主办，中国科学院近代物理研究所承办的“冷却和储存离子技术—基础物理学精密测量前沿”暑期学校在惠州河桥园区成功举办。作为2025年中德合作五十周年庆典活动的重要成果之一，本次暑期学校汇聚了中德两国顶尖科研机构与高校的优秀学者和青年学子，围绕离子技术、精密测量等前沿领域展开深入交流，为中德科技合作与青年人才培养注入了新动力。本次暑期学校的举办，源于中国科学院院长与马普学会主席于柏林共同倡议的中德合作五十周年系列庆祝活动。暑期学校活动吸引了来自德国马普核物理研究所、亥姆赫兹重离子研究中心，科隆大学、达姆施塔特工业大学等机构的25名国际学员，以及中国科学院近代物理研究所、北京大学、复旦大学、中国科学技术大学，北京航天航空大学、香港大学、先进能源科学与技术广东实验室等国内单位的近60名优秀学员参与。授课团队由中德多家知名科研机构的顶尖学者组成，围绕基于潘宁阱中储存奇异离子的低能区标准模型精密检验、放射性核素高分辨率激光光谱学、基于储存环的原子与核物理等八大前沿方向开展了系统、深入的系列讲座。课程内容兼具基础性与前瞻性，系统介绍了相关领域的基础前沿理论与最新实验进展。此外，暑期学校还安排了6场学员报告和两次海报展示环节，有效促进了学员间的交流与互动。除了学术交流，暑期学校还注重科学与文化的融合。期间举办的公众科普讲座《用放射性氪识别古老的冰和水》，生动呈现了原子物理、核物理与地质科学的交叉魅力。讲座面向全体学员与惠州学院附属学校学生同时开放，为青少年打开了跨学科探索之窗。现场互动热烈，既点燃了大家的科学热情，更启迪了创新思维。此外，暑期学校还组织了丰富多彩的文体交流活动。体育友谊赛增进了学员间的团队凝聚力；实地参观大型科研设施让学员直观感受了中德科研的实力；博物馆参观则让学员领略了文化与科学的交融。本次暑期学校不仅让国际学员深入了解中国文化与科研环境，更搭建起中外青年学者深入交流的平台，为未来的科研合作奠定了良好的基础。本次暑期学校获得了中国科学院国际交流计划-优秀青年项目（2025PY0013）、德国马普学会和中国南方核科学理论研究中心的资助以及中国科学院国际合作局欧洲处、中国散裂中子源、中共惠州市委外事工作委员会办公室的大力支持。暑期学校网页链接：https://indico.impcas.ac.cn/e/SummerSchool图1： 暑期学校开幕式合影图2：授课现场图3： 活动集锦（人事人才处    供稿）", "release_time": "2025-11-14", "source_institution": "近代物理研究所", "url": "http://www.imp.cas.cn/sndt2017/202511/t20251114_8012202.html"}
{"category": "产业应用", "title": "混合融资可降本，亚太海上风电迎发展机遇", "short_summary": "报告称混合融资机制可使亚太海上风电项目资本成本减半，助力新兴市场规模化发展。", "detailed_summary": "报告称混合融资机制可使亚太海上风电项目资本成本减半，助力新兴市场规模化发展。\n（1）全球风能理事会报告指出，混合融资等创新金融工具对解锁亚太地区海上风电潜力至关重要。\n（2）报告以菲律宾和越南的500MW项目为模型，显示混合融资可将资本成本从约12%降至约6.5%。\n（3）成本降低使上网电价下降超三分之一，提升项目债务偿付能力与投资吸引力。\n（4）报告为政府、开发商、多边开发银行等多方提出具体建议，以构建可融资的政策与项目结构。\n（5）分析框架虽聚焦亚太，但为全球新兴经济体大规模海上风电项目提供了可复制的融资模式。", "raw_content": "14 November 2025, Belém, Brazil | Unlocking innovative finance tools is crucial to realizing offshore wind’s potential in Asia-Pacific markets, with blended finance potentially halving the cost of capital for offshore wind projects, according to a new report from the Global Wind Energy Council. The report details how concessional finance, guarantees, and other mechanisms available to be used by development institutions. Multilateral Development Banks and export credit agencies can play a pivotal role in unlocking local and international capital.     ‘Innovative Finance Mechanisms for Southeast Asia’s Offshore Wind Take-off: A Study on Unlocking Blended Finance’ looks at the particularly critical role blended finance plays for first-wave offshore wind projects in EMDEs, where investment in both generation and supporting infrastructure is needed. The report identifies key challenges and opportunities to unlock blended finance for offshore wind (OFW) in the Asia-Pacific (APAC) region, with a particular focus on the Philippines and Vietnam. While the findings are regionally focused, they provide a globally applicable framework for financing large-scale offshore wind projects in emerging economies.    Rebecca Williams, Deputy CEO of the Global Wind Energy Council, said: “GWEC numbers show that offshore wind in the APAC region is on the verge of booming. Offshore wind will play a key role in powering fast growing emerging economies like the Philippines and Vietnam.     “Our analysis shows that when projects are commercially viable and risks are effectively managed, both domestic and international capital are ready to flow But central to this effort will be reducing the cost of capital By combining strong policy frameworks with credible developers and robust financial structures, offshore wind is a highly attractive and scalable investment in emerging markets. That means project pipelines and turbines in the water, which in turn realizes the benefits of clean, affordable and secure renewable energy for homes, businesses and industries in these markets.     “Offshore wind already delivers 83 GW of clean and secure renewable energy, equivalent to powering 73 million homes. As we enter the ‘Age of Electricity’, this next wave of offshore wind markets must be supported as they drive their continued economic growth with their own energy resources. The shared benefits of electrification built on local supply and energy security will be wide-ranging and have deep benefits across the APAC region.”    The Report  GWEC’s analysis demonstrates that when offshore wind projects are bankable and risks are effectively mitigated and shared, both domestic and international capital can be mobilised. Where market or deal-level gaps exist, innovative instruments such as blended finance, guarantees, concessional loans, and mechanisms from DFIs, MDBs, and ECAs can play a pivotal role in bridging gaps and unlocking capital. wind deployment across the APAC region.     The report models a 500 MW offshore wind project and quantifies the impact of different financing structures in the Philippines and Vietnam. The results show that a fully blended capital stack — combining commercial debt, concessional loans, export credit guarantees, and grants — can deliver the most competitive outcomes.    By optimising the financing mix, the weighted average cost of capital (WACC) can almost halve in both countries - falling from 11.72% to 6.54% in the Philippines, and from 12.23% to 6.82% in Vietnam. This reduction enables tariffs to decrease by more than one-third, from 16.20 PHP/kWh (0.28 USD/kWh) to 10.50 PHP/kWh (0.18 USD/kWh) in the Philippines, and from 4,579.60 VND/kWh (0.17 USD/kWh) to 2,931.45 VND/kWh (0.11 USD/kWh) in Vietnam. At the same time, the Debt-Service Coverage Ratio (DSCR) improves, enhancing lender confidence and creating a model for affordable, investable, and scalable offshore wind in emerging markets.    The report makes a series of recommendations for key energy transition stakeholders:     Governments:     Create bankable offtake and pricing frameworks     Establish a Clear Offtake Framework: Define a transparent and bankable offtake mechanism that ensures revenue predictability for developers and financiers.     Formalize Revenue Frameworks through Viable PPAs :  Explore viable PPA mechanisms  to  help  provide revenue certainty.  This approach can help de-risk early-stage projects and crowd in private investment, particularly where market maturity or offtaker  ￼ creditworthiness is still evolving.     Consider Adopting Contracts for Difference (CfD): Consider implementing CfD models, as used in the UK and Poland, to stabilize electricity prices for off-takers and reduce revenue risk for developers and financiers, improving project bankability.     Update Frameworks as the Market Evolves: Regularly assess and update frameworks to adapt to external market conditions and technology changes.        Developers:     Collaborate to shape policy      Collaborate with policymakers to shape policies that realistically balances cost, risk and market needs.      Share project experience and appropriate data to inform tariff benchmarking and design of next-generation auction packages.     Innovate project structuring and partnerships     Develop consortium structures to pool expertise and diversify project risks among commercial and development partners.        DFIs/MDBs:    Provide concessional debt for first mover OFW projects     Analysis from research and the report’s capital stack modelling demonstrated that an essential form of support from DFIs/MDBs to unlock financing for OFW in the Philippines and Vietnam is the provision of concessional (below market) debt to enhance a project’s financial viability.    Even when DFIs/MDBs provide loans at market terms, their involvement remains highly valuable due to the “halo effect,” or other financial institutions interested in participating because of the due diligence and credibility provided by DFIs/MDBs.      Provide concessional funding for infrastructure      DFIs/MDBs should extend concessional funding to support essential OFW infrastructure, namely port and grid upgrades and development. This provides catalytic value, contributing to industry-wide impact beyond just one OFW project.     Expand technical assistance and capacity-building     DFIs/MDBs also have an opportunity to double down on the technical assistance they provide for macro-level gaps. This would further help governments utilize MDBs' technical assistance programs to guide policy development, PPA design, and analytical work. Conducting technical studies to help governments plan for new or upgraded infrastructure, such as ports and grids, is also valuable.      Multilateral Climate Funds:    Provide first loss capital and other concessional funding     Multilateral climate funds such as the Green Climate Fund, Global Environment Facility, and Climate Investment Funds should expand the use of blended finance instruments, such as grants, concessional funding, and first-loss capital, to catalyse investment in OFW as an important contributor to the growth of renewable energy. This can contribute to the availability of concessional capital deployed through DFIs/MDBs and other investment vehicles.        ECAs:    Provide credit guarantees as part of a consortium     ECAs should provide credit guarantees as part of a consortium to de-risk OFW projects and crowd in private capital at scale. Case studies from Taiwan’s Hai Long and Poland’s Baltic Power projects show that ECA-backed guarantees improve debt affordability and help maintain high debt service coverage ratios. By covering up to 90–95% of project risks, ECA consortia can enable longer loan tenors, reduce perceived country and commercial risks, and attract risk-averse lenders.     Facilitate cross-border partnerships     Support parent country exports of turbines, cables, and other supply chain components through ECA-backed loans and insurance, strengthening bilateral ties and technology transfer.", "release_time": "2025-11-17", "source_institution": "全球风能理事会", "url": "https://www.gwec.net/gwec-news/new-innovations-in-finance-can-half-the-cost-of-capital-for-offshore-wind"}
{"category": "研究前沿", "title": "新算法揭示丙烷制丙烯催化反应原子机理", "short_summary": "罗切斯特大学开发算法解析纳米催化剂原子行为，助力工业反应优化。", "detailed_summary": "罗切斯特大学开发算法解析纳米催化剂原子行为，助力工业反应优化。\n（1）研究针对丙烷制丙烯工业反应中纳米催化剂的多步串联机制原子行为不明确的问题；  \n（2）开发新型算法分析催化剂在金属相与氧化物相转换过程中的复杂原子特征；  \n（3）发现氧化物选择性围绕缺陷金属位点形成，这一行为对催化剂稳定性起关键作用；  \n（4）算法工具具普适性，可应用于甲醇合成等其他工业反应机理研究；  \n（5）突破有望减少传统试错法依赖，推动化工生产向高效精准方向转型。", "raw_content": "Many familiar items, from plastic squeeze bottles to outdoor furniture, rely on a process that converts propane into propylene. In 2021, a study in Science showed that chemists could use tandem nanoscale catalysts to merge several steps of this conversion into a single reaction -- an approach that increases yield and reduces costs. However, the underlying atomic activity remained unclear, which made it difficult to adapt this strategy to other important industrial reactions.  New Algorithms Reveal Hidden Atomic Behavior Researchers at the University of Rochester created algorithms capable of identifying the atomic features that control the complicated chemistry occurring as nanoscale catalysts transform propane into propylene. Their study, published in the Journal of the American Chemical Society, explores these detailed interactions, which are made even more complex because the materials involved shift between multiple states. \"There are so many different possibilities of what's happening at the catalytic active sites, so we need an algorithmic approach to very easily yet logically screen through the large amount of possibilities that exist and focus on the most important ones,\" says Siddharth Deshpande, an assistant professor in the Department of Chemical and Sustainability Engineering. \"We refined our algorithms and used them to do a very detailed analysis of the metallic phase and oxide phase driving this very complex reaction.\" Unexpected Oxide Behavior and Catalyst Stability Deshpande and his chemical engineering PhD student Snehitha Srirangam uncovered several unexpected patterns during their investigation. They found that the oxide in the reaction tended to form around defective metal sites in a highly selective way, a feature that played an essential role in stabilizing the catalyst. Even though the oxide can appear in various chemical compositions, it consistently remained positioned around the defective metal sites. Broader Potential for Industrial Chemistry According to Deshpande, these findings and the algorithmic tools used to obtain them can help researchers probe the atomic structure of other reactions, including methanol synthesis used in products that range from paints to fuel cells. Over time, he believes this insight could guide companies toward more efficient methods of producing propylene and other industrial materials while reducing their dependence on trial-and-error approaches that have dominated the field for decades. \"Our approach is very general and can open the doors to understand many of these processes that have remained an enigma for decades,\" says Deshpande. \"We know these processes work, and we produce tons of these chemicals, but we have much to learn about why exactly they're working.\"", "release_time": "2025-11-14", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251114041152.htm"}
{"category": "产业应用", "title": "凯雷集团拟购卢克石油海外资产", "short_summary": "美私募凯雷探讨收购受制裁俄油企海外资产，估值约220亿美元。", "detailed_summary": "美私募凯雷探讨收购受制裁俄油企海外资产，估值约220亿美元。\n（1）美国私募巨头凯雷集团正初步探讨收购俄罗斯卢克石油公司海外资产方案；\n（2）收购背景涉及美国对卢克石油的制裁，此前已阻止其向瑞士贸易商出售资产；\n（3）卢克石油海外资产石油产量占全球0.5%以上，估值约为220亿美元；\n（4）凯雷集团处于初步探索阶段，正考虑申请美国许可并可能启动尽职调查；\n（5）交易仍存不确定性，凯雷集团最终可能放弃收购计划。", "raw_content": "三位知情人士透露，美国私募巨头凯雷集团正探讨收购俄罗斯石油巨头卢克石油海外资产的相关方案。 作为推动克里姆林宫就乌克兰问题参与和平谈判的举措之一，美国已对卢克石油实施制裁，并在11月21日制裁截止日前，阻止了该公司向瑞士贸易商贡沃尔出售资产的计划。 卢克石油在国内外的石油产量约占全球总产量的2%。该公司表示，正为其国际资产寻找买家。根据2024年提交的文件，这些资产的石油产量占全球0.5%以上，估值约为220亿美元。 其中一位消息人士称，凯雷集团目前处于收购该资产的初步探索阶段。 该消息人士透露，凯雷集团正考虑申请美国相关许可，以获得收购资格，随后将启动尽职调查，同时补充称，该集团仍有可能决定放弃收购。 第二位消息人士表示，凯雷集团已向卢克石油告知其收购意向。", "release_time": "2025-11-14", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1196153-1.html"}
{"category": "产业应用", "title": "欧佩克预测石油市场转向过剩致油价大跌", "short_summary": "欧佩克报告预测2026年石油供应过剩，引发国际油价大幅下跌。", "detailed_summary": "欧佩克报告预测2026年石油供应过剩，引发国际油价大幅下跌。\n(1) 欧佩克最新月度报告预测，2026年全球石油市场将从供不应求转为小幅过剩，预计过剩量约2万桶/日。\n(2) 此预测与上月及9月报告的供应缺口预期形成鲜明对比，被市场解读为强烈看空信号。\n(3) 报告发布后，11月12日国际油价应声跳水，布伦特和WTI原油期货均暴跌超4%，创近期新低。\n(4) 市场分析认为投资者更看重欧佩克的判断，而非国际能源署的乐观预期。\n(5) 欧佩克+已决定12月按计划增产但明年一季度暂停，显示其预见过剩风险，未来油价前景不确定性增加。", "raw_content": "石油输出国组织(欧佩克)在最新发布的月度报告中出人意料地调整了市场预期，指出全球石油市场或在2026年从“供不应求”转向“小幅过剩”。 该报告显示，欧佩克预计2026年全球石油需求将达到1.065亿桶/日，而市场对欧佩克+的原油需求则为4300万桶/日。值得注意的是，欧佩克+在10月的整体产量已达4302万桶/日。这意味着，即便产油国联盟维持当前产量水平，市场也将出现约2万桶/日的供应过剩。 这一预测与欧佩克此前的判断形成鲜明对比。就在上个月的报告中，该机构还预计2026年将出现5万桶/日的供应缺口，而9月份的报告更是预测缺口高达70万桶/日。从“缺口”到“过剩”的急转弯，被市场解读为极其强烈的看空信号。 受此重磅消息冲击，11月12日国际原油期货价格应声跳水。布伦特原油期货主连价格日内一度暴跌近4%，跌至每桶62.57美元，创下近三周新低;美国WTI原油期货主联价格跌幅更甚，一度跌超4%，最低探至每桶58.30美元。 Price Futures Group高级分析师Phil Flynn评论称：“市场趋于平衡的预期无疑是导致油价下跌的原因。”他认为，相较于国际能源署(IEA)的乐观预期，市场显然更看重欧佩克的判断。尽管IEA早些时候表示全球油气需求可能持续增长至2050年，但油价的走势清晰地表明，投资者更相信欧佩克关于“明年略微过剩”的警告。 此番预测的转变并非毫无征兆。本月早些时候，欧佩克+8个主要产油国已决定，将在12月按计划增产，但随即在2026年第一季度暂停增产。此举当时就被分析人士解读为该组织已预见潜在的供应过剩风险。 展望未来，市场情绪依然脆弱。尽管有分析认为，全球经济若出现新的增长点，将有效提振原油需求，但短期内，欧佩克报告带来的悲观情绪已主导市场。油市供需格局的这一微妙转变，无疑为油价的前景蒙上了一层阴影，未来的走向将充满更多不确定性。", "release_time": "2025-11-14", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1196158-1.html"}
{"category": "研究前沿", "title": "光致原子晶格位移：新型二维材料特性研究获突破", "short_summary": "研究发现Janus二维材料在光照下会发生原子晶格位移，有望推动新型光电子芯片发展。", "detailed_summary": "研究发现Janus二维材料在光照下会发生原子晶格位移，有望推动新型光电子芯片发展。\n(1) 莱斯大学研究发现，一类名为Janus的二维过渡金属硫族化合物在光照下会发生物理性的原子晶格位移。\n(2) 这种光致伸缩效应源于材料上下原子层由不同化学元素构成的不对称结构，增强了层间耦合与光敏感性。\n(3) 研究人员通过二次谐波生成技术观测到激光照射导致材料对称性破缺，揭示了光对原子产生的微小作用力。\n(4) 该现象为实现光控材料行为提供了新途径，可应用于更快速、节能的光子芯片、高灵敏度传感器和量子光源等技术。", "raw_content": "Researchers at Rice University have found that certain atom-thin semiconductors, known as transition metal dichalcogenides (TMDs), can physically shift their atomic lattice when exposed to light. This newly observed response offers a controllable way to tune the behavior and properties of these ultrathin materials.  The phenomenon appears in a subtype of TMDs called Janus materials, named for the Roman god associated with transitions. Their light sensitivity could support future technologies that rely on optical signals instead of electrical currents, including faster and cooler computer chips, highly responsive sensors and flexible optoelectronic systems. \"In nonlinear optics, light can be reshaped to create new colors, faster pulses or optical switches that turn signals on and off,\" said Kunyan Zhang, a Rice doctoral alumna and first author of the study. \"Two-dimensional materials, which are only a few atoms thick, make it possible to build these optical tools on a very small scale.\" What Makes Janus Materials Different TMDs are built from stacked layers of a transition metal such as molybdenum and two layers of a chalcogen element like sulfur or selenium. Their blend of conductivity, strong light absorption and mechanical flexibility has made them key candidates for next-generation electronic and optical devices. Within this group, Janus materials stand apart because their top and bottom atomic layers are composed of different chemical elements, giving them an asymmetric structure. This imbalance produces a built-in electrical polarity and increases their sensitivity to light and external forces. \"Our work explores how the structure of Janus materials affects their optical behavior and how light itself can generate a force in the materials,\" Zhang said.  Detecting Atomic Motion With Laser Light To investigate this behavior, the team used laser beams of various colors on a two-layer Janus TMD material composed of molybdenum sulfur selenide stacked on molybdenum disulfide. They examined how it alters light through second harmonic generation (SHG), a process in which the material emits light at twice the frequency of the incoming beam. When the incoming laser matched the material's natural resonances, the usual SHG pattern became distorted, revealing that the atoms were shifting. \"We discovered that shining light on Janus molybdenum sulfur selenide and molybdenum disulfide creates tiny, directional forces inside the material, which show up as changes in its SHG pattern,\" Zhang said. \"Normally, the SHG signal forms a six-pointed 'flower' shape that mirrors the crystal's symmetry. But when light pushes on the atoms, this symmetry breaks -- the petals of the pattern shrink unevenly.\" Optostriction and Layer Coupling The researchers traced the SHG distortion to optostriction, a process in which the electromagnetic field of light applies a mechanical force on atoms. In Janus materials, the strong coupling between layers magnifies this effect, allowing even extremely small forces to produce measurable strain. \"Janus materials are ideal for this because their uneven composition creates an enhanced coupling between layers, which makes them more sensitive to light's tiny forces -- forces so small that it is difficult to measure directly, but we can detect them through changes in the SHG signal pattern,\" Zhang said.  Potential for Future Optical Technologies This high sensitivity suggests that Janus materials could become valuable components in a wide range of optical technologies. Devices that guide or control light using this mechanism may lead to faster, more energy-efficient photonic chips, since light-based circuits produce less heat than traditional electronics. Similar properties could be used to build finely tuned sensors that detect extremely small vibrations or pressure shifts, or to develop adjustable light sources for advanced displays and imaging systems. \"Such active control could help design next-generation photonic chips, ultrasensitive detectors or quantum light sources -- technologies that use light to carry and process information instead of relying on electricity,\" said Shengxi Huang, associate professor of electrical and computer engineering and materials science and nanoengineering at Rice and a corresponding author of the study. Huang is also affiliated with the Smalley-Curl Institute, the Rice Advanced Materials Institute and the Ken Kennedy Institute. Small Structural Imbalances With Big Impact By demonstrating how the internal asymmetry of Janus TMDs creates new ways to influence the flow of light, the study shows that tiny structural differences can unlock significant technological opportunities. The research was supported by the National Science Foundation (2246564, 1943895), the Air Force Office of Scientific Research (FA9550-22-1-0408), the Welch Foundation (C-2144), the U.S. Department of Energy (DE‐SC0020042, DE-AC02-05CH11231), the U.S. Air Force Office of Scientific Research (FA2386-24-1-4049) and the Taiwan Ministry of Education. The content of this article is solely the responsibility of the authors and does not necessarily represent the official views of funding organizations and institutions.", "release_time": "2025-11-17", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/11/251114041155.htm"}
{"category": "政策计划", "title": "印尼拟削减2026年煤炭产量目标至7亿吨以下", "short_summary": "印尼因出口收入下滑，拟将2026年煤炭产量目标调降至7亿吨以下。", "detailed_summary": "印尼因出口收入下滑，拟将2026年煤炭产量目标调降至7亿吨以下。\n（1）印尼能矿部在评估2026年工作计划时，发出削减煤炭产量目标的信号。\n（2）拟将2026年目标降至6亿至7亿吨之间，低于2025年的7.35亿吨目标。\n（3）调整源于2025年前9个月煤炭出口收入同比下降20.85%，对华出口降29.33%。\n（4）能矿部正评估企业提交的生产预算计划，并研究中国、印度等市场需求下降趋势。\n（5）此举旨在根据国内需求和出口疲软情况，重新平衡煤炭生产与市场实际。", "raw_content": "据“彭博技术”(Bloomberg Technoz)11月11日发布的消息，印度尼西亚能源和矿产资源部(ESDM)在讨论2026年工作计划和财务预算(RKAB)时发出信号，拟将煤炭产量目标削减至低于7亿吨，低于2025年的目标7.35亿吨。   能矿部煤炭和矿产总局(Dirjen Minerba)局长Tri Winarno表示，该部仍正在评估煤炭公司提交的2026年的年度煤炭生产和预算计划(RKAB)，并评估今年以来的煤炭生产和出口业绩。 然而，由于今年出口表现下滑，他发出信号称印度尼西亚2026年的煤炭生产目标将在6亿吨至7亿吨的范围内。 特里(Tri)在能源与矿产资源部周二(11月11日)的一次采访说道，“是的，我们会自动调整。我们目前正在开展评估。” 关于明年的煤炭产量目标，他坚定地说：“低于那个数值，可能低于7亿吨。” 印尼煤炭和矿产的开发计划与预算(RKAB)申请自2025年10月1日已经开始，计划于2025年11月15日截止。 上周五(11月7日)，能矿部副部长尤利奥特·坦龙(Yuliot Tanjung)表示，能矿部仍需要时间来确定2026年煤炭生产的目标和出口计划。 他对媒体说道，“我们将评估国内需求，看需要多少国内市场义务(DMO)供应量，以及剩余产量可以进行出口。” 尤利奥特继续说，“所以，我们先对由企业提交的RKAB进行评估。” 同时，他表示能矿部也正在研究来自印尼煤炭主要出口目的地市场如中国和印度的煤炭进口需求下降趋势。 2025年1月至9月期间，印尼煤炭出口收入同比下降了20.85%，降至179.4亿美元(约298.79万亿印尼盾)。去年同一时期的出口额为 226. 7 亿美元。其中，出口中国下降29.33%，降至68.6亿美元，出口印度下降25.42%，降至41.2亿美元。 与此同时的煤炭出口量(不含褐煤)为 2.8523亿吨，较去年同期的2.9941亿吨下降 4.74%。 为此，在煤炭出口减弱之际, 印尼政府需要重新考虑2026年煤炭企业RKAB 计划。", "release_time": "2025-11-13", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1196114-1.html"}
{"category": "政策计划", "title": "德国五贤人委员会下调2026年经济增长预期", "short_summary": "德智库下调2026年GDP增速至0.9%，呼吁政府高效利用特别基金以提振疲软经济。", "detailed_summary": "德智库下调2026年GDP增速至0.9%，呼吁政府高效利用特别基金以提振疲软经济。\n(1) 德国经济专家委员会（五贤人委员会）发布年度报告，将2026年GDP增长预期从1.0%下调至0.9%，远低于政府预期的1.3%。\n(2) 经济持续疲弱归因于全球格局变化、国内经济安全结构调整、工业竞争力下降及人口老龄化等多重压力。\n(3) 报告批评政府投资执行不力，呼吁更高效使用5000亿欧元\"基础设施与气候中立\"特别基金作为追加投资以促进经济。\n(4) 委员会内部对改革遗产税和赠与税存在分歧，有成员认为在当前私人投资疲弱背景下提高企业遗产税不合时宜。", "raw_content": "柏林11月12日电 德国经济专家委员会在12日发布的最新年度报告中，下调了对2026年德国国内生产总值(GDP)的增长预期。    报告预计，2026年德国经济难现明显复苏，增速仅为0.9%，较春季预测的1.0%略有下调。而联邦政府此前预计明年经济增长率为1.3%。 专家指出，经济持续疲弱的原因包括全球格局变化带来的外部压力、国内经济与安全结构调整、工业竞争力下降及人口老龄化等因素。 报告认为，尽管联邦政府通过增加投资和提升国防支出应对挑战，但投资执行“仍有明显改进空间”。若落实不力，可能削弱增长潜力并危及公共财政的可持续性。 专家委员会呼吁，政府应更高效地使用“基础设施与气候中立”特别基金(SVIK)。若这项总额达5000亿欧元的资金能真正作为常规预算之外的追加投资使用，将显著促进经济发展。但这一点在当前预算规划中尚未实现。 多数专家还建议改革遗产税和赠与税，包括对企业资产征收更高税率。然而，委员会成员维罗妮卡·格里姆认为，在当前私人投资意愿疲弱背景下，讨论提高企业遗产税“显得轻率”。 德国经济专家委员会是联邦政府最重要的智库之一，由政府推荐、总统任命的五名经济学家组成，也被称为“五贤人”委员会。他们定期发布经济报告，为德国政府制定经济政策提供参考。(完)", "release_time": "2025-11-13", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1196136-1.html"}
{"category": "研究前沿", "title": "量子网络连接距离突破2000公里，全球量子互联网现曙光", "short_summary": "芝加哥大学研究将量子相干时间提升百倍，实现理论2000公里量子连接。", "detailed_summary": "芝加哥大学研究将量子相干时间提升百倍，实现理论2000公里量子连接。\n（1）量子计算机长距离连接是构建大规模量子网络的主要障碍，此前仅限于几公里范围；\n（2）芝加哥大学团队通过分子束外延新方法制备稀土掺杂晶体，将铒原子量子相干时间从0.1毫秒提升至24毫秒；\n（3）理论计算显示该突破可使量子连接距离延伸至2000公里，为全球量子互联网奠定基础；\n（4）研究团队计划通过实验室内部多台稀释制冷器连接模拟长距离网络，验证实际应用可行性。", "raw_content": "Quantum computers can perform certain calculations at remarkable speeds, yet connecting them over long distances has been one of the major obstacles to building large, reliable quantum networks.  Until recently, two quantum computers could only link through a fiber cable over a span of a few kilometers. This limitation meant that a system on the University of Chicago's South Side campus could not communicate with one in the Willis Tower, even though both are located within the same city. The distance was simply too great for current technology. A new study published on November 6 in Nature Communications by University of Chicago Pritzker School of Molecular Engineering (UChicago PME) Asst. Prof. Tian Zhong suggests that this boundary can be pushed dramatically farther. His team's work indicates that quantum connections could, in theory, extend up to 2,000 km (1,243 miles). With this method, the UChicago quantum computer that once struggled to reach the Willis Tower could instead connect with a device located outside Salt Lake City, Utah. \"For the first time, the technology for building a global-scale quantum internet is within reach,\" said Zhong, who recently received the prestigious Sturge Prize for this research. Why Quantum Coherence Matters To create high-performance quantum networks, researchers must entangle atoms and maintain that entanglement as signals travel through fiber cables. The greater the coherence time of those entangled atoms, the farther apart the connected quantum computers can be.  In the new study, Zhong's team succeeded in raising the coherence time of individual erbium atoms from 0.1 milliseconds to more than 10 milliseconds. In one experiment, they achieved 24 milliseconds of coherence. Under ideal conditions, this improvement could enable communication between quantum computers separated by roughly 4,000 km, the distance between UChicago PME and Ocaña, Colombia. Building the Same Materials in a New Way The team did not switch to unfamiliar or exotic materials. Instead, they reimagined how the materials were constructed. They produced the rare-earth doped crystals required for quantum entanglement using a method called molecular-beam epitaxy (MBE) rather than the standard Czochralski method. \"The traditional way of making this material is by essentially a melting pot,\" Zhong said, referring to the Czochralski approach. \"You throw in the right ratio of ingredients and then melt everything. It goes above 2,000 degrees Celsius and is slowly cooled down to form a material crystal.\" Afterward, researchers carve the cooled crystal chemically to shape it into a usable component. Zhong likens this to a sculptor chiseling away at marble until the final form emerges. MBE relies on a very different idea. It resembles 3D printing, but at the atomic scale. The process lays down the crystal in extremely thin layers, eventually forming the exact structure needed for the device.  \"We start with nothing and then assemble this device atom by atom,\" Zhong said. \"The quality or purity of this material is so high that the quantum coherence properties of these atoms become superb.\" Although MBE has been used in other areas of materials science, it had not previously been applied to this type of rare-earth doped material. For this project, Zhong collaborated with materials synthesis specialist UChicago PME Asst. Prof. Shuolong Yang to adapt MBE to their needs. Institute of Photonic Sciences Prof. Dr. Hugues de Riedmatten, who was not part of the study, described the results as an important step forward. \"The approach demonstrated in this paper is highly innovative,\" he said. \"It shows that a bottom-up, well-controlled nanofabrication approach can lead to the realization of single rare-earth ion qubits with excellent optical and spin coherence properties, leading to a long-lived spin photon interface with emission at telecom wavelength, all in a fiber-compatible device architecture. This is a significant advance that offers an interesting scalable avenue for the production of many networkable qubits in a controlled fashion.\" Preparing for Real-World Tests The next phase of the project is to determine whether the improved coherence times can indeed support long-distance quantum communication outside of theoretical models. \"Before we actually deploy fiber from, let's say, Chicago to New York, we're going to test it just within my lab,\" Zhong said. The team plans to link two qubits housed in separate dilution refrigerators (\"fridges\") inside Zhong's laboratory using 1,000 kilometers of coiled fiber. This step will help them verify that the system behaves as expected before moving to larger scales. \"We're now building the third fridge in my lab. When it's all together, that will form a local network, and we will first do experiments locally in my lab to simulate what a future long-distance network will look like,\" Zhong said. \"This is all part of the grand goal of creating a true quantum internet, and we're achieving one more milestone towards that.\"", "release_time": "2025-11-13", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251112111019.htm"}
{"category": "研究前沿", "title": "无人机改变国际冲突规则的新研究", "short_summary": "新书揭示无人机降低军事行动成本，常被频繁使用但不易引发冲突升级。", "detailed_summary": "新书揭示无人机降低军事行动成本，常被频繁使用但不易引发冲突升级。\n(1) MIT政治学家林-格林伯格新书《远程革命》探讨无人机对现代国家间关系的影响。\n(2) 研究指出无人机行动成本低，常被用于危机局势，但被击落时不易引发军事升级。\n(3) 与有人战机入侵相比，无人机入侵引发的国际反应和外交后果通常较轻。\n(4) 研究方法结合兵棋推演实验、专家调查、历史案例研究和档案分析。\n(5) 书中也指出无人机存在\"道德风险\"，可能因成本低而鼓励更多军事对抗。", "raw_content": "In recent months, Russia has frequently flown drones into NATO territory, where NATO countries typically try to shoot them down. By contrast, when three Russian fighter jets made an incursion into Estonian airspace in September, they were intercepted and no attempt was made to shoot them down — although the incident did make headlines and led to a Russian diplomat being expelled from Estonia.Those incidents follow a global pattern of recent years. Drone operations, to this point, seem to provoke different responses compared to other kinds of military action, especially the use of piloted warplanes. Drone warfare is expanding but not necessarily provoking major military responses, either by the countries being attacked or by the aggressor countries that have drones shot down.“There was a conventional wisdom that drones were a slippery slope that would enable leaders to use force in all kinds of situations, with a massively destabilizing effect,” says MIT political scientist Erik Lin-Greenberg. “People thought if drones were used all over the place, this would lead to more escalation. But in many cases where drones are being used, we don’t see that escalation.”On the other hand, drones have made military action more pervasive. It is at least possible that in the future, drone-oriented combat will be both more common and more self-contained.“There is a revolutionary effect of these systems, in that countries are essentially increasing the range of situations in which leaders are willing to deploy military force,” Lin-Greenberg says. To this point, though, he adds, “these confrontations are not necessarily escalating.”Now Lin-Greenberg examines these dynamics in a new book, “The Remote Revolution: Drones and Modern Statecraft,” published by Cornell University Press. Lin-Greenberg is an associate professor in MIT’s Department of Political Science.Lin-Greenberg brings a distinctive professional background to the subject of drone warfare. Before returning to graduate school, he served as a U.S. Air Force officer; today he commands a U.S. Air Force reserve squadron. His thinking is informed by his experiences as both a scholar and practitioner.“The Remote Revolution” also has a distinctive methodology that draws on multiple ways of studying the topic. In writing the book, Lin-Greenberg conducted experiments based on war games played by national security professionals; conducted surveys of expert and public thinking about drones; developed in-depth case studies from history; and dug into archives broadly to fully understand the history of drone use, which in fact goes back several decades.The book’s focus is drone use during the 2000s, as the technology has become more readily available; today about 100 countries have access to military drones. Many have used them during tensions and skirmishes with other countries.“Where I argue this is actually revolutionary is during periods of crises, which fall below the threshold of war, in that these new technologies take human operators out of harm’s way and enable states to do things they wouldn’t otherwise do,” Lin-Greenberg says.Indeed, a key point is that drones lower the costs of military action for countries — and not just financial costs, but human and political costs, too. Incidents and problems that might plague leaders if they involved military personnel, forcing major responses, seem to lessen when drones are involved.“Because these systems don’t have a human on board, they’re inherently cheaper and different in the minds of decision-makers,” Lin-Greenberg says. “That means they’re willing to use these systems during disputes, and if other states are shooting them down, the side sending them is less likely to retaliate, because they’re losing a machine but not a man or woman on board.”In this sense, the uses of drones “create new rungs on the escalation ladder,” as Lin-Greenberg writes in the book. Drone incidents don’t necessarily lead to wider military action, and may not even lead to the same kinds of international relations issues as incidents involving piloted aircraft.Consider a counterfactual that Lin-Greenberg raises in the book. One of the most notorious episodes of Cold War tension between the U.S. and U.S.S.R. occurred in 1960, when U.S. pilot Gary Powers was shot down and captured in the Soviet Union, leading to a diplomatic standoff and a canceled summit between U.S. President Dwight Eisenhower and Soviet leader Nikita Khrushchev.“Had that been a drone, it’s very likely the summit would have continued,” Lin-Greenberg says. “No one would have said anything. The Soviet Union would have been embarrassed to admit their airspace was violated and the U.S. would have just [publicly] ignored what was going on, because there would not have been anyone sitting in a prison. There are a lot of exercises where you can ask how history could have been different.”None of this is to say that drones present straightforward solutions to international relations problems. They may present the appearance of low-cost military engagement, but as Lin-Greenberg underlines in the book, the effects are more complicated.“To be clear, the remote revolution does not suggest that drones prevent war,” Lin-Greenberg writes. Indeed, one of the problems they raise, he emphasizes, is the “moral hazard” that arises from leaders viewing drones as less costly, which can lead to even more military confrontations.Moreover, the trends in drone warfare so far yield predictions for the future that are “probabilistic rather than deterministic,” as Lin-Greenberg writes. Perhaps some political or military leaders will start to use drones to attack new targets that will inevitably generate major responses and quickly escalate into broad wars. Current trends do not guarantee future outcomes.“There are a lot of unanswered questions in this area,” Lin-Greenberg says. “So much is changing. What does it look like when more drones are more autonomous? I still hope this book lays a foundation for future dicussions, even as drones are used in different ways.”Other scholars have praised “The Remote Revolution.” Joshua Kertzer, a professor of international studies and government at Harvard University, has hailed Lin-Greenberg’s “rich expertise, methodological rigor, and creative insight,” while Michael Horowitz, a political scientist and professor of international relations at the University of Pennsylvania, has called it “an incredible book about the impact of drones on the international security environment.”For his part, Lin-Greenberg says, “My hope is the book will be read by academics and practitioners and people who choose to focus on parts of it they’re interested in. I tried to write the book in way that’s approachable.”Publication of the book was supported by funding from MIT’s Security Studies Program.", "release_time": "2025-11-13", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/how-drones-are-altering-contemporary-warfare-erik-lin-greenberg-book-1113"}
{"category": "研究前沿", "title": "植物根系微生物组机制与调控研究新进展", "short_summary": "Lebeis团队揭示植物招募根系微生物机制，探索微生物互作以提升农业与生物能源产出。", "detailed_summary": "Lebeis团队揭示植物招募根系微生物机制，探索微生物互作以提升农业与生物能源产出。\n(1) 研究发现植物利用肌醇糖类物质招募特定微生物定殖根系；\n(2) 探索微生物如何抵抗植物抗生素并在胁迫环境中助益植物生长；\n(3) 揭示微生物组内部复杂互作关系，解释微生物产品田间应用失效原因；\n(4) 采用机器学习分析植物-微生物互作，推动跨学科合作；\n(5) 研究目标为开发高效微生物产品，提升粮食与生物能源生产效率。", "raw_content": "In one recent study, her lab showed how plants use a type of sugar called myo-inositol to recruit certain microbes to colonize their roots. Lebeis also investigates how some root microbes survive in spite of antibiotic compounds that plants produce to protect themselves and how microbes interact with one another within the microbiome. “I’m a very glass-half-full microbe kind of girl,” Lebeis said. “So we think about how do microbes help plants in stressful conditions?” Understanding these mechanisms can help scientists develop better products to improve food productivity and bioenergy production. For example, it’s well known that certain microbes help plants, but microbial-based products aren’t always effective when applied in the field. “When you try to change the microbiome, it often doesn’t work,” Lebeis said. “A lot of what my lab is trying to figure out is why doesn’t it work? Why is the benefit lost?” The challenge is understanding such complex systems. “We can characterize how individual microbes interact with individual plants, knowing that that’s not what happens in nature,” Lebeis said. “Then ... we build up complexity.” Lebeis says GLBRC’s interdisciplinary structure is ideally suited to investigating these topics. She is especially interested in using machine learning — a type of artificial intelligence — to analyze the extremely complex plant-microbe interactions and to connect with scientists working on plant deconstruction. Lebeis, who currently leads the GLBRC’s bioenergy crop productivity and microbiome team, will take over Dec. 1 as one of the center’s science directors.", "release_time": "2025-11-18", "source_institution": "美国能源部大湖生物能源研究中心", "url": "https://www.glbrc.org/news/unraveling-mysteries-plant-microbiome"}
{"category": "研究前沿", "title": "纽约大学发现新型光子计算材料Gyromorphs", "short_summary": "科学家发现超越准晶体的各向同性带隙新材料，有望突破光子计算机发展瓶颈。", "detailed_summary": "科学家发现超越准晶体的各向同性带隙新材料，有望突破光子计算机发展瓶颈。\n（1）纽约大学团队发现名为\"gyromorphs\"的新型材料，其各向同性带隙性能优于现有所有结构；\n（2）该材料结合液体无序性和晶体规律性特征，能从全方向完全阻挡光信号穿透；\n（3）相比准晶体只能在有限方向完全阻光或全方向部分阻光的局限，新材料实现全面突破；\n（4）研究成果发表于《物理评论快报》，为光子计算机的光信号控制提供全新解决方案；\n（5）该发现通过算法设计具有相关无序性的超材料，有望推动高效光计算系统发展。", "raw_content": "Researchers are exploring a new generation of computers that operate using light, or photons, instead of electrical currents. Systems that rely on light to store and process information could one day run far more efficiently and complete calculations much faster than conventional machines.  Light-driven computing is still at an early stage, and one of the main technical obstacles involves controlling tiny streams of light traveling through a chip. Rerouting these microscopic signals without weakening them requires carefully engineered materials. To keep signals strong, the hardware must include a lightweight substance that prevents stray light from entering from any direction. This type of material is known as an \"isotropic bandgap material.\" Discovery of Gyromorphs at NYU Scientists at New York University have identified a new material called \"gyromorphs\" that meets this challenge more effectively than any other known structure. Gyromorphs combine features normally associated with liquids and crystals, yet they exceed both in their ability to block incoming light from all angles. The discovery, reported in Physical Review Letters, introduces a fresh strategy for tuning optical behavior and could help advance the development of photonic computers. \"Gyromorphs are unlike any known structure in that their unique makeup gives rise to better isotropic bandgap materials than is possible with current approaches,\" says Stefano Martiniani, an assistant professor of physics, chemistry, mathematics and neural science, and the senior author of the study. Why Existing Materials Fall Short For decades, researchers have looked to quasicrystals when designing isotropic bandgap materials. These structures, first proposed by physicists Paul Steinhardt and Dov Levine in the 1980s and later observed by Dan Schechtman, follow mathematical rules but do not repeat like traditional crystals.  Despite their promise, quasicrystals come with a trade-off noted by the NYU team. They may completely block light, but only from limited directions. Alternatively, they can weaken light from all directions but fail to fully stop it. This limitation has driven scientists to search for alternatives that can block signal-degrading light more comprehensively. Engineering New Metamaterials In their Physical Review Letters study, the NYU researchers created \"metamaterials,\" which are engineered structures whose properties depend on their architecture rather than on their chemical composition. One major challenge in designing these materials lies in understanding how their arrangement leads to desired physical behaviors. To overcome this, the team developed an algorithm capable of producing functional structures with built-in disorder. Their work revealed a new form of \"correlated disorder\" that sits between the fully ordered and fully random extremes. \"Think of trees in a forest -- they grow at random positions, but not completely random because they're usually a certain distance from one another,\" Martiniani explains. \"This new pattern, gyromorphs, combines properties that we believed to be incompatible and displays a function that outperforms all ordered alternatives, including quasicrystals.\" How Gyromorphs Achieve Their Unique Capabilities During their analysis, the scientists observed that every isotropic bandgap material exhibited a shared structural signature.  \"We wanted to make this structural signature as pronounced as possible,\" says Mathias Casiulis, a postdoctoral fellow in NYU's Department of Physics and the paper's lead author. \"The result was a new class of materials -- gyromorphs -- that reconcile seemingly incompatible features. \"This is because gyromorphs don't have a fixed, repeating structure like a crystal, which gives them a liquid-like disorder, but, at the same time, if you look at them from a distance they form regular patterns. These properties work together to create bandgaps that lightwaves can't penetrate from any direction.\" The research also included Aaron Shih, an NYU graduate student, and received support from the Simons Center for Computational Physical Chemistry (839534) and the Air Force Office of Scientific Research (FA9550-25-1-0359).", "release_time": "2025-11-13", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/11/251113071609.htm"}
{"category": "产业应用", "title": "全球太阳能与风能产业联手推动可持续供应链标准", "short_summary": "太阳能与风能理事会签署协议，共同制定供应链可持续性与透明度标准。", "detailed_summary": "太阳能与风能理事会签署协议，共同制定供应链可持续性与透明度标准。\n(1) 太阳能管理倡议(SSI)与全球风能理事会(GWEC)签署谅解备忘录，旨在推动太阳能和风能行业供应链的可持续性、透明度和韧性。\n(2) 合作将支持GWEC在其风能可持续发展倡议(WSI)框架内为风能行业制定可持续发展标准。\n(3) 双方致力于促进环境、社会和治理(ESG)实践及可追溯性的统一标准，同时认可行业特定需求。\n(4) 将通过知识交流，利用SSI已建立的ESG和可追溯性标准来支持风能行业构建自身的可持续性保障框架。\n(5) 通过吸纳行业代表、民间社会组织和金融机构，加强多利益相关方治理，加速全球可再生能源供应链采用负责任采购实践。", "raw_content": "13 November 2025, Brussels, Belgium | The Solar Stewardship Initiative (SSI) and the Global Wind Energy Council (GWEC) have signed a Memorandum of Understanding (MoU) to drive sustainability, transparency, and resilience across the solar and wind energy industries’ supply chains.As the world scales up the deployment of renewables to drive the energy transition and meet global climate goals, ensuring responsible sourcing and production of solar and wind components is critical. GWEC is actively working to establish a dedicated multistakeholder initiative for the wind sector called the Wind Sustainability Initiative (WSI), inspired by the SSI model, which will drive industry-wide ESG and traceability standards.As both sectors scale rapidly to meet global demand, it is essential that this growth does not compromise the ethical and environmental standards we stand for. This partnership will help align best practices, enable knowledge exchange, and drive coordinated action to uphold these standards demonstrating our collective commitment to responsible growth that supports project financing and allows developers and utilities to expand confidently, without facing future compliance or sanction risks. Objectives of the MoUUnder the terms of the agreement, the SSI and GWEC will work together to:    Support GWEC in the development of Sustainability Standards for the wind sector, within the WSI framework. Promote harmonised standards for environmental, social, and governance (ESG) practices and traceability across the solar and wind industries while recognising sector-specific needs. Facilitate knowledge exchange by leveraging the SSI’s established ESG and Traceability Standards to support the wind sector in the development of its own sustainability assurance framework. Strengthen multi-stakeholder governance by engaging key industry representatives, civil society organisations, and financial institutions. Accelerate the adoption of responsible sourcing practices across global renewable energy supply chains.", "release_time": "2025-11-14", "source_institution": "全球风能理事会", "url": "https://www.gwec.net/gwec-news/ssi-and-gwec-sign-partnership-to-strengthen-sustainability-and-transparency-in-renewables-supply-chains"}
{"category": "政策计划", "title": "中科院近代物理所专题学习党的二十届四中全会精神", "short_summary": "中科院近代物理所组织学习二十届四中全会精神，部署科技创新与“十五五”规划落实。", "detailed_summary": "中科院近代物理所组织学习二十届四中全会精神，部署科技创新与“十五五”规划落实。\n（1）中科院近代物理研究所党委理论学习中心组召开专题会议，深入学习党的二十届四中全会精神及相关文件；\n（2）会议重点学习全会公报、“十五五”规划建议及习近平总书记说明，传达中科院党组部署要求；\n（3）强调科技创新在中国式现代化中的核心地位，明确科技自立自强、发展新质生产力等目标；\n（4）研究所将强化原始创新和关键技术攻关，发挥国家战略科技主力军作用；\n（5）要求全所深入学习贯彻全会精神，凝练重大科技任务，助力高质量发展。", "raw_content": "10月31日，中国科学院近代物理研究所党委理论学习中心组召开专题会议，深入学习党的二十届四中全会精神和习近平总书记在党的二十届四中全会上的重要讲话精神等。所领导班子成员、党委委员参加学习研讨，党委书记、副所长胡正国主持学习。会上，党委书记胡正国领学了党的二十届四中全会公报、《中共中央关于制定国民经济和社会展第十五个五年规划的建议》和习近平总书记关于《中共中央关于制定国民经济和社会发展第十五个五年规划的建议》的说明，传达了中国科学院党组对全面学习贯彻落实党的二十届四中全会精神的安排和部署。副所长、党委委员王猛在重点发言时指出，党的二十届四中全会高度肯定了“十四五”期间取得的重大成就，也为“十五五”时期经济社会发展提出了原则要求和主要目标。全会将科技创新摆在中国式现代化全局的核心位置，明确提出“科技自立自强水平大幅提高”的目标。强调要加快高水平科技自立自强，引领发展新质生产力；要全面增强自主创新能力，抢占科技发展制高点，不断催生新质生产力。研究所要进一步强化原始创新和关键核心技术攻关，围绕“四个率先”和“两加快一努力”目标，发挥国家战略科技主力军作用，全力推进抢占制高点任务实施，努力产出关键性、原创性、引领性重大科技成果。与会人员一致认为，党的二十届四中全会是在推进中国式现代化建设的关键时期召开的一次极其重要的会议，是乘势而上、接续推进中国式现代化的一次总动员、总部署。《中共中央关于制定国民经济和社会发展第十五个五年规划的建议》准确把握“十五五”时期党和国家事业发展所处历史方位，描绘了新时代新征程进一步全面推进中国式现代化建设的宏伟蓝图，是党中央团结带领全党全国各族人民，以中国式现代化全面推进社会主义现代化强国建设和中华民族伟大复兴的政治宣言和行动纲领。胡正国在总结学习时强调，要把深入贯彻党的二十届四中全会精神和习近平总书记在全会上的重要讲话精神作为当前和今后一个时期的重大政治任务。要进一步提高站位、深化认识，加强组织领导，统筹抓好传达学习宣传及教育培训等各项工作，在全所范围内掀起学习贯彻全会精神的热潮。要紧密围绕“十五五”发展规划，持续凝练重大科技任务，强化基础研究和关键核心技术攻关。要注重学习成效，通过深入学习研讨，切实把思想和行动统一到党中央决策部署及院党组工作要求上来，把学习目标聚焦到加快抢占科技制高点任务上来，以学习成效助力研究所科技创新事业高质量发展。（党委办公室   供稿）", "release_time": "2025-11-12", "source_institution": "近代物理研究所", "url": "http://www.imp.cas.cn/sndt2017/202511/t20251112_8010358.html"}
{"category": "产业应用", "title": "COP30聚焦核技术驱动环境解决方案", "short_summary": "IAEA在COP30展示核科技助力清洁能源、生态监测与污染治理。", "detailed_summary": "IAEA在COP30展示核科技助力清洁能源、生态监测与污染治理。\n(1) IAEA在COP30气候大会展示核科学技术应对环境挑战的多种应用；\n(2) 核技术不仅提供可靠清洁能源，还用于监测和保护生态系统；\n(3) 具体案例包括巴西利用电子束技术进行工业废水处理；\n(4) 拉丁美洲国家采用核技术控制害虫、保障作物和食品出口；\n(5) 这些创新为农民、消费者和环境带来多重效益。", "raw_content": "As global leaders, international organizations, scientists, business representatives and climate activists convene in Belém for COP30, the IAEA is showcasing how nuclear science and technology are driving solutions to environmental challenges. Nuclear science not only provides the world with reliable clean energy, but also helps scientists monitor and protect ecosystems, enhance food security and reduce pollution.  At the IAEA Atoms4Climate Pavilion, visitors can see these innovations in action. In Brazil, for example, electron beam (e-beam) technology is transforming industrial wastewater treatment. In Latin America, countries are using nuclear techniques to control pests, safeguard crops and food exports — a win for farmers, consumers and the environment.", "release_time": "2025-11-13", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/six-ways-nuclear-science-and-technology-help-protect-the-environment"}
{"category": "研究前沿", "title": "Sharp基金应对科研资金危机，RNAi疗法彰显产学研协同价值", "short_summary": "MIT设立Sharp-Alnylam基金缓解科研资金压力，回顾RNAi技术从发现到商业化历程。", "detailed_summary": "MIT设立Sharp-Alnylam基金缓解科研资金压力，回顾RNAi技术从发现到商业化历程。\n（1）美国学术研究资金中断威胁科学人才 pipeline，MIT诺贝尔奖得主Phillip Sharp担忧其长期存在性影响；\n（2）Alnylam制药公司捐赠设立Phil Sharp-Alnylam基金，为生物学系研究生和教师提供灵活资金支持；\n（3）基金以前沿生命科学为重点，旨在帮助科研人员克服不确定性，持续从事科学事业；\n（4）回顾Sharp共同创立的Alnylam公司发展历程：基于1998年RNA干扰发现，16年后获得首款RNAi疗法批准；\n（5）强调基础研究与产业应用的长期共生关系，指出AI等新技术加速下产学研协同对医疗突破的关键作用。", "raw_content": "It’s no question that graduate school in fundamental research was never for the faint of heart, but academia’s nationwide funding disruptions threaten not just research happening now, but the critical pipeline for the next generation of scientists.“What’s keeping me up at night is the uncertainty,” says MIT Institute Professor and Nobel laureate Phillip A. Sharp, who is also professor of biology emeritus and intramural faculty at the Koch Institute for Integrative Cancer Research.In the short term, Sharp foresees challenges in sustaining students so they can complete their degrees, postdocs to finish their professional preparation, and faculty to set up and sustain their labs. In the long term, the impact becomes potentially existential — fewer people pursuing academia now means fewer advancements in the decades to come.So, when Sharp was looped into discussions about a gift in his honor, he knew exactly where it should be directed. Established this year thanks to a generous donation from Alnylam Pharmaceuticals, the Phil Sharp-Alnylam Fund for Emerging Scientists will support graduate students and faculty within life sciences.“This generosity by Alnylam provides an opportunity to bridge the uncertainty and ideally create the environment where students and others will feel that it’s possible to do science and have a career,” Sharp says. The fund is set up to be flexible, so the expendable gift can be used to address the evolving needs of the Department of Biology, including financial support, research grants, and seed funding. “This fund will help us fortify the department’s capacity to train new generations of life science innovators and leaders,” says department head Amy E. Keating, the Jay A. Stein (1968) Professor of Biology and professor of biological engineering. “It is a great privilege for the department to be part of this recognition of Phil’s key role at Alnylam.”Alnylam Pharmaceuticals, a company Sharp co-founded in 2002, is, in fact, a case study for the type of long-term investment in fundamental discovery that leads to paradigm-shifting strides in biomedical science, such as: What if the genetic drivers of diseases could be silenced by harnessing a naturally occurring gene regulation process?Good things take timeIn 1998, Andrew Fire PhD ’83, who was trained as a graduate student in the Sharp Lab at MIT, and Craig Mello published a paper showing that double-stranded RNA suppresses the expression of the protein from the gene that encodes its sequence. The process, known as RNA interference, was such a groundbreaking revelation that Fire and Mello shared a Nobel Prize in Medicine and Physiology less than a decade later. RNAi is an innate cellular gene regulation process that can, for example, assist cells in defending against viruses by degrading viral RNA, thereby interfering with the production of viral proteins. Taking advantage of this natural process to fine-tune the expression of genes that encode specific proteins was a promising option for disease treatment, as many diseases are caused by the creation or buildup of mutated or faulty proteins. This approach would address the root cause of the disease, rather than its downstream symptoms.The details of the biochemistry of RNAi were characterized and patented, and in 2002, Alnylam was founded by Sharp, David Bartel, Paul Schimmel PhD ’67, Thomas Tuschl, and Phillip Zamore SM ’86. “Sixteen years later, we got our first approval for a totally novel therapeutic agent to treat disease,” Sharp says. “Something in a research laboratory, translated in about as short a time as you can do, gave rise to this whole new way of treating critical diseases.” This timeline isn’t atypical. Particularly in health care, Sharp notes, investments often occur five or 10 years before they come to fruition. “Phil Sharp’s visionary idea of harnessing RNAi to treat disease brought brilliant people together to pioneer this new class of medicines. RNAi therapeutics would not exist without the bridge Phil built between academia and industry. Now there are six approved Alnylam-discovered RNAi therapeutics, and we are exploring potential treatments for a range of rare and prevalent diseases to improve the lives of many more patients in need,” says Kevin Fitzgerald, chief scientific officer of Alnylam Pharmaceuticals. Today, the company has grown to over 2,500 employees, markets its six approved treatments worldwide, and has a long list of research programs that are likely to yield new therapeutic agents in the years to come.Change is always on the horizonSharp foresees potential benefits for companies that contribute to academia, in the way Alnylam Pharmaceuticals has through the Phil Sharp-Alnylam Fund for Emerging Scientists. “We are proud to support the MIT Department of Biology because investments in both early-stage and high-risk research have the potential to unlock the next wave of medical breakthroughs to help so many patients waiting for hope throughout the world,” says Yvonne Greenstreet, CEO of Alnylam Pharmaceuticals. It is prudent for industry to keep its finger on the pulse — for becoming aware of new talent and for anticipating landscape-shifting advancements, such as artificial intelligence. Sharp notes that academia, in its pursuit of fundamental knowledge, “creates new ideas, new opportunities, and new ways of doing things.” “All of society, including biotech, is anticipating that AI is going to be a great accelerator,” Sharp says. “Being associated with institutions that have great biology, chemistry, neuroscience, engineering, and computational innovation is how you sort through this anticipation of what the future is going to be.”But, Sharp says, it’s a two-way street: Academia should also be asking how it can best support the future workplaces for their students who will go on to have careers in industry. To that end, the Department of Biology recently launched a career connections initiative for current trainees to draw on the guidance and experience of alums, and to learn how to hone their knowledge so that they are a value-add to industry’s needs.  “The symbiotic nature of these relationships is healthy for the country, and for society, all the way from basic research through innovative companies of all sizes, health-care delivery, hospitals, and right down to primary care physicians meeting one-on-one with patients,” Sharp says. “We’re all part of that, and unless all parts of it remain healthy and appreciated, it will bode poorly for the future of the country’s economy and well-being.”", "release_time": "2025-11-13", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/phil-sharp-alnylam-fund-for-emerging-scientists-established-1112"}
{"category": "研究前沿", "title": "硼砷化物热导率超越钻石，刷新材料科学纪录", "short_summary": "研究发现高纯度硼砷化物晶体热导率超2100 W/mK，性能优于钻石并挑战现有理论。", "detailed_summary": "研究发现高纯度硼砷化物晶体热导率超2100 W/mK，性能优于钻石并挑战现有理论。\n(1) 休斯顿大学等机构研究发现，高纯度硼砷化物(BAs)晶体室温热导率超过2100 W/mK，可能超越钻石。\n(2) 这一成果颠覆了长期以来的理论预测，表明材料纯度对热传导性能起决定性作用。\n(3) 研究团队通过改进合成方法，减少了晶体缺陷，从而实现了这一突破性的实验数据。\n(4) 硼砷化物兼具优异半导体性能和超高热导率，有望应用于智能手机、高功率电子设备及数据中心的热管理。\n(5) 该发现将推动现有热传导理论的修正，并为高性能半导体材料开发开辟新路径。", "raw_content": "Researchers at the University of Houston have achieved a major scientific milestone in the study of heat transfer. Their new findings overturn long-standing assumptions about thermal conductivity and reveal that boron arsenide (BAs) can conduct heat more effectively than diamond, which has long been considered the benchmark among isotropic materials.  The research team discovered that when BAs crystals are produced with exceptional purity, they can reach thermal conductivity values greater than 2,100 watts per meter per Kelvin (W/mK) at room temperature -- possibly surpassing diamond itself. Published in Materials Today, the study challenges existing theoretical models and could reshape how scientists think about heat movement through solid materials. The results also point to a promising new semiconductor option for devices that demand advanced thermal management, including smartphones, high-power electronics, and data centers. \"We trust our measurement; our data is correct and that means the theory needs correction,\" said Zhifeng Ren, corresponding author and a professor of physics in UH's College of Natural Sciences and Mathematics. \"I'm not saying the theory is wrong, but an adjustment needs to be made to be consistent with the experimental data.\" Breaking Through Long-Held Limits The discovery emerged from a collaboration among the University of Houston's Texas Center for Superconductivity (directed by Ren), the University of California, Santa Barbara, and Boston College. For more than a decade, boron arsenide has intrigued scientists. In 2013, Boston College physicist and study co-author David Broido and colleagues predicted that BAs could theoretically conduct heat as efficiently -- or even better -- than diamond. However, revised models in 2017 added a complex factor known as four-phonon scattering, which reduced predicted performance to around 1,360 W/mK. This caused many in the field to abandon the idea that BAs could exceed diamond's conductivity.  Ren's group, however, suspected the problem wasn't the material's intrinsic ability but the impurities within it. Earlier experimental samples contained defects that limited performance to about 1,300 W/mK, well below the ideal conditions used in theoretical predictions. Cleaner Crystals, Record-Breaking Results By refining raw arsenic and developing improved synthesis methods, the UH-led team created boron arsenide crystals with significantly fewer imperfections. When tested, these high-purity samples demonstrated a remarkable thermal conductivity above 2,100 W/mK -- surpassing not only earlier experimental results but also the theoretical ceiling itself. This achievement confirms that material purity plays a decisive role in heat transfer performance and opens a path toward even more efficient heat-conducting materials. Why the Discovery Matters The implications of this breakthrough extend far beyond laboratory measurements. Boron arsenide has the potential to revolutionize electronics and semiconductor technology by providing a material that both dissipates heat effectively and performs as a high-quality semiconductor.  Its advantages include: Easier and more cost-effective manufacturing compared to diamond, without the need for extreme temperature or pressure. Exceptional thermal conductivity combined with efficient semiconductor behavior. Potentially superior electronic performance compared to silicon due to its high carrier mobility, wide band gap, and well-matched coefficient of thermal expansion.\"This new material, it's so wonderful,\" Ren said. \"It has the best properties of a good semiconductor, and a good thermal conductor -- all sorts of good properties in one material. That has never happened in other semiconducting materials.\" Looking Forward: Pushing the Boundaries of Physics Although this discovery marks a new frontier, the work is ongoing. Researchers at the Texas Center for Superconductivity plan to continue refining their methods, aiming to enhance boron arsenide's performance even further. The study is part of a $2.8 million National Science Foundation project led by Bolin Liao at UC Santa Barbara, with contributions from the University of Houston, the University of Notre Dame, and UC Irvine. The research also receives partial support from industrial partner Qorvo. Ren encourages scientists to revisit existing models and challenge theoretical assumptions that may have underestimated materials like BAs. \"You shouldn't let a theory prevent you from discovering something even bigger, and this exactly happened in this work,\" Ren said.", "release_time": "2025-11-13", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/11/251112011825.htm"}
{"category": "研究前沿", "title": "MIT学生利用鱼鳞开发生物可降解塑料替代材料", "short_summary": "研究者从鱼鳞中研制出可降解塑料替代品，为解决塑料污染提供创新方案。", "detailed_summary": "研究者从鱼鳞中研制出可降解塑料替代品，为解决塑料污染提供创新方案。\n（1）麻省理工学院材料科学与工程系学生Jacqueline Prawira利用鱼类加工废料开发出生物可降解的塑料类似材料；\n（2）该材料灵感来自鱼鳞的强度、轻质和柔性特性，可制成透明薄膜用于包装袋和餐具等一次性产品；\n（3）材料在堆肥环境中可自然降解，解决了传统塑料难以分解的环境问题；\n（4）研究者此前还参与开发了低碳水泥制造工艺，能显著减少二氧化碳排放；\n（5）该创新获得巴里·戈德华特奖学金认可，展现了环保材料研究的前沿进展。", "raw_content": "Sometimes the answers to seemingly intractable environmental problems are found in nature itself. Take the growing challenge of plastic waste. Jacqueline Prawira, an MIT senior in the Department of Materials Science and Engineering (DMSE), has developed biodegradable, plastic-like materials from fish offal, as featured in a recent segment on the CBS show “The Visioneers with Zay Harding.” “We basically made plastics to be too good at their job. That also means the environment doesn’t know what to do with this, because they simply won’t degrade,” Prawira told Harding. “And now we’re literally drowning in plastic. By 2050, plastics are expected to outweigh fish in the ocean.” “The Visioneers” regularly highlights environmental innovators. The episode featuring Prawira premiered during a special screening at Climate Week NYC on Sept. 24.Her inspiration came from the Asian fish market her family visits. Once the fish they buy are butchered, the scales are typically discarded. “But I also started noticing they’re actually fairly strong. They’re thin, somewhat flexible, and pretty lightweight, too, for their strength,” Prawira says. “And that got me thinking: Well, what other material has these properties? Plastics.” She transformed this waste product into a transparent, thin-film material that can be used for disposable products such as grocery bags, packaging, and utensils. Both her fish-scale material and a composite she developed don’t just mimic plastic — they address one of its biggest flaws. “If you put them in composting environments, [they] will degrade on their own naturally without needing much, if any, external help,” Prawira says. This isn’t Prawira’s first environmental innovation. Working in DMSE Professor Yet-Ming Chiang’s lab, she helped develop a low-carbon process for making cement — the world’s most widely used construction material, and a major emitter of carbon dioxide. The process, called silicate subtraction, enables compounds to form at lower temperatures, cutting fossil fuel use. Prawira and her co-inventors in the Chiang lab are also using the method to extract valuable lithium with zero waste. The process is patented and is being commercialized through the startup Rock Zero. For her achievements, Prawira recently received the Barry Goldwater Scholarship, awarded to undergraduates pursuing careers in science, mathematics, or engineering. In her “Visioneers” interview, she shared her hope for more sustainable ways of living. “I’m hoping that we can have daily lives that can be more in sync with the environment,” Prawira said. “So you don’t always have to choose between the convenience of daily life and having to help protect the environment.”", "release_time": "2025-11-13", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/mit-senior-turns-waste-from-fishing-industry-into-biodegradable-plastic-1112"}
{"category": "产业应用", "title": "中几合作西芒杜铁矿项目正式投产", "short_summary": "西芒杜铁矿项目投产启动，标志中几合作取得重大进展。", "detailed_summary": "西芒杜铁矿项目投产启动，标志中几合作取得重大进展。\n（1）西芒杜铁矿项目在几内亚马瑞巴亚港举行投产启动仪式。\n（2）该铁矿位于几内亚东南部，是世界级大型优质露天赤铁矿。\n（3）项目是中几两国重点合作项目，中国企业参与矿山、铁路、港口等工程建设。", "raw_content": "当地时间11月11日，西非国家几内亚在马瑞巴亚港举行西芒杜铁矿项目投产启动仪式。 西芒杜铁矿位于几内亚境内东南部，是世界级的大型优质露天赤铁矿。该项目也是中国和几内亚两国的重点合作项目，中国企业在该项目的矿山、铁路、港口等相关工程建设中发挥了重要作用。", "release_time": "2025-11-12", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1196033-1.html"}
{"category": "研究前沿", "title": "MIT研发超强气体阻隔二维聚合物薄膜", "short_summary": "MIT研制出近乎不透气的二维聚合物薄膜，可显著延长太阳能电池和食品药物寿命。", "detailed_summary": "MIT研制出近乎不透气的二维聚合物薄膜，可显著延长太阳能电池和食品药物寿命。\n(1) MIT研究人员开发出一种名为2DPA-1的新型二维聚合物薄膜，其气体阻隔性达到前所未有的水平。\n(2) 该材料通过溶液相聚合自组装成分子薄片，制备过程易于规模化，应用比石墨烯更便捷。\n(3) 实验证明其对氮气、氦气等多种气体几乎完全不可渗透，性能媲美完美晶体石墨烯。\n(4) 核心应用包括保护钙钛矿太阳能电池免受腐蚀、延长食品药品包装寿命，以及保护桥梁等基础设施。\n(5) 该材料还被用于制造首个聚合物二维谐振器，有望推动通信设备小型化和传感器技术发展。", "raw_content": "MIT researchers have developed a lightweight polymer film that is nearly impenetrable to gas molecules, raising the possibility that it could be used as a protective coating to prevent solar cells and other infrastructure from corrosion, and to slow the aging of packaged food and medicines.The polymer, which can be applied as a film mere nanometers thick, completely repels nitrogen and other gases, as far as can be detected by laboratory equipment, the researchers found. That degree of impermeability has never been seen before in any polymer, and rivals the impermeability of molecularly-thin crystalline materials such as graphene.“Our polymer is quite unusual. It’s obviously produced from a solution-phase polymerization reaction, but the product behaves like graphene, which is gas-impermeable because it’s a perfect crystal. However, when you examine this material, one would never confuse it with a perfect crystal,” says Michael Strano, the Carbon P. Dubbs Professor of Chemical Engineering at MIT.The polymer film, which the researchers describe today in Nature, is made using a process that can be scaled up to large quantities and applied to surfaces much more easily than graphene.Strano and Scott Bunch, an associate professor of mechanical engineering at Boston University, are the senior authors of the new study. The paper’s lead authors are Cody Ritt, a former MIT postdoc who is now an assistant professor at the University of Colorado at Boulder; Michelle Quien, an MIT graduate student; and Zitang Wei, an MIT research scientist.Bubbles that don’t collapseStrano’s lab first reported the novel material — a two-dimensional polymer called a 2D polyaramid that self-assembles into molecular sheets using hydrogen bonds — in 2022. To create such 2D polymer sheets, which had never been done before, the researchers used a building block called melamine, which contains a ring of carbon and nitrogen atoms. Under the right conditions, these monomers can expand in two dimensions, forming nanometer-sized disks. These disks stack on top of each other, held together by hydrogen bonds between the layers, which make the structure very stable and strong.That polymer, which the researchers call 2DPA-1, is stronger than steel but has only one-sixth the density of steel.In their 2022 study, the researchers focused on testing the material’s strength, but they also did some preliminary studies of its gas permeability. For those studies, they created “bubbles” out of the films and filled them with gas. With most polymers, such as plastics, gas that is trapped inside will seep out through the material, causing the bubble to deflate quickly.However, the researchers found that bubbles made of 2DPA-1 did not collapse — in fact, bubbles that they made in 2021 are still inflated. “I was quite surprised initially,” Ritt says. “The behavior of the bubbles didn’t follow what you’d expect for a typical, permeable polymer. This required us to rethink how to properly study and understand molecular transport across this new material.”  “We set up a series of careful experiments to first prove that the material is molecularly impermeable to nitrogen,” Strano says. “It could be considered tedious work. We had to make micro-bubbles of the polymer and fill them with a pure gas like nitrogen, and then wait. We had to repeatedly check over an exceedingly long period of time that they weren’t collapsed, in order to report the record impermeability value.”Traditional polymers allow gases through because they consist of a tangle of spaghetti-like molecules that are loosely joined together. This leaves tiny gaps between the strands. Gas molecules can seep through these gaps, which is why polymers always have at least some degree of gas permeability.However, the new 2D polymer is essentially impermeable because of the way that the layers of disks stick to each other.“The fact that they can pack flat means there’s no volume between the two-dimensional disks, and that’s unusual. With other polymers, there’s still space between the one-dimensional chains, so most polymer films allow at least a little bit of gas to get through,” Strano says.George Schatz, a professor of chemistry and chemical and biological engineering at Northwestern University, described the results as “remarkable.”“Normally polymers are reasonably permeable to gases, but the polyaramids reported in this paper are orders of magnitude less permeable to most gases under conditions with industrial relevance,” says Schatz, who was not involved in the study.A protective coatingIn addition to nitrogen, the researchers also exposed the polymer to helium, argon, oxygen, methane, and sulfur hexafluoride. They found that 2DPA-1’s permeability to those gases was at least 1/10,000 that of any other existing polymer. That makes it nearly as impermeable as graphene, which is completely impermeable to gases because of its defect-free crystalline structure.Scientists have been working on developing graphene coatings as a barrier to prevent corrosion in solar cells and other devices. However, scaling up the creation of graphene films is difficult, in large part because they can’t be simply painted onto surfaces.“We can only make crystal graphene in very small patches,” Strano says. “A little patch of graphene is molecularly impermeable, but it doesn’t scale. People have tried to paint it on, but graphene does not stick to itself but slides when sheared. Graphene sheets moving past each other are considered almost frictionless.”On the other hand, the 2DPA-1 polymer sticks easily because of the strong hydrogen bonds between the layered disks. In this paper, the researchers showed that a layer just 60 nanometers thick could extend the lifetime of a perovskite crystal by weeks. Perovskites are materials that hold promise as cheap and lightweight solar cells, but they tend to break down much faster than the silicon solar panels that are now widely used.A 60-nanometer coating extended the perovskite’s lifetime to about three weeks, but a thicker coating would offer longer protection, the researchers say. The films could also be applied to a variety of other structures.“Using an impermeable coating such as this one, you could protect infrastructure such as bridges, buildings, rail lines — basically anything outside exposed to the elements. Automotive vehicles, aircraft and ocean vessels could also benefit. Anything that needs to be sheltered from corrosion. The shelf life of food and medications can also be extended using such materials,” Strano says.The other application demonstrated in this paper is a nanoscale resonator — essentially a tiny drum that vibrates at a particular frequency. Larger resonators, with sizes around 1 millimeter or less, are found in cell phones, where they allow the phone to pick up the frequency bands it uses to transmit and receive signals.“In this paper, we made the first polymer 2D resonator, which you can do with our material because it’s impermeable and quite strong, like graphene,” Strano says. “Right now, the resonators in your phone and other communications devices are large, but there’s an effort to shrink them using nanotechnology. To make them less than a micron in size would be revolutionary. Cell phones and other devices could be smaller and reduce the power expenditures needed for signal processing.”Resonators can also be used as sensors to detect very tiny molecules, including gas molecules. The research was funded, in part, by the Center for Enhanced Nanofluidic Transport-Phase 2, an Energy Frontier Research Center funded by the U.S. Department of Energy Office of Science, as well as the National Science Foundation.This research was carried out, in part, using MIT.nano’s facilities.", "release_time": "2025-11-13", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/new-lightweight-polymer-film-can-prevent-corrosion-1112"}
{"category": "产业应用", "title": "德国启动欧洲最大GW级储能电池项目", "short_summary": "德美合作开发千兆瓦储能系统，助推可再生能源整合与电网稳定。", "detailed_summary": "德美合作开发千兆瓦储能系统，助推可再生能源整合与电网稳定。\n（1）德国LEAG与美国Fluence energy合作在勃兰登堡Jänschwalde开发1GW/4GWh储能系统；\n（2）该项目是德国首个GW级储能项目，也是欧洲同类项目中规模最大的项目之一；\n（3）项目属于LEAG的吉瓦级工厂计划，旨在将原煤矿改造为清洁能源中心；\n（4）储能系统将储存多余太阳能和风能，平衡电网供需，提高可再生能源占比；\n（5）项目将加速德国能源转型，为欧洲电网规模储能发展设立新基准。", "raw_content": "德国能源公司LEAG与美国Fluence energy的德国子公司Fluence energy GmbH建立了合作伙伴关系，将在勃兰登堡Jänschwalde开发容量为1GW/4GWh的大型储能系统。 该项目标志着德国首个正式宣布的GW级储能项目，被认为是欧洲同类项目中规模最大的项目之一。这个项目被称为GigaBattery，是LEAG更广泛的吉瓦级工厂计划的关键组成部分。这一区域工业计划的重点是在德国劳茨地区发展可再生能源发电、大规模储能和绿色氢基础设施。该计划旨在将原煤矿改造成清洁能源生产中心，支持国家的能源转型，促进该地区的工业振兴。 GigaBattery系统将提高电网的稳定性，并使可再生能源的更高份额融入德国电力系统。通过储存多余的太阳能和风能，并在需求高峰期释放，该设施将有助于平衡供需，同时支持可持续发电。该项目的规模和设计预计将为整个欧洲的电网规模储能发展设定新的基准。 LEAG的GigawattFactory计划也反映了该公司从传统的燃煤发电转向可再生能源解决方案的战略。2022年，LEAG宣布计划到2030年开发7GW的太阳能和风能产能，这是朝着建立欧洲最大的可再生能源中心之一迈出的重要一步。该公司在Jänschwalde的持续努力表明了其对能源多样化、当地经济发展和有效再利用采矿后土地的承诺。 LEAG和Fluence Energy的合作建立在两家公司的技术专长之上。Fluence Energy以其先进的电池储能系统和数字能源管理平台而闻名，这些系统被广泛用于优化电网运行。LEAG在当地的能源基础设施与Fluence的技术能力相结合，预计将加速德国大容量储能解决方案的部署。 一旦完成，GigaBattery将成为Lausitz energy转型的基石，为整个欧洲的类似项目提供一个模型。它将使可再生能源灵活地整合到电网中，同时加强德国的长期能源安全。该倡议强调了工业伙伴关系和创新如何通过将传统能源场所重新定位为面向未来的应用，推动可持续能源发展和区域经济增长。 LEAG集团首席执行官Adi Roesch表示：“通过这个项目，我们正在为我们的GigwatFactory点燃另一个增长引擎。通过建设千兆级储能设施，我们正在应对能源转型的最大挑战之一：无论可再生能源是否可用，能源的持续可用性。未来能源系统的关键在于可再生能源、可根据需要使用的储能设施和灵活的发电厂的结合。” GigaBattery Jänschwalde 1000旨在提供基本的电网服务，实现高效的电力交易，加强德国的能源安全，加快该国的能源转型。通过提供大规模、灵活的储能，该项目将有助于平衡供需，使可再生能源更加可靠和可用。 Fluence总裁兼首席执行官朱利安·内布雷达(Julian Nebreda)表示：“我们很自豪能与LEAG Clean Power合作开展如此规模和重要性的项目，并祝贺LEAG清洁能源公司为德国和欧洲的能源未来树立了这一里程碑。这个旗舰项目表明，当专业知识、远见和勇气结合在一起时，就有可能实现重大转型。我们可以共同改变能源系统，从而为我们的经济和日常生活奠定基础。” (素材来自：LEAG/Fluence energy 全球储能网、新能源网综合)", "release_time": "2025-11-13", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1196044-1.html"}
{"category": "研究前沿", "title": "MIT研发自学习大模型框架SEAL", "short_summary": "MIT新框架让大语言模型生成训练数据并自我更新，性能显著提升。", "detailed_summary": "MIT新框架让大语言模型生成训练数据并自我更新，性能显著提升。\n(1) MIT研究人员开发SEAL框架，解决大语言模型部署后无法永久学习新知识的问题。\n(2) 模型模仿人类制作学习笔记，根据输入生成多份合成数据作为自我编辑内容。\n(3) 通过强化学习的试错过程，模型选择性能提升最大的自我编辑来更新其内部权重。\n(4) 该框架允许模型自主控制学习数据、速率和迭代次数等参数。\n(5) 实验显示SEAL在问答和技能学习任务上显著提升模型准确率和成功率。\n(6) 当前存在灾难性遗忘等局限性，未来将探索多智能体协作等方向以推动科学发展。", "raw_content": "In an MIT classroom, a professor lectures while students diligently write down notes they will reread later to study and internalize key information ahead of an exam.Humans know how to learn new information, but large language models can’t do this in the same way. Once a fully trained LLM has been deployed, its “brain” is static and can’t permanently adapt itself to new knowledge.This means that if a user tells an LLM something important today, it won’t remember that information the next time this person starts a new conversation with the chatbot.Now, a new approach developed by MIT researchers enables LLMs to update themselves in a way that permanently internalizes new information. Just like a student, the LLM generates its own study sheets from a user’s input, which it uses to memorize the information by updating its inner workings.The model generates multiple self-edits to learn from one input, then applies each one to see which improves its performance the most. This trial-and-error process teaches the model the best way to train itself.The researchers found this approach improved the accuracy of LLMs at question-answering and pattern-recognition tasks, and it enabled a small model to outperform much larger LLMs.While there are still limitations that must be overcome, the technique could someday help artificial intelligence agents consistently adapt to new tasks and achieve changing goals in evolving environments.   “Just like humans, complex AI systems can’t remain static for their entire lifetimes. These LLMs are not deployed in static environments. They are constantly facing new inputs from users. We want to make a model that is a bit more human-like — one that can keep improving itself,” says Jyothish Pari, an MIT graduate student and co-lead author of a paper on this technique.He is joined on the paper by co-lead author Adam Zweiger, an MIT undergraduate; graduate students Han Guo and Ekin Akyürek; and senior authors Yoon Kim, an assistant professor in the Department of Electrical Engineering and Computer Science (EECS) and a member of the Computer Science and Artificial Intelligence Laboratory (CSAIL), and Pulkit Agrawal, an assistant professor in EECS and member of CSAIL. The research will be presented at the Conference on Neural Information Processing Systems.Teaching the model to learnLLMs are neural network models that have billions of parameters, called weights, that contain the model’s knowledge and process inputs to make predictions. During training, the model adapts these weights to learn new information contained in its training data.But once it is deployed, the weights are static and can’t be permanently updated anymore.However, LLMs are very good at a process called in-context learning, in which a trained model learns a new task by seeing a few examples. These examples guide the model’s responses, but the knowledge disappears before the next conversation.The MIT researchers wanted to leverage a model’s powerful in-context learning capabilities to teach it how to permanently update its weights when it encounters new knowledge.The framework they developed, called SEAL for “self-adapting LLMs,” enables an LLM to generate new synthetic data based on an input, and then determine the best way to adapt itself and learn from that synthetic data. Each piece of synthetic data is a self-edit the model can apply.In the case of language, the LLM creates synthetic data by rewriting the information, and its implications, in an input passage. This is similar to how students make study sheets by rewriting and summarizing original lecture content.The LLM does this multiple times, then quizzes itself on each self-edit to see which led to the biggest boost in performance on a downstream task like question answering. It uses a trial-and-error method known as reinforcement learning, where it receives a reward for the greatest performance boost.Then the model memorizes the best study sheet by updating its weights to internalize the information in that self-edit.“Our hope is that the model will learn to make the best kind of study sheet — one that is the right length and has the proper diversity of information — such that updating the model based on it leads to a better model,” Zweiger explains.Choosing the best methodTheir framework also allows the model to choose the way it wants to learn the information. For instance, the model can select the synthetic data it wants to use, the rate at which it learns, and how many iterations it wants to train on.In this case, not only does the model generate its own training data, but it also configures the optimization that applies that self-edit to its weights.“As humans, we know how we learn best. We want to grant that same ability to large language models. By providing the model with the ability to control how it digests this information, it can figure out the best way to parse all the data that are coming in,” Pari says.SEAL outperformed several baseline methods across a range of tasks, including learning a new skill from a few examples and incorporating knowledge from a text passage. On question answering, SEAL improved model accuracy by nearly 15 percent and on some skill-learning tasks, it boosted the success rate by more than 50 percent.But one limitation of this approach is a problem called catastrophic forgetting: As the model repeatedly adapts to new information, its performance on earlier tasks slowly declines.The researchers plan to mitigate catastrophic forgetting in future work. They also want to apply this technique in a multi-agent setting where several LLMs train each other.“One of the key barriers to LLMs that can do meaningful scientific research is their inability to update themselves based on their interactions with new information. Though fully deployed self-adapting models are still far off, we hope systems able to learn this way could eventually overcome this and help advance science,” Zweiger says.This work is supported, in part, by the U.S. Army Research Office, the U.S. Air Force AI Accelerator, the Stevens Fund for MIT UROP, and the MIT-IBM Watson AI Lab.", "release_time": "2025-11-12", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/teaching-large-language-models-to-absorb-new-knowledge-1112"}
{"category": "研究前沿", "title": "韦伯望远镜首次在银河系外探测到生命相关有机分子冰", "short_summary": "韦伯望远镜在大麦哲伦星云发现复杂有机分子冰，揭示生命成分或早于预期在宇宙中形成。", "detailed_summary": "韦伯望远镜在大麦哲伦星云发现复杂有机分子冰，揭示生命成分或早于预期在宇宙中形成。\n（1）韦伯望远镜首次在大麦哲伦星云年轻恒星ST6周围冰层中探测到五种复杂有机分子；\n（2）发现包括甲醇、乙醇、乙酸等化合物，其中乙酸系首次在太空冰中被明确观测；\n（3）该星云低金属丰度环境与早期宇宙相似，表明生命基础成分可能更早形成；\n（4）探测技术依赖韦伯望远镜的高灵敏度和光谱分辨率，突破以往观测局限；\n（5）研究为宇宙生命起源提供新线索，将扩展对更多原恒星系的分子普查。", "raw_content": "In a finding that could change how scientists understand the spread of life's ingredients across space, astronomers have detected large organic molecules frozen in ice around a forming star called ST6 in a galaxy beyond the Milky Way.  Using the James Webb Space Telescope's (JWST) Mid-Infrared Instrument (MIRI), the research team identified five carbon-based compounds in the Large Magellanic Cloud, our closest neighboring galaxy. The study, led by University of Maryland and NASA scientist Marta Sewilo, was published in the Astrophysical Journal Letters on October 20, 2025. Detecting Life's Chemical Ingredients in Alien Ice Sewilo's group found five complex organic molecules (COMs) within the ice surrounding the young protostar. These included methanol and ethanol (both types of alcohol), methyl formate and acetaldehyde (industrial chemicals on Earth), and acetic acid (the main ingredient in vinegar). One of the compounds, acetic acid, had never before been definitively observed in space ice, while the others -- ethanol, methyl formate, and acetaldehyde -- were detected in ices outside the Milky Way for the first time. The team also spotted signs of glycolaldehyde, a sugar-related molecule linked to RNA formation, though further analysis is required to confirm it. JWST's Sharp Vision Opens a New Window on Cosmic Chemistry \"It's all thanks to JWST's exceptional sensitivity combined with high angular resolution that we're able to detect these faint spectral features associated with ices around such a distant protostar,\" Sewilo said. \"The spectral resolution of JWST is sufficiently high to allow for reliable identifications.\" Before the Webb telescope, methanol was the only complex organic molecule ever confirmed in ice around protostars -- even within our own galaxy. According to Sewilo, the extraordinary precision of the new data allowed her team to extract an unprecedented amount of information from a single spectrum.  A Harsh Galaxy as a Laboratory for Life's Origins The discovery is especially striking because of where the molecules were found. The Large Magellanic Cloud, located about 160,000 light-years from Earth, is an ideal environment for studying how stars form in conditions resembling those of the early universe. This small galaxy has only about one-third to one-half the heavy elements (those with atomic numbers greater than helium) of our solar system and endures far more intense ultraviolet radiation. \"The low metallicity environment, meaning the reduced abundance of elements heavier than hydrogen and helium, is interesting because it's similar to galaxies at earlier cosmological epochs,\" Sewilo explained. \"What we learn in the Large Magellanic Cloud, we can apply to understanding these more distant galaxies from when the universe was much younger. The harsh conditions tell us more about how complex organic chemistry can occur in these primitive environments where much fewer heavy elements like carbon, nitrogen and oxygen are available for chemical reactions.\" How Complex Molecules Form on Cosmic Dust Study co-author Will Rocha of Leiden University in the Netherlands noted that COMs can form in both the gas phase and in icy layers coating interstellar dust grains. Once formed, these ices can later release their molecules back into the gas. Methanol and methyl formate had already been observed in the gas phase within the Large Magellanic Cloud, but this is the first evidence that such molecules are also forming in the solid ice itself. \"Our detection of COMs in ices supports these results,\" Rocha said. \"The detection of icy COMs in the Large Magellanic Cloud provides evidence that these reactions can produce them effectively in a much harsher environment than in the solar neighborhood.\" Life's Ingredients May Have Formed Early in the Universe  The presence of these complex molecules in a low-metallicity environment similar to those found in the early universe suggests that the building blocks of life may have begun forming much earlier -- and in a wider range of conditions -- than scientists once thought. While this discovery does not prove that life exists elsewhere, it indicates that organic compounds can endure through the process of planetary formation and potentially be incorporated into young planets, creating conditions where life might one day emerge. Expanding the Search for Cosmic Chemistry Sewilo and her collaborators plan to extend their work by examining more protostars in both the Large and Small Magellanic Clouds to explore how widespread these molecules may be. \"We currently only have one source in the Large Magellanic Cloud and only four sources with detection of these complex organic molecules in ices in the Milky Way. We need larger samples from both to confirm our initial results that indicate differences in COM abundances between these two galaxies,\" Sewilo said. \"But with this discovery, we've made significant advancements in understanding how complex chemistry emerges in the universe and opening new possibilities for research into how life came to be.\"", "release_time": "2025-11-12", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/11/251112011838.htm"}
{"category": "政策计划", "title": "功能材料与器件党支部专题学习二十届四中全会精神", "short_summary": "支部组织学习全会精神，聚焦科技自立自强与科研工作结合。", "detailed_summary": "支部组织学习全会精神，聚焦科技自立自强与科研工作结合。\n(1) 功能材料与器件党支部于11月10日组织全体党员开展党的二十届四中全会精神专题党课学习。\n(2) 支部书记段敬来同志带领研读全会公报和“十五五”规划建议核心内容，重点学习总书记重要讲话精神。\n(3) 学习紧密结合科研主责主业，深入解读“加快高水平科技自立自强”等重大部署。\n(4) 会议强调将个人科研追求融入国家发展大局，坚守面向应用的研究定位。\n(5) 活动旨在引导党员清晰把握科技创新战略方向，以更务实作风投身研发，贡献中国式现代化建设。", "raw_content": "功能材料与器件党支部组织开展党的二十届四中全会精神专题学习 文章来源：  |  发布时间：2025-11-12 文章来源：  |  发布时间：2025-11-12  |  【打印】 【关闭】 　　                  为深入学习贯彻党的二十届四中全会精神，切实把党员科技工作者的思想和行动统一到党中央决策部署上来，11月10日上午，功能材料与器件党支部组织全体党员开展专题党课学习。会上，支部书记段敬来同志带领全体党员系统研读了党的二十届四中全会公报及《中共中央关于制定国民经济和社会发展第十五个五年规划的建议》核心内容，重点学习领会习近平总书记在全会上的重要讲话精神。结合支部科研人员主责主业，围绕全会提出的“加快高水平科技自立自强，引领发展新质生产力”“推动科技创新和产业创新深度融合”等重大部署进行深入解读。他强调，党的二十届四中全会明确了“十五五”时期经济社会发展主要目标，其中“科技自立自强水平大幅提高，重点领域关键核心技术快速突破”的要求，与材料研究领域使命高度契合。全体党员要牢牢把握“六个坚持”重要原则，始终坚守“面向应用开展基础研究、核心研发与成果推广”的工作定位，把个人科研追求融入国家发展大局。此次专题党课紧扣科研实际，全体党员对二十届四中全会会议精神有了更深入理解，对“十五五”时期科技创新的战略方向有了更清晰的把握，对科研人员应该对标哪些方面去做出自己的贡献有了新的启迪。全体党员将以全会精神为指引，立足功能材料与器件研究特性，聚焦产业链关键环节技术需求，深入思考科技创新与产业链深度融合的实践路径，以更坚定的信念、更务实的作风投身基础研发与应用推广工作，为实现高水平科技自立自强、推进中国式现代化建设贡献科研力量。图：会议现场(功能材料与器件党支部 供稿)", "release_time": "2025-11-13", "source_institution": "近代物理研究所", "url": "http://www.imp.cas.cn/sndt2017/202511/t20251112_8010971.html"}
{"category": "产业应用", "title": "印尼2025年煤炭出口预计下降3000万吨", "short_summary": "受全球需求减弱影响，印尼今年煤炭出口量及收入双双下滑。", "detailed_summary": "受全球需求减弱影响，印尼今年煤炭出口量及收入双双下滑。\n（1）印尼能矿部预测2025年煤炭出口量约5.25亿吨，较2024年减少3000万吨；\n（2）2025年1-9月煤炭产量5.85亿吨，同比下降7.47%；\n（3）同期煤炭出口收入179.4亿美元，同比下降20.85%；\n（4）出口下降主因中国、印度等主要市场进口需求减少；\n（5）煤炭价格下滑及出口量减少共同导致收入大幅降低。", "raw_content": "据“彭博技术”(Bloomberg Technoz)11月5日发布的信息，印度尼西亚能源和矿产资源部(ESDM)预测，2025年印尼煤炭出口量将比去年出口的5.55亿吨减少约3000万吨。 印尼能矿部(ESDM)煤炭矿业总局(Minerba)局长苏里亚(Surya Herjuna)在11月5日(星期三)举行的“Coalindo Coal Conference 2025”会议上说道，今年全年的煤炭出口预计将在5.25亿吨左右。 Surya认为，由于全球宏观经济形势的不确定性，导致中国和印度等国家的煤炭进口需求减少，由此，今年印尼的煤炭出口可能会下降。   此外，苏里亚继续说道，2025年1月至9月，印度尼西亚的煤炭产量达到5.85亿吨，较去年同期下降7.47%。 由于煤炭价格下滑，印尼煤炭出口收入也大为减少。印尼国家统计局(BPS)的报告显示，2025年1月至9月，印尼煤炭(不包括褐煤)的出口额为179.4亿美元(约298.79万亿印尼盾)，同比下降20.85%。 印尼国家统计局(BPS)统计、分配与服务司副司长普迪-伊斯马尔蒂尼(Pudji Ismartini)表示，煤炭出口额的下降，除了价格下降影响以外，还主要受到前9个月煤炭出口量减少的影响。 今年1-9月，印尼煤炭(2701海关序号，不包括褐煤2702)出口量2.8523亿吨，较去年同期的2.9941亿吨下降4.74%。 印尼国家统计局(BPS)11月3日发布的统计数据显示，2025年1-9月，印尼煤炭(包括褐煤)出口量累计为3.7561亿吨，比上年同期减少2794.3万吨，同比下降7.3%。其中，9月份，印尼煤炭出口量为4554.98万吨，同比减少4.6%，环比下降7.4%。 此前，印尼能源和矿产资源部发布的数据显示，2024年，印尼煤炭总产量为8.36亿吨，煤炭出口总量为5.55亿吨。", "release_time": "2025-11-11", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1196022-1.html"}
{"category": "研究前沿", "title": "第十五届全国气体润滑与干气密封学术会议在合肥举行", "short_summary": "国内顶尖专家齐聚合肥，共商气体润滑与密封技术前沿发展。", "detailed_summary": "国内顶尖专家齐聚合肥，共商气体润滑与密封技术前沿发展。\n（1）第十五届全国气体润滑与干气密封学术会议于11月7日至9日在合肥举行；\n（2）会议由中国机械工程学会主办，多家科研机构联合承办；\n（3）会议汇聚国内顶尖专家学者，设置5个大会报告及多个分会场报告；\n（4）议题聚焦气体轴承、润滑及干气密封等关键技术的研究与应用进展；\n（5）会议旨在推动产学研融合，为高端装备制造和能源领域提供技术支撑。", "raw_content": "第十五届全国气体润滑与干气密封学术会议召开  2025-11-11 | 作者：文/李姗姗 图/李姗姗 |【大 中 小】【打印】【关闭】   11月7日至9日，第十五届全国气体润滑与干气密封学术会议在合肥举行。此次会议由中国机械工程学会主办，中国机械工程学会摩擦学分会、中国科学院合肥物质科学研究院、合肥综合性国家科学中心能源研究院（安徽省能源实验室）联合承办，汇聚了国内气体润滑与干气密封领域的顶尖专家学者，共同探讨行业前沿技术与发展趋势。等离子体所副所长秦经刚、中国机械工程学会摩擦学分会总干事白秀琴、专业委员会主任委员侯予教授、合肥综合性国家科学中心能源研究院常务副院长胡浩民等领导出席大会，大会开幕式由等离子体所低温工程与技术研究室室务委员朱志刚主持。秦经刚在会议致辞中热烈欢迎各位专家学者的到来，强调突破关键基础部件制造瓶颈，实现高端装备国产化，是新时代科研工作者的重要使命之一。他表示本次会议不仅是学术交流的平台，更是推动产学研深度融合的重要契机。随后，他应邀作了关于磁约束聚变研究进展的大会报告。本次会议共收到论文投稿70余篇，会议设置了5个大会报告，哈尔滨工业大学（深圳）杜建军教授，西安交通大学陈良教授，湖南大学冯凯教授和浙大宁波理工学院陆俊杰教授分别围绕气体轴承与润滑、干气密封等技术的研究与应用进展进行了精彩的学术报告。会议还有20个分会场邀请报告和50余个学术报告，为与会专家学者提供了广泛的学术交流机会。在分会场讨论中，专家学者们围绕大会主题展开了深入探讨，分享和交流最新研究成果，为行业技术创新提供了新的思路和方法。会后，与会代表参观了EAST全超导托卡马克实验装置及聚变创新展览馆，并进行了现场交流。本次会议旨在为国内相关机构、专家学者提供全方位的交流、学习与合作平台，探讨气体润滑与干气密封相关的关键技术难题与多学科融合的发展举措。作为高端装备制造、能源等领域的关键技术，气体润滑与干气密封技术在超精密加工、高速旋转设备中有着广泛应用。此次承办会议是对等离子体所在该领域研究成绩的认可，也体现了其在推动行业技术进步中的积极作用。领导致辞报告现场会议合影会议人员参观EAST装置", "release_time": "2025-11-12", "source_institution": "等离子体物理研究所", "url": "http://www.ipp.ac.cn/xwdt/kydt/202511/t20251111_796406.html"}
{"category": "研究前沿", "title": "中国科协调研近代物理所大科学装置建设", "short_summary": "中国科协副书记冯身洪调研近代物理所，肯定重离子加速器等大科学装置科研进展。", "detailed_summary": "中国科协副书记冯身洪调研近代物理所，肯定重离子加速器等大科学装置科研进展。\n（1）中国科协党组副书记冯身洪一行近日调研近代物理所兰州重离子加速器国家实验室；\n（2）调研听取了研究所发展历程、人才队伍及HIAF、CiADS两大国家重大科技基础设施建设进展汇报；\n（3）赵红卫院士介绍了大科学装置的技术原理、运行状况及在核物理等领域的科技成果；\n（4）冯身洪赞赏研究所聚焦国家战略需求，期望其依托装置优势为科研高质量发展贡献更大力量。", "raw_content": "中国科学技术协会党组副书记冯身洪一行调研近代物理所 文章来源：  |  发布时间：2025-11-11 文章来源：  |  发布时间：2025-11-11  |  【打印】 【关闭】 　　                  近日，中国科学技术协会（以下简称“中国科协”）党组副书记、副主席、书记处书记冯身洪一行莅临近代物理所调研兰州重离子加速器国家实验室建设运行情况。甘肃省政府副省级干部、省科协主席张世珍，省科协党组书记、第一副主席包俊宗等同志陪同调研。近代物理所副所长何源、中国科学院院士赵红卫等同志参加此次调研。何源、赵红卫对冯身洪一行的到访表示热烈欢迎，对中国科协长期以来在科研创新、学术交流等方面给予研究所的大力支持表示衷心感谢。调研中，何源系统介绍了研究所的发展历程、人才队伍建设、重要科研突破以及强流重离子加速器装置（HIAF）和加速器驱动嬗变研究装置（CiADS）两大国家重大科技基础设施的建设进展。赵红卫介绍了大科学装置的技术原理、运行状况以及在核物理、重离子科学及交叉学科领域取得的科技成果和技术创新。调研结束后，冯身洪一行对近代物理所始终聚焦国家重大战略需求、主动服务科技创新大局的使命担当表示赞赏，并希望研究所依托大科学装置形成的科研优势，为我国相关科研领域高质量发展贡献更大力量。图1： 参观所史馆图2 ：现场调研（办公室    供稿）", "release_time": "2025-11-11", "source_institution": "近代物理研究所", "url": "http://www.imp.cas.cn/sndt2017/202511/t20251111_8009726.html"}
{"category": "研究前沿", "title": "Isola教授：从计算视角探索人类与AI智能共性", "short_summary": "MIT教授通过计算模型研究智能共性，提出柏拉图假说并探索自监督学习机制。", "detailed_summary": "MIT教授通过计算模型研究智能共性，提出柏拉图假说并探索自监督学习机制。\n(1) Phillip Isola教授从计算视角研究人类与人工智能的共性机制，重点关注计算机视觉和机器学习；\n(2) 提出柏拉图表示假说，认为不同AI模型的表征正在趋同于对现实世界的共享理解；\n(3) 研究自监督学习机制，探索AI模型如何无标注地学习世界表征；\n(4) 强调基础原理研究而非单纯追求工程指标，致力于推动AI安全融入社会；\n(5) 预测通用人工智能即将到来，思考人类与智能机器共存的未来图景。", "raw_content": "What can we learn about human intelligence by studying how machines “think?” Can we better understand ourselves if we better understand the artificial intelligence systems that are becoming a more significant part of our everyday lives?These questions may be deeply philosophical, but for Phillip Isola, finding the answers is as much about computation as it is about cogitation.Isola, the newly tenured associate professor in the Department of Electrical Engineering and Computer Science (EECS), studies the fundamental mechanisms involved in human-like intelligence from a computational perspective.While understanding intelligence is the overarching goal, his work focuses mainly on computer vision and machine learning. Isola is particularly interested in exploring how intelligence emerges in AI models, how these models learn to represent the world around them, and what their “brains” share with the brains of their human creators.“I see all the different kinds of intelligence as having a lot of commonalities, and I’d like to understand those commonalities. What is it that all animals, humans, and AIs have in common?” says Isola, who is also a member of the Computer Science and Artificial Intelligence Laboratory (CSAIL).To Isola, a better scientific understanding of the intelligence that AI agents possess will help the world integrate them safely and effectively into society, maximizing their potential to benefit humanity.Asking questionsIsola began pondering scientific questions at a young age.While growing up in San Francisco, he and his father frequently went hiking along the northern California coastline or camping around Point Reyes and in the hills of Marin County.He was fascinated by geological processes and often wondered what made the natural world work. In school, Isola was driven by an insatiable curiosity, and while he gravitated toward technical subjects like math and science, there was no limit to what he wanted to learn.Not entirely sure what to study as an undergraduate at Yale University, Isola dabbled until he came upon cognitive sciences.“My earlier interest had been with nature — how the world works. But then I realized that the brain was even more interesting, and more complex than even the formation of the planets. Now, I wanted to know what makes us tick,” he says.As a first-year student, he started working in the lab of his cognitive sciences professor and soon-to-be mentor, Brian Scholl, a member of the Yale Department of Psychology. He remained in that lab throughout his time as an undergraduate.After spending a gap year working with some childhood friends at an indie video game company, Isola was ready to dive back into the complex world of the human brain. He enrolled in the graduate program in brain and cognitive sciences at MIT.“Grad school was where I felt like I finally found my place. I had a lot of great experiences at Yale and in other phases of my life, but when I got to MIT, I realized this was the work I really loved and these are the people who think similarly to me,” he says.Isola credits his PhD advisor, Ted Adelson, the John and Dorothy Wilson Professor of Vision Science, as a major influence on his future path. He was inspired by Adelson’s focus on understanding fundamental principles, rather than only chasing new engineering benchmarks, which are formalized tests used to measure the performance of a system.A computational perspectiveAt MIT, Isola’s research drifted toward computer science and artificial intelligence.“I still loved all those questions from cognitive sciences, but I felt I could make more progress on some of those questions if I came at it from a purely computational perspective,” he says.His thesis was focused on perceptual grouping, which involves the mechanisms people and machines use to organize discrete parts of an image as a single, coherent object.If machines can learn perceptual groupings on their own, that could enable AI systems to recognize objects without human intervention. This type of self-supervised learning has applications in areas such autonomous vehicles, medical imaging, robotics, and automatic language translation.After graduating from MIT, Isola completed a postdoc at the University of California at Berkeley so he could broaden his perspectives by working in a lab solely focused on computer science.“That experience helped my work become a lot more impactful because I learned to balance understanding fundamental, abstract principles of intelligence with the pursuit of some more concrete benchmarks,” Isola recalls.At Berkeley, he developed image-to-image translation frameworks, an early form of generative AI model that could turn a sketch into a photographic image, for instance, or turn a black-and-white photo into a color one.He entered the academic job market and accepted a faculty position at MIT, but Isola deferred for a year to work at a then-small startup called OpenAI.“It was a nonprofit, and I liked the idealistic mission at that time. They were really good at reinforcement learning, and I thought that seemed like an important topic to learn more about,” he says.He enjoyed working in a lab with so much scientific freedom, but after a year Isola was ready to return to MIT and start his own research group.Studying human-like intelligenceRunning a research lab instantly appealed to him.“I really love the early stage of an idea. I feel like I am a sort of startup incubator where I am constantly able to do new things and learn new things,” he says.Building on his interest in cognitive sciences and desire to understand the human brain, his group studies the fundamental computations involved in the human-like intelligence that emerges in machines.One primary focus is representation learning, or the ability of humans and machines to represent and perceive the sensory world around them.In recent work, he and his collaborators observed that the many varied types of machine-learning models, from LLMs to computer vision models to audio models, seem to represent the world in similar ways.These models are designed to do vastly different tasks, but there are many similarities in their architectures. And as they get bigger and are trained on more data, their internal structures become more alike.This led Isola and his team to introduce the Platonic Representation Hypothesis (drawing its name from the Greek philosopher Plato) which says that the representations all these models learn are converging toward a shared, underlying representation of reality.“Language, images, sound — all of these are different shadows on the wall from which you can infer that there is some kind of underlying physical process — some kind of causal reality — out there. If you train models on all these different types of data, they should converge on that world model in the end,” Isola says.A related area his team studies is self-supervised learning. This involves the ways in which AI models learn to group related pixels in an image or words in a sentence without having labeled examples to learn from.Because data are expensive and labels are limited, using only labeled data to train models could hold back the capabilities of AI systems. With self-supervised learning, the goal is to develop models that can come up with an accurate internal representation of the world on their own.“If you can come up with a good representation of the world, that should make subsequent problem solving easier,” he explains.The focus of Isola’s research is more about finding something new and surprising than about building complex systems that can outdo the latest machine-learning benchmarks.While this approach has yielded much success in uncovering innovative techniques and architectures, it means the work sometimes lacks a concrete end goal, which can lead to challenges.For instance, keeping a team aligned and the funding flowing can be difficult when the lab is focused on searching for unexpected results, he says.“In a sense, we are always working in the dark. It is high-risk and high-reward work. Every once in while, we find some kernel of truth that is new and surprising,” he says.In addition to pursuing knowledge, Isola is passionate about imparting knowledge to the next generation of scientists and engineers. Among his favorite courses to teach is 6.7960 (Deep Learning), which he and several other MIT faculty members launched four years ago.The class has seen exponential growth, from 30 students in its initial offering to more than 700 this fall.And while the popularity of AI means there is no shortage of interested students, the speed at which the field moves can make it difficult to separate the hype from truly significant advances.“I tell the students they have to take everything we say in the class with a grain of salt. Maybe in a few years we’ll tell them something different. We are really on the edge of knowledge with this course,” he says.But Isola also emphasizes to students that, for all the hype surrounding the latest AI models, intelligent machines are far simpler than most people suspect.“Human ingenuity, creativity, and emotions — many people believe these can never be modeled. That might turn out to be true, but I think intelligence is fairly simple once we understand it,” he says.Even though his current work focuses on deep-learning models, Isola is still fascinated by the complexity of the human brain and continues to collaborate with researchers who study cognitive sciences.All the while, he has remained captivated by the beauty of the natural world that inspired his first interest in science.Although he has less time for hobbies these days, Isola enjoys hiking and backpacking in the mountains or on Cape Cod, skiing and kayaking, or finding scenic places to spend time when he travels for scientific conferences.And while he looks forward to exploring new questions in his lab at MIT, Isola can’t help but contemplate how the role of intelligent machines might change the course of his work.He believes that artificial general intelligence (AGI), or the point where machines can learn and apply their knowledge as well as humans can, is not that far off.“I don’t think AIs will just do everything for us and we’ll go and enjoy life at the beach. I think there is going to be this coexistence between smart machines and humans who still have a lot of agency and control. Now, I’m thinking about the interesting questions and applications once that happens. How can I help the world in this post-AGI future? I don’t have any answers yet, but it’s on my mind,” he says.", "release_time": "2025-11-11", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/understanding-nuances-human-intelligence-phillip-isola-1111"}
{"category": "产业应用", "title": "蒙古国前10月煤炭出口量同比增1.81%", "short_summary": "蒙古煤炭出口量同比微增，价格大幅下滑，年内达标仍有望。", "detailed_summary": "蒙古煤炭出口量同比微增，价格大幅下滑，年内达标仍有望。\n(1) 2025年1-10月蒙古国煤炭出口量6973.43万吨，同比增1.81%；出口额44.87亿美元，同比降39.43%，均价64.35美元/吨，同比大幅下降。\n(2) 前10月月均出口697万吨，距全年8300万吨目标差1327万吨，完成目标有望。\n(3) 10月单月出口量711.75万吨，环比降26.52%，同比降2.07%；出口均价59.41美元/吨，处于低位。\n(4) 10月出口下滑主因中国国庆闭关、蒙海关故障、政局动荡及煤矿限装等口岸通关限制。\n(5) 前10月出口几乎全部流向中国；11月因中国炼焦煤价上涨，蒙煤出口形势预计优于10月。\n(6) 煤种结构变化显著：前10月褐煤出口同比增82.22%，无烟煤出口同比增103.69%。", "raw_content": "今年前10月蒙古国煤炭出口量同比维持正数。此前，在9月当月高位出口带动下前9月蒙古国煤炭出口量同比转正，尽管10月出口明显回落，但前10月该国煤炭累计出口量仍高于上年同期。 根据蒙古国海关总署的最新数据，2025年1-10月份，蒙古国煤炭出口量累计6973.43万吨，较上年同期的6849.34万吨增加124.09万吨，增幅1.81%。在此期间，蒙古国煤炭出口额为44.87亿美元，同比下降39.43%;出口均价64.35美元/吨，同比下降43.82美元/吨。 据此，这照该国今年8300万吨的煤炭出口目标来看，还差大约1327万吨，即月均需约663万吨。以其今年以来出口水平看，还是有希望完成这一目标的。今年前10月蒙古国月均煤炭出口量达到697万吨。 今年前10月，除了5月出口到俄罗斯的10吨，蒙古国煤炭出口都去往了中国。1-10月蒙古国累计向中国出口煤炭6973.43万吨，同比增加124.09万吨，增幅1.81%。 10月单月来看，蒙古海关未给出单月数据，中国煤炭资源网根据历史数据计算得出，今年10月蒙古国煤炭出口量较前一月的高位回落至711.75万吨，环比下降26.52%，同比下降2.07%。   当月煤炭价格略有反弹，但仍处于偏低水平。数据显示，10月蒙古国煤炭出口额为4.23亿美元，同比降37.07%，环比降26.36%。据此推算其当月出口均价为59.41美元/吨，同比降33.05美元/吨，环比增0.13美元/吨。 10月蒙古国煤炭出口全部去往中国，出口中国煤炭量环比下降26.52%、同比下降2.07%。当月中国国内炼焦煤市场回暖，下游对蒙煤采购积极向有所提升，不过口岸通关方面存在扰动，对蒙煤流入中国形成了一定阻碍。 首先，在中国国庆期间中蒙口岸闭关7日，导致有效通关天数减少，此外蒙古海关系统短暂故障、蒙古政局动荡以及煤矿限装等问题也对口岸通关造成限制，综合影响10月蒙煤对华出口总量下滑。 11月份以来，供需偏紧格局下中国国内炼焦煤价格不断上涨，在此背景下口岸蒙煤市场偏强运行，贸易商进口积极性较好，主要口岸通关处于高位，不过11月蒙古国两个纪念日期间口岸会短暂闭关，但总体而言11月蒙煤对华出口情况或将好于10月。   分煤种来看，今年1-10月份，蒙古国烟煤出口量为6174.75万吨，同比降1.69%;褐煤出口量476.11万吨，同比增82.22%;其他煤出口量为294.43万吨，同比增0.46%;无烟煤出口量为28.15万吨，同比增103.69%。 10月，蒙古国烟煤出口量为626.86万吨，同比增1.35%，环比降28.46%;褐煤出口53.76万吨，同比增2.23%，环比降17.48%;其他煤出口量为26.02万吨，同比降52.05%，环比增12.46%;无烟煤出口量为5.11万吨，同比增255.77%，环比增25.55%。", "release_time": "2025-11-11", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1196015-1.html"}
{"category": "研究前沿", "title": "金刚石二维量子缺陷阵列实现量子传感突破", "short_summary": "研究首次实现金刚石内二维量子缺陷阵列的纠缠操控，为固态量子传感开辟新路径。", "detailed_summary": "研究首次实现金刚石内二维量子缺陷阵列的纠缠操控，为固态量子传感开辟新路径。\n（1）加州大学圣塔芭芭拉分校团队利用实验室培育金刚石中的氮空位中心自旋量子比特开展量子传感研究；\n（2）研究人员首次实现二维高密度量子缺陷阵列的精确排布与纠缠操控，突破传统单量子比特传感局限；\n（3）该技术通过量子纠缠提升信噪比，可实现超越标准量子极限的精密测量；\n（4）固态金刚石传感器易集成于生物系统和新材料研究，克服气相原子传感器的空间限制难题；\n（5）当前挑战在于量子比特位置随机分布，未来需实现规则阵列以进一步提升传感性能。", "raw_content": "The quest to create useful quantum technologies begins with a deep understanding of the strange laws that govern quantum behavior and how those principles can be applied to real materials. At the University of California, Santa Barbara, physicist Ania Jayich, Bruker Endowed Chair in Science and Engineering, Elings Chair in Quantum Science, and co-director of the NSF Quantum Foundry, leads a lab where the key material is laboratory-grown diamond.  Working at the intersection of quantum physics and materials science, Jayich and her team study how precise atomic-scale imperfections in diamond -- known as spin qubits -- can be engineered for advanced quantum sensing. Among the group's standout researchers, Lillian Hughes, who recently completed her Ph.D. and is heading to Caltech for postdoctoral work, made a major breakthrough in this field. Through three co-authored papers -- one in PRX in March and two in Nature in October -- Hughes demonstrated for the first time that not just individual qubits but two-dimensional ensembles of many quantum defects can be organized and entangled inside diamond. This achievement marks a milestone toward solid-state systems that deliver a measurable quantum advantage in sensing, opening a new path for the next generation of quantum devices. Engineering Quantum Defects in Diamond \"We can create a configuration of nitrogen-vacancy (NV) center spins in the diamonds with control over their density and dimensionality, such that they are densely packed and depth-confined into a 2D layer,\" Hughes explained. \"And because we can design how the defects are oriented, we can engineer them to exhibit non-zero dipolar interactions.\" This accomplishment formed the basis of the PRX study, \"A strongly interacting, two-dimensional, dipolar spin ensemble in (111)-oriented diamond.\" An NV center consists of a nitrogen atom replacing a carbon atom and an adjacent vacancy where a carbon atom is missing. \"The NV center defect has a few properties, one of which is a degree of freedom called a spin -- a fundamentally quantum mechanical concept. In the case of the NV center, the spin is very long lived,\" said Jayich. \"These long-lived spin states make NV centers useful for quantum sensing. The spin couples to the magnetic field that we're trying to sense.\" From MRI to Quantum Sensing The concept of using spin as a sensor dates back to the development of magnetic resonance imaging (MRI) in the 1970s. Jayich explained that MRI works by controlling the alignment and energy states of protons and detecting the signals they emit as they relax, forming an image of internal structures.  \"Previous quantum-sensing experiments conducted in a solid-state system have all made use of single spins or non-interacting spin ensembles,\" Jayich said. \"What's new here is that, because Lillian was able to grow and engineer these very strongly interacting dense spin ensembles, we can actually leverage the collective behavior, which provides an extra quantum advantage, allowing us to use the phenomena of quantum entanglement to get improved signal-to-noise ratios, providing greater sensitivity and making a better measurement possible.\" Why Diamond Matters for Quantum Sensors The type of entanglement-assisted sensing demonstrated by Hughes has been shown before, but only in gas-phase atomic systems. \"Ideally, for many target applications, your sensor should be easy to integrate and to bring close to the system under study,\" Jayich said. \"It is much easier to do that with a solid-state material, like diamond, than with gas-phase atomic sensors on which, for instance, GPS is based. Furthermore, atomic sensors require significant auxiliary hardware to confine and control, such as vacuum chambers and numerous lasers, making it hard to bring an atomic sensor within nanometer-scale proximity to a protein, for instance, prohibiting high-spatial-resolution imaging.\" Jayich's team is especially focused on using diamond-based quantum sensors to study electronic properties of materials. \"You can place material targets into nanometer-scale proximity of a diamond surface, thus bringing them really close to sub-surface NV centers,\" Jayich explained. \"So it's very easy to integrate this type of diamond quantum sensor with a variety of interesting target systems. That's a big reason why this platform is so exciting.\" Probing Materials and Biology with Quantum Precision \"A solid-state magnetic sensor of this kind could be very useful for probing, for instance, biological systems,\" Jayich said. \"Nuclear magnetic resonance [NMR] is based on detecting very small magnetic fields coming from the constituent atoms in, for example, biological systems. Such an approach is also useful if you want to understand new materials, whether electronic materials, superconducting materials, or magnetic materials that could be useful for a variety of applications.\" Overcoming Quantum Noise  Every measurement has a limit set by noise, which restricts precision. A fundamental form of this noise, called quantum projection noise, sets what's known as the standard quantum limit -- the point beyond which unentangled sensors cannot improve. If scientists can engineer specific interactions between sensors, they can surpass this boundary. One way to do this is through spin squeezing, which correlates quantum states to reduce uncertainty. \"It's as if you were trying to measure something with a meter stick having gradations a centimeter apart; those centimeter-spaced gradations are effectively the amplitude of the noise in your measurement. You would not use such a meter stick to measure the size of an amoeba, which is much smaller than a centimeter,\" Jayich said. \"By squeezing -- silencing the noise -- you effectively use quantum mechanical interactions to 'squish' that meter stick, effectively creating finer gradations and allowing you to measure smaller things more precisely.\" Amplifying Quantum Signals The team's second Nature paper details another strategy for improving measurement: signal amplification. This approach strengthens the signal without increasing noise. In the meter stick analogy, amplifying the signal makes the amoeba appear larger so that even coarse measurement markings can capture it accurately. Looking ahead, Jayich is confident about applying these principles in real-world systems. \"I don't think the foreseen technical challenges will prevent demonstrating a quantum advantage in a useful sensing experiment in the near future,\" she said. \"It's mostly about making the signal amplification stronger or increasing the amount of squeezing. One way to do that is to control the position of the spins in the 2Dxy plane, forming a regular array.\" \"There's a materials challenge here, in that, because we can't dictate exactly where the spins will incorporate, they incorporate in somewhat random fashion within a plane,\" Jayich added. \"That's something we're working on now, so that eventually we can have a grid of these spins, each placed a specific distance from each other. That would address an outstanding challenge to realizing practical quantum advantage in sensing.\"", "release_time": "2025-11-12", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/11/251111010002.htm"}
{"category": "研究前沿", "title": "新研究用数学证明宇宙并非计算机模拟", "short_summary": "UBC科学家应用数学定理证明，现实本质基于非算法理解，宇宙不可能是模拟。", "detailed_summary": "UBC科学家应用数学定理证明，现实本质基于非算法理解，宇宙不可能是模拟。\n(1) UBC奥卡纳根分校研究团队在《全息物理应用杂志》发表论文，从数学上论证宇宙不可能是计算机模拟。\n(2) 研究基于量子引力理论和哥德尔不完备定理，证明任何一致的物理现实模型都无法仅通过计算完全描述。\n(3) 核心论点是现实底层存在\"非算法理解\"，这比生成时空的计算定律更基本，且无法被算法模拟。\n(4) 研究将长期属于哲学思辨的\"模拟假说\"置于可检验的数学物理框架中，提供了决定性反驳。", "raw_content": "The idea that our universe might be nothing more than an elaborate computer simulation has been a favorite theme in science fiction for decades. Yet new research from UBC Okanagan suggests that not only is this concept implausible -- it is mathematically impossible.  Dr. Mir Faizal, an Adjunct Professor at UBC Okanagan's Irving K. Barber Faculty of Science, and his collaborators, Drs. Lawrence M. Krauss, Arshid Shabir, and Francesco Marino, have shown that the underlying fabric of reality operates in a way no computer could ever replicate. Their study, published in the Journal of Holography Applications in Physics, doesn't just dispute the idea of a simulated universe like The Matrix. It goes further, demonstrating that the cosmos itself is built upon a kind of understanding that lies outside the reach of any algorithm. The Simulation Hypothesis Meets Mathematics \"It has been suggested that the universe could be simulated. If such a simulation were possible, the simulated universe could itself give rise to life, which in turn might create its own simulation. This recursive possibility makes it seem highly unlikely that our universe is the original one, rather than a simulation nested within another simulation,\" says Dr. Faizal. \"This idea was once thought to lie beyond the reach of scientific inquiry. However, our recent research has demonstrated that it can, in fact, be scientifically addressed.\" The team's findings rest on the evolving understanding of what reality truly is. Physics has moved far beyond Isaac Newton's view of solid objects moving through space. Einstein's theory of relativity replaced that classical model, and quantum mechanics transformed it yet again. Now, at the forefront of theoretical physics, quantum gravity proposes that even space and time are not fundamental elements. Instead, they arise from something deeper -- pure information. The Hidden Realm Beneath Reality Physicists describe this informational layer as a \"Platonic realm,\" a mathematical foundation more real than the physical world we perceive. According to the new research, it is from this realm that space and time themselves emerge.  However, the scientists demonstrated that even this information-based structure cannot fully describe reality through computation alone. By applying advanced mathematical principles, including Gödel's incompleteness theorem, they proved that any consistent and complete model of existence requires what they call \"non-algorithmic understanding.\" To grasp this idea, imagine how a computer works -- it follows a set of defined instructions step by step. Yet, some truths exist that cannot be reached by following any sequence of logical operations. These are known as \"Gödelian truths,\" and while they are real, they cannot be proven using computation. Where Computation Fails Consider the statement, \"This true statement is not provable.\" If it were provable, it would be false, contradicting logic. If it cannot be proven, then it is true, which means any logical system attempting to prove it is incomplete. In either case, computation alone falls short. \"We have demonstrated that it is impossible to describe all aspects of physical reality using a computational theory of quantum gravity,\" says Dr. Faizal. \"Therefore, no physically complete and consistent theory of everything can be derived from computation alone. Rather, it requires a non-algorithmic understanding, which is more fundamental than the computational laws of quantum gravity and therefore more fundamental than spacetime itself.\" Why the Universe Cannot Be Simulated If the underlying rules of the Platonic realm seem similar to those governing a computer simulation, could that realm itself be simulated? The answer, according to the researchers, is no.  \"Drawing on mathematical theorems related to incompleteness and indefinability, we demonstrate that a fully consistent and complete description of reality cannot be achieved through computation alone,\" explains Dr. Faizal. \"It requires non-algorithmic understanding, which by definition is beyond algorithmic computation and therefore cannot be simulated. Hence, this universe cannot be a simulation.\" Co-author Dr. Lawrence M. Krauss notes that the implications of this finding extend deep into the foundations of physics. \"The fundamental laws of physics cannot be contained within space and time, because they generate them. It has long been hoped, however, that a truly fundamental theory of everything could eventually describe all physical phenomena through computations grounded in these laws. Yet we have demonstrated that this is not possible. A complete and consistent description of reality requires something deeper -- a form of understanding known as non-algorithmic understanding.\" Reality Beyond Algorithms As Dr. Faizal summarizes, \"Any simulation is inherently algorithmic -- it must follow programmed rules. But since the fundamental level of reality is based on non-algorithmic understanding, the universe cannot be, and could never be, a simulation.\" For years, the simulation hypothesis was regarded as untestable, confined to the realms of philosophy and speculative fiction. This new research, however, anchors it firmly in mathematical and physical theory -- delivering what may be the final, definitive answer to one of science's most intriguing questions.", "release_time": "2025-11-10", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251110021052.htm"}
{"category": "研究前沿", "title": "万宝年院士携学子共探聚变物理前沿", "short_summary": "万宝年院士分享聚变发展历程，与学子探讨前沿议题并弘扬科学家精神。", "detailed_summary": "万宝年院士分享聚变发展历程，与学子探讨前沿议题并弘扬科学家精神。\n(1) 等离子体所举办“追光者说”活动，万宝年院士与学子共探聚变物理前沿。\n(2) 活动包括“与光同行”科研摄影展，展现科研工作的严谨与诗意。\n(3) 万宝年院士参观研究生科研海报并进行亲切交流，关注科研细节。\n(4) 院士作大会报告，回顾中国可控核聚变从无到有、部分领跑的发展历程。\n(5) 在“前沿议题共探”环节进行多维思想碰撞，探讨聚变物理核心挑战。\n(6) 活动为优秀海报获奖者颁奖，肯定学子的研究成果与创新精神。", "raw_content": "等离子体所举办“弘扬科学家精神系列之追光者说——万宝年院士携学子共探聚变物理前沿”活动  2025-11-10 | 作者：文/张永威、李解 图/孙毅、徐梦臣、王志林、鲁润 |【大 中 小】【打印】【关闭】   11月6日下午，由中国科学院等离子体物理研究所研究生联合党支部与研究生会共同主办的“弘扬科学家精神系列之追光者说——万宝年院士携学子共探聚变物理前沿”活动，在EAST控制大厅三楼圆满举行。中国科学院院士万宝年、研究生党委书记、处长王辉研究员、等离子体所托卡马克物理实验研究室主任丁锐研究员以及等离子体物理研究所其他骨干研究员和研究生处教育主管出席本次活动。本次交流以弘扬科学家精神为核心，围绕聚变物理前沿展开深度探讨。活动伊始，现场同步展出的“与光同行”科研摄影展率先吸引了众人的目光。这些由等离子体所学子精心捕捉的影像，以镜头为笔，以光影为墨，将科研工作中那些严谨与诗意交织的瞬间定格为永恒。每一帧画面，不仅是视觉的呈现，更是精神的映照；不仅是技术的捕捉，更是初心的回响，生动展现了新时代青年科技工作者“赤子逐梦、与光同行”的信念与力量。在学术成果展示环节，万宝年院士逐一观看研究生科研海报，并与同学们亲切交流。他细致询问研究细节、耐心听取汇报，展现出学术领军人对青年一代的深切关怀。这些互动不仅是对科研细节的关注，更是科研精神代际传承的生动写照，仿佛以另一种形式延续着“与光同行”的记录，刻画下等离子体所学子在攀登科学高峰道路上的坚实足迹。大会报告现场，万宝年院士以亲历者与推动者的视角，带领师生回顾了中国可控核聚变从无到有、从跟跑到并跑乃至部分领跑的发展历程。他讲述了关键节点背后的科研故事，呈现了一代代科学家如何将“人造太阳”的梦想，一步步转化为现实的科学工程。在“前沿议题共探”环节，打破了单向传递的讲座局限，让多维思想碰撞成为核心。万宝年院士围绕聚变物理核心挑战，与现场师生共同探讨可能的突破路径，激发新的科研灵感。活动最后，万宝年院士为本次活动的优秀海报获奖者颁奖，对同学们的研究成果与创新精神给予了充分肯定。参观海报展和摄影展万宝年院士作报告报告交流优秀海报颁奖合影", "release_time": "2025-11-12", "source_institution": "等离子体物理研究所", "url": "http://www.ipp.ac.cn/xwdt/kydt/202511/t20251112_796476.html"}
{"category": "研究前沿", "title": "第46届CBM合作组会议在兰州召开", "short_summary": "多国专家聚首兰州，探讨核物质相结构等前沿物理课题与合作计划。", "detailed_summary": "多国专家聚首兰州，探讨核物质相结构等前沿物理课题与合作计划。\n（1）第46届压缩重子物质合作组会议近日于兰州召开。\n（2）来自中国、德国、日本等13个国家约100余名科研人员参会。\n（3）会议聚焦核物质相结构、状态方程及中高能重离子碰撞等前沿领域进展。\n（4）深入讨论了CBM实验的探测器研制、软件开发和未来工作计划。\n（5）会议由中国科学院近代物理研究所主办，并得到多项科学院项目支持。", "raw_content": "近日，“第46届压缩重子物质（CBM）合作组会议”在兰州召开。共有来自中国、德国、日本、匈牙利、波兰、捷克、印度等13个国家的约100余名科研人员参加了会议。本次会议主要讨论交流了核物质相结构、核物质状态方程、中高能重离子碰撞等研究领域最新实验进展和未来发展方向。与会专家还深入讨论了CBM实验的探测系统研制、软件开发及数据分析进展与将来的工作计划。此外，获得中国科学院国际交流计划（PIFI）项目的杰出团队专家和青年学者还参与了“PIFI Day”学术活动。CBM实验是基于德国反质子与离子研究装置（FAIR）正在筹划的新一代高能核物理研究实验。本次会议由中国科学院近代物理研究所主办、华中师范大学协办。会议得到了中国科学院PIFI项目、中国科学院西部之光项目、兰州大学、中国科学院西北生态环境资源研究院的支持。图：会议合影（核物质相结构室   供稿）", "release_time": "2025-11-10", "source_institution": "近代物理研究所", "url": "http://www.imp.cas.cn/sndt2017/202511/t20251110_8009362.html"}
{"category": "研究前沿", "title": "MIT量子计划启动，推动跨学科量子技术研究", "short_summary": "MIT启动量子计划，整合跨学科资源推动量子技术实用化发展。", "detailed_summary": "MIT启动量子计划，整合跨学科资源推动量子技术实用化发展。\n（1）MIT启动量子计划（QMIT），由化学教授Danna Freedman担任首任主任；\n（2）旨在整合校内研究力量与产业专家，推动量子技术在科学、工业和国家安全领域的应用；\n（3）计划建立校园量子中心，并与林肯实验室合作开展国家安全相关研究；\n（4）研究重点包括量子计算、传感、模拟和算法等跨学科领域；\n（5）预计将推动医疗、物理、网络安全等多个领域的突破性发展。", "raw_content": "Danna Freedman is seeking the early adopters.She is the faculty director of the nascent MIT Quantum Initiative, or QMIT. In this new role, Freedman is giving shape to an ambitious, Institute-wide effort to apply quantum breakthroughs to the most consequential challenges in science, technology, industry, and national security.The interdisciplinary endeavor, the newest of MIT President Sally Kornbluth’s strategic initiatives, will bring together MIT researchers and domain experts from a range of industries to identify and tackle practical challenges wherever quantum solutions could achieve the greatest impact.“We’ve already seen how the breadth of progress in quantum has created opportunities to rethink the future of security and encryption, imagine new modes of navigation, and even measure gravitational waves more precisely to observe the cosmos in an entirely new way,” says Freedman, the Frederick George Keyes Professor of Chemistry. “What can we do next? We’re investing in the promise of quantum, and where the legacy will be in 20 years.”QMIT — the name is a nod to the “qubit,” the basic unit of quantum information — will formally launch on Dec. 8 with an all-day event on campus. Over time, the initiative plans to establish a physical home in the heart of campus for academic, public, and corporate engagement with state-of-the-art integrated quantum systems. Beyond MIT’s campus, QMIT will also work closely with the U.S. government and MIT Lincoln Laboratory, applying the lab’s capabilities in quantum hardware development, systems engineering, and rapid prototyping to national security priorities.“The MIT Quantum Initiative seizes a timely opportunity in service to the nation’s scientific, economic, and technological competitiveness,” says Ian A. Waitz, MIT’s vice president for research. “With quantum capabilities approaching an inflection point, QMIT will engage students and researchers across all our schools and the college, as well as companies around the world, in thinking about what a step change in sensing and computational power will mean for a wide range of fields. Incredible opportunities exist in health and life sciences, fundamental physics research, cybersecurity, materials science, sensing the world around us, and more.”Identifying the right questionsQuantum phenomena are as foundational to our world as light or gravity. At an extremely small scale, the interactions of atoms and subatomic particles are controlled by a different set of rules than the physical laws of the macro-sized world. These rules are called quantum mechanics.“Quantum, in a sense, is what underlies everything,” says Freedman.By leveraging quantum properties, quantum devices can process information at incredible speed to solve complex problems that aren’t feasible on classical supercomputers, and to enable ultraprecise sensing and measurement. Those improvements in speed and precision will become most powerful when optimized in relation to specific use cases, and as part of a complete quantum system. QMIT will focus on collaboration across domains to co-develop quantum tools, such as computers, sensors, networks, simulations, and algorithms, alongside the intended users of these systems.As it develops, QMIT will be organized into programmatic pillars led by top researchers in quantum including Paola Cappellaro, Ford Professor of Engineering and professor of nuclear science and engineering and of physics; Isaac Chuang, Julius A. Stratton Professor in Electrical Engineering and Physics; Pablo Jarillo-Herrero, Cecil and Ida Green Professor of Physics; William Oliver, Henry Ellis Warren (1894) Professor of Electrical Engineering and Computer Science and professor of physics; Vladan Vuletić, Lester Wolfe Professor of Physics; and Jonilyn Yoder, associate leader of the Quantum-Enabled Computation Group at MIT Lincoln Laboratory.While supporting the core of quantum research in physics, engineering, mathematics, and computer science, QMIT promises to expand the community at its frontiers, into astronomy, biology, chemistry, materials science, and medicine.“If you provide a foundation that somebody can integrate with, that accelerates progress a lot,” says Freedman. “Perhaps we want to figure out how a quantum simulator we’ve built can model photosynthesis, if that’s the right question — or maybe the right question is to study 10 failed catalysts to see why they failed.”“We are going to figure out what real problems exist that we could approach with quantum tools, and work toward them in the next five years,” she adds. “We are going to change the forward momentum of quantum in a way that supports impact.”The MIT Quantum Initiative will be administratively housed in the Research Laboratory of Electronics (RLE), with support from the Office of the Vice President for Research (VPR) and the Office of Innovation and Strategy.QMIT is a natural expansion of MIT’s Center for Quantum Engineering (CQE), a research powerhouse that engages more than 80 principal investigators across the MIT campus and Lincoln Laboratory to accelerate the practical application of quantum technologies.“CQE has cultivated a tremendously strong ecosystem of students and researchers, engaging with U.S. government sponsors and industry collaborators, including through the popular Quantum Annual Research Conference (QuARC) and professional development classes,” says Marc Baldo, the Dugald C. Jackson Professor in Electrical Engineering and director of RLE.“With the backing of former vice president for research Maria Zuber, former Lincoln Lab director Eric Evans, and Marc Baldo, we launched CQE and its industry membership group in 2019 to help bridge MIT’s research efforts in quantum science and engineering,” says Oliver, CQE’s director, who also spent 20 years at Lincoln Laboratory, most recently as a Laboratory Fellow. “We have an important opportunity now to deepen our commitment to quantum research and education, and especially in engaging students from across the Institute in thinking about how to leverage quantum science and engineering to solve hard problems.”Two years ago, Peter Fisher, the Thomas A. Frank (1977) Professor of Physics, in his role as associate vice president for research computing and data, assembled a faculty group led by Cappellaro and involving Baldo, Oliver, Freedman, and others, to begin to build an initiative that would span the entire Institute. Now, capitalizing on CQE’s success, Oliver will lead the new MIT Quantum Initiative’s quantum computing pillar, which will broaden the work of CQE into a larger effort that focuses on quantum computing, industry engagement, and connecting with end users.The “MIT-hard” problemQMIT will build upon the Institute’s historic leadership in quantum science and engineering. In the spring of 1981, MIT hosted the first Physics of Computation Conference at the Endicott House, bringing together nearly 50 physics and computing researchers to consider the practical promise of quantum — an intellectual moment that is now widely regarded as the kickoff of the second quantum revolution. (The first was the fundamental articulation of quantum mechanics 100 years ago.)Today, research in quantum science and engineering produces a steady stream of “firsts” in the lab and a growing number of startup companies.In collaboration with partners in industry and government, MIT researchers develop advances in areas like quantum sensing, which involves the use of atomic-scale systems to measure certain properties, like distance and acceleration, with extreme precision. Quantum sensing could be used in applications like brain imaging devices that capture more detail, or air traffic control systems with greater positional accuracy.Another key area of research is quantum simulation, which uses the power of quantum computers to accurately emulate complex systems. This could fuel the discovery of new materials for energy-efficient electronics or streamline the identification of promising molecules for drug development.“Historically, when we think about the most well-articulated challenges that quantum will solve,” Freedman says, “the best ones have come from inside of MIT. We’re open to technological solutions to problems, and nontraditional approaches to science. In many respects, we are the early adopters.”But she also draws a sharp distinction between blue-sky thinking about what quantum might do, and the deeply technical, deeply collaborative work of actually drawing the roadmap. “That’s the ‘MIT-hard’ problem,” she says.The QMIT launch event on Dec. 8 will feature talks and discussions featuring MIT faculty, including Nobel laureates and industry leaders.", "release_time": "2025-11-11", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/leading-quantum-inflection-point-1110"}
{"category": "研究前沿", "title": "近代物理所三位研究员荣获束流冷却国际大奖", "short_summary": "束流冷却国际研讨会揭晓Dieter Möhl奖，近代物理所三位科学家分获殊荣。", "detailed_summary": "束流冷却国际研讨会揭晓Dieter Möhl奖，近代物理所三位科学家分获殊荣。\n（1）第十五届束流冷却国际研讨会（COOL’25）在美国石溪大学举办，会议聚焦电子冷却等前沿方向。\n（2）近代物理所杨晓东、赵贺、汪寒冰三位研究员荣获2025年度Dieter Möhl奖。\n（3）杨晓东获“终身成就类”表彰，肯定其在电子冷却领域近30年的系统性贡献。\n（4）赵贺因基于储存环的电子冷却原创研究获奖，为高能束流冷却提供新思路。\n（5）汪寒冰因开发离子束肖特基谱模拟工具获奖，为理解束流特性提供关键技术支撑。\n（6）该奖项于2013年设立，旨在表彰束流冷却领域的创新成果，此次获奖彰显我国在该领域的国际影响力。", "raw_content": "近日，第十五届束流冷却及相关主题国际研讨会（COOL’25）在美国石溪大学圆满落幕。会议期间，2025年度Dieter Möhl奖正式揭晓。近代物理所杨晓东研究员、赵贺研究员以及汪寒冰副研究员凭借在束流冷却研究领域的重要贡献携手获奖。这是该奖项设立以来，近代物理所科研人员第二次获奖，此前冒立军研究员曾于2019年荣获此奖。杨晓东研究员此次荣获该奖项“终身成就类”表彰，以肯定他在兰州储存环电子冷却领域近30年的持续深耕与系统性贡献。他自1994年参与国家重大科学工程—兰州重离子加速器冷却储存环（HIRFL-CSR）项目以来，始终扎根电子冷却装置技术前沿，并在HIAF、EicC等大科学装置中参加关键部件研制，以及电子冷却与束内散射方面的研究。赵贺研究员因在束流冷却领域的重大原创性贡献获奖；其基于储存环的电子冷却研究成果为高能束流冷却的技术革新提供了新的思路和方法。汪寒冰副研究员凭借离子束肖特基谱模拟与分析的系统性工作获奖。他开发的专用模拟工具，为理解储存、聚束及冷却过程中离子束的肖特基谱特性提供了关键技术支撑。本届会议由美国石溪大学与布鲁克海文国家实验室联合主办，聚焦电子冷却、随机冷却、激光冷却、缪子冷却、光学随机冷却及相干电子冷却等前沿方向，吸引了全球11个研究机构、5所高校的40余位学者参会。DieterMöhl奖于2013年由CERN支持设立，以纪念在束流冷却领域做出杰出贡献的DieterMöhl博士。该奖项由国际束流冷却领域的知名专家提名，通过束流冷却国际会议顾问委员会最终评选，在束流冷却国际会议期间颁发，用于表彰在带电粒子冷却物理和技术领域取得具有影响力的创新成果。三位科研人员的获奖，肯定了我国在束流冷却领域不断积累的科研实力与国际影响力。图1：现场颁奖（杨晓东）图2：现场颁奖（赵贺）图3：现场颁奖（汪寒冰）（党委办公室    供稿）", "release_time": "2025-11-11", "source_institution": "近代物理研究所", "url": "http://www.imp.cas.cn/sndt2017/202511/t20251110_8009431.html"}
{"category": "研究前沿", "title": "Heat Pumps Watch组织推动热泵研究与传播", "short_summary": "该组织收集全球热泵研究，通过系列问答助力德国热能转型与气候目标。", "detailed_summary": "该组织收集全球热泵研究，通过系列问答助力德国热能转型与气候目标。\n（1）Heat Pumps Watch组织致力于收集和通俗化呈现全球热泵研究新见解，以支持不同目标群体。\n（2）热能转型对德国气候目标至关重要，因供热占德国最终能源消耗超50%，热泵电气化是核心。\n（3）该组织首个举措是推出18部分系列，解答热泵常见问题，涵盖现有建筑应用至AI集成可能性。\n（4）系列项目得到气候中立基金会支持，旨在以易懂方式呈现事实。\n（5）组织由咨询委员会战略支持，成员来自非营利、终端消费者、工业、通信及研发等领域专家。", "raw_content": "“Without a successful heat transition, there can be no successful climate transition, as over 50 percent of final energy consumption in Germany is attributed to heat,” said Prof. Dr. Peter Schossig, Head of the Heat and Buildings Department at Fraunhofer ISE and advisory board member at Heat Pumps Watch. “The electrification through heat pumps is crucial in this regard. Research institutions worldwide are continuously generating new insights. Heat Pumps Watch collects these and presents them in an understandable manner for various target groups.” The organization’s first initiative is an 18-part series addressing the most frequently asked questions about heat pumps, supported by the Climate Neutrality Foundation. This series explains the facts concerning various aspects, from heat pumps in existing buildings to possibilities for AI integration. Heat Pumps Watch is strategically supported by an advisory board. Experts Jan Rosenow, Tanja Loitz, Thomas Nowak, Anja Floetenmeyer-Woltmann, and Peter Schossig represent critical viewpoints from the fields of non-profit work, end consumers, industry, communication, and research and development.", "release_time": "2025-11-11", "source_institution": "德国弗劳恩霍夫协会太阳能系统研究所", "url": "http://www.ise.fraunhofer.de/en/press-media/press-releases/2025/fraunhofer-ise-spin-off-heat-pumps-watch-provides-neutral-facts-about-heat-pumps.html"}
{"category": "产业应用", "title": "新型紧凑短脉冲激光器问世，效率提升超两倍", "short_summary": "斯图加特大学团队研发高效紧凑短脉冲激光器，效率达80%，尺寸小巧应用广泛。", "detailed_summary": "斯图加特大学团队研发高效紧凑短脉冲激光器，效率达80%，尺寸小巧应用广泛。\n（1）斯图加特大学团队研发出新型紧凑型短脉冲激光器，效率高达80%，是现有技术（约35%）的两倍以上。\n（2）该设备采用多程策略，使光脉冲在单个短晶体中多次穿行，解决了高效率和宽带宽难以在小系统中兼顾的挑战。\n（3）系统体积小巧，仅需五个组件，可产生短于50飞秒的脉冲，有望替代大型昂贵的传统激光系统。\n（4）该技术可应用于精密制造、医疗成像、量子研究、气体传感和环境监测等多个产业领域。\n（5）研究获得了德国多个联邦和州级部门及基金会的资助，由大学与企业合作完成。", "raw_content": "Lasers that produce ultrashort light pulses deliver exceptional precision for manufacturing, medicine, and scientific studies. The catch is that high-efficiency short-pulse systems usually take up significant space and come with high costs. A team at the University of Stuttgart, working with Stuttgart Instruments GmbH, has introduced a compact alternative. Their device is more than twice as efficient as many existing setups, small enough to rest in a hand, and designed for broad use. The approach is reported in Nature.  \"With our new system, we can achieve levels of efficiency that were previously almost unattainable,\" says Prof. Harald Giessen, Head of the 4th Physics Institute at the University of Stuttgart. In tests, the team showed that short-pulse lasers can fundamentally reach 80% efficiency. In practical terms, 80% of the input power becomes usable output. \"For comparison: current technologies achieve only about 35% -- which means they lose much of their efficiency and are correspondingly expensive,\" explains Giessen. A lot of energy in an extremely short time Short-pulse lasers emit bursts that last for only nano-, pico-, or femtoseconds (i.e., a few billionths to quadrillionths of a second). Because the pulses are so brief, a large amount of energy can be delivered to a tiny spot almost instantly. The setup combines a pump laser with the short-pulse laser. The pump laser delivers light energy to a special crystal. This crystal drives the process by transferring energy from the pump beam to the ultrashort signal pulse. In doing so, the incoming light particles are converted to infrared light. Infrared enables experiments, measurements, or production steps that visible light cannot achieve. In industry, short-pulse lasers are used in production -- for example, for precise and gentle material processing. They are also employed in medical imaging and in quantum research for exceptionally exact measurements at the molecular scale. \"Designing short-pulse lasers efficiently remains an unsolved challenge,\" explains Dr. Tobias Steinle, lead author of the study. \"In order to generate short pulses, we need to amplify the incoming light beam and cover a wide range of wavelengths.\" Until now, it has not been possible to combine both properties simultaneously in a small and compact optical system.\" Wide-bandwidth laser amplifiers typically need crystals that are very short and thin. High-efficiency amplifiers, in contrast, favor much longer crystals. One workaround is to connect several short crystals in series, an approach already explored in research. Whatever the choice, the timing between the pump and signal pulses must stay synchronized. New multipass concept The team addresses this trade-off with a multipass strategy. Rather than relying on one long crystal or stacking many short ones, they run the light repeatedly through a single short crystal inside an optical parametric amplifier. After each pass, the separated pulses are carefully realigned to maintain synchronization. The result is a system that produces pulses shorter than 50 femtoseconds, takes up only a few square centimeters, and uses just five components. \"Our multipass system demonstrates that extremely high efficiencies need not to come at the expense of bandwidth,\" explains Steinle. \"It can replace large and expensive laser systems with high power losses, which were previously required to amplify ultrashort pulses.\" The design can also be tuned for wavelengths beyond the infrared and adapted to different crystals and pulse durations. Building on this concept, the researchers aim to create small, lightweight, compact, portable, and tunable lasers that can set wavelengths with precision. Likely use cases include medicine, analytical techniques, gas sensing, and environmental monitoring. Financial support came from the Federal Ministry of Research, Technology and Space (BMFTR) through the KMU-Innovativ program, the Federal Ministry for Economic Affairs and Energy (BMWE), the Baden-Wuerttemberg Ministry of Science, Research and the Arts, the German Research Foundation (DFG), the Carl Zeiss Foundation, the Baden-Wuerttemberg Foundation, the Center for Integrated Quantum Science and Technology (IQST), and the Innovation Campus Mobility of the Future (ICM). The work was carried out by the 4th Physics Institute of the University of Stuttgart in collaboration with Stuttgart Instruments GmbH under the MIRESWEEP project (a novel, cost-effective tunable mid-infrared laser source for analytical applications).", "release_time": "2025-11-09", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251108083854.htm"}
{"category": "政策计划", "title": "GWEC呼吁日本改革海上风电拍卖机制", "short_summary": "全球风能理事会建议日本调整海上风电拍卖框架以推动项目落地。", "detailed_summary": "全球风能理事会建议日本调整海上风电拍卖框架以推动项目落地。\n(1) 全球风能理事会发布白皮书，指出日本前三轮海上风电拍卖结果不理想，项目面临严重财务挑战。\n(2) 报告提出短期和长期建议，核心改革领域包括拍卖框架、承购机制和其他市场瓶颈。\n(3) 拍卖改革需优化评估标准，并考虑引入两阶段拍卖结构以提高确定性。\n(4) 承购机制改革建议审查价格上限，并向差价合约或上网电价补贴等更稳定模式过渡。\n(5) 需解决认证透明度、限电补偿等瓶颈，并建立基于投运日期的目标以强化供应链。", "raw_content": "Tokyo, Japan, 10 Nov 2025 | Japan should establish a public-private forum to help shape the country’s offshore wind future and restructure its offshore wind auctions to ensure project viability, says a new white paper from The Global Wind Energy Council (GWEC), produced in partnership with renewable energy consultancy OWC.   The paper, Unlocking Japan’s Offshore Wind Potential: Strategic Pathways to Overcome Market Bottlenecks and Drive Industrial Growth, outlines how Japan can align industry to ensure project viability through to final investment decisions, as well as how to align industry and policymakers.   Japan has held three rounds of offshore wind auctions. The sole bidder from Round 1 has since withdrawn, and the winners of Rounds 2 and 3 are facing severe financial challenges around the development of their projects. The project trajectories following these first auctions highlight the need for timely reform, with a more effective auction design a priority. A new approach must reflect industry feedback and keep pace with a changing market.   Without proper restructuring of Japan’s offshore wind auction framework, the country risks significant delays in achieving its decarbonisation and energy security goals, which are critical to ensuring timely project delivery and unlocking the broader economic benefits of job creation.   “Japan holds vast offshore wind potential and cannot afford to miss its chance to become an offshore wind leader especially within the Asia-Pacific region. To put the industry back on a growth trajectory, Japan must pursue auction reforms, reassess offtake mechanisms, and remove critical market bottlenecks, as outlined in GWEC’s white paper. By taking these steps, there is no doubt that offshore wind will remain the backbone of Japan’s power mix on its path toward carbon neutrality by 2050. Once Japan recalibrates its course and regains momentum in offshore wind development, unlocking this potential will deliver clean, affordable, and locally produced renewable energy, and also stimulate local economies through job creation, revitalised regional industries, and new opportunities for coastal communities.”   Takeshi Matsuki, Japan Country Manager, GWEC     “OWC is pleased to contribute to this important white paper focused on unlocking Japan’s offshore wind potential. Japan stands at a pivotal moment in its clean energy transition, and offshore wind has emerged as a central pillar of its strategy. While frameworks such as Round 1–3 tenders have laid the groundwork, recent developments have highlighted the need for structural and institutional reform to ensure project delivery and investor confidence. To enable the stable and scalable deployment of offshore wind, Japan needs to address three critical areas: auction framework, offtake mechanisms, and other market bottlenecks. Timely auction reform, including evaluation criteria optimization will be key to accelerating capacity build-out. Enhancing offtake mechanisms—such as updating price caps and transitioning to more bankable schemes — will help align bids with market realities. In parallel, resolving bottlenecks around certification, curtailment, and supply chain visibility will be essential to unlock investment and promote regional economic development.”   Masataka Nakagawa, Country Manager – Japan, OWC     GWEC’s white paper outlines both the short-and-long-term recommendations to strengthen Japan’s offshore wind framework across three key areas: (1) the auction framework, (2) offtake mechanisms, and (3) other market bottlenecks.   The short-term measures can be implemented without legislative amendments and focus on the re-tendering of Round 1 and the upcoming auction round, while the long-term measures are envisioned for Round 5 and beyond to ensure sustainable market growth and strengthen investor confidence.   Under auction reforms, it is critical to redesign the offshore wind auctions through timely and structured dialogue between the public and private sectors, along with optimisation of evaluation criteria to balance price and non-price factors. In the longer term, improvements to the centralised model and the introduction of a two-stage auction structure in territorial waters are needed to provide greater certainty for developers and strengthen business cases at the auction stage.   On offtake mechanisms, it is essential to review current price limits to prevent unrealistic bids and ensure alignment with prevailing market conditions. The reform of the existing Feed-in Premium (FIP) scheme towards either two-sided Contract for Difference (CfD) or a Feed-in Tariff (FIT) would provide more stable returns, while wider access to Corporate Power Purchase Agreements (CPPAs) would help mitigate investor and developer risks.   To address broader market bottlenecks, greater transparency around certification requirements and the adoption of risk-based assessments in the wind farm certification process are needed. It is also important to establish Commercial Operation Date (COD)-based targets instead of pipeline development targets to enable timely investment and strengthen Japan’s domestic supply chain, while minimising curtailment and introducing compensation mechanisms to enhance project bankability.   GWEC and the white paper working team members including OWC presented the findings to the Ministry of Economy, Trade and Industry (METI) and the Ministry of Land, Infrastructure, Transport and Tourism (MLIT) and the Ministry of Environment (MOE) in a series of meetings and updates at the end of October. These government agencies have expressed strong interest for the recommendations outlined in the report.   As an immediate next step, GWEC will develop a detailed plan for the bridging forum to facilitate dialogue between the public and private sectors, which will be key to building a robust policy framework. With the platform in place, we can build a transparent and reliable framework that strengthens project viability, supports Japan’s clean energy goals, drives economic growth, and create a more predictable environment for offshore wind developers and stakeholders.", "release_time": "2025-11-10", "source_institution": "全球风能理事会", "url": "https://www.gwec.net/gwec-news/japans-offshore-wind-success-at-a-critical-juncture-auction-redesign-and-public-private-forum-critical-to-accelerated-progress"}
{"category": "研究前沿", "title": "斯坦福发现钛酸锶在极低温下性能反升", "short_summary": "钛酸锶在近绝对零度下光学机械性能增强，助力量子计算与太空技术。", "detailed_summary": "钛酸锶在近绝对零度下光学机械性能增强，助力量子计算与太空技术。\n(1) 斯坦福大学工程师发现材料钛酸锶在接近绝对零度的极低温环境下性能不降反升。\n(2) 其光学非线性响应和压电性能显著增强，远超现有材料如铌酸锂和钛酸钡。\n(3) 该材料可用于开发新型低温设备，解决量子计算、激光系统和太空探索中的技术瓶颈。\n(4) 研究通过调整氧同位素进一步提升了材料性能，并得到三星、谷歌等公司资助。\n(5) 此发现为下一代量子器件和低温技术应用开辟了新途径。", "raw_content": "Stanford engineers have discovered a standout material, strontium titanate (STO), that performs even better in extreme cold. Instead of weakening, its optical and mechanical properties improve at cryogenic temperatures. STO outperforms every comparable material tested in low-temperature environments, revealing exceptional strength, stability, and tunability. Its unique capabilities could accelerate advances in quantum computing, laser systems, and space exploration, where high performance under freezing conditions is essential.Superconductivity and quantum computing have moved from theoretical physics into real-world innovation. The 2025 Nobel Prize in Physics recognized breakthroughs in superconducting quantum circuits that could lead to ultra-powerful computers. Yet many of these technologies only function at cryogenic temperatures (near absolute zero), where most materials lose their defining properties. Finding materials that perform under such extreme cold has long been one of science's biggest hurdles. A Crystal That Defies the Cold In a new Science publication, engineers at Stanford University report a breakthrough with strontium titanate (STO), a material that not only maintains but enhances its optical and mechanical performance in freezing conditions. Instead of deteriorating, it becomes significantly more capable, outperforming other known materials by a wide margin. The researchers believe this discovery could open the door to a new class of light-based and mechanical cryogenic devices that propel quantum computing, space exploration, and other advanced technologies. \"Strontium titanate has electro-optic effects 40 times stronger than the most-used electro-optic material today. But it also works at cryogenic temperatures, which is beneficial for building quantum transducers and switches that are current bottlenecks in quantum technologies,\" explained the study's senior author Jelena Vuckovic, professor of electrical engineering at Stanford. Pushing the Limits of Performance STO's optical behavior is \"non-linear,\" meaning that when an electric field is applied, its optical and mechanical properties shift dramatically. This electro-optic effect allows scientists to adjust the frequency, intensity, phase, and direction of light in ways that other materials cannot. Such versatility could enable entirely new types of low-temperature devices.  STO is also piezoelectric, meaning it physically expands and contracts in response to electric fields. This makes it ideal for developing new electromechanical components that function efficiently in extreme cold. According to the researchers, these capabilities could be especially valuable for use in the vacuum of space or in the cryogenic fuel systems of rockets. \"At low temperature, not only is strontium titanate the most electrically tunable optical material we know of, but it's also the most piezoelectrically tunable material,\" said Christopher Anderson, co-first author and now a faculty member at the University of Illinois, Urbana-Champaign. An Overlooked Material Finds New Purpose Strontium titanate is not a newly discovered substance. It has been studied for decades and is inexpensive and abundant. \"STO is not particularly special. It's not rare. It's not expensive,\" said co-first author Giovanni Scuri, a postdoctoral scholar in Vuckovic's lab. \"In fact, it has often been used as a diamond substitute in jewelry or as a substrate for growing other, more valuable materials. Despite being a 'textbook' material, it performs exceptionally well in a cryogenic context.\" The decision to test STO was guided by an understanding of what characteristics make materials highly tunable. \"We knew what ingredients we needed to make a highly tunable material. We found those ingredients already existed in nature, and we simply used them in a new recipe. STO was the obvious choice,\" Anderson said. \"When we tried it, surprisingly, it matched our expectations perfectly.\" Scuri added that the framework they developed could help identify or enhance other nonlinear materials for a variety of operating conditions.  Record-Breaking Performance at Near Absolute Zero When tested at 5 Kelvin (-450°F), STO's performance stunned researchers. Its nonlinear optical response was 20 times greater than that of lithium niobate, the leading nonlinear optical material, and nearly triple that of barium titanate, the previous cryogenic benchmark. To push its properties even further, the team replaced certain oxygen atoms in the crystal with heavier isotopes. This adjustment moved STO closer to a state called quantum criticality, producing even greater tunability. \"By adding just two neutrons to exactly 33 percent of the oxygen atoms in the material, the resulting tunability increased by a factor of four,\" Anderson said. \"We precisely tuned our recipe to get the best possible performance.\" Building the Future of Cryogenic Devices According to the team, STO also offers practical advantages that could make it appealing to engineers. It can be synthesized, structurally modified, and fabricated at wafer scale using existing semiconductor equipment. These features make it well-suited for next-generation quantum devices, such as laser-based switches used to control and transmit quantum information. The research was partially funded by Samsung Electronics and Google's quantum computing division, both of which are searching for materials to advance their quantum hardware. The team's next goal is to design fully functional cryogenic devices based on STO's unique properties. \"We found this material on the shelf. We used it and it was amazing. We understood why it was good. Then the cherry on the top -- we knew how to do better, added that special sauce, and we made the world's best material for these applications,\" Anderson said. \"It's a great story.\" Alongside Samsung and Google, the study received support from a Vannevar Bush Faculty Fellowship through the U.S. Department of Defense and the Department of Energy's Q-NEXT program. Contributors include Aaron Chan and Lu Li from the University of Michigan; Sungjun Eun, Alexander D. White, Geun Ho Ahn, Amir Safavi-Naeini, and Kasper Van Gasse from Stanford's E. L. Ginzton Laboratory; and Christine Jilly from the Stanford Nano Shared Facilities.", "release_time": "2025-11-09", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/11/251108083912.htm"}
{"category": "研究前沿", "title": "超级计算机模拟揭示动态暗能量重塑宇宙结构", "short_summary": "DESI数据与Fugaku模拟显示动态暗能量及更高物质密度显著影响早期宇宙星系团形成。", "detailed_summary": "DESI数据与Fugaku模拟显示动态暗能量及更高物质密度显著影响早期宇宙星系团形成。\n（1）研究挑战标准ΛCDM模型，基于DESI数据提出动态暗能量可能改变宇宙演化图景。\n（2）团队利用日本“富岳”超算进行大规模N体模拟，对比标准模型与动态暗能量模型。\n（3）关键发现：结合DESI参数（物质密度增加约10%）后，早期宇宙大质量星系团数量比标准模型预测多70%。\n（4）模拟结果与DESI观测的重子声波振荡峰值移动高度吻合，验证了动态暗能量模型。\n（5）研究为下一代宇宙巡天项目（如Subaru PFS）的数据解读提供了重要理论依据。", "raw_content": "Recent observations have started to challenge this long-held view. Data from the Dark Energy Spectroscopic Instrument (DESI) -- an advanced project that maps the distribution of galaxies across the Universe -- suggests the possibility of a dynamic dark energy (DDE) component. Such a finding would mark a significant shift from the standard ΛCDM model. While this points to a more intricate and evolving cosmic story, it also exposes a major gap in understanding: how a time-dependent dark energy might shape the formation and growth of cosmic structures remains unclear. Simulating an Evolving Universe To explore this mystery, a team led by Associate Professor Tomoaki Ishiyama of Chiba University's Digital Transformation Enhancement Council in Japan carried out one of the most extensive cosmological simulations ever performed. Collaborators included Francisco Prada of the Instituto de Astrofísica de Andalucía in Spain and Anatoly A. Klypin of New Mexico State University in the United States. Their study, published in Physical Review D (Volume 112, Issue 4), investigated how a time-varying dark energy could influence the evolution of the cosmos and help interpret future astronomical observations. Using Japan's flagship supercomputer, Fugaku, the researchers executed three large, high-resolution N-body simulations, each with a computational volume eight times greater than previous work. One simulation followed the standard Planck-2018 ΛCDM model, while two others incorporated dynamic dark energy. By comparing the DDE model with fixed parameters to the standard model, they were able to isolate the effects of a changing dark energy component. A third simulation used parameters drawn from DESI's first-year data, revealing how an \"updated\" cosmological model might behave if dark energy truly varies with time. How a Small Change Can Reshape the Universe The results showed that the influence of dark energy variations alone was relatively subtle. However, once the researchers adjusted the cosmological parameters in line with DESI data -- particularly increasing the matter density by about 10% -- the differences became striking. A higher matter density strengthens gravitational attraction, which accelerates the formation of massive clusters of galaxies. In this scenario, the DESI-based DDE model predicted as much as 70% more massive clusters in the early Universe than the standard model. These clusters form the cosmic framework on which galaxies and galaxy groups assemble.  The team also examined baryonic acoustic oscillations (BAOs) -- patterns left behind by sound waves in the early Universe that serve as \"cosmic rulers\" for measuring distances. In the DESI-derived DDE simulation, the BAO peak shifted by 3.71% toward smaller scales, closely matching DESI's actual observations. This strong agreement confirmed that the model not only reflects theoretical predictions but also aligns well with real-world data. Mapping Galaxy Clusters and Cosmic Structure In addition, the researchers analyzed how galaxies cluster throughout the cosmos. The DESI-based DDE model produced noticeably stronger clustering than the standard ΛCDM version, particularly on smaller scales. The enhanced clustering directly results from the higher matter density, which amplifies gravitational binding. This close match between simulation and observation further supports the validity of the dynamic dark energy model. Overall, the team's findings clarify how both dark energy and matter density shape the large-scale structure of the Universe. \"Our large simulations demonstrate that variations in cosmological parameters, particularly the matter density in the Universe, have a greater influence on structure formation than the DDE component alone,\" says Dr. Ishiyama. Preparing for the Next Generation of Cosmic Surveys With new observational campaigns on the horizon, these simulations will play a crucial role in interpreting upcoming results. \"In the near future, large-scale galaxy surveys from the Subaru Prime Focus Spectrograph and DESI are expected to significantly improve measurements of cosmological parameters. This study provides a theoretical basis for interpreting such upcoming data,\" concludes Dr. Ishiyama.", "release_time": "2025-11-09", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251109013236.htm"}
{"category": "研究前沿", "title": "绝缘体内部现量子振荡，物理学家发现新二元性", "short_summary": "科学家证实绝缘体内部存在量子振荡现象，颠覆传统认知并揭示材料新特性。", "detailed_summary": "科学家证实绝缘体内部存在量子振荡现象，颠覆传统认知并揭示材料新特性。\n(1) 密歇根大学物理学家卢力团队在《物理评论快报》发表研究，发现绝缘体内部存在量子振荡现象；\n(2) 实验使用35特斯拉强磁场对镱硼化合物进行测试，证明振荡源自材料本体而非表面；\n(3) 这一发现揭示了材料同时具备导体和绝缘体特性的\"新二元性\"，类比于波粒二象性；\n(4) 研究由多国团队合作完成，获得美国国家科学基金会和能源部等机构支持；\n(5) 尽管暂无直接应用，但为理解量子材料行为开辟了新方向，将推动后续实验和理论工作。", "raw_content": "Lu Li, a physicist who studies advanced materials, knows that people often want to hear how his research could lead to new technologies or practical breakthroughs. But sometimes, what he uncovers is so unusual that its value lies purely in revealing how strange the universe can be.  Working with an international team of scientists, Li has made one of those discoveries, recently described in Physical Review Letters. \"I would love to claim that there's a great application, but my work keeps pushing that dream further away,\" said Li, a professor of physics at the University of Michigan. \"But what we've found is still really bizarre and exciting.\" Quantum Oscillations: When Electrons Act Like Springs Supported by the U.S. National Science Foundation and the U.S. Department of Energy, the research focuses on a puzzling effect called quantum oscillations. In metals, these oscillations occur when electrons behave like tiny springs, vibrating in response to magnetic fields. By changing the magnetic field's strength, scientists can alter how quickly these \"electron springs\" move. In recent years, however, researchers have discovered the same quantum oscillations in insulators -- materials that should not conduct electricity or heat. That revelation has left scientists debating whether the effect originates only on the surface of these materials or deep within their interior (known as the bulk). Searching for Answers Inside the Material If the oscillations came from the surface, that would be particularly exciting for potential technologies. Materials called topological insulators, which conduct electricity on their surfaces while remaining insulating inside, are already being studied for new kinds of electronic, optical, and quantum devices.  To explore the mystery, Li and his collaborators turned to the National Magnetic Field Laboratory, home to the most powerful magnets in the world. Their experiments revealed that the oscillations were not just a surface effect. Instead, they came from the bulk of the material itself. \"I wish I knew what to do with that, but at this stage we have no idea,\" Li admitted. \"What we have right now is experimental evidence of a remarkable phenomenon, we've recorded it and, hopefully, at some point, we'll realize how to use it.\" A Global Collaboration and a Clear Result The study involved more than a dozen scientists from six institutions in the United States and Japan, including research fellow Kuan-Wen Chen and graduate students Yuan Zhu, Guoxin Zheng, Dechen Zhang, Aaron Chan, and Kaila Jenkins from the University of Michigan. \"For years, scientists have pursued the answer to a fundamental question about the carrier origin in this exotic insulator: Is it from the bulk or the surface, intrinsic or extrinsic?\" said Chen. \"We are excited to provide clear evidence that it is bulk and intrinsic.\" A \"New Duality\" in Physics Li describes the finding as part of what he calls a \"new duality.\" The original, or \"old,\" duality in physics emerged more than a century ago when scientists realized that light and matter can act as both waves and particles. That discovery transformed physics and led to technologies such as solar cells and electron microscopes.  The new duality, Li says, involves materials that can behave as both conductors and insulators. His team explored this idea using a compound called ytterbium boride (YbB12) inside a magnetic field so powerful that it reached 35 Tesla -- about 35 times stronger than the field inside a hospital MRI machine. \"Effectively, we're showing that this naive picture where we envisioned a surface with good conduction that's feasible to use in electronics is completely wrong,\" Li explained. \"It's the whole compound that behaves like a metal even though it's an insulator.\" Unlocking the Mystery of a \"Crazy Metal\" Although this \"metal-like\" behavior only appears under extreme magnetic conditions, the finding raises new questions about how materials behave at the quantum level. \"Confirming that the oscillations are bulk and intrinsic is exciting,\" said Zhu. \"We don't yet know what kind of neutral particles are responsible for the observation. We hope our findings motivate further experiments and theoretical work.\" The project received additional support from the Institute for Complex Adaptive Matter, the Gordon and Betty Moore Foundation, the Japan Society for the Promotion of Science, and the Japan Science and Technology Agency.", "release_time": "2025-11-09", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251108083908.htm"}
{"category": "产业应用", "title": "IAEA发布PET-CT癌症诊疗在线课程", "short_summary": "国际原子能机构推出PET-CT应用课程，覆盖13类癌症诊断与治疗规划。", "detailed_summary": "国际原子能机构推出PET-CT应用课程，覆盖13类癌症诊断与治疗规划。\n（1）国际原子能机构推出PET-CT应用e-learning课程；\n（2）课程涵盖癌症诊断、分期、疗效评估、复发检测及放疗规划；\n（3）详细介绍了13个癌症类别的诊断性能与临床影响；\n（4）特别推荐PET-CT用于前列腺癌等疾病的诊疗一体化规划。", "raw_content": "Diagnostic Performance and Clinical Impact   To further support member countries, the IAEA’s accessible e-learning course summarizes PET-CT’s use in diagnosing cancer, identifying its stage, evaluating its response to multimodal therapies, detecting a suspected recurrence, conducting regular follow-ups and planning radiotherapy.  The course reviews diagnostic performance and clinical impact for 13 cancer categories:  Central nervous system Head and neck Thoracic Breast Gastrointestinal Genitourinary Gynaecological Bone and soft tissue Cutaneous Haematological Endocrine Neuroendocrine Unknown primary  The course also highlights when PET-CT is recommended for planning theranostics — an approach which combines radionuclides for diagnosis and treatment — in prostate cancer, pancreatic neuroendocrine tumours, neuroblastomas and more.", "release_time": "2025-11-09", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/iaea-launches-new-e-learning-course-on-cancer-imaging-tool-pet-ct"}
{"category": "研究前沿", "title": "MIT证实魔角三层石墨烯存在非常规超导性", "short_summary": "MIT团队直接观测到魔角石墨烯非常规超导能隙，为室温超导研究开辟新路径。", "detailed_summary": "MIT团队直接观测到魔角石墨烯非常规超导能隙，为室温超导研究开辟新路径。\n（1）MIT物理学家在魔角三层石墨烯中首次直接观测到非常规超导性的明确证据；\n（2）通过结合隧道光谱和电输运测量的新实验平台，发现其超导能隙呈独特的V形曲线；\n（3）该形态与传统超导体的平滑能隙截然不同，表明电子通过强相互作用而非晶格振动形成库珀对；\n（4）这一发现为理解非常规超导机制提供关键线索，有望推动室温超导材料和量子计算技术的发展；\n（5）研究团队计划将新方法应用于其他二维材料，以设计下一代量子材料。", "raw_content": "Superconductors work like express trains for electricity. Once electric current enters one, it can travel through without resistance or energy loss. Because of this remarkable efficiency, superconductors are already key to technologies such as MRI scanners and particle accelerators.  However, these \"conventional\" superconductors only operate at extremely cold temperatures. They must be kept in specialized cooling systems to remain in their superconducting state. If materials could superconduct at warmer, more practical temperatures, they could transform modern technology -- from creating energy grids that waste no power to enabling more functional quantum computers. To reach that goal, researchers at MIT and other institutions are exploring \"unconventional\" superconductors, materials that defy the rules of traditional ones and may lead to the next big breakthrough. MIT's Magic-Angle Graphene Discovery In a major step forward, MIT physicists have observed clear evidence of unconventional superconductivity in \"magic-angle\" twisted tri-layer graphene (MATTG). This unique material is created by stacking three atom-thin sheets of graphene at a very specific angle. That tiny twist dramatically alters the material's properties, giving rise to strange and promising quantum effects. While earlier studies hinted that MATTG might host unconventional superconductivity, the new findings, published in Science, offer the most direct confirmation to date. A New Look at the Superconducting Gap The MIT team successfully measured MATTG's superconducting gap, which indicates how strong a material's superconducting state is at different temperatures. They found that the gap in MATTG looked completely different from what is seen in conventional superconductors. This difference suggests that the way MATTG becomes superconducting relies on a distinct, unconventional mechanism.  \"There are many different mechanisms that can lead to superconductivity in materials,\" explains co-lead author Shuwen Sun, a graduate student in MIT's Department of Physics. \"The superconducting gap gives us a clue to what kind of mechanism can lead to things like room-temperature superconductors that will eventually benefit human society.\" The team made this discovery with a new experimental system that lets them directly observe how the superconducting gap forms in two-dimensional materials. They plan to use the technique to study MATTG and other 2D materials in more detail, hoping to identify new candidates for advanced technologies. \"Understanding one unconventional superconductor very well may trigger our understanding of the rest,\" says Pablo Jarillo-Herrero, the Cecil and Ida Green Professor of Physics at MIT and senior author of the study. \"This understanding may guide the design of superconductors that work at room temperature, for example, which is sort of the Holy Grail of the entire field.\" The Origins of Twistronics Graphene is made of a single layer of carbon atoms arranged in a hexagonal pattern that looks like chicken wire. Scientists can peel off a sheet of graphene from graphite (the same material in pencil lead) to study its properties. In the 2010s, researchers predicted that stacking two layers of graphene at a very precise angle could create new electronic behaviors. In 2018, Jarillo-Herrero's group became the first to experimentally produce this so-called \"magic-angle\" graphene and reveal its extraordinary properties. That work launched a new field of research known as \"twistronics,\" which studies the surprising effects that emerge when ultra-thin materials are stacked and twisted at exact orientations. Since then, the team and others have explored a variety of graphene structures with multiple layers, revealing further signs of unconventional superconductivity.  How Electrons Cooperate Superconductivity occurs when electrons form pairs rather than scattering apart as they move through a material. These paired electrons, known as \"Cooper pairs,\" can travel without resistance, creating a perfect flow of current. \"In conventional superconductors, the electrons in these pairs are very far away from each other, and weakly bound,\" says co-lead author Jeong Min Park PhD '24. \"But in magic-angle graphene, we could already see signatures that these pairs are very tightly bound, almost like a molecule. There were hints that there is something very different about this material.\" Probing the Quantum World Through Tunneling To prove that MATTG truly exhibits unconventional superconductivity, the MIT researchers needed to measure its superconducting gap directly. As Park explains, \"When a material becomes superconducting, electrons move together as pairs rather than individually, and there's an energy 'gap' that reflects how they're bound. The shape and symmetry of that gap tells us the underlying nature of the superconductivity.\" To do this, scientists used a quantum-scale technique known as tunneling spectroscopy. At this level, electrons act both as particles and as waves, which allows them to \"tunnel\" through barriers that would normally stop them. By studying how easily electrons can tunnel through a material, researchers can learn how strongly they are bound inside it. However, tunneling results alone don't always prove that a material is superconducting, making direct measurements both crucial and challenging. A Closer Look at the Superconducting Gap Park's team developed a new platform that combines tunneling spectroscopy with electrical transport measurements, which involve tracking how current moves through the material while monitoring its resistance (zero resistance means it's superconducting). Using this method on MATTG, the researchers could clearly pinpoint the superconducting tunneling gap -- it appeared only when the material reached zero resistance, the defining mark of superconductivity. As they changed the temperature and magnetic field, the gap displayed a sharp V-shaped curve, very different from the smooth, flat pattern typical of conventional superconductors. This unusual V shape points to a new mechanism behind MATTG's superconductivity. Although the exact process is still unknown, it's now clear that this material behaves unlike any conventional superconductor discovered before. A Different Kind of Electron Pairing In most superconductors, electrons pair up due to vibrations in the surrounding atomic lattice, which gently push them together. Park believes MATTG operates differently. \"In this magic-angle graphene system, there are theories explaining that the pairing likely arises from strong electronic interactions rather than lattice vibrations,\" she says. \"That means electrons themselves help each other pair up, forming a superconducting state with special symmetry.\" The Path Ahead: Next-Generation Quantum Materials The MIT team plans to apply their new experimental setup to study other twisted and layered materials. \"This allows us to both identify and study the underlying electronic structures of superconductivity and other quantum phases as they happen, within the same sample,\" Park explains. \"This direct view can reveal how electrons pair and compete with other states, paving the way to design and control new superconductors and quantum materials that could one day power more efficient technologies or quantum computers.\" This research received support from the U.S. Army Research Office, the U.S. Air Force Office of Scientific Research, the MIT/MTL Samsung Semiconductor Research Fund, the Sagol WIS-MIT Bridge Program, the National Science Foundation, the Gordon and Betty Moore Foundation, and the Ramon Areces Foundation.", "release_time": "2025-11-09", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251108014019.htm"}
{"category": "研究前沿", "title": "科学家提出利用黑洞阴影检验引力理论新方法", "short_summary": "研究团队通过模拟提出新框架，利用黑洞阴影图像检验爱因斯坦相对论。", "detailed_summary": "研究团队通过模拟提出新框架，利用黑洞阴影图像检验爱因斯坦相对论。\n(1) 研究团队提出利用黑洞阴影图像检验爱因斯坦广义相对论及其他引力理论的新方法。\n(2) 通过先进三维计算机模拟，生成不同理论下黑洞周围等离子体的合成图像以进行比较。\n(3) 目前观测数据仍与爱因斯坦理论一致，但测量不确定性尚不能完全排除少数奇异理论。\n(4) 未来需要更高分辨率图像（如角分辨率达百万分之一角秒）才能进行决定性检验。\n(5) 事件视界望远镜网络的扩展及未来空间望远镜的加入将推动这一新观测时代的到来。", "raw_content": "Black holes are often described as cosmic gluttons, consuming everything that drifts too close -- including light itself. This is what makes the images of the supermassive black holes at the centers of the galaxy M87 and our own Milky Way so remarkable. Captured by the Event Horizon Telescope (EHT) collaboration a few years ago, these observations marked a major milestone in astronomy.  \"What you see on these images is not the black hole itself, but rather the hot matter in its immediate vicinity,\" explains Prof. Luciano Rezzolla of Goethe University Frankfurt, whose team played a crucial role in the discovery. \"As long as the matter is still rotating outside the event horizon -- before being inevitably pulled in -- it can emit final signals of light that we can, in principle, detect.\" Einstein's Theory and the Mystery of Black Holes These striking images reveal what scientists call the \"shadow\" of a black hole, offering a new way to probe the physics behind these mysterious cosmic giants. For over a century, Einstein's general theory of relativity has been the foundation of our understanding of space and time. It predicts the existence of black holes and the event horizon, a boundary beyond which nothing -- not even light -- can escape. \"There are, however, also other, still hypothetical theories that likewise predict the existence of black holes,\" Rezzolla notes. \"Some of these approaches require the presence of matter with very specific properties or even the violation of the physical laws we currently know.\" Testing Einstein's Ideas With Black Hole Shadows In collaboration with colleagues from the Tsung-Dao Lee Institute in Shanghai (China), Rezzolla and his team proposed a new way to test these alternative theories. Their work, published in Nature Astronomy, outlines how future black hole observations could help confirm or challenge Einstein's model of gravity. Until now, there has not been enough data to verify or reject competing ideas, but that may soon change through detailed analysis of black hole shadow images.  \"This requires two things,\" Rezzolla explains. \"On the one hand, high-resolution shadow images of black holes to determine their radius as accurately as possible, and on the other hand, a theoretical description of how strongly the various approaches deviate from Einstein's theory of relativity.\" Simulations Reveal How Theories Diverge To tackle this, the team produced a thorough framework describing how different theoretical types of black holes would vary from Einstein's predictions and how those differences would appear in images. They used advanced three-dimensional computer simulations to reproduce the motion of matter and magnetic fields in the warped spacetime surrounding black holes. From these simulations, they created synthetic images of the glowing plasma that circles these immense objects. \"The central question was: How significantly do images of black holes differ across various theories?\" says lead author Akhil Uniyal of the Tsung-Dao Lee Institute. The researchers identified clear patterns that, with sharper images in the future, could help scientists determine which theory best matches reality. Although today's EHT resolution cannot yet detect these fine distinctions, improvements in technology will gradually make such comparisons possible. To prepare for this, the physicists developed a universal description of black holes that can encompass many different theoretical frameworks. Einstein's Theory Still Holding Strong -- for Now \"One of the EHT collaboration's most important contributions to astrophysics is turning black holes into testable objects,\" Rezzolla emphasizes. \"Our expectation is that relativity theory will continue to prove itself, just as it has time and again up to now.\" So far, the findings remain consistent with Einstein's theory, although uncertainties in measurement mean that only a few exotic ideas have been ruled out. For example, the black holes in M87 and the Milky Way are almost certainly not \"naked singularities\" (without an event horizon) or wormholes. Still, Rezzolla notes, \"Even the established theory must be continuously tested, especially with extreme objects like black holes.\" If Einstein's model were ever shown to fail, it would mark a revolutionary moment in physics. A New Era of Cosmic Observation The EHT provides an unprecedented opportunity for these investigations. By combining data from multiple large radio telescopes across the world, it effectively creates a telescope as large as Earth, capable of capturing fine details around black holes. Plans are already underway to add more observatories to the network and, eventually, to include a radio telescope in space, which would greatly boost its resolution. Such advancements could make it possible to perform truly definitive tests of competing black hole theories. According to the new study, this would require achieving an angular resolution of less than one millionth of an arcsecond -- roughly equivalent to spotting a coin on the surface of the Moon from Earth. While that level of precision is not yet possible, scientists expect it to be within reach in the coming years, potentially unlocking a new chapter in our understanding of gravity and the universe itself.", "release_time": "2025-11-08", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251108014022.htm"}
{"category": "产业应用", "title": "俄煤对华出口价涨量稳，蒙古低价竞争加剧", "short_summary": "俄煤对华报价因冬季需求上涨，但面临蒙古低价竞争，进口增长预期温和。", "detailed_summary": "俄煤对华报价因冬季需求上涨，但面临蒙古低价竞争，进口增长预期温和。\n（1）俄罗斯能源和炼焦煤在中国市场价格自10月中下旬上涨2-3%，5500大卡动力煤达86.3美元/吨，优质焦煤达193美元/吨。\n（2）价格上涨主要受中国冬季补库需求及经济增长预期驱动，但整体消费增长预计温和。\n（3）俄罗斯煤炭面临蒙古国的激烈竞争，蒙古冶金煤平均成本比俄罗斯低30%以上。\n（4）2025年前9个月俄对华出口煤炭约6500万吨，其中焦煤2300万吨，传统第四季度采购增加支撑供应。\n（5）未来中国进口煤需求受工业活动、港口库存及钢铁需求影响，预期依旧存在但可能波动。", "raw_content": "对中国经济增长的预期以及冬季的补库需求，促使俄罗斯能源和炼焦煤报价上涨了2-3%。但在中国的俄罗斯煤炭企业面临来自其他供应商的激烈竞争，特别是蒙古国。 俄罗斯能源和炼焦煤在中国市场的价格从10月中下旬上涨了2-3%，Neft Research的一项调查显示。5500大卡动力煤CFR价格上涨至每吨86.3美元/吨，而在同一基础上的优质PLV焦煤价格上涨至193美元/吨。 Neft Research表示：“季节性供暖需求将支撑价格，但中国的总消费量仍将保持温和，增长相对有限。在炼焦煤市场，虽然价格继续大幅上涨的可能性不高。但他表示，整体的预期依旧是乐观的，在中国市场形势好转的情况下，出口商可能会将部分煤炭从韩国市场转移到中国。分析人士指出，中国煤炭进口增长主要是由于来自印度尼西亚、俄罗斯、澳大利亚和蒙古的供应量增加，采购也刺激了对未来几个月工业活动增长的预期。 NKR企业评级机构负责人表示，俄罗斯在2025年前9个月向中国出口了约6500万吨煤炭，其中包括2300万吨焦煤。他表示，中国传统上在第四季度会增加煤炭采购量，这与冬季准备、能源公司需求增加以及需要补充库存有关，专家补充说，这将支持俄罗斯的供应。与此同时，俄罗斯向中国出口炼焦煤的机会受到蒙古日益激烈的竞争的限制，蒙古提供了更低的价格。据该分析师称，蒙古冶金煤的平均成本比俄罗斯低30%以上。 BIGMINT预计，由于秋季工业需求以及国内煤炭企业供应可能减少，中国未来对进口煤依旧有需求，但需求可能受到港口库存变化以及钢铁需求的影响。", "release_time": "2025-11-07", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195885-1.html"}
{"category": "产业应用", "title": "MIT研发新型mRNA疫苗递送颗粒可大幅降低剂量", "short_summary": "MIT新型脂质纳米颗粒使mRNA疫苗剂量降至百分之一，有效降低成本和副作用。", "detailed_summary": "MIT新型脂质纳米颗粒使mRNA疫苗剂量降至百分之一，有效降低成本和副作用。\n(1) MIT团队开发出新型脂质纳米颗粒AMG1541，用于更高效递送mRNA疫苗；\n(2) 小鼠实验表明，新型颗粒仅需现有疫苗百分之一剂量即可产生同等免疫效果；\n(3) 新颗粒具有更强内体逃逸能力和生物可降解性，可快速清除减少副作用；\n(4) 技术能更好靶向抗原呈递细胞和淋巴结，增强免疫应答；\n(5) 该平台适用于流感、新冠、HIV等多种传染病疫苗开发，有望显著降低成本。", "raw_content": "A new delivery particle developed at MIT could make mRNA vaccines more effective and potentially lower the cost per vaccine dose.In studies in mice, the researchers showed that an mRNA influenza vaccine delivered with their new lipid nanoparticle could generate the same immune response as mRNA delivered by nanoparticles made with FDA-approved materials, but at around 1/100 the dose.“One of the challenges with mRNA vaccines is the cost,” says Daniel Anderson, a professor in MIT’s Department of Chemical Engineering and a member of MIT’s Koch Institute for Integrative Cancer Research and Institute for Medical Engineering and Science (IMES). “When you think about the cost of making a vaccine that could be distributed widely, it can really add up. Our goal has been to try to make nanoparticles that can give you a safe and effective vaccine response but at a much lower dose.”While the researchers used their particles to deliver a flu vaccine, they could also be used for vaccines for Covid-19 and other infectious diseases, they say.Anderson is the senior author of the study, which appears today in Nature Nanotechnology. The lead authors of the paper are Arnab Rudra, a visiting scientist at the Koch Institute; Akash Gupta, a Koch Institute research scientist; and Kaelan Reed, an MIT graduate student.Efficient deliveryTo protect mRNA vaccines from breaking down in the body after injection, they are packaged inside a lipid nanoparticle, or LNP. These fatty spheres help mRNA get into cells so that it can be translated into a fragment of a protein from a pathogen such as influenza or SARS-CoV-2.In the new study, the MIT team sought to develop particles that can induce an effective immune response, but at a lower dose than the particles now used to deliver Covid-19 mRNA vaccines. That could not only reduce the costs per vaccine dose, but may also help to lessen the potential side effects, the researchers say.LNPs typically consist of five elements: an ionizable lipid, cholesterol, a helper phospholipid, a polyethylene glycol lipid, and mRNA. In this study, the researchers focused on the ionizable lipid, which plays a key role in vaccine strength.Based on their knowledge of chemical structures that might improve delivery efficiency, the researchers designed a library of new ionizable lipids. These contained cyclic structures, which can help enhance mRNA delivery, as well as chemical groups called esters, which the researchers believed could also help improve biodegradability.The researchers then created and screened many combinations of these particle structures in mice to see which could most effectively deliver the gene for luciferase, a bioluminescent protein. Then, they took their top-performing particle and created a library of new variants, which they tested in another round of screening.From these screens, the top LNP that emerged is one that the researchers called AMG1541. One key feature of these new LNPs is that they are more effective in dealing with a major barrier for delivery particles, known as endosomal escape. After LNPs enter cells, they are isolated in cellular compartments called endosomes, which they need to break out of to deliver their mRNA. The new particles did this more effectively than existing LNPs.Another advantage of the new LNPs is that the ester groups in the tails make the particles degradable once they have delivered their cargo. This means they can be cleared from the body quickly, which the researchers believe could reduce side effects from the vaccine.More powerful vaccinesTo demonstrate the potential applications of the AMG1541 LNP, the researchers used it to deliver an mRNA influenza vaccine in mice. They compared this vaccine’s effectiveness to a flu vaccine made with a lipid called SM-102, which is FDA-approved and was used by Moderna in its Covid-19 vaccine.Mice vaccinated with the new particles generated the same antibody response as mice vaccinated with the SM-102 particle, but only 1/100 of the dose was needed to generate that response, the researchers found.“It’s almost a hundredfold lower dose, but you generate the same amount of antibodies, so that can significantly lower the dose. If it translates to humans, it should significantly lower the cost as well,” Rudra says.Further experiments revealed that the new LNPs are better able to deliver their cargo to a critical type of immune cells called antigen-presenting cells. These cells chop up foreign antigens and display them on their surfaces, which signals other immune cells such as B and T cells to become activated against that antigen.The new LNPs are also more likely to accumulate in the lymph nodes, where they encounter many more immune cells.Using these particles to deliver mRNA flu vaccines could allow vaccine developers to better match the strains of flu that circulate each winter, the researchers say. “With traditional flu vaccines, they have to start being manufactured almost a year ahead of time,” Reed says. “With mRNA, you can start producing it much later in the season and get a more accurate guess of what the circulating strains are going to be, and it may help improve the efficacy of flu vaccines.”The particles could also be adapted for vaccines for Covid-19, HIV, or any other infectious disease, the researchers say.“We have found that they work much better than anything that has been reported so far. That’s why, for any intramuscular vaccines, we think that our LNP platforms could be used to develop vaccines for a number of diseases,” Gupta says.The research was funded by Sanofi, the National Institutes of Health, the Marble Center for Cancer Nanomedicine, and the Koch Institute Support (core) Grant from the National Cancer Institute.", "release_time": "2025-11-07", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/particles-enhance-mrna-delivery-could-reduce-vaccine-dosage-costs-1107"}
{"category": "产业应用", "title": "Lamarr.AI无人机诊断技术提升建筑能效", "short_summary": "Lamarr.AI融合无人机与AI实现建筑能效精准诊断，助力节能减排与成本优化。", "detailed_summary": "Lamarr.AI融合无人机与AI实现建筑能效精准诊断，助力节能减排与成本优化。\n（1）Lamarr.AI基于MIT研究成果开发，通过无人机搭载热成像与可见光相机自动扫描建筑外围护结构；\n（2）AI系统能精准识别空气渗透、保温缺失、渗水等异常问题，并生成3D模型与投资回报分析报告；\n（3）技术将传统数周的人工检测缩短至数秒，已为医疗、教育等多领域客户避免超300万美元无效成本；\n（4）在底特律市政建筑试点中识别460余处缺陷，预计节能改造可降低22%暖通能耗；\n（5）该方案推动建筑管理从被动维修转向战略资产管理，加速全球建筑低碳转型。", "raw_content": "Older buildings let thousands of dollars-worth of energy go to waste each year through leaky roofs, old windows, and insufficient insulation. But even as building owners face mounting pressure to comply with stricter energy codes, making smart decisions about how to invest in efficiency is a major challenge.Lamarr.AI, born in part from MIT research, is making the process of finding ways to improve the energy efficiency of buildings as easy as clicking a button. When customers order a building review, it triggers a coordinated symphony of drones, thermal and visible-range cameras, and artificial intelligence designed to identify problems and quantify the impact of potential upgrades. Lamarr.AI’s technology also assesses structural conditions, creates detailed 3D models of buildings, and recommends retrofits. The solution is already being used by leading organizations across facilities management as well as by architecture, engineering, and construction firms.“We identify the root cause of the anomalies we find,” says CEO and co-founder Tarek Rakha PhD ’15. “Our platform doesn’t just say, ‘This is a hot spot and this is a cold spot.’ It specifies ‘This is infiltration or exfiltration. This is missing insulation. This is water intrusion.’ The detected anomalies are also mapped to a 3D model of the building, and there are deeper analytics, such as the cost of each retrofit and the return on investment.”To date, the company estimates its platform has helped clients across health care, higher education, and multifamily housing avoid over $3 million in unnecessary construction and retrofit costs by recommending targeted interventions over costly full-system replacements, while improving energy performance and extending asset life. For building owners managing portfolios worth hundreds of millions of dollars, Lamarr.AI’s approach represents a fundamental shift from reactive maintenance to strategic asset management.The founders, who also include MIT Professor John Fernández and Research Scientist Norhan Bayomi SM ’17, PhD ’21, are thrilled to see their technology accelerating the transition to more energy-efficient and higher-performing buildings.“Reducing carbon emissions in buildings gets you the greatest return on investment in terms of climate interventions, but what has been needed are the technologies and tools to help the real estate and construction sectors make the right decisions in a timely and economical way,” Fernández says.Automating building scansBayomi and Rakha completed their PhDs in the MIT Department of Architecture’s Building Technology Program. For her thesis, Bayomi developed technology to detect features of building exteriors and classify thermal anomalies through scans of buildings, with a specific focus on the impact of heat waves on low-income communities. Bayomi and her collaborators eventually deployed the system to detect air leaks as part of a partnership with a community in New York City.After graduating MIT, Rakha became an assistant professor at Syracuse University. In 2015, together with fellow Syracuse University Professor Senem Velipasalar, he began developing his concept for drone-based building analytics — an idea that later received support through a grant from New York State’s Department of Economic Development. In 2019, Bayomi and Fernández joined the project, and the team received a $1.8 million research award from the U.S. Department of Energy.“The technology is like giving a building an MRI using drones, infrared imaging, visible light imaging, and proprietary AI that we developed through computer vision technology, along with large language models for report generation,” Rakha explains.“When we started the research, we saw firsthand how vulnerable communities were suffering from inefficient buildings, but couldn’t afford comprehensive diagnostics,” Bayomi says. “We knew that if we could automate this process and reduce costs while improving accuracy, we’d unlock a massive market. Now we’re seeing demand from everyone, from municipal buildings to major institutional portfolios.”Lamarr.AI was officially founded in 2021 to commercialize the technology, and the founders wasted no time tapping into MIT’s entrepreneurial ecosystem. First, they received a small seed grant from the MIT Sandbox Innovation Fund. In 2022, they won the MITdesignX prize and were semifinalists in the MIT $100K Entrepreneurship Competition. The founders named the company after Hedy Lamarr, the famous actress and inventor of a patented technology that became the basis for many modern secure communications.Current methods for detecting air leaks in buildings utilize fan pressurizers or smoke. Contractors or building engineers may also spot-check buildings with handheld infrared cameras to manually identify temperature differences across individual walls, windows, and ductwork.Lamarr.AI’s system can perform building inspections far more quickly. Building managers can order the company’s scans online and select when they’d like the drone to fly. Lamarr.AI partners with drone companies worldwide to fly off-the-shelf drones around buildings, providing them with flight plans and specifications for success. Images are then uploaded onto Lamarr.AI’s platform for automated analysis.“As an example, a survey of a 180,000-square-foot building like the MIT Schwarzman College of Computing, which we scanned, produces around 2,000 images,” Fernández says. “For someone to go through those manually would take a couple of weeks. Our models autonomously analyze those images in a few seconds.”After the analysis, Lamarr.AI’s platform generates a report that includes the suspected root cause of every weak point found, an estimated cost to correct that problem, and its estimated return on investment using advanced building energy simulations.“We knew if we were able to quickly, inexpensively, and accurately survey the thermal envelope of buildings and understand their performance, we would be addressing a huge need in the real estate, building construction, and built environment sectors,” Fernández explains. “Thermal anomalies are a huge cause of unwanted heat loss, and more than 45 percent of construction defects are tied to envelope failures.”The ability to operate at scale is especially attractive to building owners and operators, who often manage large portfolios of buildings across multiple campuses.“We see Lamarr.AI becoming the premier solution for building portfolio diagnostics and prognosis across the globe, where every building can be equipped not just for the climate crisis, but also to minimize energy losses and be more efficient, safer, and sustainable,” Rakha says.Building science for everyoneLamarr.AI has worked with building operators across the U.S. as well as in Canada, the United Kingdom, and the United Arab Emirates.In June, Lamarr.AI partnered with the City of Detroit, with support from Newlab and Michigan Central, to inspect three municipal buildings to identify areas for improvement. Across two of the buildings, the system identified more than 460 problems like insulation gaps and water leaks. The findings were presented in a report that also utilized energy simulations to demonstrate that upgrades, such as window replacements and targeted weatherization, could reduce HVAC energy use by up to 22 percent.The entire process took a few days. The founders note that it was the first building inspection drone flight to utilize an off-site operator, an approach that further enhances the scalability of their platform. It also helps further reduce costs, which could make building scans available to a broader swath of people around the world.“We’re democratizing access to very high-value building science expertise that previously cost tens of thousands per audit,” Bayomi says. “Our platform makes advanced diagnostics affordable enough for routine use, not just one-time assessments. The bigger vision is automated, regular building health monitoring that keeps facilities teams informed in real-time, enabling proactive decisions rather than reactive crisis management. When building intelligence becomes continuous and accessible, operators can optimize performance systematically rather than waiting for problems to emerge.”", "release_time": "2025-11-07", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/lamarrai-giving-buildings-mri-to-make-them-more-energy-efficient-resilient-1107"}
{"category": "研究前沿", "title": "MIT发起数据中心能源论坛应对AI用电激增", "short_summary": "MIT成立数据中心能源论坛，联合业界研究应对AI发展导致的电网压力与能源挑战。", "detailed_summary": "MIT成立数据中心能源论坛，联合业界研究应对AI发展导致的电网压力与能源挑战。\n(1) 麻省理工学院能源倡议（MITEI）发起数据中心能源论坛，应对AI发展导致的数据中心用电激增对电网构成的严峻挑战。\n(2) 该论坛汇聚MIT研究人员与行业专家，旨在为数据中心的可持续供电、电网管理及市场政策提供创新解决方案。\n(3) 研究范围广泛，包括电网扩容、能效处理器、任务专用AI、数据中心选址优化及低碳能源供应等关键领域。\n(4) 论坛建立在MITEI现有数十个相关研究项目基础上，为行业成员提供一个非商业化的协作平台进行深入对话。", "raw_content": "With global power demand from data centers expected to more than double by 2030, the MIT Energy Initiative (MITEI) in September launched an effort that brings together MIT researchers and industry experts to explore innovative solutions for powering the data-driven future. At its annual research conference, MITEI announced the Data Center Power Forum, a targeted research effort for MITEI member companies interested in addressing the challenges of data center power demand. The Data Center Power Forum builds on lessons from MITEI’s May 2025 symposium on the energy to power the expansion of artificial intelligence (AI) and focus panels related to data centers at the fall 2024 research conference.In the United States, data centers consumed 4 percent of the country’s electricity in 2023, with demand expected to increase to 9 percent by 2030, according to the Electric Power Research Institute. Much of the growth in demand is from the increasing use of AI, which is placing an unprecedented strain on the electric grid. This surge in demand presents a serious challenge for the technology and energy sectors, government policymakers, and everyday consumers, who may see their electric bills skyrocket as a result.“MITEI has long supported research on ways to produce more efficient and cleaner energy and to manage the electric grid. In recent years, MITEI has also funded dozens of research projects relevant to data center energy issues. Building on this history and knowledge base, MITEI’s Data Center Power Forum is convening a specialized community of industry members who have a vital stake in the sustainable growth of AI and the acceleration of solutions for powering data centers and expanding the grid,” says William H. Green, the director of MITEI and the Hoyt C. Hottel Professor of Chemical Engineering.MITEI’s mission is to advance zero- and low-carbon solutions to expand energy access and mitigate climate change. MITEI works with companies from across the energy innovation chain, including in the infrastructure, automotive, electric power, energy, natural resources, and insurance sectors. MITEI member companies have expressed strong interest in the Data Center Power Forum and are committing to support focused research on a wide range of energy issues associated with data center expansion, Green says.MITEI’s Data Center Power Forum will provide its member companies with reliable insights into energy supply, grid load operations and management, the built environment, and electricity market design and regulatory policy for data centers. The forum complements MIT’s deep expertise in adjacent topics such as low-power processors, efficient algorithms, task-specific AI, photonic devices, quantum computing, and the societal consequences of data center expansion. As part of the forum, MITEI’s Future Energy Systems Center is funding projects relevant to data center energy in its upcoming proposal cycles. MITEI Research Scientist Deep Deka has been named the program manager for the forum.“Figuring out how to meet the power demands of data centers is a complicated challenge. Our research is coming at this from multiple directions, from looking at ways to expand transmission capacity within the electrical grid in order to bring power to where it is needed, to ensuring the quality of electrical service for existing users is not diminished when new data centers come online, and to shifting computing tasks to times and places when and where energy is available on the grid,\" said Deka.MITEI currently sponsors substantial research related to data center energy topics across several MIT departments. The existing research portfolio includes more than a dozen projects related to data centers, including low- or zero-carbon solutions for energy supply and infrastructure, electrical grid management, and electricity market policy. MIT researchers funded through MITEI’s industry consortium are also designing more energy-efficient power electronics and processors and investigating behind-the-meter low-/no-carbon power plants and energy storage. MITEI-supported experts are studying how to use AI to optimize electrical distribution and the siting of data centers and conducting techno-economic analyses of data center power schemes. MITEI’s consortium projects are also bringing fresh perspectives to data center cooling challenges and considering policy approaches to balance the interests of shareholders. By drawing together industry stakeholders from across the AI and grid value chain, the Data Center Power Forum enables a richer dialog about solutions to power, grid, and carbon management problems in a noncommercial and collaborative setting.“The opportunity to meet and to hold discussions on key data center challenges with other forum members from different sectors, as well as with MIT faculty members and research scientists, is a unique benefit of this MITEI-led effort,” Green says.MITEI addressed the issue of data center power needs with its company members during its fall 2024 Annual Research Conference with a panel session titled, “The extreme challenge of powering data centers in a decarbonized way.” MITEI Director of Research Randall Field led a discussion with representatives from large technology companies Google and Microsoft, known as “hyperscalers,” as well as Madrid-based infrastructure developer Ferrovial S.E. and utility company Exelon Corp. Another conference session addressed the related topic, “Energy storage and grid expansion.” This past spring, MITEI focused its annual Spring Symposium on data centers, hosting faculty members and researchers from MIT and other universities, business leaders, and a representative of the Federal Energy Regulatory Commission for a full day of sessions on the topic, “AI and energy: Peril and promise.”", "release_time": "2025-11-08", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/mit-energy-initiative-launches-data-center-power-forum-1107"}
{"category": "产业应用", "title": "IAEA核技术助力COP30可持续发展目标", "short_summary": "COP30展示核技术应用，涵盖害虫防治、冰川监测与蓝碳评估，推动全球可持续发展。", "detailed_summary": "COP30展示核技术应用，涵盖害虫防治、冰川监测与蓝碳评估，推动全球可持续发展。\n（1）国际原子能机构在COP30会议上重点展示核技术对可持续发展的支持；\n（2）利用不育昆虫技术控制害虫，促进拉丁美洲农业出口与可持续种植；\n（3）核技术监测冰川退缩，保障未来世代的水资源可持续性；\n（4）同位素技术评估蓝碳潜力，保护沿海生态系统及生物多样性；\n（5）核科学数据为国家政策制定和海洋环境保护提供关键支撑。", "raw_content": "Nuclear Solutions for a Sustainable Future  IAEA events will also highlight cutting-edge nuclear techniques that strengthen food security, sustainable water resources and ocean health, and related IAEA projects and initiatives supporting countries in the use of nuclear techniques in their monitoring, mitigation and adaptation efforts. An IAEA event on the sterile insect technique, an environmentally friendly nuclear method for controlling insect pests, will feature Latin American success stories. Several countries in the region have used this method to control fruit flies, enabling them to secure export markets for fruits and vegetables while promoting sustainable agriculture.  Nuclear techniques for monitoring and assessing glacier retreat are the focus of another IAEA event. Tracking the effects of glacier melting helps ensure sustainable water resources for future generations. The IAEA will also spotlight how nuclear and isotopic techniques reveal the potential of blue carbon, a nature-based solution for carbon sequestration, and the importance of preserving coastal ecosystems and their biodiversity. Nuclear sciences and techniques generate data that inform national policies and support efforts to protect marine life and coastal economies. For more details on these and other IAEA events at COP30, please click here. Follow live updates from COP30 on the IAEA social media channels: Facebook, X, LinkedIn, Instagram, and Threads.", "release_time": "2025-11-14", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/iaea-at-cop30-nuclear-energy-technology-and-science-shaping-a-sustainable-future"}
{"category": "研究前沿", "title": "实验室模拟破解宇宙缺失伽马射线之谜", "short_summary": "CERN实验证实等离子体不稳定性非主因，支持早期宇宙磁场理论。", "detailed_summary": "CERN实验证实等离子体不稳定性非主因，支持早期宇宙磁场理论。\n（1）牛津大学团队在CERN利用超级质子同步加速器首次生成等离子体“火球”，模拟遥远耀变体喷流在星际空间中的传播过程。\n（2）实验旨在探究TeV伽马射线与星际背景光作用后产生的电子-正电子对为何未产生预期的GeV伽马射线信号。\n（3）实验结果出乎意料：电子-正电子对束流保持聚焦平行，未出现显著等离子体不稳定性，表明该不稳定性不足以解释缺失伽马射线现象。\n（4）研究支持另一种理论，即星际介质中存在早期宇宙遗留的弱磁场偏转了粒子对，导致伽马射线信号未被探测到。\n（5）该发现对理解宇宙早期磁场起源提出新挑战，并展示了实验室天体物理在连接理论与观测中的关键作用。", "raw_content": "An international group of researchers led by the University of Oxford has achieved a world-first by generating plasma \"fireballs\" with the Super Proton Synchrotron accelerator at CERN in Geneva. Their goal was to investigate how plasma jets from distant blazars remain stable as they travel through space.  The team's results, published on November 3 in PNAS, could help solve a major mystery about the Universe's missing gamma rays and its vast, invisible magnetic fields. Blazars and the Puzzle of Missing Gamma Rays Blazars are a type of active galaxy powered by supermassive black holes that shoot out powerful, narrow jets of particles and radiation at nearly the speed of light. These beams release extremely energetic gamma rays that can reach several teraelectronvolts (1 TeV = 1012 eV), which are detected by ground-based observatories. As these TeV gamma rays travel across intergalactic space, they interact with faint background light from stars, producing cascades of electron-positron pairs. These pairs should then collide with the cosmic microwave background, creating lower-energy gamma rays (around 109 eV, or GeV). However, gamma-ray space telescopes such as NASA's Fermi satellite have not observed this expected signal. The cause of this discrepancy has long been unknown. Scientists have proposed two possible explanations. One theory suggests that weak magnetic fields between galaxies deflect the electron-positron pairs, redirecting the resulting gamma rays away from Earth. Another, rooted in plasma physics, proposes that the pairs themselves become unstable while passing through the thin gas that fills intergalactic space. In this scenario, small disturbances in the plasma generate magnetic fields and turbulence that drain energy from the beam. Recreating Cosmic Conditions in the Laboratory To test these ideas, the research team -- combining expertise from Oxford and the Science and Technology Facilities Council's (STFC) Central Laser Facility (CLF) -- used CERN's HiRadMat (High-Radiation to Materials) setup. They produced beams of electron-positron pairs using the Super Proton Synchrotron and sent them through a one-meter-long plasma. This experiment served as a small-scale simulation of how a blazar's pair cascade moves through intergalactic matter.  By measuring the beam's shape and the magnetic fields it generated, the researchers were able to determine whether plasma instabilities could be strong enough to disrupt the beam's flow. Surprising Results Point to Ancient Magnetic Fields The findings were unexpected. Instead of breaking apart, the pair beam stayed tightly focused and nearly parallel, showing very little disturbance or magnetic activity. When applied to cosmic scales, this suggests that plasma instabilities alone are too weak to account for the missing gamma rays. The outcome supports the alternative explanation -- that the intergalactic medium contains a magnetic field left over from the early Universe. Lead researcher Professor Gianluca Gregori (Department of Physics, University of Oxford) said: \"Our study demonstrates how laboratory experiments can help bridge the gap between theory and observation, enhancing our understanding of astrophysical objects from satellite and ground-based telescopes. It also highlights the importance of collaboration between experimental facilities around the world, especially in breaking new ground in accessing increasingly extreme physical regimes.\" The Early Universe and the Origin of Magnetism The results raise new questions about how such a magnetic field could have formed. The early Universe is thought to have been highly uniform, so the existence of magnetic fields from that era is difficult to explain. The researchers suggest that the answer may involve physics beyond the Standard Model. Future observatories such as the Cherenkov Telescope Array Observatory (CTAO) are expected to provide sharper data to explore these theories.  Co-investigator Professor Bob Bingham (STFC Central Laser Facility and the University of Strathclyde) said: \"These experiments demonstrate how laboratory astrophysics can test theories of the high-energy Universe. By reproducing relativistic plasma conditions in the lab, we can measure processes that shape the evolution of cosmic jets and better understand the origin of magnetic fields in intergalactic space.\" Co-investigator Professor Subir Sarkar (Department of Physics, University of Oxford) added: \"It was a lot of fun to be part of an innovative experiment like this that adds a novel dimension to the frontier research being done at CERN -- hopefully our striking result will arouse interest in the plasma (astro)physics community to the possibilities for probing fundamental cosmic questions in a terrestrial high energy physics laboratory.\" The project brought together scientists from the University of Oxford, STFC's Central Laser Facility (RAL), CERN, the University of Rochester's Laboratory for Laser Energetics, AWE Aldermaston, Lawrence Livermore National Laboratory, the Max Planck Institute for Nuclear Physics, the University of Iceland, and Instituto Superior Técnico in Lisbon.", "release_time": "2025-11-08", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251107010252.htm"}
{"category": "研究前沿", "title": "MIT教授新书揭示18世纪苏格兰民谣文化传承", "short_summary": "新书探讨安娜·戈登保存的古老民谣及其对苏格兰文化认同的深远影响。", "detailed_summary": "新书探讨安娜·戈登保存的古老民谣及其对苏格兰文化认同的深远影响。\n(1) 麻省理工学院荣休教授露丝·佩里出版新书，聚焦18世纪苏格兰女性安娜·戈登及其保存的三十多首古老民谣。\n(2) 研究揭示了民谣作为口头诗歌的创作传播方式，及其在苏格兰启蒙运动时期的文化重要性。\n(3) 书中分析了18世纪苏格兰独特的社会环境，包括女性受教育程度高和法律地位相对优越的背景。\n(4) 戈登的民谣版本语言更为古老优美，内容多涉及家庭冲突、爱情与背叛等人类普遍主题。\n(5) 该研究强调了民谣在苏格兰民族认同形成中的作用，是抵抗英格兰文化同化的独特文化形式。", "raw_content": "Traditional folk ballads are one of our most enduring forms of cultural expression. They can also be lost to society, forgotten over time. That’s why, in the mid-1700s, when a Scottish woman named Anna Gordon was found to know three dozen ancient ballads, collectors tried to document all of these songs — a volume of work that became a kind of sensation in its time, a celebrated piece of cultural heritage.That story is told in MIT Professor Emerita Ruth Perry’s latest book, “The Ballad World of Anna Gordon, Mrs. Brown of Falkland,” published this year by Oxford University Press. In it, Perry details what we know about the ways folk ballads were created and transmitted; how Anna Gordon came to know so many; the social and political climate in which they existed; and why these songs meant so much in Scotland and elsewhere in the Atlantic world. Indeed, Scottish immigrants brought their music to the U.S., among other places.MIT News sat down with Perry, who is MIT’s Ann Fetter Friedlaender Professor of Humanities, Emerita, to talk about the book.Q: This is fascinating topic with a lot of threads woven together. To you, what is the book about?A: It’s really three books. It’s a book about Anna Gordon and her family, a very interesting middle-class family living in Aberdeen in the middle of the 18th century. And it’s a book about balladry and what a ballad is — a story told in song, and ballads are the oldest known poetry in English. Some of them are gorgeous. Third, it’s a book about the relationship between Scotland and England, the effects of the Jacobite uprising in 1745, social attitudes, how people lived, what they ate, education — it’s very much about 18th century Scotland.Q: Okay, who was Anna Gordon, and what was her family milieu?A: Anna’s father, Thomas Gordon, was a professor at King’s College, now the University of Aberdeen. He was a professor of humanity, which in those days meant Greek and Latin, and was well-connected to the intellectual community of the Scottish Enlightenment. A friend of his, an Edinburgh writer, lawyer, and judge, William Tytler, who heard cases all over the country and always stayed with Thomas Gordon and his family when he came to Aberdeen, was intensely interested in Scottish traditional music. He found out that Anna Gordon had learned all these ballads as a child, from her mother and aunt and some servants. Tytler asked if she would write them down, both tunes and words.That was the earliest manuscript of ballads ever collected from a named person in Scotland. Once it was in existence, all kinds of people wanted to see it; it got spread throughout the country. In my book, I detail much of the excitement over this manuscript.The thing about Anna’s ballads is: It’s not just that there are more of them, and more complete versions that are fuller, with more verses. They’re more beautiful. The language is more archaic, and there are marvelous touches. It is thought, and I agree, that Anna Gordon was an oral poet. As she remembered ballads and reproduced them, she improved on them. She had a great memory for the best bits and would improve other parts.Q: How did it come about that at this time, a woman such as Anna Gordon would be the keeper and creator of cultural knowledge?A: Women were more literate in Scotland than elsewhere. The Scottish Parliament passed an act in 1695 requiring every parish in the Church of Scotland to have not only a minister, but a teacher. Scotland was the most literate country in Europe in the 18th century. And those parish schoolmasters taught local kids. The parents did have to pay a few pennies for their classes, and, true, more parents paid for sons than for daughters. But there were daughters who took classes. And there were no opportunities like this in England at the time. Education was better for women in Scotland. So was their legal position, under common law in Scotland. When the Act of Union was formed in 1707, Scotland retained its own legal system, which had more extensive rights for women than in England.Q: I know it’s complex, but generally, why was this?A: Scotland was a much more democratic country, culture, and society than England, period. When Elizabeth I died in 1603, the person who inherited the throne was the King of Scotland James VI, who went to England with his court — which included the Scottish aristocracy. So, the Scottish aristocracy ended up in London. I’m sure they went back to their hunting lodges for the hunting season, but they didn’t live there [in Scotland] and they didn’t set the tone of the country. It was democratized because all that was left were a lot of lawyers and ministers and teachers.Q: What is distinctive about the ballads in this corpus of songs Anna Gordon knew and documented?A: A common word about ballads is that there’s a high body count, and they’re all about people dying and killing each other. But that is not true of Anna Gordon’s ballads. They’re about younger women triumphing in the world, often against older women, which is interesting, and even more often against fathers. The ballads are about family discord, inheritance, love, fidelity, lack of fidelity, betrayal. There are ballads about fighting and bloodshed, but not so many. They’re about the human condition. And they have interesting qualities because they’re oral poetry, composed and remembered and changed and transmitted from mouth to ear and not written down. There are repetitions and parallelisms, and other hallmarks of oral poetry. The sort of thing you learned when you read Homer.Q: So is this a form of culture generated in opposition to those controlling society? Or at least, one that’s popular regardless of what some elites thought?A: It is in Scotland, because of the enmity between Scotland and England. We’re talking about the period of Great Britain when England is trying to gobble up Scotland and some Scottish folks don’t want that. They want to retain their Scottishness. And the ballad was a Scottish tradition that was not influenced by England. That’s one reason balladry was so important in 18th-century Scotland. Everybody was into balladry partly because it was a unique part of Scottish culture.Q: To that point, it seems like an unexpected convergence, for the time, to see a more middle-class woman like Anna Gordon transmitting ballads that had often been created and sung by people of all classes.A: Yes. At first I thought I was just working on a biography of Anna Gordon. But it’s fascinating how the culture was transmitted, how intellectually rich that society was, how much there is to examine in Scottish culture and society of the 18th century. Today people may watch “Outlander,” but they still wouldn’t know anything about this!", "release_time": "2025-11-06", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/qa-how-folk-ballads-explain-world-ruth-perry-book-1106"}
{"category": "研究前沿", "title": "MIT提出可提升软件可读性的概念同步架构模式", "short_summary": "MIT研究提出概念与同步新架构，解决功能碎片化，提升软件模块化与LLM代码生成可靠性。", "detailed_summary": "MIT研究提出概念与同步新架构，解决功能碎片化，提升软件模块化与LLM代码生成可靠性。\n(1) MIT CSAIL研究团队提出名为“概念与同步”的新软件结构模式，旨在解决现代软件中“功能碎片化”问题。\n(2) “概念”指封装单一功能（如分享、点赞）的独立模块，“同步”则是用特定领域语言描述概念间交互规则的显式契约。\n(3) 该方法使软件架构更模块化、透明且易于理解，尤其有利于大型语言模型可靠地生成正确的集成代码。\n(4) 案例研究显示，该模式能将分散在多服务中的功能集中到单一概念中，并通过同步处理错误处理等通用问题。\n(5) 研究展望包括创建“概念目录”库及推动软件架构文化转变，使软件意图更透明、更可信。", "raw_content": "Coding with large language models (LLMs) holds huge promise, but it also exposes some long-standing flaws in software: code that’s messy, hard to change safely, and often opaque about what’s really happening under the hood. Researchers at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) are charting a more “modular” path ahead. Their new approach breaks systems into “concepts,” separate pieces of a system, each designed to do one job well, and “synchronizations,” explicit rules that describe exactly how those pieces fit together. The result is software that’s more modular, transparent, and easier to understand. A small domain-specific language (DSL) makes it possible to express synchronizations simply, in a form that LLMs can reliably generate. In a real-world case study, the team showed how this method can bring together features that would otherwise be scattered across multiple services.The team, including Daniel Jackson, an MIT professor of electrical engineering and computer science (EECS) and CSAIL associate director, and Eagon Meng, an EECS PhD student, CSAIL affiliate, and designer of the new synchronization DSL, explore this approach in their paper “What You See Is What It Does: A Structural Pattern for Legible Software,” which they presented at the Splash Conference in Singapore in October. The challenge, they explain, is that in most modern systems, a single feature is never fully self-contained. Adding a “share” button to a social platform like Instagram, for example, doesn’t live in just one service. Its functionality is split across code that handles posting, notification, authenticating users, and more. All these pieces, despite being scattered across the code, must be carefully aligned, and any change risks unintended side effects elsewhere.Jackson calls this “feature fragmentation,” a central obstacle to software reliability. “The way we build software today, the functionality is not localized. You want to understand how ‘sharing’ works, but you have to hunt for it in three or four different places, and when you find it, the connections are buried in low-level code,” says Jackson.Concepts and synchronizations are meant to tackle this problem. A concept bundles up a single, coherent piece of functionality, like sharing, liking, or following, along with its state and the actions it can take. Synchronizations, on the other hand, describe at a higher level how those concepts interact. Rather than writing messy low-level integration code, developers can use a small domain-specific language to spell out these connections directly. In this DSL, the rules are simple and clear: one concept’s action can trigger another, so that a change in one piece of state can be kept in sync with another.“Think of concepts as modules that are completely clean and independent. Synchronizations then act like contracts — they say exactly how concepts are supposed to interact. That’s powerful because it makes the system both easier for humans to understand and easier for tools like LLMs to generate correctly,” says Jackson. “Why can’t we read code like a book? We believe that software should be legible and written in terms of our understanding: our hope is that concepts map to familiar phenomena, and synchronizations represent our intuition about what happens when they come together,” says Meng. The benefits extend beyond clarity. Because synchronizations are explicit and declarative, they can be analyzed, verified, and of course generated by an LLM. This opens the door to safer, more automated software development, where AI assistants can propose new features without introducing hidden side effects.In their case study, the researchers assigned features like liking, commenting, and sharing each to a single concept — like a microservices architecture, but more modular. Without this pattern, these features were spread across many services, making them hard to locate and test. Using the concepts-and-synchronizations approach, each feature became centralized and legible, while the synchronizations spelled out exactly how the concepts interacted.The study also showed how synchronizations can factor out common concerns like error handling, response formatting, or persistent storage. Instead of embedding these details in every service, synchronization can handle them once, ensuring consistency across the system. More advanced directions are also possible. Synchronizations could coordinate distributed systems, keeping replicas on different servers in step, or allow shared databases to interact cleanly. Weakening synchronization semantics could enable eventual consistency while still preserving clarity at the architectural level.Jackson sees potential for a broader cultural shift in software development. One idea is the creation of “concept catalogs,” shared libraries of well-tested, domain-specific concepts. Application development could then become less about stitching code together from scratch and more about selecting the right concepts and writing the synchronizations between them. “Concepts could become a new kind of high-level programming language, with synchronizations as the programs written in that language.”“It’s a way of making the connections in software visible,” says Jackson. “Today, we hide those connections in code. But if you can see them explicitly, you can reason about the software at a much higher level. You still have to deal with the inherent complexity of features interacting. But now it’s out in the open, not scattered and obscured.”“Building software for human use on abstractions from underlying computing machines has burdened the world with software that is all too often costly, frustrating, even dangerous, to understand and use,” says University of Virginia Associate Professor Kevin Sullivan, who wasn’t involved in the research. “The impacts (such as in health care) have been devastating. Meng and Jackson flip the script and insist on building interactive software on abstractions from human understanding, which they call ‘concepts.’ They combine expressive mathematical logic and natural language to specify such purposeful abstractions, providing a basis for verifying their meanings, composing them into systems, and refining them into programs fit for human use. It’s a new and important direction in the theory and practice of software design that bears watching.”\"It’s been clear for many years that we need better ways to describe and specify what we want software to do,” adds Thomas Ball, Lancaster University honorary professor and University of Washington affiliate faculty, who also wasn’t involved in the research. “LLMs’ ability to generate code has only added fuel to the specification fire. Meng and Jackson’s work on concept design provides a promising way to describe what we want from software in a modular manner. Their concepts and specifications are well-suited to be paired with LLMs to achieve the designer's intent.”Looking ahead, the researchers hope their work can influence how both industry and academia think about software architecture in the age of AI. “If software is to become more trustworthy, we need ways of writing it that make its intentions transparent,” says Jackson. “Concepts and synchronizations are one step toward that goal.”This work was partially funded by the Machine Learning Applications (MLA) Initiative of CSAIL Alliances. At the time of funding, the initiative board was British Telecom, Cisco, and Ernst and Young.", "release_time": "2025-11-07", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/mit-researchers-propose-new-model-for-legible-modular-software-1106"}
{"category": "研究前沿", "title": "MIT-IBM合作推进AI可信度与多模态推理前沿研究", "short_summary": "MIT-IBM实验室五项AI突破：提升模型可信度、优化推理效率、增强多模态数据理解能力。", "detailed_summary": "MIT-IBM实验室五项AI突破：提升模型可信度、优化推理效率、增强多模态数据理解能力。\n(1) 模型可信度研究：开发新型探测方法评估大语言模型不确定性，通过梯度分析和数据分布检测提升预测可靠性；\n(2) 知识图谱增强：设计单智能体强化学习框架，实现大模型与知识库的高效交互，平衡答案准确性与完整性；\n(3) 推理效率优化：创新线性注意力机制与动态位置编码，显著降低长序列处理的计算复杂度；\n(4) 视觉文档理解：构建大规模合成图表数据集ChartGen，通过代码生成技术提升多模态数据解析能力；\n(5) 程序合成系统：开发自主代码迭代优化方法，实现基于文本描述的视觉材质生成，推动CAD应用创新。", "raw_content": "Adoption of new tools and technologies occurs when users largely perceive them as reliable, accessible, and an improvement over the available methods and workflows for the cost. Five PhD students from the inaugural class of the MIT-IBM Watson AI Lab Summer Program are utilizing state-of-the-art resources, alleviating AI pain points, and creating new features and capabilities to promote AI usefulness and deployment — from learning when to trust a model that predicts another’s accuracy to more effectively reasoning over knowledge bases. Together, the efforts from the students and their mentors form a through-line, where practical and technically rigorous research leads to more dependable and valuable models across domains.Building probes, routers, new attention mechanisms, synthetic datasets, and program-synthesis pipelines, the students’ work spans safety, inference efficiency, multimodal data, and knowledge-grounded reasoning. Their techniques emphasize scaling and integration, with impact always in sight.Learning to trust, and whenMIT math graduate student Andrey Bryutkin’s research prioritizes the trustworthiness of models. He seeks out internal structures within problems, such as equations governing a system and conservation laws, to understand how to leverage them to produce more dependable and robust solutions. Armed with this and working with the lab, Bryutkin developed a method to peer into the nature of large learning models (LLMs) behaviors. Together with the lab’s Veronika Thost of IBM Research and Marzyeh Ghassemi — associate professor and the Germeshausen Career Development Professor in the MIT Department of Electrical Engineering and Computer Science (EECS) and a member of the Institute of Medical Engineering Sciences and the Laboratory for Information and Decision Systems — Bryutkin explored the “uncertainty of uncertainty” of LLMs. Classically, tiny feed-forward neural networks two-to-three layers deep, called probes, are trained alongside LLMs and employed to flag untrustworthy answers from the larger model to developers; however, these classifiers can also produce false negatives and only provide point estimates, which don’t offer much information about when the LLM is failing. Investigating safe/unsafe prompts and question-answer tasks, the MIT-IBM team used prompt-label pairs, as well as the hidden states like activation vectors and last tokens from an LLM, to measure gradient scores, sensitivity to prompts, and out-of-distribution data to determine how reliable the probe was and learn areas of data that are difficult to predict. Their method also helps identify potential labeling noise. This is a critical function, as the trustworthiness of AI systems depends entirely on the quality and accuracy of the labeled data they are built upon. More accurate and consistent probes are especially important for domains with critical data in applications like IBM’s Granite Guardian family of models.Another way to ensure trustworthy responses to queries from an LLM is to augment them with external, trusted knowledge bases to eliminate hallucinations. For structured data, such as social media connections, financial transactions, or corporate databases, knowledge graphs (KG) are natural fits; however, communications between the LLM and KGs often use fixed, multi-agent pipelines that are computationally inefficient and expensive. Addressing this, physics graduate student Jinyeop Song, along with lab researchers Yada Zhu of IBM Research and EECS Associate Professor Julian Shun created a single-agent, multi-turn, reinforcement learning framework that streamlines this process. Here, the group designed an API server hosting Freebase and Wikidata KGs, which consist of general web-based knowledge data, and a LLM agent that issues targeted retrieval actions to fetch pertinent information from the server. Then, through continuous back-and-forth, the agent appends the gathered data from the KGs to the context and responds to the query. Crucially, the system uses reinforcement learning to train itself to deliver answers that strike a balance between accuracy and completeness. The framework pairs an API server with a single reinforcement learning agent to orchestrate data-grounded reasoning with improved accuracy, transparency, efficiency, and transferability.Spending computation wiselyThe timeliness and completeness of a model’s response carry similar weight to the importance of its accuracy. This is especially true for handling long input texts and those where elements, like the subject of a story, evolve over time, so EECS graduate student Songlin Yang is re-engineering what models can handle at each step of inference. Focusing on transformer limitations, like those in LLMs, the lab’s Rameswar Panda of IBM Research and Yoon Kim, the NBX Professor and associate professor in EECS, joined Yang to develop next-generation language model architectures beyond transformers.Transformers face two key limitations: high computational complexity in long-sequence modeling due to the softmax attention mechanism, and limited expressivity resulting from the weak inductive bias of RoPE (rotary positional encoding). This means that as the input length doubles, the computational cost quadruples. RoPE allows transformers to understand the sequence order of tokens (i.e., words); however, it does not do a good job capturing internal state changes over time, like variable values, and is limited to the sequence lengths seen during training.To address this, the MIT-IBM team explored theoretically grounded yet hardware-efficient algorithms. As an alternative to softmax attention, they adopted linear attention, reducing the quadratic complexity that limits the feasible sequence length. They also investigated hybrid architectures that combine softmax and linear attention to strike a better balance between computational efficiency and performance.Increasing expressivity, they replaced RoPE with a dynamic reflective positional encoding based on the Householder transform. This approach enables richer positional interactions for deeper understanding of sequential information, while maintaining fast and efficient computation. The MIT-IBM team’s advancement reduces the need for transformers to break problems into many steps, instead enabling them to handle more complex subproblems with fewer inference tokens.Visions anewVisual data contain multitudes that the human brain can quickly parse, internalize, and then imitate. Using vision-language models (VLMs), two graduate students are exploring ways to do this through code.Over the past two summers and under the advisement of Aude Oliva, MIT director of the MIT-IBM Watson AI Lab and a senior research scientist in the Computer Science and Artificial Intelligence Laboratory; and IBM Research’s Rogerio Feris, Dan Gutfreund, and Leonid Karlinsky (now at Xero), Jovana Kondic of EECS has explored visual document understanding, specifically charts. These contain elements, such as data points, legends, and axes labels, that require optical character recognition and numerical reasoning, which models still struggle with. In order to facilitate the performance on tasks such as these, Kondic’s group set out to create a large, open-source, synthetic chart dataset from code that could be used for training and benchmarking. With their prototype, ChartGen, the researchers created a pipeline that passes seed chart images through a VLM, which is prompted to read the chart and generate a Python script that was likely used to create the chart in the first place. The LLM component of the framework then iteratively augments the code from many charts to ultimately produce over 200,000 unique pairs of charts and their codes, spanning nearly 30 chart types, as well as supporting data and annotation like descriptions and question-answer pairs about the charts. The team is further expanding their dataset, helping to enable critical multimodal understanding to data visualizations for enterprise applications like financial and scientific reports, blogs, and more.Instead of charts, EECS graduate student Leonardo Hernandez Cano has his eyes on digital design, specifically visual texture generation for CAD applications and the goal of discovering efficient ways to enable to capabilities in VLMs. Teaming up with the lab groups led by Armando Solar-Lezama, EECS professor and Distinguished Professor of Computing in the MIT Schwarzman College of Computing, and IBM Research’s Nathan Fulton, Hernandez Cano created a program synthesis system that learns to refine code on its own. The system starts with a texture description given by a user in the form of an image. It then generates an initial Python program, which produces visual textures, and iteratively refines the code with the goal of finding a program that produces a texture that matches the target description, learning to search for new programs from the data that the system itself produces. Through these refinements, the novel program can create visualizations with the desired luminosity, color, iridescence, etc., mimicking real materials.When viewed together, these projects, and the people behind them, are making a cohesive push toward more robust and practical artificial intelligence. By tackling the core challenges of reliability, efficiency, and multimodal reasoning, the work paves the way for AI systems that are not only more powerful, but also more dependable and cost-effective, for real-world enterprise and scientific applications.", "release_time": "2025-11-07", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/charting-the-future-of-ai-from-safer-answers-to-faster-thinking-1106"}
{"category": "产业应用", "title": "国际动力煤价飙升至近三月高点", "short_summary": "动力煤价连续上涨破113美元，受冬季需求及亚洲政策支撑。", "detailed_summary": "动力煤价连续上涨破113美元，受冬季需求及亚洲政策支撑。\n（1）国际市场动力煤价格连续上涨，纽卡斯尔期货升至113.85美元/吨，创近三个月新高；\n（2）价格上涨主因冬季需求强劲、中国维持煤炭发电预期及亚洲欧洲经济体依赖；\n（3）中国主要产煤区价格走强，进口煤价随需求恢复上涨；\n（4）印尼、俄罗斯供应紧张加剧价格支撑，吉尔吉斯斯坦增产应对需求。", "raw_content": "据CNBC Indonesia 频道11月5日报道的消息，昨日(11月4日)，国际市场动力煤价格飙升至近三个月来的最高水平。 路孚特(Refinitiv)数据显示，本周以来的前两个交易日，全球动力煤基准洲际交易所(ICE)纽卡斯尔煤炭期货合约交易价格连续上涨。 周一(11月3日)交易日，收盘价突破每吨110美元，交收于112美元/吨，环比前一交易日上涨2.5%; 周二(11月4日)交易日，该煤炭期货合约交易价格继续上升至113.85美元，环比上涨1.65%。 这是自2025年8月8日以来或近三个月来的最高价格。这次煤价上涨也延续了近期煤炭市场的积极趋势，连续三天累计上涨了5.5%。   煤炭价格的上涨，可能是由趋冷冬季依然强劲的需求前景推动的。然而，由于亚洲主要买家国家的进口需求仍显示不振迹象，市场情绪也仍然保持较为谨慎的心态。 中国最近发出的信号，预计在未来几十年内可能将保持煤炭发电需求，到2030年按期实现碳达峰，而不是此前传闻的要加速减少煤炭使用。 这种趋势与一些亚洲和欧洲的经济体是一致的，这些经济体也仍然依赖煤炭，特别是由于电力供应的波动性和数据中心的发展带来的对能源新需求的增加。 近期中国主要产煤区内蒙古、陕西和山西的动力煤产地价格，随着燃煤电厂和供暖部门在冬季来临前季节性需求增加而再次走强。燃煤电厂的补货需求激增和用电量的增加，推动了煤炭产区坑口价格的上涨。 受到电力公司(发电厂)和贸易商购买兴趣增加的推动，进口动力煤的价格也再次上涨。在几个星期横盘整理之后，由于需求恢复和中国买家的补货活动，国际现货市场价格也再次上涨。 有关数据显示，来自印度尼西亚和俄罗斯的进口需求出现明显增加。由于预计印尼的降雨和恶劣天气影响生产和物流，11月、12月的供应状况将更加紧张，为价格提供了额外的支撑。 通常情况下，冬季补货期为10月至12月，因此预计煤矿坑口价格上涨趋势将在短期内得以持续。 如果燃煤电厂的需求持续增加，价格在短期内预计将会保持坚挺。之前公用事业的煤炭采购态度是等待和观察，现在开始重新回到现货市场。 即使中亚煤炭消费小国的吉尔吉斯斯坦也报告称，为了应对寒冷冬季的到来，正在增加国内煤炭产量，国有的六座矿井中有四座已满负荷运转。 2025年前9个月，吉尔吉斯斯坦生产了655,000吨煤炭。为了确保燃料供应的稳定，吉尔吉斯斯坦负责以社会可承受价格采购并监督煤炭开采和分配的国有Kyrgyzkomur公司，已经与全国126个煤炭贸易基地签署了协议，力求以更低的价格采购煤炭，旨在支持低收入家庭并减轻公共事业的经济负担。", "release_time": "2025-11-06", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195832-1.html"}
{"category": "研究前沿", "title": "MXenes材料革新电催化合成氨研究", "short_summary": "科学家利用可调谐MXenes材料，开发高效清洁合成氨新路径。", "detailed_summary": "科学家利用可调谐MXenes材料，开发高效清洁合成氨新路径。\n(1) 研究聚焦二维材料MXenes，通过调整其晶格氮反应性优化电催化性能；\n(2) 采用计算模拟与拉曼光谱揭示分子相互作用及材料振动特性；\n(3) 证实钛氮化物MXenes合成氨效率优于传统碳化物材料；\n(4) 该研究为替代贵金属催化剂、利用地球富集资源生产化学品提供新思路。", "raw_content": "Scientists are working to make renewable technologies more efficient by studying ultra-thin materials known as two-dimensional (2D) materials. These materials could open new pathways for producing essential chemicals like ammonia, a key ingredient in fertilizer, through cleaner and more sustainable methods.  Among these materials, a family called MXenes stands out. MXenes are low-dimensional compounds capable of converting components from the air into ammonia that can be used in fertilizers and transportation fuels. Their unique chemistry allows scientists to adjust their composition, providing precise control over their properties and performance. This research was detailed in the Journal of the American Chemical Society by chemical engineering professors Drs. Abdoulaye Djire and Perla Balbuena, along with Ph.D. candidate Ray Yoo. Rethinking Catalyst Design Djire and his team are challenging long-held beliefs about how transition metal-based materials function. Traditionally, scientists believed a catalyst's effectiveness was determined solely by the type of metal it contained. Djire's group aims to expand that understanding. \"We aim to expand our understanding of how materials function as catalysts under electrocatalytic conditions,\" Djire said. \"Ultimately, this knowledge may help us identify the key components needed to produce chemicals and fuels from earth-abundant resources.\" Tuning Atomic Properties for Better Performance The structure of MXenes can be adjusted by modifying how nitrogen atoms interact within the lattice. This change, known as lattice nitrogen reactivity, influences the way molecules vibrate, known as their vibrational properties. These properties are critical in determining how effectively a material can catalyze chemical reactions.  Because MXenes can be fine-tuned, they can be optimized for a wide variety of renewable energy applications. Yoo explained that this makes them promising alternatives to costly electrocatalyst materials. \"MXenes are the ideal candidates as transition metal-based alternative materials. They have promising potential due to their many desirable qualities,\" Yoo said. \"Nitride MXenes play an important role in electrocatalysis, as shown through their improvement in performance compared to the widely studied carbide counterparts.\" Computational Insights and Molecular Interactions To deepen their understanding, Ph.D. student Hao-En Lai from Dr. Balbuena's group conducted computational studies to model how MXenes behave at the molecular level. The simulations revealed how energy-relevant solvents interact with MXene surfaces, helping the researchers quantify molecular interactions important to ammonia synthesis. Djire, Yoo, and their collaborators also analyzed the vibrational behavior of titanium nitride using Raman spectroscopy, a non-destructive method that reveals detailed information about a material's structure and bonding. \"I feel that one of the most important parts of this research is the ability of Raman spectroscopy to reveal the lattice nitrogen reactivity,\" Yoo said. \"This reshapes the understanding of the electrocatalytic system involving MXenes.\" According to Yoo, continuing to explore nitride MXenes and their interactions with polar solvents through Raman spectroscopy could yield major advancements in green chemistry.  Toward Atom-by-Atom Control of Energy Conversion \"We demonstrate that electrochemical ammonia synthesis can be achieved through the protonation and replenishment of lattice nitrogen,\" Djire said. \"The ultimate goal of this project is to gain an atomistic-level understanding of the role played by the atoms that constitute a material's structure.\" This research received support from the U.S. Army DEVCOM ARL Army Research Office Energy Sciences Competency, Electrochemistry Program (award # W911NF-24-1-0208). The authors noted that the opinions and conclusions presented are their own and do not necessarily reflect the official policies of the U.S. Army or the U.S. Government.", "release_time": "2025-11-07", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251106003937.htm"}
{"category": "研究前沿", "title": "MIT团队确认魔角三层石墨烯非常规超导性", "short_summary": "MIT通过新型实验平台直接观测到魔角石墨烯超导能隙，为室温超导研究提供新路径。", "detailed_summary": "MIT通过新型实验平台直接观测到魔角石墨烯超导能隙，为室温超导研究提供新路径。\n（1）MIT团队开发结合电子隧穿与电输运测量的实验平台，首次直接观测魔角三层石墨烯的超导能隙；\n（2）发现V形超导能隙特征明显区别于常规超导体，证实其非常规超导机制；\n（3）电子可能通过强相互作用而非晶格振动实现配对，为室温超导研究提供新方向；\n（4）该平台可推广至其他二维材料研究，助力量子计算与零损耗电网技术发展。", "raw_content": "Superconductors are like the express trains in a metro system. Any electricity that “boards” a superconducting material can zip through it without stopping and losing energy along the way. As such, superconductors are extremely energy efficient, and are used today to power a variety of applications, from MRI machines to particle accelerators.But these “conventional” superconductors are somewhat limited in terms of uses because they must be brought down to ultra-low temperatures using elaborate cooling systems to keep them in their superconducting state. If superconductors could work at higher, room-like temperatures, they would enable a new world of technologies, from zero-energy-loss power cables and electricity grids to practical quantum computing systems. And so scientists at MIT and elsewhere are studying “unconventional” superconductors — materials that exhibit superconductivity in ways that are different from, and potentially more promising than, today’s superconductors.In a promising breakthrough, MIT physicists have today reported their observation of new key evidence of unconventional superconductivity in “magic-angle” twisted tri-layer graphene (MATTG) — a material that is made by stacking three atomically-thin sheets of graphene at a specific angle, or twist, that then allows exotic properties to emerge.MATTG has shown indirect hints of unconventional superconductivity and other strange electronic behavior in the past. The new discovery, reported in the journal Science, offers the most direct confirmation yet that the material exhibits unconventional superconductivity.In particular, the team was able to measure MATTG’s superconducting gap — a property that describes how resilient a material’s superconducting state is at given temperatures. They found that MATTG’s superconducting gap looks very different from that of the typical superconductor, meaning that the mechanism by which the material becomes superconductive must also be different, and unconventional.“There are many different mechanisms that can lead to superconductivity in materials,” says study co-lead author Shuwen Sun, a graduate student in MIT’s Department of Physics. “The superconducting gap gives us a clue to what kind of mechanism can lead to things like room-temperature superconductors that will eventually benefit human society.”The researchers made their discovery using a new experimental platform that allows them to essentially “watch” the superconducting gap, as the superconductivity emerges in two-dimensional materials, in real-time. They plan to apply the platform to further probe MATTG, and to map the superconducting gap in other 2D materials — an effort that could reveal promising candidates for future technologies.“Understanding one unconventional superconductor very well may trigger our understanding of the rest,” says Pablo Jarillo-Herrero, the Cecil and Ida Green Professor of Physics at MIT and the senior author of the study. “This understanding may guide the design of superconductors that work at room temperature, for example, which is sort of the Holy Grail of the entire field.”The study’s other co-lead author is Jeong Min Park PhD ’24; Kenji Watanabe and Takashi Taniguchi of the National Institute for Materials Science in Japan are also co-authors.The ties that bindGraphene is a material that comprises a single layer of carbon atoms that are linked in a hexagonal pattern resembling chicken wire. A sheet of graphene can be isolated by carefully exfoliating an atom-thin flake from a block of graphite (the same stuff of pencil lead). In the 2010s, theorists predicted that if two graphene layers were stacked at a very special angle, the resulting structure should be capable of exotic electronic behavior.In 2018, Jarillo-Herrero and his colleagues became the first to produce magic-angle graphene in experiments, and to observe some of its extraordinary properties. That discovery sprouted an entire new field known as “twistronics,” and the study of atomically thin, precisely twisted materials. Jarillo-Herrero’s group has since studied other configurations of magic-angle graphene with two, three, and more layers, as well as stacked and twisted structures of other two-dimensional materials. Their work, along with other groups, have revealed some signatures of unconventional superconductivity in some structures.Superconductivity is a state that a material can exhibit under certain conditions (usually at very low temperatures). When a material is a superconductor, any electrons that pass through can pair up, rather than repelling and scattering away. When they couple up in what is known as “Cooper pairs,” the electrons can glide through a material without friction, instead of knocking against each other and flying away as lost energy. This pairing up of electrons is what enables superconductivity, though the way in which they are bound can vary.“In conventional superconductors, the electrons in these pairs are very far away from each other, and weakly bound,” says Park. “But in magic-angle graphene, we could already see signatures that these pairs are very tightly bound, almost like a molecule. There were hints that there is something very different about this material.”Tunneling throughIn their new study, Jarillo-Herrero and his colleagues aimed to directly observe and confirm unconventional superconductivity in a magic-angle graphene structure. To do so, they would have to measure the material’s superconducting gap.“When a material becomes superconducting, electrons move together as pairs rather than individually, and there’s an energy ‘gap’ that reflects how they’re bound,” Park explains. “The shape and symmetry of that gap tells us the underlying nature of the superconductivity.”Scientists have measured the superconducting gap in materials using specialized techniques, such as tunneling spectroscopy. The technique takes advantage of a quantum mechanical property known as “tunneling.” At the quantum scale, an electron behaves not just as a particle, but also as a wave; as such, its wave-like properties enable an electron to travel, or “tunnel,” through a material, as if it could move through walls.Such tunneling spectroscopy measurements can give an idea of how easy it is for an electron to tunnel into a material, and in some sense, how tightly packed and bound the electrons in the material are. When performed in a superconducting state, it can reflect the properties of the superconducting gap. However, tunneling spectroscopy alone cannot always tell whether the material is, in fact, in a superconducting state. Directly linking a tunneling signal to a genuine superconducting gap is both essential and experimentally challenging.In their new work, Park and her colleagues developed an experimental platform that combines electron tunneling with electrical transport — a technique that is used to gauge a material’s superconductivity, by sending current through and continuously measuring its electrical resistance (zero resistance signals that a material is in a superconducting state).The team applied the new platform to measure the superconducting gap in MATTG. By combining tunneling and transport measurements in the same device, they could unambiguously identify the superconducting tunneling gap, one that appeared only when the material exhibited zero electrical resistance, which is the hallmark of superconductivity. They then tracked how this gap evolved under varying temperature and magnetic fields. Remarkably, the gap displayed a distinct V-shaped profile, which was clearly different from the flat and uniform shape of conventional superconductors.This V shape reflects a certain unconventional mechanism by which electrons in MATTG pair up to superconduct. Exactly what that mechanism is remains unknown. But the fact that the shape of the superconducting gap in MATTG stands out from that of the typical superconductor provides key evidence that the material is an unconventional superconductor.In conventional superconductors, electrons pair up through vibrations of the surrounding atomic lattice, which effectively jostle the particles together. But Park suspects that a different mechanism could be at work in MATTG.“In this magic-angle graphene system, there are theories explaining that the pairing likely arises from strong electronic interactions rather than lattice vibrations,” she posits. “That means electrons themselves help each other pair up, forming a superconducting state with special symmetry.”Going forward, the team will test other two-dimensional twisted structures and materials using the new experimental platform.“This allows us to both identify and study the underlying electronic structures of superconductivity and other quantum phases as they happen, within the same sample,” Park says. “This direct view can reveal how electrons pair and compete with other states, paving the way to design and control new superconductors and quantum materials that could one day power more efficient technologies or quantum computers.”This research was supported, in part, by the U.S. Army Research Office, the U.S. Air Force Office of Scientific Research, the MIT/MTL Samsung Semiconductor Research Fund, the Sagol WIS-MIT Bridge Program, the National Science Foundation, the Gordon and Betty Moore Foundation, and the Ramon Areces Foundation.", "release_time": "2025-11-07", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/physicists-observe-evidence-unconventional-superconductivity-graphene-1106"}
{"category": "研究前沿", "title": "MIT跨学科实验室聚焦气候变化人文解决方案", "short_summary": "MIT实验室通过社区合作与跨学科对话应对气候变化现实挑战。", "detailed_summary": "MIT实验室通过社区合作与跨学科对话应对气候变化现实挑战。\n(1) MIT Living Climate Futures Lab聚焦气候变化的人文维度，整合全校资源应对全球挑战；\n(2) 三大目标包括关注日常生活影响、发展社区导向合作、促进校园跨学科对话；\n(3) 通过体验式学习课程连接课堂与现实，培养学生批判性思维和以人为本的解决方案；\n(4) 具体案例包括蒙古的熔盐热能银行和城市粮食主权运动等社区合作项目；\n(5) 获得50万美元种子基金，将举办研讨会和系列讲座，持续推动气候应对创新。", "raw_content": "The MIT Living Climate Futures Lab (LCFL) centers the human dimensions of climate change, bringing together expertise from across MIT to address one of the world’s biggest challenges.The LCFL has three main goals: “addressing how climate change plays out in everyday life, focusing on community-oriented partnerships, and encouraging cross-disciplinary conversations around climate change on campus,” says Chris Walley, the SHASS Dean’s Distinguished Professor of Anthropology and head of MIT’s Anthropology Section. “We think this is a crucial direction for MIT and will make a strong statement about the kind of human-centered, interdisciplinary work needed to tackle this issue.”Walley is faculty lead of LCFL, working in collaboration with a group of 19 faculty colleagues and researchers. The LCFL began to coalesce in 2022 when MIT faculty and affiliates already working with communities dealing with climate change issues organized a symposium, inviting urban farmers, place-based environmental groups, and others to MIT. Since then, the lab has consolidated the efforts of faculty and affiliates representing disciplines from across the MIT School of Humanities, Arts, and Social Sciences (SHASS) and the Institute.Amah Edoh, a cultural anthropologist and managing director of LCFL, says the lab’s collaboration with community organizations and development of experiential learning classes aims to bridge the gap that can exist between the classroom and the real world.“Sometimes we can find ourselves in a bubble where we’re only in conversation with other people from within academia or our own field of practice. There can be a disconnect between what students are learning somewhat abstractly and the ‘real world’ experience of the issues” Edoh says. “By taking up topics from the multidimensional approach that experiential learning makes possible, students learn to take complexity as a given, which can help to foster more critical thinking in them, and inform their future practice in profound ways.”Edoh points out that the effects of climate change play out in a huge array of areas: health, food security, livelihoods, housing, and governance structures, to name a few.“The Living Climate Futures Lab supports MIT researchers in developing the long-term collaborations with community partners that are essential to adequately identifying and responding to the challenges that climate change creates in everyday life,” she says.Manduhai Buyandelger, professor of anthropology and one of the participants in LCFL, developed the class 21A.S01 (Anthro-Engineering: Decarbonization at the Million-Person Scale), which has in turn sparked related classes. The goal is “to merge technological innovation with people-centered environments.” Working closely with residents of Ulaanbaatar, Mongolia, Buyandelger and collaborator Mike Short, the Class of 1941 Professor of Nuclear Science and Engineering, helped develop a molten salt heat bank as a reusable energy source.“My work with Mike Short on energy and alternative heating in Mongolia helps to cultivate a new generation of creative and socially minded engineers who prioritize people in thinking about technical solutions,” Buyandelger says, adding, “In our course, we collaborate on creating interdisciplinary methods where we fuse anthropological methods with engineering innovations so that we can expand and deepen our approach to mitigate climate change.”        Play video                         MIT Living Climate Futures Lab Launch  Video: MIT Anthropology                  Iselle Barrios ’25, says 21A.S01 was her first anthropology course. She traveled to Mongolia and was able to experience firsthand all the ways in which the air pollution and heating problem was much larger and more complicated than it seemed from MIT’s Cambridge, Massachusetts, campus.“It was my first exposure to anthropological and STS critiques of science and engineering, as well as international development,” says Barrios, a chemical engineering major. “It fundamentally reshaped the way I see the role of technology and engineers in the broader social context in which they operate. It really helped me learn to think about problems in a more holistic and people-centered way.”LCFL participant Alvin Harvey, a postdoc in the MIT Media Lab’s Space Enabled Research Group and a citizen of the Navajo Nation, works to incorporate traditional knowledge in engineering and science to “support global stewardship of earth and space ecologies.”\"I envision the Living Climate Futures Lab as a collaborative space that can be an igniter and sustainer of relationships, especially between MIT and those whose have generational and cultural ties to land and space that is being impacted by climate change,” Harvey says. “I think everyone in our lab understands that protecting our climate future is a collective journey.\"Kate Brown, the Thomas M. Siebel Distinguished Professor in History of Science, is also a participant in LCFL. Her current interest is urban food sovereignty movements, in which working-class city dwellers used waste to create “the most productive agriculture in recorded human history,” Brown says. While pursuing that work, Brown has developed relationships and worked with urban farmers in Mansfield, Ohio, as well as in Washington and Amsterdam.Brown and Susan Solomon, the Lee and Geraldine Martin Professor of Environmental Studies and Chemistry, teach a class called STS.055 (Living Dangerously: Environmental Programs from 1900 to Today) that presents the environmental problems and solutions of the 20th century, and how some “solutions” created more problems over time. Brown also plans to teach a class on the history of global food production once she gets access to a small plot of land on campus for a lab site.“The Living Climate Futures Lab gives us the structure and flexibility to work with communities that are struggling to find solutions to the problems being created by the climate crisis,” says Brown.Earlier this year, the MIT Human Insight Collaborative (MITHIC) selected the Living Climate Futures Lab as its inaugural Faculty-Driven Initiative (FDI), which comes with a $500,000 seed grant.MIT Provost Anantha Chandrakasan, co-chair of MITHIC, says the LCFL exemplifies how we can confront the climate crisis by working in true partnership with the communities most affected.“By combining scientific insight with cultural understanding and lived experience, this initiative brings a deeper dimension to MIT’s climate efforts — one grounded in collaboration, empathy, and real-world impact,” says Chandrakasan.Agustín Rayo, the Kenan Sahin Dean of SHASS and co-chair of MITHIC, says the LCFL is precisely the type of interdisciplinary collaboration the FDI program was designed to support.\"By bringing together expertise from across MIT, I am confident the Living Climate Futures Lab will make significant contributions in the Institute’s effort to address the climate crisis,\" says Rayo.Walley said the seed grant will support a second symposium in 2026 to be co-designed with community groups, a suite of experiential learning classes, workshops, a speaker series, and other programming. Throughout this development phase, the lab will solicit donor support to build it into an ongoing MIT initiative and a leader in the response to climate change.", "release_time": "2025-11-07", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/where-climate-meets-community-1106"}
{"category": "研究前沿", "title": "新研究挑战暗物质暗能量理论，提出自然力减弱假说", "short_summary": "研究提出宇宙基本力随年龄减弱，可统一解释暗物质与暗能量相关现象。", "detailed_summary": "研究提出宇宙基本力随年龄减弱，可统一解释暗物质与暗能量相关现象。\n(1) 渥太华大学Rajendra Gupta教授提出新理论，认为宇宙基本力（如引力）随时间和空间演化逐渐减弱。\n(2) 该理论用单一方程统一解释宇宙大尺度加速膨胀（原归于暗能量）和星系旋转及聚团（原归于暗物质）现象。\n(3) 模型通过引入参数α，在星系尺度上自然解释外围恒星高速旋转问题，无需假设暗物质晕。\n(4) 理论将宇宙年龄延长近一倍，为早期宇宙快速形成巨大星系和黑洞提供了更合理的时间线。\n(5) 若成立将颠覆现有宇宙学模型，并质疑耗资巨大的暗物质粒子搜寻实验的必要性。", "raw_content": "For many years, scientists have believed that dark matter and dark energy make up most of the cosmos. But new research challenges that view, suggesting these mysterious components might not exist at all. Instead, the effects we attribute to them could arise naturally if the fundamental forces of the universe slowly weaken as it grows older.  The study, led by Rajendra Gupta, an Adjunct Professor in the Department of Physics at the University of Ottawa, proposes that gradual changes in the strength of nature's forces (such as gravity) over time and space could explain several puzzling cosmic behaviors. These include how galaxies rotate, evolve, and cluster, as well as how the universe expands. Challenging Long-Held Assumptions \"The universe's forces actually get weaker on the average as it expands,\" Professor Gupta explains. \"This weakening makes it look like there's a mysterious push making the universe expand faster (which is identified as dark energy). However, at galactic and galaxy-cluster scale, the variation of these forces over their gravitationally bound space results in extra gravity (which is considered due to dark matter). But those things might just be illusions, emergent from the evolving constants defining the strength of the forces.\" He continues, \"There are two very different phenomena needed to be explained by dark matter and dark energy: The first is at cosmological scale, that is, at a scale larger than 600 million light years assuming the universe is homogeneous and the same in all directions. The second is at astrophysical scale, that is, at smaller scale the universe is very lumpy and direction dependent. In the standard model, the two scenarios require different equations to explain observations using dark matter and dark energy. Ours is the only one that explains them with the same equation, and without needing dark matter or dark energy.\" Gupta adds that the approach provides a single framework for explaining observations like galaxy rotation, clustering, and the bending of light around massive objects. \"It's all just the result of the constants of nature varying as the universe ages and becomes lumpy,\" he says. A New Model on the Galactic Scale In earlier work, Professor Gupta questioned the existence of dark matter on a cosmic scale. His latest research extends that idea to smaller, astrophysical scales, examining how galaxies rotate.  In this model, a parameter known as α emerges when the coupling constants -- the quantities describing the strength of fundamental forces -- are allowed to evolve. This α term acts as an additional element in gravitational equations, reproducing the same effects traditionally explained by dark matter and dark energy. At large scales, α is treated as constant (for example, using supernova data). Locally, within galaxies, α changes depending on how ordinary matter (black holes, stars, planets, and gas) is distributed. In regions rich in matter, the effect is smaller; in sparse regions, it grows stronger. As a result, the model naturally explains why stars in a galaxy's outer regions move faster than expected without invoking unseen dark matter halos. Rethinking the Universe's Timeline Gupta believes this approach could help resolve longstanding astronomical puzzles. \"For years, we've struggled to explain how galaxies in the early universe formed so quickly and became so massive,\" he notes. \"With our model, you don't need to assume any exotic particles or break the rules of physics. The timeline of the universe simply stretches out, almost doubling the universe's age, and making room for everything we observe.\" By effectively lengthening the universe's developmental timeline, the model makes it easier to understand how enormous structures -- such as galaxies and black holes -- could have formed so soon after the Big Bang. This theory could dramatically reshape our understanding of the cosmos. It even suggests that the decades-long search for dark matter particles, which has cost billions of dollars, might not be needed. Even if such exotic particles were discovered, Gupta argues, they would still only account for about six times the mass of ordinary matter. \"Sometimes, the simplest explanation is the best one. Maybe the Universe's biggest secrets are just tricks played by the evolving constants of nature,\" he concludes. The research, titled \"Testing CCC+TL Cosmology with Galaxy Rotation Curves,\" appears in the peer-reviewed journal Galaxies.", "release_time": "2025-11-07", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251106003906.htm"}
{"category": "政策计划", "title": "IAEA推动小型模块堆标准化与监管协调", "short_summary": "IAEA发起NHSI倡议，通过标准化与监管协调加速小型模块堆部署。", "detailed_summary": "IAEA发起NHSI倡议，通过标准化与监管协调加速小型模块堆部署。\n(1) 国际原子能机构（IAEA）于2022年发起核能协调与标准化倡议（NHSI）。\n(2) 该倡议采用双轨方法：产业轨道聚焦标准化工业方法，监管轨道致力于协调监管考量。\n(3) 最新进展包括发布工作文件，旨在统一在役检查代码与标准，以促进SMR出口。\n(4) 在役检查对确保电厂全生命周期运行至关重要，在设计中考虑并标准化相关实践有助于加速SMR部署。\n(5) 倡议强调需要全行业有效合作，优化供应链，以推动先进反应堆的部署。", "raw_content": "The Nuclear Harmonization and Standardization Initiative  The Nuclear Harmonization and Standardization Initiative (NHSI), which IAEA Director General Rafael Mariano Grossi launched in 2022, aims to facilitate the deployment of small modular reactors (SMRs) and other advanced reactors through a dual-track methodology. The initiative’s Industry Track focuses on standardizing industrial approaches while the Regulatory Track examines how to harmonize regulatory considerations.     The initiative’s Industry Track released its latest working paper last week on aligning in-service inspection codes and standards to boost SMR exports. In-service inspections are essential for keeping plants functional throughout their operational lifetimes by verifying system integrity and minimizing reactor outages. Accounting for these inspections in the design phase and standardizing practices across jurisdictions, where possible, could enable a more standardized SMR fleet and hasten their introduction into more markets.  “Benchmarking supply chain practices with other industries can help speed up advanced reactor deployments going forward,” said Jeremy Hubert, Chair of the Working Group on Supply Chain at the Nuclear Energy Agency. “Regulators are doing their part, but we need more effective collaboration. Full, industry-wide cooperation is needed to optimize the supply chain.”", "release_time": "2025-11-08", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/optimizing-supply-chain-readiness-for-nuclear-power-reactors"}
{"category": "研究前沿", "title": "暗物质新解银河系中心伽马射线之谜", "short_summary": "模拟显示银河系早期碰撞重塑暗物质分布，或解释中心伽马射线过剩现象。", "detailed_summary": "模拟显示银河系早期碰撞重塑暗物质分布，或解释中心伽马射线过剩现象。\n（1）研究针对银河系中心伽马射线过剩现象，重新评估暗物质解释可行性；  \n（2）通过Hestia高精度模拟再现银河系早期碰撞史，发现暗物质分布呈非对称复杂结构；  \n（3）新暗物质构型与费米望远镜观测的辐射模式高度吻合，削弱毫秒脉冲星替代理论；  \n（4）未来切伦科夫望远镜阵列将进一步验证暗物质是否为该现象的源头。", "raw_content": "New findings suggest that dark matter could once again be the missing piece in one of astronomy's longest-running puzzles: the strange excess of gamma rays glowing from the Milky Way's core. By recreating the galaxy's turbulent early life and the massive collisions that shaped it, scientists discovered that dark matter near the center may be arranged very differently than once believed. This new configuration closely matches the mysterious radiation pattern first seen by NASA's Fermi telescope, restoring dark matter as a strong candidate for explaining the Milky Way's glowing heart.  The new study has breathed fresh life into one of astrophysics' most persistent debates: what is causing the powerful gamma-ray glow at the center of our galaxy? Led by Dr. Moorits Muru, with Dr. Noam Libeskind and Dr. Stefan Gottlöber of the Leibniz Institute for Astrophysics Potsdam (AIP), in collaboration with Professor Yehuda Hoffman of the Hebrew University of Jerusalem's Racah Institute of Physics and Professor Joseph Silk of Oxford University, the research appears in Physical Review Letters. Their work uses advanced cosmological simulations to test whether dark matter -- the invisible material thought to make up most of the universe -- can still account for the surplus of high-energy radiation first spotted by NASA's Fermi Gamma-ray Space Telescope. Revisiting the Galactic Center Excess For more than a decade, scientists have wrestled with the so-called \"Galactic Center Excess,\" an unexpected surge of gamma rays streaming from the Milky Way's heart. Early on, researchers suspected that dark matter particles migh t be colliding and annihilating each other, creating intense bursts of radiation. However, the observed pattern of gamma rays didn't quite fit the expected shape of dark matter distributions. This discrepancy led many to favor another explanation: ancient, fast-spinning neutron stars known as millisecond pulsars. To test the possibilities, the team turned to Hestia, a series of high-resolution simulations designed to model galaxies like the Milky Way within realistic cosmic environments. By retracing the galaxy's violent mergers and chaotic beginnings, the researchers found that these ancient events could have significantly altered the shape and density of dark matter in its core. Their results reveal a far more intricate, nonspherical dark matter structure than earlier models predicted -- one that naturally reproduces the spread of gamma rays without the need to invoke large numbers of pulsars.  The Milky Way's Chaotic Past Leaves a Mark \"The Milky Way's history of collisions and growth leaves clear fingerprints on how dark matter is arranged at its core,\" the researchers explained. \"When we account for that, the gamma-ray signal looks a lot more like something dark matter could explain.\" Although the study doesn't end the debate, it reestablishes dark matter as a leading explanation for one of modern astronomy's most intriguing phenomena. Future observatories such as the Cherenkov Telescope Array, capable of detecting even higher-energy gamma rays, will provide sharper tests of these competing theories. These instruments could confirm whether the glow truly comes from dark matter or whether another cosmic process is responsible. \"This study gives us a fresh way to interpret one of the most intriguing signals in the sky,\" the team said. \"Either we'll confirm that dark matter leaves an observable trace -- or we'll learn something entirely new about the Milky Way itself.\"", "release_time": "2025-11-05", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251104094152.htm"}
{"category": "研究前沿", "title": "磁振子产生电信号有望催生超高速计算芯片", "short_summary": "磁振子电信号新发现为超高速低功耗计算芯片开辟全新路径。", "detailed_summary": "磁振子电信号新发现为超高速低功耗计算芯片开辟全新路径。\n（1）特拉华大学研究发现磁振子（微小磁波）能在反铁磁材料中诱导电极化并产生可测量电信号；\n（2）该发现使计算机芯片可直接融合磁电系统，避免传统电子流动的能量损耗；\n（3）反铁磁磁振子运行频率达太赫兹级别，比传统材料快约千倍；\n（4）理论模型已建立，团队正通过实验验证并研究光控磁振子交互机制；\n（5）该研究属于量子材料前沿探索，获美国国家科学基金会资助支持。", "raw_content": "Engineers at the University of Delaware have uncovered a new way to connect magnetic and electric forces in computing, a finding that could pave the way for computers that run dramatically faster while consuming far less energy.  Tiny Magnetic Waves Generate Electric Signals In a study published in Proceedings of the National Academy of Sciences, researchers from the university's Center for Hybrid, Active and Responsive Materials (CHARM), a National Science Foundation-funded Materials Research Science and Engineering Center, report that magnons -- tiny magnetic waves that move through solid materials -- are capable of generating measurable electric signals. This discovery suggests that future computer chips could merge magnetic and electric systems directly, removing the need for the constant energy exchange that limits the performance of today's devices. How Magnons Transmit Information Traditional electronics rely on the flow of charged electrons, which lose energy as heat when moving through circuits. In contrast, magnons carry information through the synchronized \"spin\" of electrons, creating wave-like patterns across a material. According to theoretical models developed by the UD team, when these magnetic waves travel through antiferromagnetic materials, they can induce electric polarization, effectively creating a measurable voltage. Toward Ultrafast, Energy-Efficient Computing Antiferromagnetic magnons can move at terahertz frequencies -- around a thousand times faster than magnetic waves in conventional materials. This exceptional speed points to a promising path for ultrafast, low-power computing. The researchers are now working to verify their theoretical predictions through experiments and to investigate how magnons interact with light, which could lead to even more efficient ways of controlling them.  Advancing Quantum Material Research This work contributes to CHARM's larger goal of developing hybrid quantum materials for cutting-edge technologies. The center's researchers study how different types of materials -- such as magnetic, electronic, and quantum systems -- can be combined and controlled to create next-generation technologies. CHARM's goal is to design smart materials that respond to their environments and enable breakthroughs in computing, energy, and communication. The study's co-authors are Federico Garcia-Gaitan, Yafei Ren, M. Benjamin Jungfleisch, John Q. Xiao, Branislav K. Nikolić, Joshua Zide, and Garnett W. Bryant (NIST/University of Maryland). Funding was provided by the National Science Foundation under award DMR-2011824", "release_time": "2025-11-05", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251104094141.htm"}
{"category": "研究前沿", "title": "MIT团队发现结核病疫苗新抗原", "short_summary": "MIT研究筛选出结核菌关键蛋白，为开发新型高效疫苗奠定基础。", "detailed_summary": "MIT研究筛选出结核菌关键蛋白，为开发新型高效疫苗奠定基础。\n（1）MIT生物工程团队从超过4000种结核菌蛋白中筛选出可能刺激T细胞反应的免疫原性肽。\n（2）研究重点分析了被感染人类细胞表面MHC-II分子呈现的结核菌肽段，识别出27个高频出现的肽段。\n（3）测试发现其中24个肽段能在曾感染结核病的捐赠者T细胞中引发免疫反应。\n（4）研究评估了基于mRNA技术的疫苗候选方案，靶向特定分泌系统蛋白（如EsxB和EsxG）。\n（5）该发现为开发替代现有BCG疫苗的新型高效结核病疫苗提供了关键靶点。", "raw_content": "A large-scale screen of tuberculosis proteins has revealed several possible antigens that could be developed as a new vaccine for TB, the world’s deadliest infectious disease.In the new study, a team of MIT biological engineers was able to identify a handful of immunogenic peptides, out of more than 4,000 bacterial proteins, that appear to stimulate a strong response from a type of T cells responsible for orchestrating immune cells’ response to infection.There is currently only one vaccine for tuberculosis, known as BCG, which is a weakened version of a bacterium that causes TB in cows. This vaccine is widely administered in some parts of the world, but it poorly protects adults against pulmonary TB. Worldwide, tuberculosis kills more than 1 million people every year.“There’s still a huge TB burden globally that we’d like to make an impact on,” says Bryan Bryson, an associate professor of biological engineering at MIT and a member of the Ragon Institute of Mass General Brigham, MIT, and Harvard. “What we’ve tried to do in this initial TB vaccine is focus on antigens that we saw frequently in our screen and also appear to stimulate a response in T cells from people with prior TB infection.”Bryson and Forest White, the Ned C. and Janet C. Rice Professor of Biological Engineering at MIT, and a member of the Koch Institute for Integrative Cancer Research, are the senior authors of the study, which appears today in Science Translational Medicine. Owen Leddy PhD ’25 is the paper’s lead author.Identifying vaccine targetsSince the BCG vaccine was developed more than 100 years ago, no other TB vaccines have been approved for use. Mycobacterium tuberculosis produces more than 4,000 proteins, which makes it a daunting challenge to pick out proteins that might elicit a strong immune response if used as a vaccine.In the new study, Bryson and his students set out to narrow the field of candidates by identifying TB proteins presented on the surface of infected human cells. When an immune cell such as a phagocyte is infected with Mycobacterium tuberculosis, some of the bacterial proteins get chopped into fragments called peptides, which are then displayed on the surface of the cell by MHC proteins. These MHC-peptide complexes act as a signal that can activate T cells.MHCs, or major histocompatibility complexes, come in two types known as class I and class II. Class I MHCs activate killer T cells, while class II MHCs stimulate helper T cells. In human cells, there are three genes that can encode MHC-II proteins, and each of these comes in hundreds of variants. This means that any two people can have a very different repertoire of MHC-II molecules, which present different antigens.“Instead of looking at all of those 4,000 TB proteins, we wanted to ask which of those proteins from TB actually end up being displayed to the rest of the immune system via MHC,” Bryson says. “If we could just answer that question, then we could design vaccines to match that.”To try to answer the question, the researchers infected human phagocytes with Mycobacterium tuberculosis. After three days, they extracted MHC-peptide complexes from the cell surfaces, then identified the peptides using mass spectrometry.Focusing on peptides bound to MHC-II, the researchers found 27 TB peptides, from 13 proteins, that appeared most often in the infected cells. Then, they further tested those peptides by exposing them to T cells donated by people who had previously been infected with TB.They found that 24 of these peptides did elicit a T cell response in at least some of the samples. None of the proteins from which these peptides came worked for every single donor, but Bryson believes that a vaccine using a combination of these peptides would likely work for most people.“In a perfect world, if you were trying to design a vaccine, you would pick one protein and that protein would be presented across every donor. It should work for every person,” Bryson says. “However, using our measurements, we’ve not yet found a TB protein that covers every donor we’ve analyzed thus far.”Enter mRNA vaccinesAmong the vaccine candidates that the researchers identified are several peptides from a class of proteins called type 7 secretion systems (T7SSs). Some of these peptides also turned up in an earlier study from Bryson’s lab on MHC-1.“Type 7 secretion system substrates are a very small sliver of the overall TB proteome, but when you look at MHC class I or MHC class II, it seems as though the cells are preferentially presenting these,” Bryson says.Two of the best-known of these proteins, EsxA and EsxB, are secreted by bacteria to help them escape from the membranes that phagocytes use to envelop them within the cell. Neither protein can break through the membrane on its own, but when joined together to form a heterodimer, they can poke holes, which also allow other T7SS proteins to escape.To evaluate whether the proteins they identified could make a good vaccine, the researchers created mRNA vaccines encoding two protein sequences — EsxB and EsxG. The researchers designed several versions of the vaccine, which were targeted to different compartments within the cells.The researchers then delivered this vaccine into human phagocytes, where they found that vaccines that targeted cell lysosomes — organelles that break down molecules — were the most effective. These vaccines induced 1,000 times more MHC presentation of TB peptides than any of the others.They later found that the presentation was even higher if they added EsxA to the vaccine, because it allows the formation of the heterodimers that can poke through the lysosomal membrane.The researchers currently have a mix of eight proteins that they believe could offer protection against TB for most people, but they are continuing to test the combination with blood samples from people around the world. They also hope to run additional studies to explore how much protection this vaccine offers in animal models. Tests in humans are likely several years away.The research was funded by the MIT Center for Precision Cancer Research at the Koch Institute, the National Institutes of Health, the National Institute of Environmental Health Sciences, and the Frederick National Laboratory for Cancer Research.", "release_time": "2025-11-06", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/mit-study-finds-targets-new-tuberculosis-vaccine-1105"}
{"category": "研究前沿", "title": "MIT研究对比核废料碘-129处理策略", "short_summary": "MIT研究量化三种碘-129处理方案，发现美国深地封存释放量远低于法国海洋稀释。", "detailed_summary": "MIT研究量化三种碘-129处理方案，发现美国深地封存释放量远低于法国海洋稀释。\n（1）MIT研究团队对比了碘-129的三种处理方案：美国深地封存、法国海洋稀释释放以及使用过滤器后浅层填埋。\n（2）研究发现法国现行核燃料后处理做法导致约91%的碘-129释放至生物圈，而美国深地封存方案百万年内释放量仅为前者的约亿分之一。\n（3）研究量化了不同方案下碘-129的释放量（单位：kg/GWe.y），并分析了法国、英国及美国特定站点附近地表水中的碘-129浓度差异。\n（4）研究表明环境稀释效应（如靠近大河）对降低局部浓度作用显著，但深地封存设计需谨慎以避免局部污染。\n（5）研究者强调核废料隔离策略的重要性，并指出过滤器捕获结合浅层填埋可作为替代方案，但不应因废料问题放弃核能。", "raw_content": "One of the highest-risk components of nuclear waste is iodine-129 (I-129), which stays radioactive for millions of years and accumulates in human thyroids when ingested. In the U.S., nuclear waste containing I-129 is scheduled to be disposed of in deep underground repositories, which scientists say will sufficiently isolate it.Meanwhile, across the globe, France routinely releases low-level radioactive effluents containing iodine-129 and other radionuclides into the ocean. France recycles its spent nuclear fuel, and the reprocessing plant discharges about 153 kilograms of iodine-129 each year, under the French regulatory limit.Is dilution a good solution? What’s the best way to handle spent nuclear fuel? A new study by MIT researchers and their collaborators at national laboratories quantifies I-129 release under three different scenarios: the U.S. approach of disposing spent fuel directly in deep underground repositories, the French approach of dilution and release, and an approach that uses filters to capture I-129 and disposes of them in shallow underground waste repositories.The researchers found France’s current practice of reprocessing releases about 90 percent of the waste’s I-129 into the biosphere. They found low levels of I-129 in ocean water around France and the U.K.’s former reprocessing sites, including the English Channel and North Sea. Although the low level of I-129 in the water in Europe is not considered to pose health risks, the U.S. approach of deep underground disposal leads to far less I-129 being released, the researchers found.The researchers also investigated the effect of environmental regulations and technologies related to I-129 management, to illuminate the tradeoffs associated with different approaches around the world.“Putting these pieces together to provide a comprehensive view of Iodine-129 is important,” says MIT Assistant Professor Haruko Wainwright, a first author on the paper who holds a joint appointment in the departments of Nuclear Science and Engineering and of Civil and Environmental Engineering. “There are scientists that spend their lives trying to clean up iodine-129 at contaminated sites. These scientists are sometimes shocked to learn some countries are releasing so much iodine-129. This work also provides a life-cycle perspective. We’re not just looking at final disposal and solid waste, but also when and where release is happening. It puts all the pieces together.”MIT graduate student Kate Whiteaker SM ’24 led many of the analyses with Wainwright. Their co-authors are Hansell Gonzalez-Raymat, Miles Denham, Ian Pegg, Daniel Kaplan, Nikolla Qafoku, David Wilson, Shelly Wilson, and Carol Eddy-Dilek. The study appears today in Nature Sustainability.Managing wasteIodine-129 is often a key focus for scientists and engineers as they conduct safety assessments of nuclear waste disposal sites around the world. It has a half-life of 15.7 million years, high environmental mobility, and could potentially cause cancers if ingested. The U.S. sets a strict limit on how much I-129 can be released and how much I-129 can be in drinking water — 5.66 nanograms per liter, the lowest such level of any radionuclides.“Iodine-129 is very mobile, so it is usually the highest-dose contributor in safety assessments,” Wainwright says.For the study, the researchers calculated the release of I-129 across three different waste management strategies by combining data from current and former reprocessing sites as well as repository assessment models and simulations.The authors defined the environmental impact as the release of I-129 into the biosphere that humans could be exposed to, as well as its concentrations in surface water. They measured I-129 release per the total electrical energy generated by a 1-gigawatt power plant over one year, denoted as kg/GWe.y.Under the U.S. approach of deep underground disposal with barrier systems, assuming the barrier canisters fail at 1,000 years (a conservative estimate), the researchers found 2.14 x 10–8 kg/GWe.y of I-129 would be released between 1,000 and 1 million years from today.They estimate that 4.51 kg/GWe.y of I-129, or 91 percent of the total, would be released into the biosphere in the scenario where fuel is reprocessed and the effluents are diluted and released. About 3.3 percent of I-129 is captured by gas filters, which are then disposed of in shallow subsurfaces as low-level radioactive waste. A further 5.2 percent remains in the waste stream of the reprocessing plant, which is then disposed of as high-level radioactive waste.If the waste is recycled with gas filters to directly capture I-129, 0.05 kg/GWe.y of the I-129 is released, while 94 percent is disposed of in the low-level disposal sites. For shallow disposal, some kind of human disruption and intrusion is assumed to occur after government or institutional control expires (typically 100-1,000 years). That results in a potential release of the disposed amount to the environment after the control period.Overall, the current practice of recycling spent nuclear fuel releases the majority of I-129 into the environment today, while the direct disposal of spent fuel releases around 1/100,000,000 that amount over 1 million years. When the gas filters are used to capture I-129, the majority of I-129 goes to shallow underground repositories, which could be accidentally released through human intrusion down the line.The researchers also quantified the concentration of I-129 in different surface waters near current and former fuel reprocessing facilities, including the English Channel and the North Sea near reprocessing plants in France and U.K. They also analyzed the U.S. Columbia River downstream of a site in Washington state where material for nuclear weapons was produced during the Cold War, and they studied a similar site in South Carolina. The researchers found far higher concentrations of I-129 within the South Carolina site, where the low-level radioactive effluents were released far from major rivers and hence resulted in less dilution in the environment.“We wanted to quantify the environmental factors and the impact of dilution, which in this case affected concentrations more than discharge amounts,” Wainwright says. “Someone might take our results to say dilution still works: It’s reducing the contaminant concentration and spreading it over a large area. On the other hand, in the U.S., imperfect disposal has led to locally higher surface water concentrations. This provides a cautionary tale that disposal could concentrate contaminants, and should be carefully designed to protect local communities.”Fuel cycles and policyWainwright doesn’t want her findings to dissuade countries from recycling nuclear fuel. She says countries like Japan plan to use increased filtration to capture I-129 when they reprocess spent fuel. Filters with I-129 can be disposed of as low-level waste under U.S. regulations.“Since I-129 is an internal carcinogen without strong penetrating radiation, shallow underground disposal would be appropriate in line with other hazardous waste,” Wainwright says. “The history of environmental protection since the 1960s is shifting from waste dumping and release to isolation. But there are still industries that release waste into the air and water. We have seen that they often end up causing issues in our daily life — such as CO2, mercury, PFAS and others — especially when there are many sources or when bioaccumulation happens. The nuclear community has been leading in waste isolation strategies and technologies since the 1950s. These efforts should be further enhanced and accelerated. But at the same time, if someone does not choose nuclear energy because of waste issues, it would encourage other industries with much lower environmental standards.”The work was supported by MIT’s Climate Fast Forward Faculty Fund and the U.S. Department of Energy.", "release_time": "2025-11-05", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/what-should-countries-do-with-their-nuclear-waste-1105"}
{"category": "研究前沿", "title": "MIT研发新型全脑细胞3D模型，助力阿尔茨海默病研究", "short_summary": "MIT开发集成六类脑细胞的miBrains模型，揭示阿尔茨海默病新机制。", "detailed_summary": "MIT开发集成六类脑细胞的miBrains模型，揭示阿尔茨海默病新机制。\n(1) MIT研究人员成功开发名为\"miBrains\"的新型3D人脑组织平台，首次将神经元、胶质细胞、血管等六种主要脑细胞类型集成于单一培养体系。\n(2) 该模型由捐赠者的诱导多能干细胞培育而成，具备高度模块化设计，可进行基因编辑以模拟特定健康或疾病状态。\n(3) 在首次应用中，miBrains揭示了阿尔茨海默病最强遗传风险因子APOE4的新作用机制：小胶质细胞与星形胶质细胞之间的分子对话是导致磷酸化tau蛋白病理所必需的。\n(4) 此平台结合了简单细胞培养的易操作性和动物模型的生物复杂性优势，有望推动脑疾病研究和新药开发，并为个性化医疗铺平道路。", "raw_content": "A new 3D human brain tissue platform developed by MIT researchers is the first to integrate all major brain cell types, including neurons, glial cells, and the vasculature, into a single culture. Grown from individual donors’ induced pluripotent stem cells, these models — dubbed Multicellular Integrated Brains (miBrains) — replicate key features and functions of human brain tissue, are readily customizable through gene editing, and can be produced in quantities that support large-scale research.Although each unit is smaller than a dime, miBrains may be worth a great deal to researchers and drug developers who need more complex living lab models to better understand brain biology and treat diseases.“The miBrain is the only in vitro system that contains all six major cell types that are present in the human brain,” says Li-Huei Tsai, Picower Professor, director of The Picower Institute for Learning and Memory, and a senior author of the open-access study describing miBrains, published Oct. 17 in the Proceedings of the National Academy of Sciences.“In their first application, miBrains enabled us to discover how one of the most common genetic markers for Alzheimer’s disease alters cells’ interactions to produce pathology,” she adds.Tsai’s co-senior authors are Robert Langer, David H. Koch (1962) Institute Professor, and Joel Blanchard, associate professor in the Icahn School of Medicine at Mt. Sinai in New York, and a former Tsai Laboratory postdoc. The study is led by Alice Stanton, former postdoc in the Langer and Tsai labs and now assistant professor at Harvard Medical School and Massachusetts General Hospital, and Adele Bubnys, a former Tsai lab postdoc and current senior scientist at Arbor Biotechnologies.Benefits from two kinds of modelsThe more closely a model recapitulates the brain’s complexity, the better suited it is for extrapolating how human biology works and how potential therapies may affect patients. In the brain, neurons interact with each other and with various helper cells, all of which are arranged in a three-dimensional tissue environment that includes blood vessels and other components. All of these interactions are necessary for health, and any of them can contribute to disease.Simple cultures of just one or a few cell types can be created in quantity relatively easily and quickly, but they cannot tell researchers about the myriad interactions that are essential to understanding health or disease. Animal models embody the brain’s complexity, but can be difficult and expensive to maintain, slow to yield results, and different enough from humans to yield occasionally divergent results.MiBrains combine advantages from each type of model, retaining much of the accessibility and speed of lab-cultured cell lines while allowing researchers to obtain results that more closely reflect the complex biology of human brain tissue. Moreover, they are derived from individual patients, making them personalized to an individual’s genome. In the model, the six cell types self-assemble into functioning units, including blood vessels, immune defenses, and nerve signal conduction, among other features. Researchers ensured that miBrains also possess a blood-brain-barrier capable of gatekeeping which substances may enter the brain, including most traditional drugs.“The miBrain is very exciting as a scientific achievement,” says Langer. “Recent trends toward minimizing the use of animal models in drug development could make systems like this one increasingly important tools for discovering and developing new human drug targets.”Two ideal blends for functional brain modelsDesigning a model integrating so many cell types presented challenges that required many years to overcome. Among the most crucial was identifying a substrate able to provide physical structure for cells and support their viability. The research team drew inspiration from the environment that surrounds cells in natural tissue, the extracellular matrix (ECM). The miBrain’s hydrogel-based “neuromatrix” mimics the brain’s ECM with a custom blend of polysaccharides, proteoglycans, and basement membrane that provide a scaffold for all the brain’s major cell types while promoting the development of functional neurons.A second blend would also prove critical: the proportion of cells that would result in functional neurovascular units. The actual ratios of cell types have been a matter of debate for the last several decades, with even the more advanced methodologies providing only rough brushstrokes for guidance, for example 45-75 percent for oligodendroglia of all cells or 19-40 percent for astrocytes.The researchers developed the six cell types from patient-donated induced pluripotent stem cells, verifying that each cultured cell type closely recreated naturally-occurring brain cells. Then, the team experimentally iterated until they hit on a balance of cell types that resulted in functional, properly structured neurovascular units. This laborious process would turn out to be an advantageous feature of miBrains: because cell types are cultured separately, they can each be genetically edited so that the resulting model is tailored to replicate specific health and disease states.“Its highly modular design sets the miBrain apart, offering precise control over cellular inputs, genetic backgrounds, and sensors — useful features for applications such as disease modeling and drug testing,” says Stanton.Alzheimer’s discovery using miBrainTo test miBrain’s capabilities, the researchers embarked on a study of the gene variant APOE4, which is the strongest genetic predictor for the development of Alzheimer’s disease. Although one brain cell type, astrocytes, are known to be a primary producer of the APOE protein, the role that astrocytes carrying the APOE4 variant play in disease pathology is poorly understood.MiBrains were well-suited to the task for two reasons. First of all, they integrate astrocytes with the brain’s other cell types, so that their natural interactions with other cells can be mimicked. Second, because the platform allowed the team to integrate cell types individually, APOE4 astrocytes could be studied in cultures where all other cell types carried APOE3, a gene variant that does not increase Alzheimer’s risk. This enabled the researchers to isolate the contribution APOE4 astrocytes make to pathology.In one experiment, the researchers examined APOE4 astrocytes cultured alone, versus ones in APOE4 miBrains. They found that only in the miBrains did the astrocytes express many measures of immune reactivity associated with Alzheimer’s disease, suggesting the multicellular environment contributes to that state.The researchers also tracked the Alzheimer’s-associated proteins amyloid and phosphorylated tau, and found all-APOE4 miBrains accumulated them, whereas all-APOE3 miBrains did not, as expected. However, in APOE3 miBrains with APOE4 astrocytes, they found that APOE4 miBrains still exhibited amyloid and tau accumulation.Then the team dug deeper into how APOE4 astrocytes’ interactions with other cell types might lead to their contribution to disease pathology. Prior studies have implicated molecular cross-talk with the brain’s microglia immune cells. Notably, when the researchers cultured APOE4 miBrains without microglia, their production of phosphorylated tau was significantly reduced. When the researchers dosed APOE4 miBrains with culture media from astrocytes and microglia combined, phosphorylated tau increased, whereas when they dosed them with media from cultures of astrocytes or microglia alone, the tau production did not increase. The results therefore provided new evidence that molecular cross-talk between microglia and astrocytes is indeed required for phosphorylated tau pathology.In the future, the research team plans to add new features to miBrains to more closely model characteristics of working brains, such as leveraging microfluidics to add flow through blood vessels, or single-cell RNA sequencing methods to improve profiling of neurons.Researchers expect that miBrains could advance research discoveries and treatment modalities for Alzheimer’s disease and beyond. “Given its sophistication and modularity, there are limitless future directions,” says Stanton. “Among them, we would like to harness it to gain new insights into disease targets, advanced readouts of therapeutic efficacy, and optimization of drug delivery vehicles.”“I’m most excited by the possibility to create individualized miBrains for different individuals,” adds Tsai. “This promises to pave the way for developing personalized medicine.”Funding for the study came from the BT Charitable Foundation, Freedom Together Foundation, the Robert A. and Renee E. Belfer Family, Lester A. Gimpelson, Eduardo Eurnekian, Kathleen and Miguel Octavio, David B. Emmes, the Halis Family, the Picower Institute, and an anonymous donor.", "release_time": "2025-11-07", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/researchers-invent-human-brain-model-to-enable-disease-research-drug-discovery-1105"}
{"category": "产业应用", "title": "亚洲海运冶金煤价格坚挺，中国需求复苏支撑市场", "short_summary": "亚洲海运冶金煤价格因中国需求反弹而走强，印度需求延迟复苏支撑四季度前景。", "detailed_summary": "亚洲海运冶金煤价格因中国需求反弹而走强，印度需求延迟复苏支撑四季度前景。\n(1) 亚洲海运冶金煤市场预计第四季度价格保持坚挺，主因印度季风季后需求复苏和中国持续兴趣。\n(2) 第三季度优质低挥发份硬焦煤价格指数上涨9.6%，中国现货市场活跃度反弹推动价格回升。\n(3) 中国需求增长得益于国内期货价格上涨和政策刺激，低挥发份硬焦煤相对溢价升至四年来高点。\n(4) 印度进口需求因季风季节延长而有限，但预计后续复苏；澳大利亚生产商现货供应紧张。\n(5) 市场前景依赖中国政策变化，价差收窄显示供应多元化，加拿大煤炭在中国港口具有价格优势。", "raw_content": "据标普全球普氏(S&P Global Platts)10月22日发布的信息，亚洲海运冶金煤市场预计第四季度价格将保持坚挺，这主要得益于季风季节过后印度需求的预期复苏以及中国的持续兴趣。然而，市场前景可能仍取决于中国可能的政策变化，特别是涉及钢铁生产和煤炭开采方面的政策。 三季度，各等级的区域性价格因中国低挥发分硬焦煤需求的回升而走强，这也支撑了低挥发分硬焦煤价格相对于优质低挥发分硬焦煤(LV HCC)评估价的反弹。 相对应的是，作为海运冶金煤最大进口国的印度，由于其持续的季风季节一直延续到10月中旬，因此进口需求兴趣有限。 根据标普全球大宗商品洞察旗下(S&P Global Commodity Insights)普氏能源资讯的数据，第三季度优质低挥发份硬焦煤价格指数(PLV HCC index)稳步上涨，回升了16.7美元/吨，上涨9.6%，即从7月1日的173.5美元/吨升至9月30日的190.20美元/吨。 中国重返低挥发份硬焦煤(LV HCC)现货市场。三季度中国海运炼焦煤现货市场活跃度反弹，主要得益于大连商品交易所自7月初以来炼焦煤期货价格的上涨。 最活跃的1月合约在第三季度上涨了78%，较6月3日创下的九年来低点709元/吨大幅回升，9月17日达到1258.50元/吨(约合176美元/吨)，该合约在第三季度最后一个交易日(10月1日至8日国庆假期前夕)收盘于1126元/吨。 这次涨价是本季度早些时候中国钢铁价格上涨更广泛趋势的一部分，该上涨趋势应是受到了国家统计局7月15日发布的GDP积极数据以及河南省政府7月21日发出的关于限制煤炭超能力生产通知的推动。 据普氏能源资讯的计算，由于国内焦煤价格较高，为焦煤贸易商创造了套利机会，8月13日国内与海运市场焦煤价格差扩大至每吨20美元。 一位来自浙江的交易员表示：“中国贸易商对澳大利亚、印尼和加拿大的煤炭表现出浓厚兴趣，我们也在积极寻找现货船货。”与此同时，澳大利亚生产商称，他们现有的现货船货不足以满足需求。   第三季度普氏低挥发份硬焦煤(LV HCC)中国到岸价指数平均为每吨164美元，较第二季度的每吨147.50美元每吨上涨了16.50美元，并于9月23日触及到10个月来的高点每吨180美元。 这同时也推高了普氏LV HCC澳大利亚离岸价指数，该指数第三季度平均为每吨150.68美元，环比每吨上涨了6.68美元。 随着对中国兴趣的增加，普氏能源资讯(Platts)在第三季度公布了1092笔基于CFR中国价格条款的所有冶金煤等级的报价、出价、交易及可交易意向，而第二季度这一数字为580笔。 低挥发份硬焦煤(LV HCC)相对值收窄。中国对低挥发份硬焦煤(LV HCC)的兴趣也带来对优质硬焦煤(PHCC)品种货物产生了一定影响，尽管影响程度较轻，但也导致LV HCC价格相对于PLV HCC评估的溢价要更高一些。 基于中国到岸价(CFR)的基准，普氏低挥发份硬焦煤(LV HCC)指数的相对值在第三季度升至91.7%，为近四年来最高水平，较第二季度的88.7%有所上升。 上一次的季度均值高的是在2021年第一季度，当时中国实施了对澳大利亚煤炭进口的非官方禁令。 一位总部位于新加坡的交易员表示，中国煤炭生产运营可能面临削减，这为优质硬焦煤价格提供了上涨机会，他对中国到岸价(CFR)和澳大利亚离岸价(FOB)都持看涨观点。“我们也看到了进一步政府刺激措施出台的可能性，这可能会提振钢铁需求。”   交易员表示，尽管中国的交易员考虑在LV HCC 价格上涨时购买 PHCCs，但由于在中国港口库存的加拿大炼焦煤具有价格竞争优势，使他们从未在现货市场购买澳大利亚 PHCCs。 9月，加拿大优质和标准的炼焦煤在中国北方港口的库提价达到今年以来的高点每吨1600-1620元人民币，相当于每吨189-191美元中国到岸价(CFR)。相比之下，根据普氏的计算，澳大利亚优质硬焦煤(PHCC)中国到岸价(CFR，含巴拿马型船运费)的平均价格为每吨202.05美元，这一水平显然高于中国港口库存的加拿大炼焦煤价格。 第三季度普氏优质低挥发份硬焦煤中国到岸价(PLV HCC CFR)指数平均为176美元/吨，季环比每吨上涨10美元，但仍落后于低挥发份硬焦煤中国到岸价(LV HCC CFR)指数每吨上涨的16.50美元。同样，第三季度普氏优质低挥发份硬焦煤(PLV HCC)京唐港库提价指数平均为1482元/吨，也比前一季度每吨上涨了217元。 优质低挥发份硬焦煤中国到岸价(PLV HCC CFR0 与澳大利亚离岸价(FOB)的价差收窄。中国市场价格上涨，使普氏优质低挥发份硬焦煤(PLV HCC)澳大利亚离岸价(FOB)与中国到岸价(CFR)的指数价差在第三季度末收窄至每吨3.20美元，较季度初的每吨15.50美元大为收窄。然而，中国市场参与者并不预期该价差会倒挂，除非对澳大利亚优质硬焦煤(PHCCs)的需求显著增强。   浙江的这位商人表示：“已经不太可能回到过去了，因为中国市场有更多的供应选择，我们不再是处于一半进口量都来自澳大利亚的年代了。” 根据“标普全球大宗商品航运”(S&P Global Commodities at Sea)10月13日的数据，今年1月至9月，中国从澳大利亚和加拿大进口的煤炭数量基本相当，分别为1000万吨和880万吨。 与此同时，普氏能源资讯(Platts)数据显示，2025年前9个月，澳大利亚半硬焦煤(PHCCs)价格获得了南亚地区的价格支持，80笔交易中有68笔的收货目的地为印度。", "release_time": "2025-11-05", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195757-1.html"}
{"category": "研究前沿", "title": "MIT新AI系统实现机器人快速3D场景重建", "short_summary": "MIT研发AI系统可秒级生成复杂3D地图，助力搜救机器人高效导航。", "detailed_summary": "MIT研发AI系统可秒级生成复杂3D地图，助力搜救机器人高效导航。\n(1) MIT研究人员开发新型AI系统，解决机器人同步定位与建图（SLAM）中处理大量图像速度慢的难题。\n(2) 核心技术是将场景分割为小型子地图进行增量生成，再通过数学变换对齐拼接成完整3D重建图。\n(3) 系统无需相机预先校准或复杂调试，5秒内可重建MIT教堂等复杂场景，平均误差小于5厘米。\n(4) 相比现有模型仅能处理约60张图像，新方法支持任意数量图像处理，显著提升实时性。\n(5) 技术可应用于搜救机器人导航、仓库工业机器人及VR设备等扩展现实领域。", "raw_content": "A robot searching for workers trapped in a partially collapsed mine shaft must rapidly generate a map of the scene and identify its location within that scene as it navigates the treacherous terrain.Researchers have recently started building powerful machine-learning models to perform this complex task using only images from the robot’s onboard cameras, but even the best models can only process a few images at a time. In a real-world disaster where every second counts, a search-and-rescue robot would need to quickly traverse large areas and process thousands of images to complete its mission.To overcome this problem, MIT researchers drew on ideas from both recent artificial intelligence vision models and classical computer vision to develop a new system that can process an arbitrary number of images. Their system accurately generates 3D maps of complicated scenes like a crowded office corridor in a matter of seconds. The AI-driven system incrementally creates and aligns smaller submaps of the scene, which it stitches together to reconstruct a full 3D map while estimating the robot’s position in real-time.Unlike many other approaches, their technique does not require calibrated cameras or an expert to tune a complex system implementation. The simpler nature of their approach, coupled with the speed and quality of the 3D reconstructions, would make it easier to scale up for real-world applications.Beyond helping search-and-rescue robots navigate, this method could be used to make extended reality applications for wearable devices like VR headsets or enable industrial robots to quickly find and move goods inside a warehouse.“For robots to accomplish increasingly complex tasks, they need much more complex map representations of the world around them. But at the same time, we don’t want to make it harder to implement these maps in practice. We’ve shown that it is possible to generate an accurate 3D reconstruction in a matter of seconds with a tool that works out of the box,” says Dominic Maggio, an MIT graduate student and lead author of a paper on this method.Maggio is joined on the paper by postdoc Hyungtae Lim and senior author Luca Carlone, associate professor in MIT’s Department of Aeronautics and Astronautics (AeroAstro), principal investigator in the Laboratory for Information and Decision Systems (LIDS), and director of the MIT SPARK Laboratory. The research will be presented at the Conference on Neural Information Processing Systems.Mapping out a solutionFor years, researchers have been grappling with an essential element of robotic navigation called simultaneous localization and mapping (SLAM). In SLAM, a robot recreates a map of its environment while orienting itself within the space.Traditional optimization methods for this task tend to fail in challenging scenes, or they require the robot’s onboard cameras to be calibrated beforehand. To avoid these pitfalls, researchers train machine-learning models to learn this task from data.While they are simpler to implement, even the best models can only process about 60 camera images at a time, making them infeasible for applications where a robot needs to move quickly through a varied environment while processing thousands of images.To solve this problem, the MIT researchers designed a system that generates smaller submaps of the scene instead of the entire map. Their method “glues” these submaps together into one overall 3D reconstruction. The model is still only processing a few images at a time, but the system can recreate larger scenes much faster by stitching smaller submaps together.“This seemed like a very simple solution, but when I first tried it, I was surprised that it didn’t work that well,” Maggio says.Searching for an explanation, he dug into computer vision research papers from the 1980s and 1990s. Through this analysis, Maggio realized that errors in the way the machine-learning models process images made aligning submaps a more complex problem.Traditional methods align submaps by applying rotations and translations until they line up. But these new models can introduce some ambiguity into the submaps, which makes them harder to align. For instance, a 3D submap of a one side of a room might have walls that are slightly bent or stretched. Simply rotating and translating these deformed submaps to align them doesn’t work.“We need to make sure all the submaps are deformed in a consistent way so we can align them well with each other,” Carlone explains.A more flexible approachBorrowing ideas from classical computer vision, the researchers developed a more flexible, mathematical technique that can represent all the deformations in these submaps. By applying mathematical transformations to each submap, this more flexible method can align them in a way that addresses the ambiguity.Based on input images, the system outputs a 3D reconstruction of the scene and estimates of the camera locations, which the robot would use to localize itself in the space.“Once Dominic had the intuition to bridge these two worlds — learning-based approaches and traditional optimization methods — the implementation was fairly straightforward,” Carlone says. “Coming up with something this effective and simple has potential for a lot of applications.Their system performed faster with less reconstruction error than other methods, without requiring special cameras or additional tools to process data. The researchers generated close-to-real-time 3D reconstructions of complex scenes like the inside of the MIT Chapel using only short videos captured on a cell phone.The average error in these 3D reconstructions was less than 5 centimeters.In the future, the researchers want to make their method more reliable for especially complicated scenes and work toward implementing it on real robots in challenging settings.“Knowing about traditional geometry pays off. If you understand deeply what is going on in the model, you can get much better results and make things much more scalable,” Carlone says.This work is supported, in part, by the U.S. National Science Foundation, U.S. Office of Naval Research, and the National Research Foundation of Korea. Carlone, currently on sabbatical as an Amazon Scholar, completed this work before he joined Amazon.", "release_time": "2025-11-06", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/teaching-robots-to-map-large-environments-1105"}
{"category": "产业应用", "title": "荷兰蓝魔2025产业活动聚焦国防创新", "short_summary": "荷兰蓝魔活动将汇聚国防与航空领袖，探讨新兴技术应用与产业合作。", "detailed_summary": "荷兰蓝魔活动将汇聚国防与航空领袖，探讨新兴技术应用与产业合作。\n（1）Blue Magic Netherlands 2025活动将于11月18日在荷兰埃因霍温举行；\n（2）荷兰国防采购部长Gijs Tuinman和北约DIANA总法律顾问Thomas McSorley将发表主题演讲；\n（3）活动旨在促进荷兰工业生态系统内的技术构思与实施，连接企业与投资者；\n（4）荷兰本土技术及航空航天公司将展示下一代创新解决方案；\n（5）活动由通用原子航空系统公司牵头，联合多家合作伙伴共同举办，以应对全球国防与安全挑战。", "raw_content": "GA-ASI Announces Netherlands’ SecDef and NATO-DIANA General Counsel To Headline Dutch Industry Event Being Held on Nov. 18 SAN DIEGO – 05 November 2025 – As the Blue Magic Netherlands (BMNL) 2025 event team continues to collect registrations for event attendees, the organizers have announced that two major figures in Dutch and European defence will be keynote speakers for the November 18 event in Eindhoven: Dutch Minister for Arms Procurement and Personnel Gijs Tuinman and General Counsel at NATO-Defence Innovation Accelerator for the North Atlantic (DIANA) Thomas McSorley. “Our Blue Magic events have become known for connecting businesses and technology with investors,” said Brad Lunn, Managing Director at General Atomics Aeronautical Systems, Inc. (GA-ASI), the lead organizer of BMNL. “We also want our events to deliver important industry information and insights from key European defence leaders, so we’re thrilled to have Gijs Tuinman and Tom McSorley speak at this year’s event.” This will be Mr. Tuinman’s first appearance at BMNL and Mr. McSorley’s second. In addition, Paul Malcontent from VDL Defentec and Hugo Leyte from ODIN have accepted invitations to speak at BMNL. Blue Magic Netherlands fosters technology ideation and implementation within the Dutch industrial ecosystem. Netherlands-based technology and aerospace companies will pitch their innovative, next-gen solutions that could shape the course of commercial and defence technologies. The event is open for anyone interested in networking with attendees and they are encouraged to register no later than November 10. Registration form and details about the event agenda are located at http://www.ga-asi.com/blue-magic-netherlands-2025. BMNL brings together leaders in advanced technology, aerospace, business, and government in a single Dutch forum to explore emerging technologies that address the world’s most pressing defence and security challenges. Along with partners Brainport Development Eindhoven, Lockheed Martin Ventures, Brabant Development Agency, and the Netherlands Industries for Defence & Security (NIDV), GA-ASI will hear from Dutch businesses as they present capabilities on a broad range of technologies. Participating in this transformational event provides an ideal opportunity to connect with funding sources and collaborate with industry leaders.  About GA-ASI General Atomics Aeronautical Systems, Inc., is the world’s foremost builder of Unmanned Aircraft Systems (UAS). Logging more than 9 million flight hours, the Predator® line of UAS has flown for over 30 years and includes MQ-9A Reaper®, MQ-1C Gray Eagle®, MQ-20 Avenger®, and MQ-9B SkyGuardian®/SeaGuardian®. The company is dedicated to providing long-endurance, multi-mission solutions that deliver persistent situational awareness and rapid strike. For more information, visit www.ga-asi.com      Avenger, EagleEye, Gray Eagle, Lynx, Predator, Reaper, SeaGuardian, and SkyGuardian are trademarks of General Atomics Aeronautical Systems, Inc., registered in the United States and/or other countries.", "release_time": "2025-11-06", "source_institution": "通用原子能公司", "url": "http://www.ga.com/tuinman-and-mcsorley-will-keynote-blue-magic-netherlands-2025"}
{"category": "研究前沿", "title": "韩国团队研发新型铜基催化剂，低温高效转化二氧化碳", "short_summary": "韩国研究所开发出世界领先铜基催化剂，可在400°C低温下高效将二氧化碳转化为燃料原料。", "detailed_summary": "韩国研究所开发出世界领先铜基催化剂，可在400°C低温下高效将二氧化碳转化为燃料原料。\n(1) 韩国能源研究所团队成功研发出一种新型铜-镁-铁混合氧化物催化剂。\n(2) 该催化剂专用于逆水煤气变换反应，可将二氧化碳转化为合成燃料关键原料一氧化碳。\n(3) 其最大突破在于能在400°C相对低温下高效工作，避免镍基催化剂高温结块问题且不产生甲烷副产物。\n(4) 性能表现卓越：一氧化碳产率达33.4%，生成速率比商用铜催化剂快1.7倍，甚至优于昂贵铂基催化剂。\n(5) 该技术为利用廉价金属生产可持续合成燃料提供突破性方案，有力推动碳中和与绿色燃料商业化进程。", "raw_content": "A team of scientists led by Dr. Kee Young Koo from the Hydrogen Research Department at the Korea Institute of Energy Research (President Yi Chang-Keun, hereafter referred to as KIER) has created a world-leading catalyst capable of transforming carbon dioxide, a major greenhouse gas, into an essential ingredient for producing eco-friendly fuels.  The reverse water-gas shift (RWGS) reaction is a chemical process that converts carbon dioxide (CO2) into carbon monoxide (CO) and water (H2O) by reacting it with hydrogen (H2) in a reactor. The resulting carbon monoxide can then be combined with hydrogen to make syngas, a fundamental building block used to produce synthetic fuels such as e-fuels* and methanol. Because of its ability to recycle CO2 into usable fuel components, the RWGS reaction is seen as a promising pathway for advancing sustainable energy production. Overcoming the Limits of Conventional Catalysts Traditionally, the RWGS reaction operates best at temperatures above 800 °C. Nickel-based catalysts are often used because they can withstand such heat, but they lose performance over time as particles clump together, reducing surface area and efficiency. Operating at lower temperatures avoids this problem, but it also leads to the formation of unwanted byproducts such as methane, lowering carbon monoxide output. To make the process more efficient and affordable, researchers have been searching for catalysts that remain highly active under low-temperature conditions. The KIER team succeeded by developing a new copper-based catalyst that delivers outstanding results at just 400 °C. A Breakthrough in Copper Catalyst Design The newly engineered copper-magnesium-iron mixed oxide catalyst outperformed commercial copper catalysts, producing carbon monoxide 1.7 times faster and with a 1.5 times higher yield at 400 °C.  Copper catalysts have a key advantage over nickel: they can selectively produce only carbon monoxide at temperatures below 400 °C without forming methane. However, copper's thermal stability typically weakens near that temperature, leading to particle agglomeration and loss of activity. To solve this challenge, Dr. Koo's team incorporated a layered double hydroxide (LDH) structure into their design. This layered structure contains thin metal sheets with water molecules and anions between them. By adjusting the ratio and type of metal ions, the researchers fine-tuned the catalyst's physical and chemical characteristics. Adding iron and magnesium helped fill the gaps between copper particles, effectively preventing clumping and improving heat resistance. Real-time infrared analysis and reaction testing revealed why the new catalyst performs so well. Conventional copper catalysts convert CO2 into carbon monoxide through intermediate compounds called formates. The new material, however, bypasses these intermediates entirely, converting CO2 directly into CO on its surface. Because it avoids side reactions that produce methane or other byproducts, the catalyst maintains high activity even at a relatively low temperature of 400 °C. Record Performance and Global Significance At 400 °C, the catalyst achieved a carbon monoxide yield of 33.4% and a formation rate of 223.7 micromoles per gram of catalyst per second (μmol·gcat⁻¹·s⁻¹), maintaining stability for over 100 continuous hours. These results represent a 1.7-fold higher formation rate and a 1.5-fold higher yield than standard copper catalysts. When compared to platinum-based catalysts, which are costly but highly active, the new catalyst still outperformed them with a 2.2-fold faster formation rate and a 1.8-fold higher yield. This places it among the top-performing CO2 conversion catalysts in the world. \"The low-temperature CO2 hydrogenation catalyst technology is a breakthrough achievement that enables the efficient production of carbon monoxide using inexpensive and abundant metals,\" said Dr. Kee Young Koo, the project's lead researcher. \"It can be directly applied to the production of key feedstocks for sustainable synthetic fuels. Moving forward, we will continue our research to expand its application to real industrial settings, thereby contributing to the realization of carbon neutrality and the commercialization of sustainable synthetic fuel production technologies.\" Notes * E-Fuels are synthetic fuels produced by combining green hydrogen, generated with renewable electricity, and captured CO2 from the atmosphere or sustainable biomass. They are emerging as a promising alternative to conventional fossil fuels, especially for hard-to-decarbonize sectors such as aviation and shipping. The research findings were published online in May 2025 in Applied Catalysis B: Environmental and Energy, a leading journal in the field of energy and environmental catalysis. The study was supported by the KIER's R&D project, 'Development of e-SAF (sustainable aviation fuel) production technology from carbon dioxide and hydrogen.", "release_time": "2025-11-06", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/11/251105050712.htm"}
{"category": "研究前沿", "title": "MIT研发可注射微型脑芯片，无创治疗脑部疾病", "short_summary": "MIT开发出可通过注射递送的微型无线生物电子器件，能自主靶向脑区进行精准神经调控。", "detailed_summary": "MIT开发出可通过注射递送的微型无线生物电子器件，能自主靶向脑区进行精准神经调控。\n(1) MIT研究人员开发出名为\"循环电子学\"的微型无线生物电子器件，尺寸极小，可通过臂部注射进入血液循环。\n(2) 该器件与活体免疫细胞融合，能自主穿越完整血脑屏障并精准植入目标脑区，无需外科手术。\n(3) 通过外部无线供能，器件可对目标区域进行高精度电刺激（神经调控），精度达微米级且不损伤周围神经元。\n(4) 该技术在小鼠实验中成功靶向脑部炎症，有望治疗阿尔茨海默症、多发性硬化症、脑肿瘤等疾病。\n(5) 此平台技术有望三年内进入临床试验，未来或可扩展至身体其他部位疾病的治疗。", "raw_content": "What if clinicians could place tiny electronic chips in the brain that electrically stimulate a precise target, through a simple injection in the arm? This may someday help treat deadly or debilitating brain diseases, while eliminating surgery-related risks and costs.MIT researchers have taken a major step toward making this scenario a reality. They developed microscopic, wireless bioelectronics that could travel through the body’s circulatory system and autonomously self-implant in a target region of the brain, where they would provide focused treatment.In a study on mice, the researchers show that after injection, these miniscule implants can identify and travel to a specific brain region without the need for human guidance. Once there, they can be wirelessly powered to provide electrical stimulation to the precise area. Such stimulation, known as neuromodulation, has shown promise as a way to treat brain tumors and diseases like Alzheimer’s and multiple sclerosis.Moreover, because the electronic devices are integrated with living, biological cells before being injected, they are not attacked by the body’s immune system and can cross the blood-brain barrier while leaving it intact. This maintains the barrier’s crucial protection of the brain.   The researchers demonstrated the use of this technology, which they call “circulatronics,” to target brain inflammation, a major factor in the progression of many neurological diseases. They show that the implants can provide localized neuromodulation deep inside the brain achieving high precision, to within several microns around the target area.In addition, the biocompatible implants do not damage surrounding neurons.While brain implants usually require hundreds of thousands of dollars in medical costs and risky surgical procedures, circulatronics technology holds the potential to make therapeutic brain implants accessible to all by eliminating the need for surgery, says Deblina Sarkar, the AT&T Career Development Associate Professor in the MIT Media Lab and MIT Center for Neurobiological Engineering, head of the Nano-Cybernetic Biotrek Lab, and senior author of a study on the work.She is joined on the paper by lead author Shubham Yadav, an MIT graduate student; as well as others at MIT, Wellesley College, and Harvard University. The research appears today in Nature Biotechnology.Hybrid implantsThe team has been working on circulatronics for more than six years. The electronic devices, each about one-billionth the length of a grain of rice, are composed of organic semiconducting polymer layers sandwiched between metallic layers to create an electronic heterostructure.They are fabricated using CMOS-compatible processes in the MIT.nano facilities, and then integrated with living cells to create cell-electronics hybrids. To do this, the researchers lift the devices off the silicon wafer on which they are fabricated, so they are free-floating in a solution.“The electronics worked perfectly when they were attached to the substrate, but when we originally lifted them off, they didn’t work anymore. Solving that challenge took us more than a year,” Sarkar says.Key to their operation is the high wireless power conversion efficiency of the tiny electronics. This enables the devices to work deep inside the brain and still harness enough energy for neuromodulation.The researchers use a chemical reaction to bond the electronic devices to cells. In the new study, they fused the electronics with a type of immune cell called monocytes, which target areas of inflammation in the body. They also applied a fluorescent dye, allowing them to trace the devices as they crossed the intact blood-brain barrier and self-implanted in the target brain region.While they explored brain inflammation in this study, the researchers hope to use different cell types and engineer the cells to target specific regions of the brain.“Our cell-electronics hybrid fuses the versatility of electronics with the biological transport and biochemical sensing prowess of living cells,” Sarkar says. “The living cells camouflage the electronics so that they aren’t attacked by the body’s immune system and they can travel seamlessly through the bloodstream. This also enables them to squeeze through the intact blood-brain barrier without the need to invasively open it.”Over the course of about four years, the team tried many methods to autonomously and noninvasively cross the blood-brain barrier before they perfected this cellular integration technique.In addition, because the circulatronics devices are so tiny, they offer much higher precision than conventional electrodes. They can self-implant, leading to millions of microscopic stimulation sites that take the exact shape of the target region.Their small size also enables the biocompatible devices to live alongside neurons without causing harmful effects. Through a series of biocompatibility tests, the researchers found that circulatronics can safely integrate among neurons without impacting the brain processes behind cognition or motion.After the devices have self-implanted in the target region, a clinician or researcher uses an external transmitter to provide electromagnetic waves, in the form of near-infrared light, that power the technology and enable electrical stimulation of the neurons.Targeting deadly diseasesThe Sarkar lab is currently working on developing their technology to treat multiple diseases including brain cancer, Alzheimer’s disease, and chronic pain.The tiny size and self-implantation capabilities of circulatronics devices could make them well-suited to treat brain cancers such as glioblastoma that cause tumors at multiple locations, some of which may be too small to identify with imaging techniques. They may also provide new avenues for treating especially deadly cancers like diffuse intrinsic pontine glioma, an aggressive type of tumor found in the brain stem that usually cannot be surgically removed.“This is a platform technology and may be employed to treat multiple brain diseases and mental illnesses,” Sarkar says. “Also, this technology is not just confined to the brain but could also be extended to other parts of the body in future.”The researchers hope to move the technology into clinical trials within three years through the recently launched startup Cahira Technologies.They are also exploring integration of additional nanoelectronic circuits into their devices to enable functionalities including sensing, feedback based on-chip data analysis, and capabilities such as creating synthetic electronic neurons.“Our tiny electronic devices seamlessly integrate with the neurons and co-live and co-exist with the brain cells creating a unique brain-computer symbiosis. We are working dedicatedly to employ this technology for treating neural diseases, where drugs or standard therapies fail, for alleviating human suffering and envision a future where humans could transcend beyond diseases and biological limitations,” says Sarkar.", "release_time": "2025-11-05", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/new-therapeutic-brain-implants-defy-surgery-need-1105"}
{"category": "产业应用", "title": "欧佩克+决定12月日均增产13.7万桶原油", "short_summary": "欧佩克+八国12月小幅增产，但计划2026年初暂停增产步伐。", "detailed_summary": "欧佩克+八国12月小幅增产，但计划2026年初暂停增产步伐。\n(1) 欧佩克+中的八个主要产油国决定自12月起日均增产原油13.7万桶。\n(2) 增产幅度与10月、11月保持一致。\n(3) 计划于2026年的1月、2月和3月暂停增产，主要考虑季节性因素。\n(4) 参与决策的国家包括沙特阿拉伯、俄罗斯、伊拉克、阿联酋、科威特、哈萨克斯坦、阿尔及利亚和阿曼。\n(5) 自4月以来八国逐步增产，但因市场预测供应过剩，10月起已放缓增产步伐。", "raw_content": "11月3日电 据路透社报道，当地时间11月2日，石油输出国组织(欧佩克)发表声明称，欧佩克和非欧佩克产油国中的8个主要产油国决定，自12月起日均增产13.7万桶原油，但2026年前三个月将暂停增产计划。  据报道，沙特阿拉伯、俄罗斯、伊拉克、阿联酋、科威特、哈萨克斯坦、阿尔及利亚和阿曼的代表当天举行线上会议，同意将12月的日产量目标提高13.7万桶，与10月和11月的增产幅度相同。 声明还指出，考虑到季节性因素，上述国家决定在2026年1月、2月和3月暂停增产步伐。 报道称，自4月份以来，八国逐步增加原油产量，但由于市场预测供应过剩即将到来，10月起又放缓了增产步伐。", "release_time": "2025-11-04", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195674-1.html"}
{"category": "研究前沿", "title": "MIT研发新方法预测未来飞机雷击风险", "short_summary": "MIT团队开发基于物理学的雷击区域预测工具，助力未来非常规飞机设计安全。", "detailed_summary": "MIT团队开发基于物理学的雷击区域预测工具，助力未来非常规飞机设计安全。\n(1) 研究背景：传统飞机依赖历史飞行数据确定雷击防护区，但未来非常规飞机设计（如翼身融合体、桁架支撑翼）无法沿用此方法。\n(2) 方法原理：MIT团队开发基于流体动力学和统计模型的物理工具，模拟雷击初始附着点及电流在机身的扫掠路径。\n(3) 验证过程：在传统管翼结构上验证，生成的分区图与行业多年经验结果一致。\n(4) 应用前景：该方法可为任何几何形状的飞机设计早期提供雷击防护分区指导，优化重量与安全性。\n(5) 潜在影响：研究正推动纳入行业标准，并有望应用于风力涡轮机等其他领域。", "raw_content": "More than 70 aircraft are struck by lightning every day. If you happen to be flying when a strike occurs, chances are you won’t feel a thing, thanks to lightning protection measures that are embedded in key zones throughout the aircraft.Lightning protection systems work well, largely because they are designed for planes with a “tube-and-wing” structure, a simple geometry common to most aircraft today. But future airplanes may not look and fly the same way. The aviation industry is exploring new designs, including blended-wing bodies and truss-braced wings, partly to reduce fuel and weight costs. But researchers don’t yet know how these unconventional designs might respond to lightning strikes.MIT aerospace engineers are hoping to change that with a new physics-based approach that predicts how lightning would sweep across a plane with any design. The tool then generates a zoning map highlighting sections of an aircraft that would require various degrees of lightning protection, given how they are likely to experience a strike.“People are starting to conceive aircraft that look very different from what we’re used to, and we can’t apply exactly what we know from historical data to these new configurations because they’re just too different,” says Carmen Guerra-Garcia, associate professor of aeronautics and astronautics (AeroAstro) at MIT. “Physics-based methods are universal. They’re agnostic to the type of geometry or vehicle. This is the path forward to be able to do this lightning zoning and protect future aircraft.”She and her colleagues report their results in a study appearing this week in IEEE Access. The study’s first author is AeroAstro graduate student Nathanael Jenkins. Other co-authors include Louisa Michael and Benjamin Westin of Boeing Research and Technology.First strikeWhen lightning strikes, it first attaches to a part of a plane — typically a sharp edge or extremity — and hangs on for up to a second. During this brief flash, the plane continues speeding through the air, causing the lightning current to “sweep” over parts of its surface, potentially changing in intensity and re-attaching at certain points where the intense current flow could damage vulnerable sections of an aircraft.In previous work, Guerra-Garcia’s group developed a model to predict the parts of a plane where lightning is most likely to first connect. That work, led by graduate student Sam Austin, established a starting point for the team’s new work, which aims to predict how and where the lightning will then sweep over the plane’s surface. The team next converted their lightning sweep predictions into zoning maps to identify vulnerable regions requiring certain levels of protection.A typical tube-and-wing plane is divided into three main zones, as classified by the aviation industry. Each zone has a clear description of the level of current it must withstand in order to be certified for flight. Parts of a plane that are more likely to be hit by lightning are generally classified as zone 1 and require more protection, which can include embedded metal foil in the skin of the airplane that conducts away a lightning current.To date, an airplane’s lightning zones have been determined over many years of flight inspections after lightning strikes and fine-tuning of protection measures. Guerra-Garcia and her colleagues looked to develop a zoning approach based on physics, rather than historical flight data. Such a physics-based mapping could be applied to any shape of aircraft, such as unconventional and largely untested designs, to identify regions that really require reinforcement.“Protecting aircraft from lightning is heavy,” Jenkins says. “Embedding copper mesh or foil throughout an aircraft is an added weight penalty. And if we had the greatest level of protection for every part of the plane’s surface, the plane would weigh far too much. So zoning is about trying to optimize the weight of the system while also having it be as safe as possible.”In the zoneFor their new approach, the team developed a model to predict the pattern of lightning sweep and the corresponding lightning protection zones, for a given airplane geometry. Starting with a specific airplane shape — in their case, a typical tube-and-wing structure — the researchers simulated the fluid dynamics, or how air would flow around a plane, given a certain speed, altitude, and pitch angle. They also incorporated their previous model that predicts the places where lightning is more likely to initially attach.For each initial attachment point, the team simulated tens of thousands of potential lightning arcs, or angles from which the current strikes the plane. They then ran the model forward to predict how the tens of thousands of potential strikes would follow the air flow across the plane’s surface. These runs produced a statistical representation of where lightning, striking a specific point on a plane, is likely to flow and potentially cause damage. The team converted this statistical representation into a map of zones of varying vulnerability.They validated the method on a conventional tube-and-wing structure, showing that the zoning maps generated by the physics-based approach were consistent with what the aviation industry has determined over decades of fine-tuning.“We now have a physics-based tool that provides some metrics like the probability of lightning attachment and dwell time, which is how long an arc will linger at a specific point,” Guerra-Garcia explains. “We convert those physics metrics into zoning maps to show, if I’m in this red region, the lightning arc will stay for a long time, so that region needs to be heavily protected.”The team is starting to apply the approach to new geometries, such as blended-wing designs and truss-braced structures. The researchers envision that the tool can help designers incorporate safe and efficient lightning-protection systems early on in the design process.“Lightning is incredible and terrifying at the same time, and I have full confidence in flying on planes at the moment,” Jenkins says. “I want to have that same confidence in 20 years’ time. So, we need a new way to zone aircraft.”“With physics-based methods like the ones developed with professor Guerra-Garcia’s group we have the opportunity to shape industry standards and as an industry rely on the underlying physics to develop guidelines for aircraft certification through simulation,” says co-author Louisa Michael of Boeing Technology Innovation. Currently, we are engaging with industrial committees to propose these methods to be included in Aerospace Recommended Practices.”“Zoning unconventional aircraft is not an easy task,” adds co-author Ben Westin of Boeing Technology Innovation. “But these methods will allow us to confidently identify which threat levels each part of the aircraft needs to be protected against and certified for, and they give our design engineers a platform to do their best work to optimize aircraft design.”Beyond airplanes, Guerra-Garcia is looking at ways to adapt the lightning protection model to other technologies, including wind turbines.“About 60 percent of blade losses are due to lightning and will become worse as we move offshore because wind turbines will be even bigger and more susceptible to upward lightning,” she says. “They have many of the same challenges of a flowing gas environment. It’s more complex, and we will apply this same sort of methodology to this space.”This research was funded, in part, by the Boeing Company.", "release_time": "2025-11-04", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/lightning-prediction-tool-could-help-protect-planes-future-1104"}
{"category": "研究前沿", "title": "MIT研发可编程心脏修复贴片", "short_summary": "MIT工程师开发出可植入心脏的智能贴片，能按程序释放药物促进组织再生。", "detailed_summary": "MIT工程师开发出可植入心脏的智能贴片，能按程序释放药物促进组织再生。\n(1)MIT工程师成功研发一种柔性药物输送贴片，可在心脏病发作后植入心脏以促进愈合和再生。\n(2)该贴片核心创新在于可编程定时释放多种药物，分别于术后不同天数（如1-3天、7-9天、12-14天）递送防止细胞死亡、促进血管生成和抑制疤痕形成的药物。\n(3)在大鼠实验中，此疗法将心脏组织损伤面积减少50%，显著改善心功能，并将存活率提高33%。\n(4)贴片由生物相容性水凝胶制成，最终可在体内安全降解，未来有望通过临床试验应用于人类患者。", "raw_content": "MIT engineers have developed a flexible drug-delivery patch that can be placed on the heart after a heart attack to help promote healing and regeneration of cardiac tissue.The new patch is designed to carry several different drugs that can be released at different times, on a pre-programmed schedule. In a study of rats, the researchers showed that this treatment reduced the amount of damaged heart tissue by 50 percent and significantly improved cardiac function.If approved for use in humans, this type of patch could help heart attack victims recover more of their cardiac function than is now possible, the researchers say.“When someone suffers a major heart attack, the damaged cardiac tissue doesn’t regenerate effectively, leading to a permanent loss of heart function. The tissue that was damaged doesn’t recover,” says Ana Jaklenec, a principal investigator at MIT’s Koch Institute for Integrative Cancer Research. “Our goal is to restore that function and help people regain a stronger, more resilient heart after a myocardial infarction.”Jaklenec and Robert Langer, the David H. Koch Institute Professor at MIT and a member of the Koch Institute, are the senior authors of the new study, which appears today in Cell Biomaterials. Former MIT postdoc Erika Wangis the lead author of the paper.Programmed drug deliveryAfter a heart attack, many patients end up having bypass surgery, which improves blood flow to the heart but doesn’t repair the cardiac tissue that was damaged. In the new study, the MIT team wanted to create a patch that could be applied to the heart at the same time that the surgery is performed.This patch, they hoped, could deliver drugs over an extended time period to promote tissue healing. Many diseases, including heart conditions, require phase-specific treatment, but most systems release drugs all at once. Timed delivery better synchronizes therapy with recovery.“We wanted to see if it’s possible to deliver a precisely orchestrated therapeutic intervention to help heal the heart, right at the site of damage, while the surgeon is already performing open-heart surgery,” Jaklenec says.To achieve this, the researchers set out to adapt drug-delivery microparticles they had previously developed, which consist of capsules similar to tiny coffee cups with lids. These capsules are made from a polymer called PLGA and can be sealed with a drug inside.By changing the molecular weight of the polymers used to form the lids, the researchers can control how quickly they degrade, which enables them to program the particles to release their contents at specific times. For this application, the researchers designed particles that break down during days 1-3, days 7-9, and days 12-14 after implantation.This allowed them to devise a regimen of three drugs that promote heart healing in different ways. The first set of particles release neuregulin-1, a growth factor that helps to prevent cell death. At the next time point, particles release VEGF, a growth factor that promotes formation of blood vessels surrounding the heart. The last batch of particles releases a small molecule drug called GW788388, which inhibits the formation of scar tissue that can occur following a heart attack.“When tissue regenerates, it follows a carefully timed series of steps,” Jaklenec says. “Dr. Wang created a system that delivers key components at just the right time, in the sequence that the body naturally uses to heal.”The researchers embedded rows of these particles into thin sheets of a tough but flexible hydrogel, similar to a contact lens. This hydrogel is made from alginate and PEGDA, two biocompatible polymers that eventually break down in the body. For this study, the researchers created compact, miniature patches only a few millimeters across.“We encapsulate arrays of these particles in a hydrogel patch, and then we can surgically implant this patch into the heart. In this way, we’re really programming the treatment into this material,” Wang says.Better heart functionOnce they created these patches, the researchers tested them on spheres of heart tissue that included cardiomyocytes generated from induced pluripotent stem cells. These spheres also included endothelial cells and human ventricular cardiac fibroblasts, which are also important components of the heart.The researchers exposed those spheres to low-oxygen conditions, mimicking the effects of a heart attack, then placed the patches over them. They found that the patches promoted blood vessel growth, helped more cells to survive, and reduced the amount of fibrosis that developed.In tests in a rat model of heart attack, the researchers also saw significant improvements following treatment with the patch. Compared to no treatment or IV injection of the same drugs, animals treated with the patch showed 33 percent higher survival rates, a 50 percent reduction in the amount of damaged tissue, and significantly increased cardiac output.The researchers showed that the patches would eventually dissolve over time, becoming a very thin layer over the course of a year without disrupting the heart’s mechanical function.“This is an important way to combine drug delivery and biomaterials to potentially new treatments for patients,” Langer says.Of the drugs tested in this study, neuregulin-1 and VEGF have been tested in clinical trials to treat heart conditions, but GW788388 has only been explored in animal models. The researchers now hope to test their patches in additional animal models in hopes of running a clinical trial in the future.The current version of the patch needs to be implanted surgically, but the researchers are exploring the possibility of incorporating these microparticles into stents that could be inserted into arteries to deliver drugs on a programmed schedule.Other authors of the paper include Elizabeth Calle, Binbin Ying, Behnaz Eshaghi, Linzixuan Zhang, Xin Yang, Stacey Qiaohui Lin, Jooli Han, Alanna Backx, Yuting Huang, Sevinj Mursalova, Chuhan Joyce Qi, and Yi Liu.The researchers were supported by the Natural Sciences and Engineering Research Council of Canada and the U.S. National Heart, Lung, and Blood Institute.", "release_time": "2025-11-05", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/new-patch-could-help-heal-heart-1104"}
{"category": "产业应用", "title": "进口煤市场稳中趋强 电厂刚需采购价分化", "short_summary": "进口煤价维持坚挺，电厂刚需采购谨慎，招标成交价呈现分化态势。", "detailed_summary": "进口煤价维持坚挺，电厂刚需采购谨慎，招标成交价呈现分化态势。\n(1) 进口煤炭市场整体表现稳中转好，外矿因销售压力不大且看好后市，报价保持坚挺。\n(2) 国内电厂对远期交货的进口煤维持刚需采购，招标活动较多，但对高价煤抵触情绪明显。\n(3) 采购行为谨慎，多以低价少量拿货为主，反映出当前电厂补库压力一般。\n(4) 具体案例显示，某大型电力集团招标中，12月上半月交期的3800卡煤种成交价出现分化，分别在463、468、473元/吨成交。", "raw_content": "进口市场表现稳中有所转好，国内电厂对远期交货的进口煤保持刚需采购，发布的招标仍然较多。外矿对后市继续看好加上当前销售压力不大，因此报价维持坚挺，进口商采购新货表现谨慎，对电厂投标价维持高位。 昨日某大型电力集团开标，各电厂收到的投标价和上期相比部分维稳，部分小幅上涨。 目前电厂补库压力一般，对高价抵触明显，依然是低价少量拿货， 如某电厂采购12月上半月交期的3800卡煤种，最终以463元/吨成交2船，以468、473元/吨分别成交1船。", "release_time": "2025-11-04", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195701-1.html"}
{"category": "研究前沿", "title": "原子间直接相互作用被发现可增强超辐射现象", "short_summary": "研究发现原子间直接相互作用可增强超辐射，为开发先进量子技术开辟新途径。", "detailed_summary": "研究发现原子间直接相互作用可增强超辐射，为开发先进量子技术开辟新途径。\n(1) 华沙大学与埃默里大学联合研究发现，原子间的直接偶极相互作用可以增强由光子介导的超辐射现象。\n(2) 超辐射是一种量子效应，原子在光腔中同步发射光，产生远超个体总和的亮度。\n(3) 研究团队开发了新计算方法，明确保留了光与物质间的量子纠缠，揭示了此前被忽略的原子相互作用的关键影响。\n(4) 该发现对量子电池、量子通信网络和高精度传感器等未来量子技术的发展具有重要指导意义。", "raw_content": "Researchers from the Faculty of Physics at the University of Warsaw, the Centre for New Technologies at the University of Warsaw, and Emory University (Atlanta, USA) have explored how atoms influence one another when interacting with light. Their study, published in Physical Review Letters, expands on existing models of this effect. By demonstrating that direct atom-to-atom interactions can enhance a powerful collective burst of light known as superradiance, the team opens new possibilities for developing advanced quantum technologies.  In light-matter systems, many emitters (e.g., atoms) share the same optical mode within a cavity. This mode represents a pattern of light confined between mirrors, enabling collective behaviors that isolated atoms cannot exhibit. A key example is superradiance, a quantum effect in which atoms emit light in perfect synchronization, creating a brightness far greater than the sum of their individual emissions. Most earlier studies of superradiance assumed that light-matter coupling dominates, modeling the entire atomic group as one large \"giant dipole\" connected to the cavity's electromagnetic field. \"Photons act as mediators that couple each emitter to all others inside the cavity,\" explains Dr. João Pedro Mendonça, the study's first author, who earned his PhD at the University of Warsaw and now conducts research at its Centre for New Technologies. In real materials, however, nearby atoms also interact through short-range dipole-dipole forces, which are often overlooked. The new study examines what happens when these intrinsic atom-atom interactions are considered. The findings show that such interactions can either compete with or reinforce the photon-mediated coupling responsible for superradiance. Understanding this balance is vital for interpreting experiments where light and matter strongly influence one another. The Role of Entanglement in Light-Matter Interactions At the heart of this behavior lies quantum entanglement, the deep connection between particles that share quantum states. Yet many common theoretical methods treat light and matter as separate entities, erasing this crucial link. \"Semiclassical models greatly simplify the quantum problem but at the cost of losing crucial information; they eﬀectively ignore possible entanglement between photons and atoms, and we found that in some cases this is not a good approximation,\" the authors note. To address this, the team developed a computational method that keeps entanglement explicitly represented, allowing them to track correlations both within and between the atomic and photonic subsystems. Their results show that direct interactions between neighboring atoms can lower the threshold for superradiance and even reveal a previously unknown ordered phase that shares its key properties. Overall, the work demonstrates that including entanglement is essential for accurately describing the full range of light-matter behaviors. Implications for Quantum Technologies Beyond deepening fundamental understanding, this discovery has practical significance for future quantum technologies. Cavity-based light-matter systems are central to many emerging devices, including quantum batteries -- conceptual energy storage units that could charge and discharge much faster by exploiting collective quantum effects. Superradiance can speed up both processes, enhancing overall efficiency. The new findings clarify how microscopic atomic interactions influence these processes. By adjusting the strength and nature of atom-atom interactions, scientists can tune the conditions needed for superradiance and control how energy moves through the system. \"Once you keep light-matter entanglement in the model, you can predict when a device will charge quickly and when it won't. That turns a many-body eﬀect into a practical design rule,\" said João Pedro Mendonça. Similar principles could also advance quantum communication networks and high-precision sensors. The research grew from an international partnership that brought together expertise from several institutions. João Pedro Mendonça conducted multiple research stays in the United States, supported by the University of Warsaw's \"Excellence Initiative -- Research University\" (IDUB) program and the Polish National Agency for Academic Exchange (NAWA). The researchers emphasize that collaboration and mobility were key to their success. \"This is a great example of how international mobility and collaboration can open the door to breakthroughs,\" the team concludes.", "release_time": "2025-11-04", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/11/251103093009.htm"}
{"category": "研究前沿", "title": "研究颠覆钠离子电池更安全认知，揭示其热失控风险", "short_summary": "青岛能源所发现钠离子电池热失控风险高于锂电，并提出系列安全优化方案。", "detailed_summary": "青岛能源所发现钠离子电池热失控风险高于锂电，并提出系列安全优化方案。\n（1）研究颠覆传统认知，发现钠离子电池在常规体系下热失控风险甚至高于锂离子电池。\n（2）机理在于硬碳负极中形成的准金属态高活性钠簇，会诱发电解液剧烈分解并触发热失控链式反应。\n（3）团队提出并验证了隔膜改性、电解液调控及构筑固态电解质等多维度安全优化方案。\n（4）发展了高安全聚合物基固态钠电池技术路线，并实现了在电动两轮车等场景的示范应用。\n（5）该研究为钠离子电池的本征安全设计提供了理论依据，对推动高安全储能体系发展具有重要意义。", "raw_content": "钠离子电池作为锂离子电池的有力补充与潜在替代技术，近年来受到广泛关注。学术界和产业界普遍认为，钠离子电池在能量密度较低、电极材料热稳定性高的前提下，其安全性应当优于锂离子电池。然而，青岛能源所固态能源系统技术中心在系统研究中发现，这一认识并不完全正确。在常规电池体系下，钠离子电池同样存在显著的安全隐患，其热失控风险甚至高于锂离子电池。根源在于硬碳负极中形成的准金属态高活性钠簇，可诱发电解液剧烈分解并触发热失控的链式反应。针对这一问题，研究团队围绕“问题发现−机理揭示−策略调控”的逻辑主线，提出并验证了包括隔膜改性、电解液体系调控以及固态电解质构筑在内的多维度安全优化方案，并发展了高安全聚合物基固态钠电池的技术路线，实现了从热失控机理认识到安全性本征提升的系列进展。研究团队首先通过多尺度表征与理论计算系统揭示了钠离子电池热失控的微观起源。结果表明，在硬碳负极中，钠离子在常规钠化过程中不仅以离子态形式嵌入碳结构，还会生成被认为具有“准金属”特征的钠簇。相比之下，锂离子在锂离子电池石墨负极中以稳定的层间嵌入态存在，分布均匀、电子密度分布稳定。研究发现，这些钠簇的化学状态更接近金属钠，通常直径仅为1−2 nm，其形成与分布受硬碳孔隙结构、表面化学基团及局部电子环境的协同影响。纳米尺度使其表面原子比例显著提高，表面能远高于体相钠金属；重要的是，团队通过固态核磁弛豫技术首次捕捉到硬碳中钠簇转瞬即逝的弛豫信号，发现在费米能级附近具有比钠金属更高的电子密度，这意味着钠簇并不是传统认知的“准金属”态，而更应该成为“强金属”态。结合绝热量热测试结果，研究团队确认电子富集效应显著增强了钠簇的化学反应活性，在极端条件下易诱发快速氧化还原反应，释放大量热量并加速电解液分解与气体生成，形成正反馈的热失控链条（图1）。此外，钠簇间可能存在电子耦合与迁移行为，进一步加剧反应的空间非均匀性，导致局部过热甚至形成“热点”，成为热失控的微观起点（Energy Environ. Sci.2025, 18, 2474；Adv. Energy Mater.2025, 15, e03209）。图1（a）硬碳中钠簇形态（b）不同SOC下硬碳负极放热行为演变（c）硬碳负极热失控机理的流程图（d）20 Ah钠离子电池的热安全潜在危险基于微观机理的揭示，研究团队开展了安时级钠离子电池的系统化热安全评估。结果显示，钠离子电池在安时级电芯测试中，其自产热起始温度普遍低于同类型锂离子电池，表明其更易发生热失控。这一宏观测试结果与微观机理分析高度一致，验证了钠簇在热失控触发与演化过程中的关键作用，进一步表明钠离子电池存在被低估的热失控安全风险。需要指出的是，新型电池的应用，尤其在新兴领域，需要充分认识电池的失控行为。当前，钠电正处于向产业化迈进的关键时刻，硬碳仍然是目前产业化最可行的负极材料。随着生产规模的不断扩大及能量密度的提升，深刻理解其热安全背后的物化本质显得尤为重要，以便有效防控，确保健康发展。针对热失控问题，研究团队围绕“源头削弱”与“路径阻断”两大思路，提出并验证了多维度安全调控策略。其中，通过采用多功能聚酰亚胺（PI）隔膜构筑热响应性阻燃层，可在电池温升过程中原位形成隔离阻燃屏障，实现自抑制反应并显著延缓热扩散。同时，PI隔膜可调控纳离子溶剂化结构，促进稳定的电极/电解液界面形成，降低界面副反应的发生（ACS Energy Lett.2025, 10, 3941）。该策略在安时级电芯中表现出优异的热安全性能：自产热起始温度提升约10 ℃，热失控触发温度提升约24 ℃，显著延缓热失控传播，并首次实现钠离子电池在90 ℃极端温度下的稳定运行。在电解液方面，团队通过引入功能性添加剂二氟二草酸磷酸钠，在负极界面构筑了热稳定、抗溶解的界面结构，降低钠簇活性与副反应速率，从根本上削弱热失控的触发条件，显著提升了电池的高温循环稳定性与安全性（Adv. Sci.2025, 12, 2502860）。进一步，研究团队提出以聚合物固态电解质取代传统液态体系的固态钠电池技术路线，发展了基于共熔化学的电极/电解质一体化融合新策略，结合干湿法制膜工艺以及化成−原位聚合耦合技术，搭建了全链条电池制造平台，实现100−140 Wh kg−1系列型号固态钠电芯的工艺定型，完成在电动两轮车、离网智慧微电网系统的示范应用。最近，团队创新性提出了基于二次聚合的电池安全自防护技术。当温度超过120 ℃时，原位聚合固态电解质中的异氰酸酯和脲交联，阻断气、液物质在正负极之间串扰，热失控温度延迟40 ℃以上（Nat. Commun.2025, 16, 2979）。该系列研究揭示了钠离子电池热失控的独特起源机制，颠覆了“钠电更安全”的传统认知，建立了从微观机理解析到体系级安全调控的完整研究框架。相关成果为钠离子电池的本征安全设计提供了理论依据与实践路径，对推动新一代高安全储能体系的发展具有重要科学意义和应用价值。（文/图 李川川）原文链接：https://doi.org/10.1038/s41467-025-57964-7Li Du, Gaojie Xu*, Chenghao Sun, Yu-Han Zhang, Huanrui Zhang*, Tiantian Dong*, Lang Huang, Jun Ma, Fu Sun, Chuanchuan Li, Xiangchun Zhuang, Shenghang Zhang, Jiedong Li, Bin Xie, Jinzhi Wang, Jingwen Zhao, Jiangwei Ju, Zhiwei Hu, Fan-Hsiu Chang, Chang-Yang Kuo, Chien-Te Chen, André Hilger, Ingo Manke, Shanmu Dong & Guanglei Cui*, Smart gel polymer electrolytes enlightening high safety and long life sodium ion batteries， Nat. Commun. 2025, 16, 2979.", "release_time": "2025-11-17", "source_institution": "青岛生物能源与过程研究所", "url": "https://qibebt.cas.cn/news/kyjz/202511/t20251104_8005726.html"}
{"category": "产业应用", "title": "qBraid平台降低量子计算应用门槛", "short_summary": "qBraid提供云端量子计算一站式平台，助力全球用户快速入门与应用开发。", "detailed_summary": "qBraid提供云端量子计算一站式平台，助力全球用户快速入门与应用开发。\n（1）qBraid是由Kanav Setia和Jason Necaise创立的量子计算平台，提供云端接口访问领先量子设备与软件。\n（2）平台集成Nvidia、微软和IBM等公司资源，用户可快速编码或部署跨设备软件，降低学习与使用门槛。\n（3）自2020年成立以来，已服务超过120个国家2万名用户，包括400所大学和100家企业。\n（4）获得MIT Sandbox创新基金等支持，并开发qBraid-OS操作系统，被四家领先量子公司采用。\n（5）平台推动量子计算在人工智能、药物发现和金融等领域的应用，助力量子产业生态发展。", "raw_content": "Quantum computers have the potential to model new molecules and weather patterns better than any computer today. They may also one day accelerate artificial intelligence algorithms at a much lower energy footprint. But anyone interested in using quantum computers faces a steep learning curve that starts with getting access to quantum devices and then figuring out one of the many quantum software programs on the market.Now qBraid, founded by Kanav Setia and Jason Necaise ’20, is providing a gateway to quantum computing with a platform that gives users access to the leading quantum devices and software. Users can log on to qBraid’s cloud-based interface and connect with quantum devices and other computing resources from leading companies like Nvidia, Microsoft, and IBM. In a few clicks, they can start coding or deploy cutting-edge software that works across devices.“The mission is to take you from not knowing anything about quantum computing to running your first program on these amazing machines in less than 10 minutes,” Setia says. “We’re a one-stop platform that gives access to everything the quantum ecosystem has to offer. Our goal is to enable anyone — whether they’re enterprise customers, academics, or individual users — to build and ultimately deploy applications.”Since its founding in June of 2020, qBraid has helped more than 20,000 people in more than 120 countries deploy code on quantum devices. That traction is ultimately helping to drive innovation in a nascent industry that’s expected to play a key role in our future.“This lowers the barrier to entry for a lot of newcomers,” Setia says. “They can be up and running in a few minutes instead of a few weeks. That’s why we’ve gotten so much adoption around the world. We’re one of the most popular platforms for accessing quantum software and hardware.”A quantum “software sandbox”Setia met Necaise while the two interned at IBM. At the time, Necaise was an undergraduate at MIT majoring in physics, while Setia was at Dartmouth College. The two enjoyed working together, and Necaise said if Setia ever started a company, he’d be interested in joining.A few months later, Setia decided to take him up on the offer. At Dartmouth, Setia had taken one of the first applied quantum computing classes, but students spent weeks struggling to install all the necessary software programs before they could even start coding.“We hadn’t even gotten close to developing any useful algorithms,” Seita said. “The idea for qBraid was, ‘Why don’t we build a software sandbox in the cloud and give people an easy programming setup out of the box?’ Connection with the hardware would already be done.”The founders received early support from the MIT Sandbox Innovation Fund and took part in the delta v summer startup accelerator run by the Martin Trust Center for MIT Entrepreneurship.“Both programs provided us with very strong mentorship,” Setia says. “They give you frameworks on what a startup should look like, and they bring in some of the smartest people in the world to mentor you — people you’d never have access to otherwise.”Necaise left the company in 2021. Setia, meanwhile, continued to find problems with quantum software outside of the classroom.“This is a massive bottleneck,” Setia says. “I’d worked on several quantum software programs that pushed out updates or changes, and suddenly all hell broke loose on my codebase. I’d spend two to four weeks jostling with these updates that had almost nothing to do with the quantum algorithms I was working on.”QBraid started as a platform with pre-installed software that let developers start writing code immediately. The company also added support for version-controlled quantum software so developers could build applications on top without worrying about changes. Over time, qBraid added connections to quantum computers and tools that lets quantum programs run across different devices.“The pitch was you don’t need to manage a bunch of software or a whole bunch of cloud accounts,” Setia says. “We’re a single platform: the quantum cloud.”QBraid also launched qBook, a learning platform that offers interactive courses in quantum computing.“If you see a piece of code you like, you just click play and the code runs,” Setia says. “You can run a whole bunch of code, modify it on the fly, and you can understand how it works. It runs on laptops, iPads, and phones. A significant portion of our users are from developing countries, and they’re developing applications from their phones.”Democratizing quantum computingToday qBraid’s 20,000 users come from over 400 universities and 100 companies around the world. As qBraid’s user base has grown, the company went from integrating quantum computers onto their platform from the outside to creating a quantum operating system, qBraid-OS, that is currently being used by four leading quantum companies.“We are productizing these quantum computers,” Setia explains. “Many quantum companies are realizing they want to focus their energy completely on the hardware, with us productizing their infrastructure. We’re like the operating system for quantum computers.”People are using qBraid to build quantum applications in AI and machine learning, to discover new molecules or develop new drugs, and to develop applications in finance and cybersecurity. With every new use case, Setia says qBraid is democratizing quantum computing to create the quantum workforce that will continue to advance the field.“[In 2018], an article in The New York Times said there were possibly less than 1,000 people in the world that could be called experts in quantum programming,” Setia says. “A lot of people want to access these cutting-edge machines, but they don’t have the right software backgrounds. They are just getting started and want to play with algorithms. QBraid gives those people an easy programming setup out of the box.”", "release_time": "2025-11-04", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/startup-provides-nontechnical-gateway-coding-quantum-computers-1104"}
{"category": "产业应用", "title": "通用原子公司发布新型“Gambit 6”多用途无人作战飞机", "short_summary": "通用原子发布Gambit 6无人战机，兼具空对空与空对地能力，2027年起可供国际采购。", "detailed_summary": "通用原子发布Gambit 6无人战机，兼具空对空与空对地能力，2027年起可供国际采购。\n(1) 通用原子航空系统公司发布Gambit系列最新迭代型号Gambit 6，这是一种协作作战飞机。\n(2) Gambit 6在原空对空能力基础上新增空对地作战功能，适用于电子战、防空压制及纵深精确打击等多重任务。\n(3) 该机型采用模块化架构和内置武器舱，便于集成先进自主系统、传感器和武器，具备高度适应性和可扩展性。\n(4) 国际采购将于2027年启动，欧洲任务定制版本将于2029年交付，公司正寻求欧洲产业合作以提供主权能力。\n(5) Gambit系列基于通用核心平台，旨在快速、低成本地生产多种任务变体，如美空军YFQ-42A无人僚机。", "raw_content": "SAN DIEGO – 04 November 2025 – The latest iteration of the innovative Gambit Series of unmanned combat air vehicles (UCAV) from General Atomics Aeronautical Systems, Inc. (GA-ASI) is Gambit 6, a collaborative combat aircraft (CCA) that adds air-to-ground operations to its already proven air-to-air capability. The multi-role platform is optimized for roles such as electronic warfare, suppression of enemy air defenses (SEAD), and deep precision strike, making it a versatile option for evolving defense needs. Air forces throughout the world are looking to air-to-ground-capable CCAs to enhance operational capabilities and address emerging threats in a denied environment. Gambit 6 is being developed to meet the corresponding need for adaptability, scalability, and mission-specific performance. “These are real threats, and they require real solutions,” said GA-ASI President David R. Alexander. “The modular architecture and signature-reducing internal weapons bay of Gambit 6 allow for easy integration of advanced autonomy, sensors, and weapons systems, ensuring the aircraft can adapt to a wide range of operational scenarios.” Airframes will be available for international procurement starting in 2027, with European missionized versions deliverable in 2029. GA-ASI is building industry partnerships throughout Europe with the aim of providing sovereign capabilities for all its platforms. GA-ASI’s Gambit Series envisions multiple CCA variants rapidly reconfigured from a common core, enabling substantial commonality for rapid and affordable production at scale. The Gambit Series is a modular family of unmanned aircraft designed to meet diverse mission requirements, including intelligence, surveillance, and reconnaissance; multi-domain combat; advanced training; and stealth reconnaissance. It’s built around a common core platform that accounts for a significant proportion of the aircraft’s hardware, including the landing gear, baseline avionics, and chassis. This shared foundation reduces costs, increases interoperability, and accelerates the development of mission-specific variants like Gambit 6. By leveraging specialized configurations and advanced autonomy, Gambit aircraft offer tailored capabilities that enhance operational efficiency, reduce costs, and improve survivability in contested environments. One Gambit derivative is the U.S. Air Force’s YFQ-42A, developed as part of that service’s effort to field an AI-enabled uncrewed wingman. Based off the original Gambit 2 concept, the YFQ-42A is designed to complement human-crewed fighters like the F-35 and Next-Generation Air Dominance (NGAD) systems, expanding sensing, weapons capacity, and survivability in contested airspace. The original concept for Gambit was announced three years ago and was based on four models. Gambit 1 is a nimble sensing platform optimized for long endurance; Gambit 2 adds the provision for air-to-air weapons; Gambit 3 looks much like Gambit 2 but is optimized for a complex adversary air role; Gambit 4 is a combat reconnaissance-focused model with no tail and swept wings. Then in 2024, GA-ASI announced Gambit 5 for ship-based CCA operations.  About GA-ASI General Atomics Aeronautical Systems, Inc., is the world’s foremost builder of Unmanned Aircraft Systems (UAS). Logging more than 9 million flight hours, the Predator® line of UAS has flown for over 30 years and includes MQ-9A Reaper®, MQ-1C Gray Eagle®, MQ-20 Avenger®, and MQ-9B SkyGuardian®/SeaGuardian®. The company is dedicated to providing long-endurance, multi-mission solutions that deliver persistent situational awareness and rapid strike. For more information, visit www.ga-asi.com      Avenger, EagleEye, Gray Eagle, Lynx, Predator, Reaper, SeaGuardian, and SkyGuardian are trademarks of General Atomics Aeronautical Systems, Inc., registered in the United States and/or other countries.", "release_time": "2025-11-05", "source_institution": "通用原子能公司", "url": "http://www.ga.com/new-ga-asi-gambit-6-ucav-adds-air-to-ground-operations-for-international-cca"}
{"category": "产业应用", "title": "IAEA巴黎核能博览会展示多领域应用前景", "short_summary": "IAEA参与巴黎核能博览会，推动核技术在能源健康等产业应用与国际合作。", "detailed_summary": "IAEA参与巴黎核能博览会，推动核技术在能源健康等产业应用与国际合作。\n（1）世界核能博览会于11月4日至6日在巴黎举行，覆盖核能全产业链与非电力应用领域；\n（2）法国经济部长与IAEA总干事均强调创新合作对核能未来发展的关键作用；\n（3）IAEA通过展台展示核技术在能源、医疗、农业、水资源等领域的支撑作用；\n（4）全球核能产业呈现复苏趋势，多国积极扩展核电计划以应对能源需求。", "raw_content": "From clean and reliable energy to food security to healthcare, the IAEA is putting nuclear technology and science in the spotlight this week at the World Nuclear Exhibition in Paris. Taking place on 4 to 6 November, the exhibition attracts professionals from across the civil nuclear sector, covering the entire value chain and nuclear fuel cycle — from mining and fuel fabrication to reactor design, waste management and decommissioning as well as non-electric applications such as water desalination, medicine, agriculture, and space. At the opening ceremony, Roland Lescure, France’s Minister for the Economy, Finance, Industrial, Energy and Digital Sovereignty, underscored the central role of innovation in shaping the future of nuclear energy. “Innovation is at the heart of what you will see in the next three days — and what we will achieve in the next three decades,” he said. “We must innovate together — in how we finance, govern, build supply chains and public-private partnerships, and in how we attract diverse new talent to shape the future of energy.” IAEA Director General Rafael Mariano Grossi echoed this call for forward-looking collaboration. “Two years after COP28’s historic recognition of nuclear’s indispensable role and the pledge to triple global capacity by 2050, we are seeing clear advancements.”  He added. “From promise to progress, the sector is experiencing a return to realism, as countries expand existing programmes, launch new ones and update regulations to meet future energy needs. The IAEA is proud to take part in this year’s exhibition with its own booth showing how nuclear science supports progress not only in energy but also in health, food, water and more.”", "release_time": "2025-11-06", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/iaea-takes-centre-stage-at-world-nuclear-exhibition-2025"}
{"category": "研究前沿", "title": "研究揭示暗能量或非常数，宇宙膨胀加速可能减缓", "short_summary": "新研究结合多组数据，首次强烈暗示暗能量可能随时间演化而非恒定。", "detailed_summary": "新研究结合多组数据，首次强烈暗示暗能量可能随时间演化而非恒定。\n（1）最新宇宙学数据分析挑战了暗能量是爱因斯坦提出的宇宙常数的传统观点，暗示其可能是一种动态演化的现象。\n（2）研究基于DES、DESI、Planck等多个重要天文项目的综合数据，发现动态暗能量模型比常数模型更符合观测。\n（3）提出的物理模型基于一种超轻轴子粒子，其密度在宇宙历史后期开始缓慢下降，导致宇宙加速膨胀随之减缓。\n（4）若模型正确，宇宙将避免“大撕裂”或“大挤压”的极端结局，而是走向“大冻结”的漫长冷却未来。\n（5）这是二十多年来首次出现暗能量可能非常数的强烈迹象，未来观测将对此进行最终验证。", "raw_content": "Dark energy, the mysterious force thought to drive the universe's accelerating expansion, remains one of the deepest puzzles in modern physics. For years, the leading explanation has been that this energy is constant -- an unchanging property of empty space responsible for cosmic acceleration. But recent evidence has scientists rethinking that assumption.  Last year, results from the Dark Energy Survey (DES) and the Dark Energy Spectroscopic Instrument (DESI) caught the attention of cosmologists by suggesting that dark energy might not be fixed after all. \"This would be our first indication that dark energy is not the cosmological constant introduced by Einstein over 100 years ago but a new, dynamical phenomenon,\" explained Josh Frieman, Professor Emeritus of Astronomy and Astrophysics. New Analysis Points to an Evolving Force In a study published in Physical Review D in September, Frieman and Anowar Shajib, a NASA Hubble Fellowship Program Einstein Fellow in Astronomy and Astrophysics, analyzed a broad range of existing cosmological data. Their findings indicate that dynamic, time-varying models of dark energy provide a better fit to current observations than the long-standing cosmological constant model. Shajib specializes in observational cosmology and galaxy evolution, applying strong gravitational lensing to measure the Hubble constant and narrow down dark energy parameters. Frieman's work also centers on observational cosmology, making use of massive sky surveys like the Sloan Digital Sky Survey (SDSS) and the DES to study the universe's origin, structure, and fate while probing the mysterious force driving its accelerated expansion. The University of Chicago spoke with Shajib and Frieman about their findings, what these new models could mean for our understanding of cosmic evolution, and how future observations might reveal whether dark energy truly changes over time. Why is dark energy significant in the study of the universe?  Frieman: We now know precisely how much dark energy there is in the universe, but we have no physical understanding of what it is. The simplest hypothesis is that it is the energy of empty space itself, in which case it would be unchanging in time, a notion that goes back to Einstein, Lemaitre, de Sitter, and others in the early part of the last century. It's a bit embarrassing that we have little to no clue what 70 percent of the universe is. And whatever it is, it will determine the future evolution of the universe. What recent findings led cosmologists to consider that dark energy may be evolving? Shajib: Although there has been interest in the dynamical nature of dark energy since its discovery in the '90s to resolve some observational discrepancies, until recently, most of the major and robust datasets were consistent with a non-evolving dark energy model, which is accepted as the standard cosmology. However, interest in evolving dark energy was vigorously rekindled last year from the combination of supernovae, baryon acoustic oscillation, and cosmic microwave background data from the DES, DESI, and Planck experiments. This combination of datasets indicated a strong discrepancy with the standard, non-evolving model of dark energy. The interesting feature of non-evolving dark energy is that its density stays constant through time even though space is expanding. However, for the evolving dark energy model, dark energy density will change with time. Frieman: The data from these surveys allow us to infer the history of cosmic expansion -- how fast the universe has been expanding at different epochs in the past. If dark energy evolves in time, that history will be different than if dark energy is constant. The cosmic expansion history results suggest that over the last several billion years or so, the density of dark energy has decreased by about 10 percent -- not much, and much less than the densities of other matter and energy, but still significant. What was the goal of this study, and what were the overall findings? Shajib and Frieman: The goal of this study is to compare the predictions of a physical model for evolving dark energy with the latest data sets and to infer the physical properties of dark energy from this comparison. The evolving dark energy \"model\" used in most previous data analyses is just a mathematical formula that isn't constrained to behave as physical models do. In our paper, we directly compare physics-based models for evolving dark energy to the data and find that these models describe the current data better than the standard, non-evolving dark energy model. We also show that near-future surveys such as DESI and the Vera Rubin Observatory Legacy Survey of Space and Time (LSST) will be able to definitively tell us whether these models are correct or if, instead, dark energy really is constant.  Describe the models presented and why they better explain the behavior of dark energy compared to existing models. Frieman: These models are based on particle physics theories of hypothetical particles called axions. Axions were first predicted by physicists in the 1970s, who sought to explain certain observed features of strong interactions. Today, axions are considered plausible candidates for dark matter, and experiments worldwide are actively searching for them, including physicists at Fermilab and the University of Chicago. The models in our paper are based on a different, ultra-light version of the axion that would act as dark energy, not dark matter. In these models, dark energy would, in fact, be constant for the first several billion years of cosmic history, but the axion would then start to evolve -- like a ball on a sloping field that's released from rest and starts to roll -- and its density would slowly decrease, which is what the data appear to prefer. So the data suggest the existence of a new particle in nature that's about 38 orders of magnitude lighter than the electron. What are the implications of these findings for understanding cosmic expansion? Shajib: In these models, the dark energy density decreases with time. Dark energy is the reason for the universe's accelerated expansion, so if its density decreases, the acceleration will also decrease with time. If we consider the very far future of the universe, different characteristics of dark energy can lead to different outcomes. Two extremes of these outcomes are a Big Rip, where the accelerated expansion itself accelerates to the point that it rips everything apart, even atoms, and a Big Crunch, where the universe stops expanding at some point and recollapses, which will look like a reverse Big Bang. Our models suggest that the universe will avoid both of these extremes: it will undergo accelerated expansion for many billions of years, yielding a cold, dark universe -- a Big Freeze. Could these results have other, less apparent implications? Frieman: The only practical implications I can imagine are the technologies we need to develop to explore these ideas further -- building new telescopes, launching new satellites, or developing novel detectors, for example. Such developments are likely to have much more of an impact on our lives than events happening trillions of years in the future. What excites you the most about these results? Shajib: For this paper, we gathered all the major data sets -- from the DES, DESI, SDSS, Time-Delay COSMOgraphy, Planck, and Atacama Cosmology Telescope -- and combined them to get the most constraining measurement of dark energy to date. All these measurements come from extensive experiments, so in a way, they represent the collective knowledge that the cosmological community has gathered as a whole. Frieman: When we began working on the DES in 2003, our goal was to constrain the properties of dark energy to determine whether it was constant or changing. For two decades, the data indicated that it was constant. We almost gave up on that question because the data consistently supported the assumption. However, we now have the first hint in over 20 years that dark energy might be changing, and if it is evolving, it must be something new, which would change our understanding of fundamental physics. That feeling is reminiscent of where we were at the beginning. It could still turn out that these hints are incorrect, but we may be on the cusp of answering that question, and that's quite exciting.", "release_time": "2025-11-05", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251104013010.htm"}
{"category": "研究前沿", "title": "MIT开发可解释模型KATMAP解析RNA剪接调控", "short_summary": "MIT团队开发KATMAP模型，结合扰动实验与序列信息预测RNA剪接因子靶点。", "detailed_summary": "MIT团队开发KATMAP模型，结合扰动实验与序列信息预测RNA剪接因子靶点。\n(1) MIT生物学系研究人员在《自然-生物技术》发表论文，提出KATMAP计算框架。\n(2) 该模型整合剪接因子扰动实验数据与其结合序列信息，预测其直接调控靶点。\n(3) KATMAP为可解释模型，能生成生物学可解释参数，克服\"黑箱\"模型局限。\n(4) 模型目前考虑单一剪接因子，是理解复杂剪接调控网络的简化起点。\n(5) 该工具有助于解析剪接突变所致疾病机制，并评估核酸药物治疗潜力。", "raw_content": "Although heart cells and skin cells contain identical instructions for creating proteins encoded in their DNA, they’re able to fill such disparate niches because molecular machinery can cut out and stitch together different segments of those instructions to create endlessly unique combinations.The ingenuity of using the same genes in different ways is made possible by a process called splicing and is controlled by splicing factors; which splicing factors a cell employs determines what sets of instructions that cell produces, which, in turn, gives rise to proteins that allow cells to fulfill different functions. In an open-access paper published today in Nature Biotechnology, researchers in the MIT Department of Biology outlined a framework for parsing the complex relationship between sequences and splicing regulation to investigate the regulatory activities of splicing factors, creating models that can be applied to interpret and predict splicing regulation across different cell types, and even different species. Called Knockdown Activity and Target Models from Additive regression Predictions, KATMAP draws on experimental data from disrupting the expression of a splicing factor and information on which sequences the splicing factor interacts with to predict its likely targets. Aside from the benefits of a better understanding of gene regulation, splicing mutations — either in the gene that is spliced or in the splicing factor itself — can give rise to diseases such as cancer by altering how genes are expressed, leading to the creation or accumulation of faulty or mutated proteins. This information is critical for developing therapeutic treatments for those diseases. The researchers also demonstrated that KATMAP can potentially be used to predict whether synthetic nucleic acids, a promising treatment option for disorders including a subset of muscular atrophy and epilepsy disorders, affect splicing.Perturbing splicing In eukaryotic cells, including our own, splicing occurs after DNA is transcribed to produce an RNA copy of a gene, which contains both coding and non-coding regions of RNA. The noncoding intron regions are removed, and the coding exon segments are spliced back together to make a near-final blueprint, which can then be translated into a protein. According to first author Michael P. McGurk, a postdoc in the lab of MIT Professor Christopher Burge, previous approaches could provide an average picture of regulation, but could not necessarily predict the regulation of splicing factors at particular exons in particular genes.KATMAP draws on RNA sequencing data generated from perturbation experiments, which alter the expression level of a regulatory factor by either overexpressing it or knocking down its levels. The consequences of overexpression or knockdown are that the genes regulated by the splicing factor should exhibit different levels of splicing after perturbation, which helps the model identify the splicing factor’s targets. Cells, however, are complex, interconnected systems, where one small change can cause a cascade of effects. KATMAP is also able to distinguish between direct targets from indirect, downstream impacts by incorporating known information about the sequence the splicing factor is likely to interact with, referred to as a binding site or binding motif.“In our analyses, we identify predicted targets as exons that have binding sites for this particular factor in the regions where this model thinks they need to be to impact regulation,” McGurk says, while non-targets may be affected by perturbation but don’t have the likely appropriate binding sites nearby. This is especially helpful for splicing factors that aren’t as well-studied. “One of our goals with KATMAP was to try to make the model general enough that it can learn what it needs to assume for particular factors, like how similar the binding site has to be to the known motif or how regulatory activity changes with the distance of the binding sites from the splice sites,” McGurk says. Starting simpleAlthough predictive models can be very powerful at presenting possible hypotheses, many are considered “black boxes,” meaning the rationale that gives rise to their conclusions is unclear. KATMAP, on the other hand, is an interpretable model that enables researchers to quickly generate hypotheses and interpret splicing patterns in terms of regulatory factors while also understanding how the predictions were made. “I don’t just want to predict things, I want to explain and understand,” McGurk says. “We set up the model to learn from existing information about splicing and binding, which gives us biologically interpretable parameters.” The researchers did have to make some simplifying assumptions in order to develop the model. KATMAP considers only one splicing factor at a time, although it is possible for splicing factors to work in concert with one another. The RNA target sequence could also be folded in such a way that the factor wouldn’t be able to access a predicted binding site, so the site is present but not utilized.“When you try to build up complete pictures of complex phenomena, it’s usually best to start simple,” McGurk says. “A model that only considers one splicing factor at a time is a good starting point.” David McWaters, another postdoc in the Burge Lab and a co-author on the paper, conducted key experiments to test and validate that aspect of the KATMAP model.Future directionsThe Burge lab is collaborating with researchers at Dana-Farber Cancer Institute to apply KATMAP to the question of how splicing factors are altered in disease contexts, as well as with other researchers at MIT as part of an MIT HEALS grant to model splicing factor changes in stress responses. McGurk also hopes to extend the model to incorporate cooperative regulation for splicing factors that work together. “We’re still in a very exploratory phase, but I would like to be able to apply these models to try to understand splicing regulation in disease or development. In terms of variation of splicing factors, they are related, and we need to understand both,” McGurk says.Burge, the Uncas (1923) and Helen Whitaker Professor and senior author of the paper, will continue to work on generalizing this approach to build interpretable models for other aspects of gene regulation.“We now have a tool that can learn the pattern of activity of a splicing factor from types of data that can be readily generated for any factor of interest,” says Burge, who is also an extra-mural member of the Koch Institute for Integrative Cancer Research and an associate member of the Broad Institute of MIT and Harvard. “As we build up more of these models, we’ll be better able to infer which splicing factors have altered activity in a disease state from transcriptomic data, to help understand which splicing factors are driving pathology.”", "release_time": "2025-11-05", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/katmap-new-way-to-understand-predict-gene-splicing-1104"}
{"category": "产业应用", "title": "亚洲动力煤价回升但进口量普遍下降", "short_summary": "亚洲海运动力煤价格自低点反弹，然主要进口国十月到港量环比均现下滑。", "detailed_summary": "亚洲海运动力煤价格自低点反弹，然主要进口国十月到港量环比均现下滑。\n（1）亚洲海运动力煤价格自6月触及四年低点后持续小幅回升，澳大利亚及印尼主要煤种价格均有上涨。\n（2）世界四大煤炭进口国（中国、印度、日本、韩国）10月煤炭进口到港量预计均低于9月水平，呈现“价升量减”态势。\n（3）中国10月进口量预计为2817万吨，环比微降0.9%；印度预计为1335万吨，环比降3%。\n（4）日本10月进口量预计为952万吨，环比降8.8%；韩国预计为645万吨，环比大幅下降21.2%。\n（5）分析指出，中国和印度买家对价格敏感，高价导致需求退缩；而日本和韩国进口量下降更可能与“肩季”需求疲软等季节性因素有关。", "raw_content": "据路透社(Reuters)10月30日发布的消息，随着亚洲海运动力煤各类品种价格持续从四年低点持续小幅回升，而同时主要进口国却削减需求，看来价格的上涨是以成交量减少为代价的。 据分析机构DBX Commodities汇编的数据，世界四大煤炭进口国——中国、印度、日本和韩国——10月的煤炭进口到港量预计都将低于9月。 澳大利亚和印度尼西亚的主要品种等级的动力煤价格自2023年10月起一直呈现下降走势，直到今年自6月初触底之后，又逐渐波动上涨。 虽然较低的价格在7月和8月确实提振了进口需求，但现在较高的价格似乎又导致买家开始退缩。 DBX估计，10月份中国进口的海运动力煤(主要用于发电的燃料)大约为2817万吨，较9月份的2843万吨微降0.9%，较去年10月的3353万吨下降16%。 全球第二大煤炭进口国的印度，10月份动力煤进口量预计为1335万吨，较9月的1376万吨减少3%，较去年同期的1382万吨下降3.4%。 排名第三的日本，10月份动力煤进口量预计为952万吨，较9月的1044万吨以及去年同期的994万吨分别下降8.8%和4.2%。 第四大煤炭进口国的韩国，10月份动力煤进口到港量预计为645万吨，环比9月的819万吨下降21.2%，但较去年同期的592万吨增长9.0%。 由于货物从进口采购安排到实际交付之间存在数周时间的滞后，因此10月的煤炭进口量下降，实际上反映了7月份以来价格逐渐涨高的情况。 6月之后全球价格复苏 澳大利亚热值5500千卡/千克的动力煤，该等级在中国和印度均广受欢迎，该品种价格由全球大宗商品价格分析机构阿格斯(Argus)10月20日当周评估为每吨76.34美元。 该价格自今年6月初的四年低点65.72美元以来，已上涨16%，目前处于3月3日当周以来的最高水平。 印尼热值为4200千卡/千克的煤炭，Argus将其在10月13日至20日这一周的评估价定为每吨45.26美元，较其在7月4日当周触及的四年低点40.45美元上涨了12%。 日本和韩国更青睐澳大利亚高热值动力煤，全球煤炭(globalCOAL)周三评估的纽卡斯尔港6000大卡/千克动力煤价格为每吨105.34美元，较上周的每吨103.74美元上涨1.6美元。 然而，纽卡斯尔动力煤的价格最近几周在每吨104美元左右的狭窄范围内波动、基本持平。 这也意味着日本和韩国的动力煤进口量下降更可能是由于肩季(shoulder season，即北半球夏季高峰和即将到来的冬季高峰之间)需求疲软所致。 亚洲海运动力煤进口和价格的近期变化趋势表明，市场参与者大致可分两类，一类为价格敏感型买家(如中国和印度)，另一类为更具季节性驱动因素的消费者(如日本和韩国)。", "release_time": "2025-11-04", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195712-1.html"}
{"category": "研究前沿", "title": "科学家发现电子逸出固体的关键门户态", "short_summary": "研究揭示电子逃离固体需经特定门户态，修正传统能量阈值理论。", "detailed_summary": "研究揭示电子逃离固体需经特定门户态，修正传统能量阈值理论。\n（1）维也纳技术大学团队解决了电子逸出固体材料的精确计算难题；\n（2）研究发现仅能量达标不足够，电子必须通过特定\"门户态\"才能逸出；\n（3）门户态是连接材料内部与外部状态的关键量子态，并非所有高能态都是有效出口；\n（4）该发现解释了不同层数材料电子发射行为的差异，为材料设计提供新原理。", "raw_content": "Imagine a frog inside a box with an opening partway up one side. Whether it can escape depends on how much energy it has: if it can jump high enough, it could, in theory, reach the opening. But success requires more than just a high jump -- it also needs to pass through that opening.  Electrons inside solid materials behave in a surprisingly similar way. When they gain extra energy (for instance, when the material is struck by other electrons), they can sometimes break free from the solid. This process has been known for decades and forms the basis of many technologies. However, until recently, scientists had been unable to calculate it with precision. Researchers from several groups at TU Wien have now found the solution. Just as the frog must find the right opening, an electron also needs to locate a specific \"exit,\" known as a \"doorway state.\" A Simple Setup, Unexpected Results \"Solids from which relatively slow electrons emerge play a key role in physics. From the energies of these electrons, we can extract valuable information about the material,\" explains Anna Niggas from the Institute of Applied Physics at TU Wien, the study's first author. Inside any material, electrons can exist with a range of energies. As long as they stay below a certain energy limit, they remain trapped. When the material is supplied with extra energy, some electrons can surpass this boundary. \"One might assume that all these electrons, once they have enough energy, simply leave the material,\" says Prof. Richard Wilhelm, head of the Atomic and Plasma Physics group at TU Wien. \"If that were true, things would be simple: we would just look at the electrons' energies inside the material and directly infer which electrons should appear outside. But, as it turns out, that's not what happens.\" Theoretical models and experimental findings often failed to match. This mismatch was especially puzzling because \"different materials -- such as graphene structures with different amounts of layers -- can have very similar electron energy levels, yet show completely different behaviors in the emitted electrons,\" says Anna Niggas.  No Exit Without a Doorway The key discovery is that energy alone cannot determine whether an electron escapes. There are quantum states above the energy threshold that still fail to lead out of the material, a fact missing from earlier models. \"From an energetic point of view, the electron is no longer bound to the solid. It has the energy of a free electron, yet it still remains spatially located where the solid is,\" says Richard Wilhelm. The electron behaves like the frog that jumps high enough but fails to find the exit. \"The electrons must occupy very specific states -- so-called doorway states,\" explains Prof. Florian Libisch from the Institute for Theoretical Physics. \"These states couple strongly to those that actually lead out of the solid. Not every state with sufficient energy is such a doorway state -- only those that represent an 'open door' to the outside.\" \"For the first time, we've shown that the shape of the electron spectrum depends not only on the material itself, but crucially on whether and where such resonant doorway states exist,\" says Anna Niggas. Interestingly, some of these states appear only when more than five layers of a material are stacked. This insight offers new opportunities for precisely designing and applying layered materials in both research and advanced technologies.", "release_time": "2025-11-05", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/11/251104013012.htm"}
{"category": "政策计划", "title": "俄煤炭业巨亏2632亿卢布，政府出台多项救助措施", "short_summary": "俄罗斯煤炭业前八月亏损激增，政府推出税收减免及补贴等一揽子救助方案。", "detailed_summary": "俄罗斯煤炭业前八月亏损激增，政府推出税收减免及补贴等一揽子救助方案。\n（1）2025年1-8月俄罗斯煤炭行业净亏损达2632亿卢布，较去年同期49亿卢布亏损额急剧扩大，盈利公司份额降至33%。\n（2）俄罗斯政府已批准多项支持措施，包括免征采矿税和保险费、提供出口物流补贴、允许债务重组及限制股息支付。\n（3）能源部正评估政策效果，并已建立130多家公司税收优惠名单，专项援助申请正在分批审查中。\n（4）能源部考虑推动行业围绕大型企业进行整合，并制定2050年前行业发展规划，以期危机后转向增长。", "raw_content": "俄罗斯煤炭公司2025年1-8月亏损净额达到2632亿卢布。去年同期亏损49亿卢布。俄统计局数据显示，2025年1-8月俄罗斯煤炭公司获得了530亿卢布的利润。(比2024年同期下降54%)，亏损3162亿卢布。(增长2.6倍)报告期内，煤炭行业盈利公司的份额为33%，而上年同期为48%，亏损公司为67%，而上年同期为52%。 俄罗斯能源部此前曾表示，在国外市场、卢布汇率和利率不变的情况下，俄罗斯煤炭企业2025年亏损净额可能达到3000-3500亿卢布。5月底，俄罗斯政府批准了一系列支持煤炭行业的措施。其中包括批准企业财务整顿计划，限制股息支付。公司将获得定向补贴，以补偿长途出口煤炭的部分物流成本。 截至12月1日，所有煤炭企业将获得免交采矿税和保险费的待遇。面临严重债务负担的公司将有机会重新安排贷款。西伯利亚煤炭企业将获得西北和南部煤炭出口运输关税的12.8%。政府表示，在向煤炭企业分配支持措施时，将采取有针对性的方法。 能源部副部长德米特里·伊斯兰莫夫在REN-2025会议期间表示，俄罗斯能源部正在分析支持煤炭行业的措施的有效性，根据结果将决定是否需要延长这些措施。 俄罗斯能源部长谢尔盖·齐维列夫在接受塔斯社采访时说：尽管形势艰难，俄罗斯2025年上半年煤炭产量仍保持在2.188亿吨。他还指出，为了支持该行业，已经建立了130多家煤炭公司的名单，这些公司已经获得了税收优惠。还采取措施支持煤炭运输。 至于定向援助，谢尔盖·西维列夫说，财政部长领导的小组委员会正在审查申请。目前，已经对42家企业的申请进行了审查，另有8家企业正在审查中，约15家企业计划在近期提交申请。 谢尔盖·齐维列夫还表示，俄罗斯能源部正在考虑围绕大型企业整合煤炭行业的可能性。他强调，这一进程需要一个全面的评估，类似于1990年代工业结构调整期间进行的评估。 部长说：“只有在那之后，才能为整合创造条件。能源部已经在开展这项工作，为2050年前煤炭行业的发展制定了一项更新的计划。在该计划获得批准后，我们将能够具体讨论巩固问题，包括将生产转向东方。”。 只有围绕大型煤炭企业才能实现合并，在大公司拥有广泛的产品线、煤炭主产地、自己的港口终端和车辆车队，最重要的是还有-一个稳定的金融模式。目前煤炭行业的危机将推动企业整合，小型企业将加入强大的行列，低效产能将减少。与此同时，能源部预计该行业最终将转向增长，但确切的时间取决于公司盈利状况本身。", "release_time": "2025-11-04", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195644-1.html"}
{"category": "产业应用", "title": "欧佩克+或再度小幅提高石油产量", "short_summary": "欧佩克+考虑12月日产量小幅增加13.7万桶，延续此前调整幅度。", "detailed_summary": "欧佩克+考虑12月日产量小幅增加13.7万桶，延续此前调整幅度。\n（1）欧佩克+成员国在周日线上会议前倾向12月再次小幅提高石油产量；\n（2）以沙特阿拉伯为首的核心成员国讨论日产量增加约13.7万桶；\n（3）此次增幅与10月和11月的调整幅度保持一致；\n（4）代表们将这一温和增产视为基准方案，但会谈尚未公开。", "raw_content": "据三位代表透露，在周日举行线上会议之前，欧佩克+成员国倾向于在12月再次小幅提高石油产量。这些不愿具名的代表表示（因会谈尚未公开），以沙特阿拉伯为首的该组织核心成员国正讨论将日产量提高约13.7万桶，这一增幅与10月和11月的调整幅度一致。本周早些时候有报道称，代表们将这一温和增幅视为基准方案。", "release_time": "2025-11-04", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195641-1.html"}
{"category": "研究前沿", "title": "近代物理所技术中心获评优秀支撑前沿研究", "short_summary": "近代物理所公共技术中心考核优秀，三大平台有力支撑重大科研任务。", "detailed_summary": "近代物理所公共技术中心考核优秀，三大平台有力支撑重大科研任务。\n（1）近代物理所所级公共技术中心在2025年度全院数理领域考核中荣获优秀，为2家优秀单位之一；\n（2）中心资源配置科学、管理体系完善，仪器设备运行良好且开放共享率高；\n（3）拥有53名技术人员及51台套、总值约2.07亿元的仪器设备，构建低能重离子应用、分析测试、仪器研发三大支撑平台；\n（4）技术支撑能力强，为重大科研任务和前沿探索提供了有力保障；\n（5）未来将深化机制改革，持续推进平台开放共享，提升技术支撑能力并服务社会。", "raw_content": "在2025年度全院数理领域所级公共技术中心（以下简称“所级中心”）考核评估中，近代物理所荣获优秀。本次参评共有16家，最终评选出优秀单位2家，12家单位获得通过。评审专家组一致认为，近代物理所所级中心在多个方面成效显著：资源配置科学合理、管理体系规范完善；仪器设备运行状态良好，使用效率及开放共享率高；技术人员运维及支撑能力强，运行高效且贡献突出；服务支撑成效显著，为研究所承担的重大科研任务、重点研究方向及相关领域的前沿探索提供了有力的技术保障。近代物理所所级中心成立于2014年，现有管理及技术人员53人，开放共享仪器设备51台（套），总价值约2.07亿元。中心集仪器管理、运行维护、技术研发与自主研制于一体，构建了三大支撑平台：一是低能重离子应用平台（包括320kV低能重离子综合研究平台等3个系统）；二是分析测试平台（包括材料成像分析与生物医学综合分析等5个方向）；三是仪器研发平台（包括核电子学研发等3个重点领域）。未来，所级中心将深化管理与运行机制改革，充分发挥特色技术优势，持续推进大型仪器平台的建设和开放共享，提升技术支撑能力，在保障国家重大科研任务实施的同时，积极面向社会提供专业的分析测试和技术服务，助力地方经济高质量发展。图1：所级中心现场答辩（周军军/摄）图2：评审专家对所级中心进行实地考察（张桐民/摄）（科技处、所级公共技术中心  供稿）", "release_time": "2025-11-03", "source_institution": "近代物理研究所", "url": "http://www.imp.cas.cn/sndt2017/202511/t20251103_8005031.html"}
{"category": "产业应用", "title": "印尼煤价走势分化，华南电厂采购意愿提升", "short_summary": "印尼中卡煤价上涨，低卡煤维稳，价格优势促华南电厂采购。", "detailed_summary": "印尼中卡煤价上涨，低卡煤维稳，价格优势促华南电厂采购。\n(1) 印尼3800卡低卡煤报价FOB45.3美元/吨，较上周略回调0.2美元/吨，报价保持稳定；\n(2) 印尼4600卡中卡煤报价FOB62.3美元/吨，较上周上调2.35美元/吨，因供应紧张和需求端询货良好推动上涨；\n(3) 在中国内贸煤价高位震荡背景下，进口印尼煤价格优势明显；\n(4) 华南地区电厂对印尼低卡煤采购意愿因此提升。", "raw_content": "截至上周五，印尼煤3800卡报价为FOB45.3美元/吨，比上周略回调了0.2美元/吨;4600卡报价为FOB62.3美元/吨，比上周上调了2.35美元/吨。本周印尼低卡煤报价维稳，中卡煤因供应紧张加需求端询货良好，报价继续上涨。本周我国内贸煤价高位震荡下，而进口印尼煤价格优势明显，华南电厂对印尼低卡煤采购意愿提升。", "release_time": "2025-11-04", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195642-1.html"}
{"category": "研究前沿", "title": "MIT研发新型癌症免疫疗法：让肿瘤自我摧毁", "short_summary": "MIT团队利用mRNA技术激活肿瘤免疫通路，结合现有疗法可完全消除小鼠肿瘤。", "detailed_summary": "MIT团队利用mRNA技术激活肿瘤免疫通路，结合现有疗法可完全消除小鼠肿瘤。\n（1）MIT研究人员开发新型癌症免疫疗法，通过mRNA使肿瘤细胞产生cGAS酶；\n（2）该酶催化生成cGAMP分子，激活免疫细胞中的STING通路引发抗肿瘤反应；\n（3）在黑色素瘤小鼠实验中，单独使用可使肿瘤生长显著减缓；\n（4）与检查点抑制剂联合使用时，30%小鼠肿瘤完全消除，效果最佳；\n（5）该方法利用肿瘤自身机制，所需剂量小且毒性低，具临床转化潜力。", "raw_content": "By stimulating cancer cells to produce a molecule that activates a signaling pathway in nearby immune cells, MIT researchers have found a way to force tumors to trigger their own destruction.Activating this signaling pathway, known as the cGAS-STING pathway, worked even better when combined with existing immunotherapy drugs known as checkpoint blockade inhibitors, in a study of mice. That dual treatment was successfully able to control tumor growth.The researchers turned on the cGAS-STING pathway in immune cells using messenger RNA delivered to cancer cells. This approach may avoid the side effects of delivering large doses of a STING activator, and takes advantage of a natural process in the body. This could make it easier to develop a treatment for use in patients, the researchers say.“Our approach harnesses the tumor’s own machinery to produce immune-stimulating molecules, creating a powerful antitumor response,” says Natalie Artzi, a principal research scientist at MIT’s Institute for Medical Engineering and Science, an associate professor of medicine at Harvard Medical School, a core faculty member at the Wyss Institute for Biologically Inspired Engineering at Harvard, and the senior author of the study.“By increasing cGAS levels inside cancer cells, we can enhance delivery efficiency — compared to targeting the more scarce immune cells in the tumor microenvironment — and stimulate the natural production of cGAMP, which then activates immune cells locally,” she says. “This strategy not only strengthens antitumor immunity but also reduces the toxicity associated with direct STING agonist delivery, bringing us closer to safer and more effective cancer immunotherapies.”Alexander Cryer, a visiting scholar at IMES, is the lead author of the paper, which appears this week in the Proceedings of the National Academy of Sciences.Immune activationSTING (short for stimulator of interferon genes) is a protein that helps to trigger immune responses. When STING is activated, it turns on a pathway that initiates production of type one interferons, which are cytokines that stimulate immune cells.Many research groups, including Artzi’s, have explored the possibility of artificially stimulating this pathway with molecules called STING agonists, which could help immune cells to recognize and attack tumor cells. This approach has worked well in animal models, but it has had limited success in clinical trials, in part because the required doses can cause harmful side effects.While working on a project exploring new ways to deliver STING agonists, Cryer became intrigued when he learned from previous work that cancer cells can produce a STING activator known as cGAMP. The cells then secrete cGAMP, which can activate nearby immune cells.“Part of my philosophy of science is that I really enjoy using endogenous processes that the body already has, and trying to utilize them in a slightly different context. Evolution has done all the hard work. We just need to figure out how push it in a different direction,” Cryer says. “Once I saw that cancer cells produce this molecule, I thought: Maybe there’s a way to take this process and supercharge it.”Within cells, the production of cGAMP is catalyzed by an enzyme called cGAS. To get tumor cells to activate STING in immune cells, the researchers devised a way to deliver messenger RNA that encodes cGAS. When this enzyme detects double-stranded DNA in the cell body, which can be a sign of either infection or cancer-induced damage, it begins producing cGAMP.“It just so happens that cancer cells, because they’re dividing so fast and not particularly accurately, tend to have more double-stranded DNA fragments than healthy cells,” Cryer says.The tumor cells then release cGAMP into tumor microenvironment, where it can be taken up by neighboring immune cells and activate their STING pathway.Targeting tumorsUsing a mouse model of melanoma, the researchers evaluated their new strategy’s potential to kill cancer cells. They injected mRNA encoding cGAS, encapsulated in lipid nanoparticles, into tumors. One group of mice received this treatment alone, while another received a checkpoint blockade inhibitor, and a third received both treatments.Given on their own, cGAS and the checkpoint inhibitor each significantly slowed tumor growth. However, the best results were seen in the mice that received both treatments. In that group, tumors were completely eradicated in 30 percent of the mice, while none of the tumors were fully eliminated in the groups that received just one treatment.An analysis of the immune response showed that the mRNA treatment stimulated production of interferon as well as many other immune signaling molecules. A variety of immune cells, including macrophages and dendritic cells, were activated. These cells help to stimulate T cells, which can then destroy cancer cells.The researchers were able to elicit these responses with just a small dose of cancer-cell-produced cGAMP, which could help to overcome one of the potential obstacles to using cGAMP on its own as therapy: Large doses are required to stimulate an immune response, and these doses can lead to widespread inflammation, tissue damage, and autoimmune reactions. When injected on its own, cGAMP tends to spread through the body and is rapidly cleared from the tumor, while in this study, the mRNA nanoparticles and cGAMP remained at the tumor site.“The side effects of this class of molecule can be pretty severe, and one of the potential advantages of our approach is that you’re able to potentially subvert some toxicity that you might see if you’re giving the free molecules,” Cryer says.The researchers now hope to work on adapting the delivery system so that it could be given as a systemic injection, rather than injecting it into the tumor. They also plan to test the mRNA therapy in combination with chemotherapy drugs or radiotherapy that damage DNA, which could make the therapy even more effective because there could be even more double-stranded DNA available to help activate the synthesis of cGAMP.", "release_time": "2025-11-04", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/turning-immune-pathway-tumors-could-lead-their-destruction-1103"}
{"category": "研究前沿", "title": "爱尔兰科学家突破弹壳指纹提取技术", "short_summary": "新电化学法可从射击后弹壳提取指纹，解决法医学长期难题。", "detailed_summary": "新电化学法可从射击后弹壳提取指纹，解决法医学长期难题。\n(1)爱尔兰梅努斯大学科学家开发新型电化学指纹提取技术；\n(2)该技术能在射击后的黄铜弹壳上显现指纹痕迹，突破传统认知；\n(3)方法使用环保聚合物材料，无需有毒化学品或昂贵设备；\n(4)技术对保存16个月的样本仍有效，具有显著耐久性；\n(5)便携式设备可实现现场检测，有望变革刑事调查方式。", "raw_content": "Two Irish scientists have created a groundbreaking method for recovering fingerprints from fired bullet casings -- something long believed to be impossible.  Dr. Eithne Dempsey and her former PhD student, Dr. Colm McKeever, from the Department of Chemistry at Maynooth University in Ireland, have designed a novel electrochemical process that reveals fingerprints on brass casings even after exposure to the intense heat generated when a gun is fired. Solving a Long-Standing Forensic Challenge For decades, forensic experts have struggled to retrieve fingerprints from firearms or ammunition. The extreme temperatures, gas, and friction produced during gunfire typically destroy any biological residue. Because of this, many criminals have relied on the assumption that fired weapons and casings could not link them to a crime scene. \"The Holy Grail in forensic investigation has always been retrieving prints from fired ammunition casings,\" said Dr. Dempsey. \"Traditionally, the intense heat of firing destroys any biological residue. However, our technique has been able to reveal fingerprint ridges that would otherwise remain imperceptible.\" The research team discovered that coating brass casings with a thin layer of specially chosen materials can expose hidden fingerprint ridges. Unlike many existing forensic methods, this approach does not rely on toxic chemicals or expensive, high-powered equipment. Instead, it uses environmentally friendly polymers and requires very little energy to produce clear fingerprint images in seconds. The process works by placing a brass casing inside an electrochemical cell filled with a chemical solution. When a low electrical voltage is applied, the chemicals are drawn toward the surface, filling the tiny gaps between fingerprint ridges and forming a distinct, high-contrast image. The result appears almost instantly.  \"Using the burnt material that remains on the surface of the casing as a stencil, we can deposit specific materials in between the gaps, allowing for the visualisation,\" said Dr. McKeever. Durable Results and New Investigative Possibilities Tests showed that this technique also worked on samples aged up to 16 months, demonstrating remarkable durability. The research has significant implications for criminal investigations, where the current assumption is that firing a gun eliminates fingerprint residues on casings. \"Currently, the best case of forensic analysis of ammunition casings is to match it to the gun that fired it,\" said Dr. McKeever. \"But we hope a method like this could match it back to the actual person who loaded the gun.\" The team focused specifically on brass ammunition casings, a substance that has been traditionally resistant to fingerprint detection and is the most common type of material used globally.  The researchers believe that the test for fingerprints on brass they have developed could be adapted for other metallic surfaces, expanding its range of potential forensic applications, from firearm-related crimes to arson. This technique uses a device called a potentiostat, which controls voltage and can be as portable as a mobile phone, making it possible to create a compact forensic testing kit. \"With this method, we have turned the ammunition casing into an electrode, allowing us to drive chemical reactions at the surface of the casing,\" said Dr. McKeever. Toward Real-World Use Although early results are promising, the new fingerprint recovery method will need further testing and validation before it can be used by law enforcement agencies around the world. The project, supported by Research Ireland and Maynooth University, was recently published in a leading forensic science journal and represents a major step forward for global policing and criminal investigation.", "release_time": "2025-11-03", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/11/251102011206.htm"}
{"category": "研究前沿", "title": "研究：援助项目管理质量决定当地冲突增减", "short_summary": "MIT研究揭示援助项目管理优劣直接影响冲突概率，良好管理可降冲突12%。", "detailed_summary": "MIT研究揭示援助项目管理优劣直接影响冲突概率，良好管理可降冲突12%。\n（1）MIT经济学家研究发现援助项目管理质量是决定是否引发当地冲突的关键因素。\n（2）基于1997-2014年世界银行非洲项目数据，管理最佳项目使冲突概率降低达12%，管理最差项目则增加冲突风险。\n（3）项目负责人能力差异显著，从25分位换至75分位负责人会使冲突概率增加15%。\n（4）冲突多发于资源流动阶段而非项目启动时，易被侵占资源（如食品、医疗设备）更易引发冲突。\n（5）研究为先前相互矛盾结论提供解释，强调援助组织内部管理而非受援国政治条件的主导作用。", "raw_content": "Good management of aid projects in developing countries reduces violence in those areas — but poorly managed projects increase the chances of local violence, according to a new study by an MIT economist.The research, examining World Bank projects in Africa, illuminates a major question surrounding international aid. Observers have long wondered if aid projects, by bringing new resources into developing countries, lead to conflict over those goods as an unintended consequence. Previously, some scholars have identified an increase in violence attached to aid, while others have found a decrease.The new study shows those prior results are not necessarily wrong, but not entirely right, either. Instead, aid oversight matters. World Bank programs earning the highest evaluation scores for their implementation reduce the likelihood of conflict by up to 12 percent, compared to the worst-managed programs.“I find that the management quality of these projects has a really strong effect on whether that project leads to conflict or not,” says MIT economist Jacob Moscona, who conducted the research. “Well-managed aid projects can actually reduce conflict, and poorly managed projects increase conflict, relative to no conflict. So, the way aid programs are organized is very important.”The findings also suggest aid projects can work well almost anywhere. At times, observers have suggested the political conditions in some countries prevent aid from being effective. But the new study finds otherwise.“There are ways these programs can have their positive effects without the negative consequences,” Moscona says. “And it’s not the result of what politics looks like on the receiving end; it’s about the organization itself.”Moscona’s paper detailing the study, “The Management of Aid and Conflict in Africa,” is published in the November issue of the American Economic Journal: Economic Policy. Moscona, the paper’s the sole author, is the 3M Career Development Assistant Professor in MIT’s Department of Economics.Decisions on the groundTo conduct the study, Moscona examined World Bank data from the 1997-2014 time period, using the information compiled by AidData, a nonprofit group that also studies World Bank programs. Importantly, the World Bank conducts extensive evaluations of its projects and includes the identities of project leaders as part of those reviews.“There are a lot of decisions on the ground made by managers of aid, and aid organizations themselves, that can have a huge impact on whether or not aid leads to conflict, and how aid resources are used and whether they are misappropriated or captured and get into the wrong hands,” Moscona says.For instance, diligent daily checks about food distribution programs can and have substantially reduced the amount of food that is stolen or “leaks” out of the program. Other projects have created innovative ways of tagging small devices to ensure those objects are used by program participants, reducing appropriation by others.Moscona combined the World Bank data with statistics from the Armed Conflict Location and Event Data Project (ACLED), a nonprofit that monitors political violence. That enabled him to evaluate how the quality of aid project implementation — and even the quality of the project leadership — influenced local outcomes.For instance, by looking at the ratings of World Bank project leaders, Moscona found that shifting from a project leader at the 25th percentile, in terms of how frequently projects are linked with conflict, to one at the 75th percentile, increases the chances of local conflict by 15 percent.“The magnitudes are pretty large, in terms of the probability that a conflict starts in the vicinity of a project,” Moscona observes.Moscona’s research identified several other aspects of the interaction between aid and conflict that hold up over the region and time period. The establishment of aid programs does not seem to lead to long-term strategic activity by non-government forces, such as land acquisition or the establishment of rebel bases. The effects are also larger in areas that have had recent political violence. And armed conflict is greater when the resources at stake can be expropriated — such as food or medical devices.“It matters most if you have more divertable resources, like food and medical devices that can be captured, as opposed to infrastructure projects,” Moscona says.Reconciling the previous resultsMoscona also found a clear trend in the data about the timing of violence in relation to aid. Government and other armed groups do not engage in much armed conflict when aid programs are being established; it is the appearance of desired goods themselves that sets off violent activity.“You don’t see much conflict when the projects are getting off the ground,” Moscona says.” You really see the conflict start when the money is coming in or when the resources start to flow. Which is consistent with the idea of the relevant mechanism being about aid resources and their misappropriation, rather than groups trying to deligitimize a project.”All told, Moscona’s study finds a logical mechanism explaining the varying results other scholars have found with regard to aid and conflict. If aid programs are not equally well-administered, it stands to reason that their outcomes will not be identical, either.“There wasn’t much work trying to make those two sets of results speak to each other,” says Moscona. “I see it less as overturning existing results than providing a way to reconcile different results and experiences.”Moscona’s findings may also speak to the value of aid in general — and provide actionable ideas for institutions such as the World Bank. If better management makes such a difference, then the potential effectiveness of aid programs may increase.“One goal is to change the conversation about aid,” Moscona says. The data, he suggests, shows that the public discourse about aid can be “less defeatist about the potential negative consequences of aid, and the idea that it’s out of the control of the people who administer it.”", "release_time": "2025-11-03", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/study-good-management-aid-projects-reduces-local-violence-1103"}
{"category": "研究前沿", "title": "研究证实热泵在旧建筑中高效运行", "short_summary": "弗劳恩霍夫研究显示热泵在旧建筑中效率高，碳排放比燃气系统低约64%。", "detailed_summary": "弗劳恩霍夫研究显示热泵在旧建筑中效率高，碳排放比燃气系统低约64%。\n(1) 弗劳恩霍夫ISE研究所对77个热泵系统进行实测，证明其在旧建筑中运行良好，平均季节性能系数空气源热泵为3.4，地源热泵为4.3。\n(2) 热泵的温室气体排放比天然气供暖系统平均低64%，气候友好性显著。\n(3) 研究分析了热泵与光伏系统的结合，加装电池后建筑能源自给率可达32%至62%。\n(4) 项目同时进行了声学测量，发现部分设备存在夜间噪音略超限情况，但可通过设备选型与隔音措施解决。\n(5) 研究揭示了优化潜力，如部分热泵规格过大、切换频率过高，并为此创建了规划与安装的质量控制流程矩阵。", "raw_content": "Heat pumps are becoming increasingly popular: In the first half of 2025, they ranked at the top of the sold heating systems for the first time in the history of the German heating market. This means they have displaced gas heating systems from the top spot. In new buildings, heat pumps have dominated for years, with nearly 70 percent of new constructions completed in 2024 using a heat pump for heating. However, homeowners of older existing buildings are still wondering whether these heat generators can also operate efficiently and climate-friendly in their homes. Heat pumps work well, but there is also optimization potential These doubts are unfounded. “The results clearly show that heat pumps can be operated efficiently even in older buildings and that they provide climate-friendly heating without the need for the buildings to be renovated to new construction standards,” says Danny Günther, team leader for 'Heat Pumps and Transformation of Existing Buildings' at Fraunhofer ISE. “However, we have also uncovered optimization potential.” Based on the detailed analysis of measurement data, it can be understood which planning or installation errors occur most frequently and where inefficient operational behavior is evident,” Günther adds. Efficiency: Seasonal performance factors ranging from 2.6 to 5.4 In the research project, Fraunhofer ISE monitored 77 heat pump heating systems under real conditions. The efficiency of the heat pumps has improved compared to the project “WPsmart in Existing Buildings”, which was completed in 2019. Air/water heat pumps achieve an average seasonal performance factor (SPF) of 3.4, meaning they generate 3.4 units of heat from one unit of electricity. In the previous project, the average was 3.1. The air/water heat pump with the lowest efficiency had an APF of 2.6, while the highest reached 4.9. The more efficient ground-coupled systems exhibit an average APF of 4.3 (WPsmart in Existing Buildings: 4.1). The range for ground source heat pumps spans from 3.6 to 5.4. No correlation between the year of construction of the buildings and the efficiency of the heat pump was found. The study also showed that adequately sized radiators can be operated at similarly low temperatures as underfloor heating. The energy consumption of the electric heating rods, which support the heat pump in particularly cold temperatures, plays a minor role in the measured systems, which is also linked to the comparatively mild weather conditions during the measurement period. They accounted for only 1.3 percent of the electrical work in air/water heat pumps, while the share was close to zero percent for ground source heat pumps. Greenhouse gas emissions: 57 to 68 percent lower than with gas boilers The efficient operation of heat pumps results in them being significantly more climate-friendly compared to natural gas heating systems. Considering the German electricity mix from the past year, the examined pool of heat pumps shows a calculated CO2 reduction of 68 percent compared to gas heating systems. However, this annual accounting does not take into account the intra-year or intra-day variance in heat pump efficiency, as well as the contributions of individual power plant types to electricity production. Therefore, the study has now also incorporated the quarterly calculated emission values from the German electricity mix for the first time. This allows for a more precise assessment of the climate-friendliness of heat pumps. With this dynamic accounting, the savings decrease, but only slightly. In 2024, the CO2 emissions of the examined heat pumps were on average 64 percent lower than those of gas heating systems – four percentage points less than with the static method. Sound measurements also conducted In the project, the researchers developed a method for long-term sound field measurements on air/water heat pumps and successfully demonstrated it on five randomly selected systems. In two buildings, the ambient noise was so dominant that the heat pumps had little acoustic impact, and no exceedances could be attributed to any of the heat pumps. At three locations, the operation of the heat pumps correlated with increased exceedances of the permissible night emissions. However, these exceedances consistently remained below the ambient noise levels. Compliance with the ”TA Lärm” regulations in Germany could have been achieved by selecting better devices in terms of sound power levels, the placement of the heat pump, or common soundproofing measures. Combination of Heat Pumps and Photovoltaics Additionally, the researchers at Fraunhofer ISE analyzed the combination of heat pumps with photovoltaic (PV) systems. A classic approach to increasing the self-consumption of locally generated PV electricity is to raise target temperatures when there is excess PV power. Operating the heat pump more frequently with solar power can be advantageous: solar electricity is cheaper than grid electricity, even at heat pump tariffs, heat pumps can be operated in a more climate-friendly manner, and it can relieve the distribution network at certain times. The results of the investigation of six heat pump/PV combinations: without a battery, buildings with a PV system achieve 25 to 40 percent autonomy and 22 to 37 percent self-consumption. With a battery, these ranges shift significantly, with building autonomy values from 32 to 62 percent and building self-consumption values from 40 to 83 percent. Process Matrix for Optimization Despite good measured efficiency values, the research project also highlighted optimization potentials. For example, many heat pumps were oversized in relation to consumption, and the switching frequencies were very high for some systems. In some systems with combined storage, a reliable separation of temperature levels for space heating and domestic hot water heating was not achieved, leading to unnecessary heat provision at the hot water temperature level. Based on the analysis of the measurement data and feedback from stakeholders, the research team at Fraunhofer ISE created a process matrix in the final report. This documents possible quality deficiencies for the individual phases of planning, installation, and commissioning. It also shows how to address these issues. The results and recommendations from the project provide valuable insights for planners, installers, and operators of heat pump systems. 61 Buildings with Air/Water Heat Pumps, 16 with Ground Source Heat Pumps The examined pool of systems included 61 units with the heat source being outside air. These air/water heat pumps are the most commonly used type of heat pump in Germany. 16 systems utilize a brine/water heat pump, drawing heat from the ground. 34 of the examined heat pumps come from the project “WPsmart in Existing Buildings”, completed in 2019, where the research partners continued monitoring, partly with more recent heat pump models. 43 measurement objects were newly added. For the efficiency evaluation, heat pumps in buildings constructed between 1826 and 2001 were considered. The heated area ranges from 90 to 370 square meters, with an average of 170 square meters. Residential buildings built before 1977 (the first thermal insulation regulation) have been renovated more extensively than the national average. For example, half of the buildings, 51 percent, had their façades retrofitted with insulation – nationwide, only 30 percent were insulated based on 2016 data. Buildings constructed from 1977 onwards are, with one exception, entirely unrenovated. Partners of Fraunhofer ISE included heat pump manufacturers Bosch Thermotechnik, Glen Dimplex Deutschland, Max Weishaupt, NIBE Systemtechnik, Panasonic Heating & Ventilation Air-Conditioning Europe, DAIKIN Airconditioning Germany, Stiebel Eltron, Viessmann, and Vaillant, as well as energy suppliers Lechwerke and Stuttgart municipal utilities. The Federal Ministry for Economic Affairs and Energy (BMWi) financially supported the project under the funding code FKZ: 03EN2029A. The detailed results of the research project 'Quality Assurance of Heat Pumps in Existing Buildings,' abbreviated as 'WP-QS in Existing Buildings,' can be found on the project page.", "release_time": "2025-11-04", "source_institution": "德国弗劳恩霍夫协会太阳能系统研究所", "url": "http://www.ise.fraunhofer.de/en/press-media/press-releases/2025/fraunhofer-ise-research-project-completed-heat-pumps-provide-climate-friendly-heating-in-existing-buildings.html"}
{"category": "政策计划", "title": "俄罗斯终止与芬兰部分能源协议效力", "short_summary": "俄总理签署命令，因芬兰拒购俄电力，终止相关能源协议条款。", "detailed_summary": "俄总理签署命令，因芬兰拒购俄电力，终止相关能源协议条款。\n(1)俄总理米舒斯京签署命令，批准终止1972年签署的苏芬能源协议第三和第四条效力。\n(2)终止原因是芬兰自2022年4月起单方面拒绝采购俄罗斯电力。\n(3)该协议曾允许芬兰利用跨境水资源开发水电，伊马特拉水电站为关键节点。\n(4)俄罗斯统一电力进出口公司已于2022年5月停止对芬兰供电。", "raw_content": "总台记者当地时间11月2日获悉，俄联邦政府总理米舒斯京已于1日签署命令，批准终止《苏联政府与芬兰政府关于有限利用斯韦托戈尔斯克水电站和伊马特拉水电站段武奥克萨河进行能源开发的协议》(下称《协议》)第三和第四条效力。 米舒斯京在命令中称，鉴于芬兰自2022年4月4日起单方面拒绝采购俄罗斯电力，俄方不再承担《协议》第三和第四条规定的供应补偿性能源的义务。 《协议》于1972年签署，曾允许芬兰利用跨境水资源开发水电，位于芬兰境内武奥克萨河上游的伊马特拉水电站作为合作的关键节点。俄罗斯统一电力进出口公司旗下北欧子公司已于2022年5月14日停止对芬兰供电。", "release_time": "2025-11-03", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195616-1.html"}
{"category": "产业应用", "title": "GA-ASI无人战斗机机队亮相国际会议，推动自主航空产业化", "short_summary": "GA-ASI展示量产无人战机，引领自主空战技术产业化发展。", "detailed_summary": "GA-ASI展示量产无人战机，引领自主空战技术产业化发展。\n（1）GA-ASI作为四星首席合作伙伴参加国际战斗机会议25周年活动，突显其在自主战斗机领域的全球领导地位；\n（2）公司量产无人战机机队包括MQ-20 Avenger、XQ-67A和YFQ-42A等型号，正定义自主半自主战斗机的未来；\n（3）YFQ-42A协作作战飞机已于2025年8月首飞，实现夏季前交付美国空军的承诺，标志战斗机新时代；\n（4）公司拥有超过30年经验，交付1300多架战机，总飞行时数超900万小时，持续主导无人机系统发展；\n（5）通过模块化Gambit系列和自主技术整合，为美军及盟友提供可扩展、经济高效的未来空战解决方案。", "raw_content": "GA-ASI Brings Uncrewed Fighter Fleet into Focus at International Fighter Conference 2025  SAN DIEGO – 03 November 2025 – General Atomics Aeronautical Systems, Inc. (GA-ASI), the world leader in uncrewed aircraft systems, is excited to participate in the upcoming 25th anniversary of the International Fighter Conference as the event’s only Four-Star Lead Partner, reflecting the company’s global commitment to the future of autonomous fighter jets. GA-ASI’s growing production fleet of unmanned combat jets – including the MQ-20 Avenger®, XQ-67A Off-Board Sensing Station, and YFQ-42A Collaborative Combat Aircraft – is defining the global future of autonomous and semi-autonomous combat jets, leading the way in autonomy development, manned-unmanned teaming, and affordable, rapid delivery at scale. The company’s vision for its Gambit Series of modular, scalable, uncrewed fighters paves the way for U.S. forces, allies and partners to quickly evolve global air forces for the future fight. Publicly promising to build and fly a production-representative uncrewed jet fighter for the U.S. Air Force by summer 2025, GA-ASI launched its YFQ-42A CCA in August, pioneering a new era for fighter jets. Flight operations continue today across the growing fleet, cementing GA-ASI’s continued dominance in UAS development and delivery while meeting anticipated timelines and remaining true to its word.  “The YFQ-42A is a revolutionary aircraft, and the fleet is in production and in the air today,” said David R. Alexander, president of GA-ASI. “This isn’t a ‘wait and see’ moment. We’re flying. We’re delivering. And we’re advancing this future of combat aviation, the same way we have for more than three decades.” Since 1992, GA-ASI has delivered more than 1,300 combat aircraft to U.S. forces and international partners, surpassing more than 9 million total flight hours in 2025. The company’s Predator®, Reaper®, Gray Eagle®, SkyGuardian® and SeaGuardian® aircraft continue to set the standard for medium-altitude, long-endurance UAS performance. The company’s MQ-20 Avenger, an internally funded uncrewed combat jet that achieved first flight in 2009, continues to serve as a test bed for advanced autonomy integration and demonstration, incorporating and flying the latest cutting-edge software from U.S. government sources, leading industry suppliers and GA-ASI’s own autonomy software development teams, often at company expense. For International Fighter Conference, Nov. 4-6 in Rome, GA-ASI plans to offer attendees a chance to see the future for themselves, with a full-scale model display of the YFQ-42A CCA co-located inside the show venue and other announcements. For more information on IFC 2025, visit https://www.defenceiq.com/events-internationalfighter. About GA-ASI General Atomics Aeronautical Systems, Inc., is the world’s foremost builder of Unmanned Aircraft Systems (UAS). Logging more than 9 million flight hours, the Predator® line of UAS has flown for over 30 years and includes MQ-9A Reaper®, MQ-1C Gray Eagle®, MQ-20 Avenger®, and MQ-9B SkyGuardian®/SeaGuardian®. The company is dedicated to providing long-endurance, multi-mission solutions that deliver persistent situational awareness and rapid strike. For more information, visit www.ga-asi.com      Avenger, EagleEye, Gray Eagle, Lynx, Predator, Reaper, SeaGuardian, and SkyGuardian are trademarks of General Atomics Aeronautical Systems, Inc., registered in the United States and/or other countries.", "release_time": "2025-11-04", "source_institution": "通用原子能公司", "url": "http://www.ga.com/the-future-of-autonomous-fighters-is-coming-to-rome"}
{"category": "研究前沿", "title": "MIT研发FSNet工具加速电网优化求解", "short_summary": "MIT新工具融合机器学习与优化算法，大幅提升复杂问题求解速度与可行性。", "detailed_summary": "MIT新工具融合机器学习与优化算法，大幅提升复杂问题求解速度与可行性。\n（1）MIT研究人员开发FSNet工具，用于解决电网调度等复杂优化问题；\n（2）采用两步骤框架：神经网络预测初始解，传统求解器进行可行性修正；\n（3）相比传统求解器，速度提升数个数量级，且能保证解决方案不违反约束；\n（4）优于纯机器学习方法，后者虽快但无法确保可行性；\n（5）应用前景广泛，包括电网调度、产品设计、投资组合管理和生产规划等领域。", "raw_content": "Managing a power grid is like trying to solve an enormous puzzle.Grid operators must ensure the proper amount of power is flowing to the right areas at the exact time when it is needed, and they must do this in a way that minimizes costs without overloading physical infrastructure. Even more, they must solve this complicated problem repeatedly, as rapidly as possible, to meet constantly changing demand.To help crack this consistent conundrum, MIT researchers developed a problem-solving tool that finds the optimal solution much faster than traditional approaches while ensuring the solution doesn’t violate any of the system’s constraints. In a power grid, constraints could be things like generator and line capacity.This new tool incorporates a feasibility-seeking step into a powerful machine-learning model trained to solve the problem. The feasibility-seeking step uses the model’s prediction as a starting point, iteratively refining the solution until it finds the best achievable answer.The MIT system can unravel complex problems several times faster than traditional solvers, while providing strong guarantees of success. For some extremely complex problems, it could find better solutions than tried-and-true tools. The technique also outperformed pure machine learning approaches, which are fast but can’t always find feasible solutions.In addition to helping schedule power production in an electric grid, this new tool could be applied to many types of complicated problems, such as designing new products, managing investment portfolios, or planning production to meet consumer demand.“Solving these especially thorny problems well requires us to combine tools from machine learning, optimization, and electrical engineering to develop methods that hit the right tradeoffs in terms of providing value to the domain, while also meeting its requirements. You have to look at the needs of the application and design methods in a way that actually fulfills those needs,” says Priya Donti, the Silverman Family Career Development Professor in the Department of Electrical Engineering and Computer Science (EECS) and a principal investigator at the Laboratory for Information and Decision Systems (LIDS).Donti, senior author of an open-access paper on this new tool, called FSNet, is joined by lead author Hoang Nguyen, an EECS graduate student. The paper will be presented at the Conference on Neural Information Processing Systems.Combining approachesEnsuring optimal power flow in an electric grid is an extremely hard problem that is becoming more difficult for operators to solve quickly.“As we try to integrate more renewables into the grid, operators must deal with the fact that the amount of power generation is going to vary moment to moment. At the same time, there are many more distributed devices to coordinate,” Donti explains.Grid operators often rely on traditional solvers, which provide mathematical guarantees that the optimal solution doesn’t violate any problem constraints. But these tools can take hours or even days to arrive at that solution if the problem is especially convoluted.On the other hand, deep-learning models can solve even very hard problems in a fraction of the time, but the solution might ignore some important constraints. For a power grid operator, this could result in issues like unsafe voltage levels or even grid outages.“Machine-learning models struggle to satisfy all the constraints due to the many errors that occur during the training process,” Nguyen explains.For FSNet, the researchers combined the best of both approaches into a two-step problem-solving framework.Focusing on feasibilityIn the first step, a neural network predicts a solution to the optimization problem. Very loosely inspired by neurons in the human brain, neural networks are deep learning models that excel at recognizing patterns in data.Next, a traditional solver that has been incorporated into FSNet performs a feasibility-seeking step. This optimization algorithm iteratively refines the initial prediction while ensuring the solution does not violate any constraints.Because the feasibility-seeking step is based on a mathematical model of the problem, it can guarantee the solution is deployable.“This step is very important. In FSNet, we can have the rigorous guarantees that we need in practice,” Hoang says.The researchers designed FSNet to address both main types of constraints (equality and inequality) at the same time. This makes it easier to use than other approaches that may require customizing the neural network or solving for each type of constraint separately.“Here, you can just plug and play with different optimization solvers,” Donti says.By thinking differently about how the neural network solves complex optimization problems, the researchers were able to unlock a new technique that works better, she adds.They compared FSNet to traditional solvers and pure machine-learning approaches on a range of challenging problems, including power grid optimization. Their system cut solving times by orders of magnitude compared to the baseline approaches, while respecting all problem constraints.FSNet also found better solutions to some of the trickiest problems.“While this was surprising to us, it does make sense. Our neural network can figure out by itself some additional structure in the data that the original optimization solver was not designed to exploit,” Donti explains.In the future, the researchers want to make FSNet less memory-intensive, incorporate more efficient optimization algorithms, and scale it up to tackle more realistic problems.“Finding solutions to challenging optimization problems that are feasible is paramount to finding ones that are close to optimal. Especially for physical systems like power grids, close to optimal means nothing without feasibility. This work provides an important step toward ensuring that deep-learning models can produce predictions that satisfy constraints, with explicit guarantees on constraint enforcement,” says Kyri Baker, an associate professor at the University of Colorado Boulder, who was not involved with this work.", "release_time": "2025-11-03", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/faster-problem-solving-tool-guarantees-feasibility-1103"}
{"category": "研究前沿", "title": "剑桥大学研发新型半人工树叶助力化工脱碳", "short_summary": "剑桥团队开发光驱动半人工树叶，可将二氧化碳转化为燃料并合成药物。", "detailed_summary": "剑桥团队开发光驱动半人工树叶，可将二氧化碳转化为燃料并合成药物。\n（1）剑桥大学团队开发出一种新型“半人工树叶”混合装置，结合有机半导体与细菌酶。\n（2）该装置利用阳光、水和二氧化碳生产甲酸盐（一种清洁燃料），并可驱动后续化学反应。\n（3）相比以往设计，新模型使用无毒材料，运行更高效稳定，无需额外添加剂。\n（4）实验室测试中，成功利用阳光将二氧化碳转化为甲酸盐，并直接合成高纯度药物成分。\n（5）该技术为化工行业“脱化石燃料化”提供了新平台，有望推动绿色燃料和化学品生产。", "raw_content": "“If we’re going to build a circular, sustainable economy, the chemical industry is a big, complex problem that we must address,” said Professor Erwin Reisner from Cambridge’s Yusuf Hamied Department of Chemistry, who led the research. “We’ve got to come up with ways to de-fossilize this important sector, which produces so many important products we all need. It’s a huge opportunity if we can get it right.” es about 6% of the world’s total carbon emissions.Now, a team led by the University of Cambridge is exploring innovative approaches that could eventually “de-fossilize” this vital industry.Their breakthrough involves a hybrid device that brings together light-absorbing organic polymers and bacterial enzymes to transform sunlight, water, and carbon dioxide into formate, a clean fuel that can power additional chemical reactions.This “semi-artificial leaf” replicates photosynthesis, the natural process plants use to turn sunlight into energy, and operates entirely on its own power. Unlike previous designs that relied on toxic or unstable light absorbers, this new biohybrid model uses non-toxic materials, runs more efficiently, and remains stable without extra additives.In laboratory tests, the team successfully used sunlight to convert carbon dioxide into formate and then applied it directly in a “domino” reaction to synthesize a valuable compound used in pharmaceuticals, achieving both high yield and purity.According to findings published in Joule, this marks the first instance where organic semiconductors have served as the light-capturing component in such a biohybrid system, paving the way for a new generation of eco-friendly artificial leaves.The chemical industry remains a cornerstone of the global economy, producing a vast range of goods—from medicines and fertilizers to plastics, paints, electronics, cleaning agents, and toiletries. “If we’re going to build a circular, sustainable economy, the chemical industry is a big, complex problem that we must address,” said Professor Erwin Reisner from Cambridge’s Yusuf Hamied Department of Chemistry, who led the research. “We’ve got to come up with ways to de-fossilize this important sector, which produces so many important products we all need. It’s a huge opportunity if we can get it right.” Reisner’s research group specializes in the development of artificial leaves, which turn sunlight into carbon-based fuels and chemicals without relying on fossil fuels. But many of their earlier designs depend on synthetic catalysts or inorganic semiconductors, which either degrade quickly, waste much of the solar spectrum, or contain toxic elements such as lead. “If we can remove the toxic components and start using organic elements, we end up with a clean chemical reaction and a single end product, without any unwanted side reactions,” said co-first author Dr. Celine Yeung, who completed the research as part of her PhD work in Reisner’s lab. “This device combines the best of both worlds – organic semiconductors are tuneable and non-toxic, while biocatalysts are highly selective and efficient.” The new device integrates organic semiconductors with enzymes from sulfate-reducing bacteria, splitting water into hydrogen and oxygen or converting carbon dioxide into formate. The researchers have also addressed a long-standing challenge: most systems require chemical additives, known as buffers, to keep the enzymes running. These can break down quickly and limit stability. By embedding a helper enzyme, carbonic anhydrase, into a porous titania structure, the researchers enabled the system to work in a simple bicarbonate solution — similar to sparkling water — without unsustainable additives. “It’s like a big puzzle,” said co-first author Dr. Yongpeng Liu, a postdoctoral researcher in Reisner’s lab. “We have all these different components that we’ve been trying to bring together for a single purpose. It took us a long time to figure out how this specific enzyme is immobilized on an electrode, but we’re now starting to see the fruits from these efforts.” “By really studying how the enzyme works, we were able to precisely design the materials that make up the different layers of our sandwich-like device,” said Yeung. “This design made the parts work together more effectively, from the tiny nanoscale up to the full artificial leaf.”  Tests showed the artificial leaf produced high currents and achieved near-perfect efficiency in directing electrons into fuel-making reactions. The device successfully ran for over 24 hours: more than twice as long as previous designs. The researchers are hoping to further develop their designs to extend the lifespan of the device and adapt it so it can produce different types of chemical products. “We’ve shown it’s possible to create solar-powered devices that are not only efficient and durable but also free from toxic or unsustainable components,” said Reisner. “This could be a fundamental platform for producing green fuels and chemicals in future – it’s a real opportunity to do some exciting and important chemistry.” The research was supported in part by the Singapore Agency for Science, Technology and Research (A*STAR), the European Research Council, the Swiss National Science Foundation, the Royal Academy of Engineering, and UK Research and Innovation (UKRI). Erwin Reisner is a Fellow of St John’s College, Cambridge. Celine Yeung is a Member of Downing College, Cambridge.", "release_time": "2025-11-02", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/11/251102011148.htm"}
{"category": "研究前沿", "title": "量子材料首次实现太赫兹偶次谐波生成", "short_summary": "拓扑绝缘体突破材料对称性限制，实现太赫兹频段偶次谐波生成。", "detailed_summary": "拓扑绝缘体突破材料对称性限制，实现太赫兹频段偶次谐波生成。\n（1）研究团队利用拓扑绝缘体材料成功扩展高次谐波产生至太赫兹频段；\n（2）通过设计纳米环谐振器增强光场，首次实验观测到6.4THz偶次谐波和9.7THz奇次谐波；\n（3）揭示了材料体相对称性和表面不对称性对谐波产生的协同作用；\n（4）验证了拓扑绝缘体支持高阶谐波产生的理论预测；\n（5）为开发紧凑型太赫兹光源和高速通信器件奠定基础。", "raw_content": "High-order harmonic generation (HHG) is a process that transforms light into much higher frequencies, allowing scientists to explore areas of the electromagnetic spectrum that are otherwise difficult to reach. However, generating terahertz (THz) frequencies using HHG has remained a major obstacle because most materials are too symmetrical to support this conversion.  Graphene has long been a promising candidate for HHG research, but its perfect symmetry restricts it to producing only odd harmonics -- frequencies that are odd multiples of the original light source. Even harmonics, which are essential for expanding practical uses of this technology, have been much harder to achieve. Quantum Materials Break the Barrier In a recent study published in Light: Science & Applications, a research group led by Prof. Miriam Serena Vitiello has achieved a major advance in optical science. By working with exotic quantum materials, the team successfully extended HHG into new and previously unreachable parts of the electromagnetic spectrum. Their work centers on topological insulators (TIs), a special class of materials that behave as electrical insulators inside but conduct electricity along their surfaces. These materials exhibit unusual quantum behavior due to strong spin-orbit coupling and time-reversal symmetry. Although scientists had predicted that TIs could support advanced forms of harmonic generation, no one had yet demonstrated it experimentally -- until now. Amplifying Light With Quantum Nanostructures The researchers designed specialized nanostructures called split ring resonators and integrated them with thin layers of Bi2Se₃ and van der Waals heterostructures made from (InₓBi₁₋ₓ)2Se₃. These resonators significantly intensified the incoming light, allowing the team to observe HHG at both even and odd THz frequencies, an exceptional accomplishment.  They recorded frequency up-conversion between 6.4 THz (even) and 9.7 THz (odd), uncovering how both the symmetrical interior and the asymmetrical surface of the topological materials contribute to light generation. This result represents one of the first clear demonstrations of how topological effects can shape harmonic behavior in the THz range. Toward Next-Generation Terahertz Technology This experimental achievement not only validates long-standing theoretical predictions but also establishes a new foundation for developing compact terahertz light sources, sensors, and ultrafast optoelectronic components. It gives researchers a new way to study the complex interplay between symmetry, quantum states, and light-matter interactions at the nanoscale. As industries continue to demand smaller, faster, and more efficient devices, such progress highlights the growing potential of quantum materials to drive real-world innovation. The discovery also points toward the creation of compact, tunable terahertz light sources powered by optical methods -- an advance that could reshape technologies in high-speed communications, medical imaging, and quantum computing.", "release_time": "2025-11-02", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/11/251102011155.htm"}
{"category": "研究前沿", "title": "第71届ICFA强子束流动力学国际研讨会在惠州开幕", "short_summary": "国际专家齐聚惠州，共议强子加速器前沿技术与未来发展趋势。", "detailed_summary": "国际专家齐聚惠州，共议强子加速器前沿技术与未来发展趋势。\n(1) 第71届ICFA强流高亮度强子束流动力学国际研讨会在广东惠州开幕，汇聚全球数百名专家学者。\n(2) 会议聚焦强子束流动力学、加速器技术及其在基础物理、医学等多领域应用的前沿进展。\n(3) 会期五天，包含近90场报告和68份海报，旨在推动该领域的国际协同发展与深度合作。\n(4) 这是我国继2012年后第二次主办该全球影响力最大的强子加速器束流动力学专题会议。\n(5) 会议有助于展示我国在强流重离子加速器等大科学装置建设方面的成果，提升国际学术影响力。", "raw_content": "近日，由中国科学院近代物理研究所主办的第71届ICFA学术研讨会暨强流高亮度强子束流动力学国际研讨会在广东惠州开幕。来自北美、欧洲、亚洲多家科研机构和高校的数百名专家学者齐聚一堂，围绕强子束流动力学、强子加速器技术及其应用等前沿领域，深入探讨当前研究进展与未来发展趋势。强子加速器作为支撑国家重大战略需求和前沿科学探索的关键平台，是大科学装置的核心组成部分。除基础物理研究外，该技术在中子科学、材料科学、医学应用等多个领域均发挥着日益重要的作用。本次会议聚焦2023至2025年间国际上各类强子加速器的发展动态、技术突破与最新科研研究成果，旨在推动国际科研机构间的协同发展与深度合作。图：中国科学院院士赵红卫出席开幕式并致辞在为期五天的会议中，近200名参会人员围绕强子束流动力学、加速器技术、新方法与新概念以及工业应用等议题展开交流。会议共安排了近90场邀请报告和口头报告，并展出68份学术海报。据悉，国际未来加速器委员会（ICFA）于1976年由国际纯粹与应用物理联合会发起成立，旨在推动高能物理加速器领域的国际合作，推动相关大科学装置的建设和应用。ICFA学术研讨会下设多个分会，涵盖强流高亮度强子束流动力学、正负电子对撞机、未来光源等多个研究方向。其中，强流高亮度强子束流动力学国际研讨会（HB系列会议）自2002年创办以来，每两年分别在美国、欧洲和亚洲轮流举办，现已成为全球规模最大、影响力最广的强子加速器束流动力学专题会议。此次是我国继2012年在北京承办第52届会议后，第二次主办该系列会议。当前，中国科学院近代物理研究所正积极推进国家重大科技基础设施——强流重离子加速器装置（HIAF）与加速器驱动嬗变研究装置（CiADS）的建设。本次会议的成功举办，不仅有助于深化我国在该领域的国际交流与合作，展示我国在相关技术研发与应用方面的最新成果，也将进一步提升惠州在国际学术界的知名度，促进对惠州历史文化与城市发展的了解。", "release_time": "2025-11-02", "source_institution": "近代物理研究所", "url": "http://www.imp.cas.cn/sndt2017/202511/t20251101_8004821.html"}
{"category": "研究前沿", "title": "机器学习革新煤热解研究范式", "short_summary": "机器学习数据驱动精准预测煤热解产物，推动煤炭清洁高效利用研究。", "detailed_summary": "机器学习数据驱动精准预测煤热解产物，推动煤炭清洁高效利用研究。\n(1) 机器学习方法不依赖先验机理假设，通过数据驱动从实验数据中挖掘煤结构与热解条件的隐藏规律，构建高维非线性映射。\n(2) 人工神经网络、随机森林等算法在预测焦油、气体与半焦产率方面精度已优于传统热解模型。\n(3) 机器学习不仅是预测工具，更通过特征重要性分析等可解释AI技术，为揭示煤热解本征反应网络提供新视角。\n(4) 当前研究面临数据碎片化、多源异构和跨尺度关联不足等挑战，需构建高通量表征平台和整合多维数据库。\n(5) 未来融合机理模型与高性能计算的“白盒化”机器学习方法是实现煤热解产物定向调控、推动煤炭清洁高效利用的关键路径。", "raw_content": "煤炭是我国能源体系的重要支柱，掌握热解过程是实现清洁高效转化的关键环节。由于煤的结构并非由单一分子构成，而是以芳香环为骨架、由烷基侧链和杂原子桥联组成的复杂空间网络。在加热过程中，该网络经历一系列随机的化学键断裂、自由基反应及二次反应，转化路径高度非线性，产物分布受煤阶、矿物组成、颗粒尺度、温度场等多因素耦合影响。传统热解研究，无论是基于宏观动力学的分布式活化能模型，还是基于煤结构片段的大分子网络模型，均依赖于反应路径与网络连接的强假设简化，难以在宽条件范围内实现对产物组成与性质的精准预测。谢克昌院士在多个场合强调人工智能对煤科学、技术与工程的重要性，在此背景下，机器学习方法展现出独特的优势。它不依赖先验机理假设，而是通过数据驱动，从大量实验与模拟数据中自主挖掘煤结构特征与热解条件之间的隐藏规律，构建输入与输出之间的高维非线性映射。研究表明，人工神经网络、随机森林等算法在预测焦油、气体与半焦产率方面已优于传统模型的精度。更为重要的是，机器学习不仅作为预测工具，更逐渐成为理解煤热解复杂性的新范式。通过特征重要性分析和可解释AI技术，研究者能够识别出影响产物分布的关键结构参数（如氢含量、挥发分）与过程变量，为揭示煤热解的本征反应网络提供了新视角。当前煤热解研究仍面临数据碎片化、多源异构和跨尺度关联不足等问题，建议通过构建高通量热解表征平台，整合煤的微观结构与宏观热解行为数据，建立多维数据库，为机器学习模型提供更可靠的训练基础。未来，融合机理模型与高性能计算的“白盒化”机器学习方法，将成为揭示煤热解本质、实现产物定向调控的关键路径。这将有力推动煤炭转化从“经验试错”走向“智能调控”，为煤炭的清洁高效利用奠定科学基础。相关研究成果近日发表于Renewable and Sustainable Energy Reviews，系统综述了机器学习在煤热解领域的应用进展，揭示了人工智能在理解复杂煤结构、预测产物分布及优化工艺条件方面的巨大潜力。该研究由谢克昌院士指导，青岛能源所泛能源大数据与战略研究中心田亚峻研究员团队联合多个团队合作完成。（文/图 刘媛媛）原文链接：https://www.sciencedirect.com/science/article/pii/S136403212500961X?dgcid=coauthorXingxing MA, Yajun Tian*, Nana Wang, Jinghao Zhao, Wenying Li* ,Kechang Xie. Machine learning methods for understanding coal pyrolysis. Renewable and Sustainable Energy Reviews. 2026, 226: 116288.", "release_time": "2025-11-17", "source_institution": "青岛生物能源与过程研究所", "url": "https://qibebt.cas.cn/news/kyjz/202510/t20251031_8004689.html"}
{"category": "研究前沿", "title": "我国首次实现熔盐堆钍铀燃料转换", "short_summary": "中科院实验堆实现钍铀核燃料转换，为第四代核能发展提供关键技术支撑。", "detailed_summary": "中科院实验堆实现钍铀核燃料转换，为第四代核能发展提供关键技术支撑。\n(1) 由中科院上海应物所牵头的2MWt液态燃料钍基熔盐实验堆首次实现钍铀核燃料转换，在国际上首次获取相关实验数据。\n(2) 该实验堆是目前国际上唯一运行并实现钍燃料入堆的熔盐堆，证明了利用钍资源的技术可行性，巩固了我国在该领域的引领地位。\n(3) 钍基熔盐堆作为第四代先进核能系统，具有固有安全、无水冷却、常压工作和高温输出等优点。\n(4) 该项目于2011年启动先导专项，2024年完成世界首次熔盐堆加钍，整体国产化率超90%，供应链自主可控。\n(5) 此项突破为实验堆、研究堆、示范堆“三步走”战略奠定基础，为我国能源安全与钍资源规模化利用提供全新解决方案。", "raw_content": "我国首次实现基于熔盐堆的钍铀核燃料转换                                    发布日期：2025/11/01  [ 大 中 小 ] [ 打印 ] [ 关闭 ]    由中国科学院上海应用物理研究所牵头建成的2MWt液态燃料钍基熔盐实验堆（简称“实验堆”）首次实现钍铀核燃料转换，在国际上首次获取钍入熔盐堆运行后实验数据，成为目前国际上唯一运行并实现钍燃料入堆的熔盐堆，证明了熔盐堆核能系统利用钍资源的技术可行性，巩固了我国在国际熔盐堆研究领域的引领地位。第四代先进核能系统熔盐堆是以高温熔盐作为冷却剂的第四代先进核能系统，具有固有安全、无水冷却、常压工作和高温输出等优点，是国际公认最适配钍资源核能利用的堆型。这一技术路线契合我国钍资源丰富的资源禀赋，可与太阳能、风能、高温熔盐储能、高温制氢、煤气油化工等产业深度融合，构建多能互补低碳复合能源系统，为我国能源安全提供全新解决方案。钍基熔盐堆的研发，为我国未来钍资源的规模化开发利用、发展第四代先进核能系统提供核心技术支撑与可行方案。钍基熔盐实验堆堆本体吊装面向国家战略需求2011年，面向国家能源安全与可持续发展的战略需求，中国科学院启动了战略性先导科技专项“未来先进核裂变能——钍基熔盐堆核能系统”，依托中国科学院体系化、建制化优势，成功组建并培育了国际一流的钍基熔盐堆专业研发团队。2017年11月，实验堆选址武威市民勤县。2024年10月完成世界上首次熔盐堆加钍，在国际上率先建成独具特色的熔盐堆和钍铀燃料循环研究平台。近百家国内科研机构、高等院校和产业集团深度参与实验堆研发与工程建设，攻克了设计、关键材料与设备研制、安装与调试及堆安全等方面的技术难题，实现了核心材料、装备与技术从实验室研发到实验堆工程验证的跨越，实验堆整体国产化率>90%，关键核心设备100%国产化，供应链自主可控，钍基熔盐堆相关技术产业链的雏形在我国已经基本形成。钍基熔盐实验堆堆厂房大厅实验堆的建成并首次实现钍铀核燃料转换，为实验堆、研究堆、示范堆“三步走”奠定了坚实的基础，为我国率先实现钍基熔盐堆的工业应用，提供了核心科技支撑。", "release_time": "2025-11-02", "source_institution": "上海应用物理研究所", "url": "http://www.sinap.cas.cn/xwzx/kydt/202511/t20251102_8004865.html"}
{"category": "政策计划", "title": "第六届新型电力系统国际论坛探讨能源低碳转型", "short_summary": "国际论坛聚焦新型电力系统与低碳转型，探讨碳市场机遇与电力行业路径。", "detailed_summary": "国际论坛聚焦新型电力系统与低碳转型，探讨碳市场机遇与电力行业路径。\n（1）第六届新型电力系统国际论坛于10月29日至31日在海南博鳌召开，主题为“共建新型电力系统，加快能源低碳转型”。\n（2）王文军研究员作专题报告，分析全球碳市场整合趋势及中国全国碳市场稳步推进的现状。\n（3）报告指出电力行业应建立电碳核算体系、推进绿电直联，并探索与国际规则衔接的低碳技术路径。\n（4）论坛围绕关键技术、政策机制等议题进行深入交流，为深化产学研合作奠定基础。", "raw_content": "10月29日至31日，由中国南方电网有限责任公司、南方电网数字传媒科技有限公司和博鳌新型电力系统协会共同主办的“第六届新型电力系统国际论坛暨二十一届中国南方电网国际技术论坛”在海南省琼海市博鳌镇召开。论坛以“共建新型电力系统，加快能源低碳转型”为主题，共同探讨新型电力系统构建路径。中国科学院广州能源研究所能源战略研与碳资产研究中心王文军研究员受邀出席分论坛“AI+智慧用电，助力能源低碳转型”。王文军作题为《国内外碳市场发展新趋势与电力行业新机遇探析》的分享报告，提出当前全球碳市场规则体系正加速整合，市场规模持续增长，中国全国碳市场也稳步推进，行业覆盖范围扩大。报告通过阐述国际碳关税机制的演变趋势以及国内碳市场深化对电力行业的多维影响，指出行业应尽快建立完善的电碳核算体系，积极推进绿电直联等典型场景落地，主动探索与国际规则衔接的低碳技术路径，以有效把握碳市场带来的新发展机遇。与会人员围绕电力行业关键技术、政策机制、市场模式与产业生态等热点议题展开深入交流，拓宽了低碳转型研究的视野。广州能源所参会代表积极与各方代表互动，就碳市场机制、绿电交易等议题进行多轮洽谈，为后续深化产学研合作奠定了良好基础。王文军作专题报告", "release_time": "2025-11-01", "source_institution": "广州能源研究所", "url": "http://www.giec.cas.cn/xshd2016/202510/t20251031_8000781.html"}
{"category": "产业应用", "title": "日立高新发布超高分辨率扫描电镜SU9600", "short_summary": "日立SU9600电镜实现亚纳米级观测，助力半导体与新材料研发自动化。", "detailed_summary": "日立SU9600电镜实现亚纳米级观测，助力半导体与新材料研发自动化。\n(1) 日立高新发布超高分辨率扫描电镜SU9600，支持亚纳米级物质精确观测。\n(2) 产品具备0.4nm二次电子分辨率，整合高效自动化功能提升数据采集通量。\n(3) 旨在满足AI驱动下半导体市场对高精度、高通量分析的增长需求。\n(4) 通过自动化软件实现大规模数据自动采集，显著减少人工操作负担。\n(5) 作为数字化资产支持日立Lumada 3.0战略，推动工业创新自动化。", "raw_content": "Ultrahigh-Resolution Scanning Electron Microscope SU9600   Tokyo, October 31, 2025–Hitachi High-Tech Corporation (\"Hitachi High-Tech\"), has launched the Ultrahigh-Resolution Scanning Electron Microscope SU9600, which allows for highly accurate and precise observation of substances down to the sub-nano level*1. The SU9600 retains the world-leading high resolution. It also incorporates efficient and automated functions to provide improved throughput of data acquisition, thereby helping users with highly precise and highly efficient observation. In response to the growing demand for large-scale data analysis driven by the rise of AI, Hitachi High-Tech supports the research and development of next-generation semiconductors and advanced materials. Hitachi Group is advancing Lumada 3.0, providing digital services that combines data generated from digitalized assets with domain knowledge and advanced AI. Through the SU9600 as a digitalized asset that acquires and generates data, Hitachi High-Tech is realizing the digital service \"HMAX for Industry\" that embodies Lumada 3.0, aiming to deliver greater value to our customers. By focusing on \"Integrated Industry Automation\" which aims to expand \"HMAX for Industry\" into growth industries horizontally such as semiconductors, we will contribute to drive innovation for frontline workers.  *1 Sub-nano level: Less than one nanometer (one millionth of a millimeter) in size.  SU9600 Development Background Scanning Electron Microscopes (\"SEM\") are used in a wide range of fields, including semiconductor devices, electronics and advanced materials. They have become indispensable in cases requiring high-precision observation of microstructures, including everything from research and development to process control at production sites. In particular, the recent surge in AI-driven demand within the semiconductor market has accelerated development cycles and created a growing need for high-precision, high-throughput analysis using SEMs. This is driven by the requirement for faster innovation and precise dimensional control of devices with reduced feature sizes. In response, expectations are rising for the use of SEM to provide feedback in research and manufacturing processes through large-scale data analysis. Given these circumstances, Hitachi High-Tech has developed the SU9600. Building on the high precision and stable observation capabilities–characteristic of our existing high-resolution FE-SEMs*2, we have developed automated imaging and data-handling workflows to help streamline observation by increasing throughput. The SU9600 can be used for a wide variety of observations in line with user needs including academic foundational research.  *2 Field Emission SEM  Main Features of SU9600 (1) High-Resolution, High-Precision Observation Powered by Hitachi's Proprietary Technologies The SU9600 includes Hitachi's proprietary CFE Electron Gun (Cold Field Emission Electron Gun) technology. The CFE Electron Gun enables the emission of a highly stable and luminous electron beam, meaning observation can begin immediately after the device is started up. This allows for long, continuous acquisition of sharp, high-contrast images with excellent S/N*3. The SU9600's improved column structure has made the acquisition of even brighter and higher-precision images possible.  *3 S/N (Signal to Noise Ratio): Ratio of signal strength divided by noise intensity. Generally, the higher the S/N, the better.  In addition, Hitachi's proprietary in-lens objective lens technology enhances its world-class resolution, enabling high-precision observation in this flagship model of Hitachi High-Tech's SEM lineup.     Secondary Electron Resolution 0.4nm (accelerating voltage 30 kV)   1.0nm (accelerating voltage 1 kV)   STEM Resolution*4 0.34nm (accelerating voltage 30 kV /  lattice image obtained using scanning transmission electron microscopy)     (2) Custom Capture Modes to Suit User Needs through High Resolution and High Throughput In addition to providing increased versatility in terms of setting the electron beam scanning time, SU9600 also includes a Custom Reduced Scan function*4, enabling users to select only their desired field of view for imaging. The device also features a High-Definition Image Capture function*4 capable of capturing high-resolution images of up to 40k pixels. Combining these functions enables the efficient acquisition of high-precision image data. (3) Automatic Observations Streamline Large-Scale Data Acquisition With recent advances in information processing technology, analysis is performed based on large amounts of data obtained by observing many different areas at various operating conditions. The SU9600 can be equipped with EM Flow Creator*4, an automation software that helps reduce operator workload when acquiring large amounts of data. This enables operators to configure a series of steps by combining condition settings such as magnification, stage position, focus and contrast according to their specific requirements.  As a result, users can run continuous automatic observations, which significantly reduces operator workload and minimizes the manual configuration and adjustment tasks that were previously required.  *4 STEM Resolution, Custom Reduced Scan function, High-Definition Image Capture function, and EM Flow Creator are optional functions.  About SU9600 About Hitachi High-Tech  Hitachi High-Tech provides cutting-edge technologies, products and services to society and customers with its corporate vision of \"Changing the World and Future with the Power of Knowledge\" to contribute to a sustainable global environment, healthy, safe and secure lives, and the sustained development of science and industry. We manufacture and sell clinical analyzers, biotechnology products and radiation therapy systems in the healthcare field, semiconductor manufacturing and inspection equipment in the semiconductor field, as well as analytical systems and electron microscopes used in environmental fields and materials research. We are also engaged in a wide range of business areas globally, providing high added-value solutions in battery, communication infrastructure, railway inspection, digital and other industrial and social infrastructure fields. We provide solutions through a deeper understanding of the issues facing society and our customers to contribute to realizing a sustainable society. The company's consolidated revenues for FY2024 were approx. JPY 756.5 billion.  For further information, visit https://www.hitachi-hightech.com/global/en/ Business Contact  Bito  Global Sales Strategy Dept.,  Business Strategy Planning Div.,  Core Technology & Solutions Business Group,  Hitachi High-Tech Corporation  Information contained in this news release is current as of the date of the press announcement, but may be subject to change without prior notice.", "release_time": "2025-11-18", "source_institution": "日本日立", "url": "http://www.hitachi.com/New/cnews/month/2025/10/251031a.html"}
{"category": "研究前沿", "title": "宾州大学开发新型超导材料预测理论", "short_summary": "研究团队结合熵理论与量子计算，开创预测高温超导材料新方法。", "detailed_summary": "研究团队结合熵理论与量子计算，开创预测高温超导材料新方法。\n(1) 宾州州立大学研究团队获得美国能源部支持，开发出名为\"zentropy理论\"的新计算方法；\n(2) 该理论首次将BCS超导理论与密度泛函理论相结合，能预测材料是否具有超导性及临界温度；\n(3) 成功预测了传统理论无法解释的高温超导材料行为，甚至发现铜银金可能具备超导潜力；\n(4) 新方法有助于发现可在更高温度下工作的超导材料，有望实现室温超导突破；\n(5) 下一步将筛选500万种材料数据库并实验验证，推动能源传输技术革命。", "raw_content": "When electricity moves through wires, some of its energy is lost along the way. That loss, however, might not be inevitable. Researchers at Penn State have developed a new way to identify materials known as superconductors -- substances that can carry electric current with zero resistance, meaning no energy is wasted during transmission.  The Challenge of Cold Superconductors Despite their promise, most superconducting materials cannot yet be used in everyday technology. Their extraordinary ability to conduct electricity only appears at extremely low temperatures, far below what is practical for energy systems or advanced electronics. Supported by the \"Theory of Condensed Matter\" program within the Department of Energy's (DOE) Basic Energy Sciences, the Penn State team created a new computational approach to predict which materials might display superconductivity, potentially paving the way to finding ones that work at much higher, even near-room, temperatures. A New Look at a Longstanding Mystery Predicting superconductivity -- especially in materials that could operate at higher temperatures -- has remained an unsolved challenge. Existing theories have long been considered accurate only for low-temperature superconductors, explained Zi-Kui Liu, a professor of materials science and engineering at Penn State. \"The goal has always been to raise the temperature at which superconductivity persists,\" said Liu, the lead author of a new study published in Superconductor Science and Technology. \"But first, we need to understand exactly how superconductivity happens, and that is where our work comes in.\" How the Classic Theory Explains Superconductors For decades, scientists have relied on the Bardeen-Cooper-Schrieffer (BCS) theory to describe how conventional superconductors function at extremely low temperatures. According to this theory, electrons move without resistance because of interactions with vibrations in the atomic lattice, called phonons. These interactions allow electrons to pair up into what are known as Cooper pairs, which move in sync through the material, avoiding atomic collisions and preventing energy loss as heat.  \"Imagine a superhighway just for electrons,\" Liu explained. \"If there are too many routes, electrons bump into things and lose energy. But if you create a straight tunnel for them, like the Autobahn in Germany, they can travel fast and freely without resistance.\" The Quest for Power Without Resistance This ability to transmit energy without resistance is what makes superconductors so promising, Liu said. If scientists can develop materials that stay superconducting at higher temperatures, electricity could travel farther, faster, and more efficiently, transforming global power systems. To understand this phenomenon, the DOE-backed project uses computational tools known as density functional theory (DFT). DFT helps model how electrons behave in ordinary conductors compared to superconductors. The team hypothesizes that even though DFT does not directly model Cooper pairs, the electron density it predicts should resemble that of paired electrons, allowing researchers to study potential superconducting behavior. Until recently, BCS theory and DFT -- one describing electron pairing, the other rooted in quantum mechanics -- were treated separately. Liu's team found a way to connect these frameworks, creating a new path to predict superconductivity. Introducing Zentropy Theory The breakthrough centers on a concept called zentropy theory. This approach merges principles from statistical mechanics, which studies the collective behavior of many particles, with quantum physics and modern computational modeling. Zentropy theory links a material's electronic structure to how its properties change with temperature, revealing when it transitions from a superconducting to a non-superconducting state. To apply the theory, scientists must understand how a material behaves at absolute zero (zero Kelvin), the coldest temperature possible, where all atomic motion ceases. Liu's team demonstrated that even DFT -- though not originally intended to study superconductors -- can provide key insights into when and how superconductivity occurs.  Predicting the Next Generation of Superconductors According to Liu, the new method allows scientists to predict whether a material could become superconducting. Zentropy theory can then estimate the critical temperature at which the material loses that property. The classic BCS theory successfully explains superconductors that operate only at very low temperatures, but fails for high-temperature varieties, where Cooper pairs break apart more easily. Through DFT modeling, Liu's group discovered that in high-temperature superconductors, the electron \"superhighway\" remains stable because of a unique atomic structure -- similar to a pontoon bridge that flexes with waves, allowing electrons to move smoothly even when thermal vibrations increase. Using this combined approach, the team successfully predicted superconducting behavior in both conventional and high-temperature materials, including one that traditional theory could not explain. They also forecasted potential superconductivity in copper, silver, and gold -- metals not typically considered superconductors -- likely because they would require extremely low temperatures for the effect to appear. These findings could accelerate the discovery of new materials that operate as superconductors at higher, more practical temperatures. Next Steps in the Search for Practical Superconductors The Penn State researchers now plan to expand their work in two ways. First, they will use the zentropy theory to predict how pressure affects the temperature at which superconductors lose their resistance. Second, they will search a massive database of five million materials to identify new candidates that could exhibit superconductivity. The goal is to find the most promising materials and collaborate with experimental researchers to test them. \"We are not just explaining what is already known,\" Liu said. \"We are building a framework to discover something entirely new. If successful, the approach could lead to the discovery of high-temperature superconductors that work in practical settings, potentially even at room temperature if they exist. That kind of breakthrough could have an enormous impact on modern technology and energy systems.\" Shun-Li Shang, research professor of materials science and engineering at Penn State, is a co-investigator on this study. The U.S. Department of Energy supported this research.", "release_time": "2025-10-31", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/10/251030075132.htm"}
{"category": "研究前沿", "title": "纳米颗粒递送IL-12联合疗法高效治愈卵巢癌", "short_summary": "MIT研发新型纳米颗粒，靶向递送IL-12联合免疫疗法高效清除卵巢癌。", "detailed_summary": "MIT研发新型纳米颗粒，靶向递送IL-12联合免疫疗法高效清除卵巢癌。\n(1) MIT研究人员设计新型纳米颗粒，可靶向递送免疫刺激分子IL-12至卵巢肿瘤。\n(2) 该疗法与检查点抑制剂联用，旨在激活被肿瘤抑制的T细胞，对免疫疗法不敏感的卵巢癌有效。\n(3) 小鼠实验表明，超过80%的转移性卵巢癌模型小鼠肿瘤被消除，并建立了长期免疫记忆。\n(4) 新型纳米颗粒实现了IL-12的缓释，避免了全身给药的严重副作用，提高了治疗安全性。\n(5) 该技术有望为卵巢癌等难治性癌症提供新疗法，团队正推动其商业化量产。", "raw_content": "Cancer immunotherapy, which uses drugs that stimulate the body’s immune cells to attack tumors, is a promising approach to treating many types of cancer. However, it doesn’t work well for some tumors, including ovarian cancer.To elicit a better response, MIT researchers have designed new nanoparticles that can deliver an immune-stimulating molecule called IL-12 directly to ovarian tumors. When given along with immunotherapy drugs called checkpoint inhibitors, IL-12 helps the immune system launch an attack on cancer cells.Studying a mouse model of ovarian cancer, the researchers showed that this combination treatment could eliminate metastatic tumors in more than 80 percent of the mice. When the mice were later injected with more cancer cells, to simulate tumor recurrence, their immune cells remembered the tumor proteins and cleared them again.“What’s really exciting is that we’re able to deliver IL-12 directly in the tumor space. And because of the way that this nanomaterial is designed to allow IL-12 to be borne on the surfaces of the cancer cells, we have essentially tricked the cancer into stimulating immune cells to arm themselves against that cancer,” says Paula Hammond, an MIT Institute Professor, MIT’s vice provost for faculty, and a member of the Koch Institute for Integrative Cancer Research.Hammond and Darrell Irvine, a professor of immunology and microbiology at the Scripps Research Institute, are the senior authors of the new study, which appears today in Nature Materials. Ivan Pires PhD ’24, now a postdoc at Brigham and Women’s Hospital, is the lead author of the paper.“Hitting the gas”Most tumors express and secrete proteins that suppress immune cells, creating a microenvironment in which the immune response is weakened. One of the main players that can kill tumor cells are T cells, but they get sidelined or blocked by the cancer cells and are unable to attack the tumor. Checkpoint inhibitors are an FDA-approved treatment designed to take those brakes off the immune system by removing the immune-suppressing proteins so that T cells can mount an attack on tumor cellsFor some cancers, including some types of melanoma and lung cancer, removing the brakes is enough to provoke the immune system into attacking cancer cells. However, ovarian tumors have many ways to suppress the immune system, so checkpoint inhibitors alone usually aren’t enough to launch an immune response.“The problem with ovarian cancer is no one is hitting the gas. So, even if you take off the brakes, nothing happens,” Pires says.IL-12 offers one way to “hit the gas,” by supercharging T cells and other immune cells. However, the large doses of IL-12 required to get a strong response can produce side effects due to generalized inflammation, such as flu-like symptoms (fever, fatigue, GI issues, headaches, and fatigue), as well as more severe complications such as liver toxicity and cytokine release syndrome — which can be so severe they may even lead to death.In a 2022 study, Hammond’s lab developed nanoparticles that could deliver IL-12 directly to tumor cells, which allows larger doses to be given while avoiding the side effects seen when the drug is injected. However, these particles tended to release their payload all at once after reaching the tumor, which hindered their ability to generate a strong T cell response.In the new study, the researchers modified the particles so that IL-12 would be released more gradually, over about a week. They achieved this by using a different chemical linker to attach IL-12 to the particles.“With our current technology, we optimize that chemistry such that there’s a more controlled release rate, and that allowed us to have better efficacy,” Pires says.The particles consist of tiny, fatty droplets known as liposomes, with IL-12 molecules tethered to the surface. For this study, the researchers used a linker called maleimide to attach IL-12 to the liposomes. This linker is more stable than the one they used in the previous generation of particles, which was susceptible to being cleaved by proteins in the body, leading to premature release.To make sure that the particles get to the right place, the researchers coat them with a layer of a polymer called poly-L-glutamate (PLE), which helps them directly target ovarian tumor cells. Once they reach the tumors, the particles bind to the cancer cell surfaces, where they gradually release their payload and activate nearby T cells.Disappearing tumorsIn tests in mice, the researchers showed that the IL-12-carrying particles could effectively recruit and stimulate T cells that attack tumors. The cancer models used for these studies are metastatic, so tumors developed not only in the ovaries but throughout the peritoneal cavity, which includes the surface of the intestines, liver, pancreas, and other organs. Tumors could even be seen in the lung tissues.First, the researchers tested the IL-12 nanoparticles on their own, and they showed that this treatment eliminated tumors in about 30 percent of the mice. They also found a significant increase in the number of T cells that accumulated in the tumor environment.Then, the researchers gave the particles to mice along with checkpoint inhibitors. More than 80 percent of the mice that received this dual treatment were cured. This happened even when the researchers used models of ovarian cancer that are highly resistant to immunotherapy or to the chemotherapy drugs usually used for ovarian cancer.Patients with ovarian cancer are usually treated with surgery followed by chemotherapy. While this may be initially effective, cancer cells that remain after surgery are often able to grow into new tumors. Establishing an immune memory of the tumor proteins could help to prevent that kind of recurrence.In this study, when the researchers injected tumor cells into the cured mice five months after the initial treatment, the immune system was still able to recognize and kill the cells.“We don’t see the cancer cells being able to develop again in that same mouse, meaning that we do have an immune memory developed in those animals,” Pires says.The researchers are now working with MIT’s Deshpande Center for Technological Innovation to spin out a company that they hope could further develop the nanoparticle technology. In a study published earlier this year, Hammond’s lab reported a new manufacturing approach that should enable large-scale production of this type of nanoparticle.The research was funded by the National Institutes of Health, the Marble Center for Nanomedicine, the Deshpande Center for Technological Innovation, the Ragon Institute of MGH, MIT, and Harvard, and the Koch Institute Support (core) Grant from the National Cancer Institute.", "release_time": "2025-10-31", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/new-nanoparticles-stimulate-immune-system-attack-ovarian-tumors-1031"}
{"category": "研究前沿", "title": "MIT研究淬火机制助力航天与核能发展", "short_summary": "MIT博士生探索淬火微观机理，提升太空燃料管理与核反应堆冷却效率。", "detailed_summary": "MIT博士生探索淬火微观机理，提升太空燃料管理与核反应堆冷却效率。\n(1) MIT核科学与工程系博士生Marco Graffiedi研究淬火现象，重点分析莱顿弗罗斯特效应导致的蒸气膜绝缘问题；\n(2) 研究获NASA支持，旨在解决太空低温燃料沸腾损失问题，并应用于核反应堆冷却系统优化；\n(3) 探索电场增强临界热通量技术，提升介电流体沸腾效率，助力数据中心浸没冷却发展；\n(4) Graffiedi具机械工程背景，曾获曼森·本尼迪克特奖，研究成果发表于《应用热力工程》期刊。", "raw_content": "Quenching, a powerful heat transfer mechanism, is remarkably effective at transporting heat away. But in extreme environments, like nuclear power plants and aboard spaceships, a lot rides on the efficiency and speed of the process.It’s why Marco Graffiedi, a fifth-year doctoral student at MIT’s Department of Nuclear Science and Engineering (NSE), is researching the phenomenon to help develop the next generation of spaceships and nuclear plants.Growing up in small-town ItalyGraffiedi’s parents encouraged a sense of exploration, giving him responsibilities for family projects even at a young age. When they restored a countryside cabin in a small town near Palazzolo, in the hills between Florence and Bologna, the then-14-year-old Marco got a project of his own. He had to ensure the animals on the property had enough accessible water without overfilling the storage tank. Marco designed and built a passive hydraulic system that effectively solved the problem and is still functional today.His proclivity for science continued in high school in Lugo, where Graffiedi enjoyed recreating classical physics phenomena, through experiments. Incidentally, the high school is named after Gregorio Ricci-Curbastro, a mathematician who laid the foundation for the theory of relativity — history that is not lost on Graffiedi. After high school, Graffiedi attended the International Physics Olympiad in Bangkok, a formative event that cemented his love for physics.A gradual shift toward engineeringA passion for physics and basic sciences notwithstanding, Graffiedi wondered if he’d be a better fit for engineering, where he could use the study of physics, chemistry, and math as tools to build something.Following that path, he completed a bachelor’s and master’s in mechanical engineering — because an undergraduate degree in Italy takes only three years, pretty much everyone does a master’s, Graffiedi laughs — at the Università di Pisa and the Scuola Superiore Sant’Anna (School of Engineering). The Sant’Anna is a highly selective institution that most students attend to complement their university studies.Graffiedi’s university studies gradually moved him toward the field of environmental engineering. He researched concentrated solar power in order to reduce the cost of solar power by studying the associated thermal cycle and trying to improve solar power collection. While the project was not very successful, it reinforced Graffiedi’s impression of the necessity of alternative energies. Still firmly planted in energy studies, Graffiedi worked on fracture mechanics for his master’s thesis, in collaboration with (what was then) GE Oil and Gas, researching how to improve the effectiveness of centrifugal compressors. And a summer internship at Fermilab had Graffiedi working on the thermal characterization of superconductive coatings.With his studies behind him, Graffiedi was still unsure about this professional path. Through the Edison Program from GE Oil and Gas, where he worked shortly after graduation, Graffiedi got to test drive many fields — from mechanical and thermal engineering to exploring gas turbines and combustion. He eventually became a test engineer, coordinating a team of engineers to test a new upgrade to the company’s gas turbines. “I set up the test bench, understanding how to instrument the machine, collect data, and run the test,” Graffiedi remembers, “there was a lot you need to think about, from a little turbine blade with sensors on it to the location of safety exits on the test bench.”The move toward nuclear engineeringAs fun as the test engineering job was, Graffiedi started to crave more technical knowledge and wanted to pivot to science. As part of his exploration, he came across nuclear energy and, understanding it to be the future, decided to lean on his engineering background to apply to MIT NSE.He found a fit in Professor Matteo Bucci’s group and decided to explore boiling and quenching. The move from science to engineering, and back to science, was now complete.NASA, the primary sponsor of the research, is interested in preventing boiling of cryogenic fuels, because boiling leads to loss of fuel and the resulting vapor will need to be vented to avoid overpressurizing a fuel tank.Graffiedi’s primary focus is on quenching, which will play an important role in refueling in space — and in the cooling of nuclear cores. When a cryogen is used to cool down a surface, it undergoes what is known as the Leidenfrost effect, which means it first forms a thin vapor film that acts as an insulator and prevents further cooling. To facilitate rapid cooling, it’s important to accelerate the collapse of the vapor film. Graffiedi is exploring the mechanics of the quenching process on a microscopic level, studies that are important for land and space applications.Boiling can be used for yet another modern application: to improve the efficiency of cooling systems for data centers. The growth of data centers and electric transportation systems needs effective heat transfer mechanisms to avoid overheating. Immersion cooling using dielectric fluids — fluids that do not conduct electricity — is one way to do so. These fluids remove heat from a surface by leaning on the principle of boiling. For effective boiling, the fluid must overcome the Leidenfrost effect and break the vapor film that forms. The fluid must also have high critical heat flux (CHF), which is the maximum value of the heat flux at which boiling can effectively be used to transfer heat from a heated surface to a liquid. Because dielectric fluids have lower CHF than water, Graffiedi is exploring solutions to enhance these limits. In particular, he is investigating how high electric fields can be used to enhance CHF and even to use boiling as a way to cool electronic components in the absence of gravity. He published this research in Applied Thermal Engineering in June.Beyond boilingGraffiedi’s love of science and engineering shows in his commitment to teaching as well. He has been a teaching assistant for four classes at NSE, winning awards for his contributions. His many additional achievements include winning the Manson Benedict Award presented to an NSE graduate student for excellence in academic performance and professional promise in nuclear science and engineering, and a service award for his role as past president of the MIT Division of the American Nuclear Society.Boston has a fervent Italian community, Graffiedi says, and he enjoys being a part of it. Fittingly, the MIT Italian club is called MITaly. When he’s not at work or otherwise engaged, Graffiedi loves Latin dancing, something he makes time for at least a couple of times a week. While he has his favorite Italian restaurants in the city, Graffiedi is grateful for another set of skills his parents gave him when was just 11: making perfect pizza and pasta.", "release_time": "2025-10-31", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/using-classic-physical-phenomena-solve-new-problems-marco-graffiedi-1031"}
{"category": "研究前沿", "title": "澳学者作超分子自组装纳米材料学术报告", "short_summary": "Ádám Mechler教授介绍超分子自组装多肽纳米材料设计与应用研究。", "detailed_summary": "Ádám Mechler教授介绍超分子自组装多肽纳米材料设计与应用研究。\n（1）澳大利亚拉筹伯大学Ádám Mechler教授应邀作《超分子自组装层级纳米材料设计》学术报告；\n（2）报告重点展示基于3-取代β-氨基酸构建的低聚酰胺类多肽结构及其自组装调控；\n（3）阐释通过调控溶剂环境与氨基酸序列实现纤维束集与层级结构构建的路径；\n（4）介绍引入金属配位基团形成低维框架材料的研究突破；\n（5）交流活动深化了广州能源所与拉筹伯大学在生物大分子组装与资源化利用领域的合作。", "raw_content": "10月28日，澳大利亚拉筹伯大学化学与生物化学系Ádám Mechler教授应广东省可再生能源重点实验室邀请作专题学术报告，生物质高值化研究中心和新兴固废高值循环研究中心相关科研人员听取了报告。在题为《超分子自组装层级纳米材料设计》的学术报告中，Ádám Mechler系统介绍了其团队在超分子自组装领域二十多年的研究积累，重点展示了基于3-取代β-氨基酸构建的低聚酰胺类多肽结构，并从结构可塑性与序列多样性角度出发阐释了通过调控溶剂环境与氨基酸序列实现纤维束集与层级结构构建的路径，展示了引入金属配位基团后形成低维框架材料的研究突破。报告结束后，Ádám Mechler教授与参会人员围绕层级多肽纳米材料的制备方法、生物膜物化特性检测技术等议题展开了深入交流。Ádám Mechler教授此次访问获中国科学院未来伙伴网络专项支持，交流活动深化了广州能源所与拉筹伯大学在生物大分子组装与资源化利用领域的合作交流。", "release_time": "2025-10-31", "source_institution": "广州能源研究所", "url": "http://www.giec.cas.cn/xshd2016/202510/t20251031_8000197.html"}
{"category": "研究前沿", "title": "科学家首次实现锗材料超导突破", "short_summary": "研究团队通过分子束外延技术成功诱导锗产生超导性，为量子器件开发铺平道路。", "detailed_summary": "研究团队通过分子束外延技术成功诱导锗产生超导性，为量子器件开发铺平道路。\n（1）国际团队在《自然·纳米技术》发表研究，首次实现锗材料的超导特性；\n（2）采用分子束外延技术将镓原子精确掺杂至锗晶格，在3.5开尔文温度下实现零电阻导电；\n（3）该突破解决了半导体与超导体界面清洁度的关键难题；\n（4）成果有望推动量子电路、低功耗电子设备等下一代技术发展；\n（5）研究由纽约大学、昆士兰大学等多机构合作完成，获美国空军科研办公室支持。", "raw_content": "For decades, researchers have tried to create semiconductor materials that can also act as superconductors -- materials capable of carrying electric current without resistance. Semiconductors, which form the foundation of modern computer chips and solar cells, could operate far faster and more efficiently if they also possessed superconducting abilities. Yet turning materials like silicon and germanium into superconductors has remained a major challenge, largely because it requires maintaining a delicate atomic arrangement that allows electrons to move freely.  A global team of scientists has now achieved what once seemed out of reach. In a new study published in Nature Nanotechnology, they report creating a form of germanium that exhibits superconductivity. This means it can conduct electricity with zero resistance, allowing electric currents to circulate endlessly without losing energy. Such behavior could dramatically boost the performance of electronic and quantum devices while reducing power consumption. \"Establishing superconductivity in germanium, which is already widely used in computer chips and fiber optics, can potentially revolutionize scores of consumer products and industrial technologies,\" explains Javad Shabani, a physicist at New York University and director of its Center of Quantum Information Physics and Quantum Institute. Peter Jacobson, a physicist at the University of Queensland, adds that the findings could accelerate progress in building practical quantum systems. \"These materials could underpin future quantum circuits, sensors, and low-power cryogenic electronics, all of which need clean interfaces between superconducting and semiconducting regions,\" he says. \"Germanium is already a workhorse material for advanced semiconductor technologies, so by showing it can also become superconducting under controlled growth conditions there's now potential for scalable, foundry-ready quantum devices.\" How Semiconductors Become Superconductors Germanium and silicon, both group IV elements with diamond-like crystal structures, occupy a unique position between metals and insulators. Their versatility and durability make them central to modern manufacturing. To induce superconductivity in such elements, scientists must carefully alter their atomic structure to increase the number of electrons available for conduction. These electrons then pair up and move through the material without resistance -- a process that is notoriously difficult to fine-tune on the atomic scale. In the new study, researchers developed germanium films heavily infused with gallium, a softer element commonly used in electronics. This technique, known as \"doping,\" has long been used to modify a semiconductor's electrical behavior. Normally, high levels of gallium destabilize the crystal, preventing superconductivity.  The team overcame this limitation using advanced X-ray methods to guide a refined process that encourages gallium atoms to take the place of germanium atoms in the crystal lattice. Although this substitution slightly distorts the crystal, it preserves its overall stability and allows it to carry current with zero resistance at 3.5 Kelvin (about -453 degrees Fahrenheit), confirming that it had become superconducting. Precision Tools Unlock Atomic Control \"Rather than ion implantation, molecular beam epitaxy was used to precisely incorporate gallium atoms into the germanium's crystal lattice,\" says Julian Steele, a physicist at the University of Queensland and a co-author of the study. \"Using epitaxy -- growing thin crystal layers -- means we can finally achieve the structural precision needed to understand and control how superconductivity emerges in these materials.\" As Shabani notes, \"This works because group IV elements don't naturally superconduct under normal conditions, but modifying their crystal structure enables the formation of electron pairings that allow superconductivity.\" The study also involved researchers from ETH Zurich and the Ohio State University and received partial support from the US Air Force's Office of Scientific Research (FA9550-21-1-0338). This international effort marks a key step toward integrating superconducting behavior into the very materials that drive today's electronics, potentially reshaping the landscape of computing and quantum technology.", "release_time": "2025-10-31", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251030075105.htm"}
{"category": "研究前沿", "title": "双黑洞合并验证爱因斯坦理论，揭示宇宙极端物理", "short_summary": "LIGO探测到两次特殊黑洞合并，以极高精度验证广义相对论并探索新粒子。", "detailed_summary": "LIGO探测到两次特殊黑洞合并，以极高精度验证广义相对论并探索新粒子。\n（1）2024年10-11月LIGO-Virgo-KAGRA合作组探测到两次特殊双黑洞合并事件GW241011和GW241110；  \n（2）GW241011包含一个快速旋转的黑洞，GW241110首次观测到黑洞自转方向与轨道方向相反；  \n（3）事件数据以创纪录精度验证了爱因斯坦广义相对论和克尔黑洞模型预测；  \n（4）黑洞质量差异和自转特征表明它们可能通过层级合并机制形成于稠密星团；  \n（5）研究成果为探索超轻玻色子等新粒子提供了新途径，推动引力波天文学发展。", "raw_content": "Two colossal black hole collisions, detected just a month apart in late 2024, are reshaping how scientists interpret the most extreme cosmic events in the universe. These twin mergers not only provide fresh insight into how black holes form and evolve but also confirm, with unmatched precision, the predictions of Albert Einstein's general theory of relativity. The findings may also help researchers uncover new, undiscovered particles that could extract energy from black holes.  In a study published October 28 in The Astrophysical Journal Letters, the international LIGO-Virgo-KAGRA Collaboration announced the detection of two remarkable gravitational wave signals from black holes with unusual spin patterns recorded in October and November of last year. Ripples in Space and Time Reveal Cosmic Collisions Gravitational waves are tiny ripples in space-time that occur when massive celestial objects crash or merge. The strongest signals come from the collision of black holes. The first event, GW241011 (October 11, 2024), happened about 700 million light years from Earth when two black holes -- about 20 and 6 times the mass of our sun -- merged. The larger one was identified as one of the fastest-spinning black holes ever observed. Roughly a month later, a second event, GW241110 (November 10, 2024), was detected some 2.4 billion light years away. This merger involved black holes weighing roughly 17 and 8 solar masses. Unlike most black holes that spin in the same direction as their orbit, the main black hole in GW241110 spun in the opposite direction, marking the first observation of such a configuration. \"Each new detection provides important insights about the universe, reminding us that each observed merger is both an astrophysical discovery but also an invaluable laboratory for probing the fundamental laws of physics,\" said co-author Carl-Johan Haster, assistant professor of astrophysics at the University of Nevada, Las Vegas (UNLV). \"Binaries like these had been predicted given earlier observations, but this is the first direct evidence for their existence.\" Revealing the Secret Lives of Merging Black Holes Einstein first predicted the existence of gravitational waves in 1916 as part of his general theory of relativity. Their existence was indirectly confirmed in the 1970s, but scientists did not directly observe them until 2015 when the LIGO observatory detected waves created by a black hole merger.  Today, the LIGO-Virgo-KAGRA network operates as a global system of advanced detectors. The team is currently in its fourth observation campaign, known as O4, which began in May 2023 and will continue through mid-November 2025. To date, about 300 black hole mergers have been detected, including candidates found during this ongoing run. The recent detection of GW241011 and GW241110 demonstrates how far gravitational-wave astronomy has advanced in uncovering the inner workings of black hole systems. Both events suggest that some of these black holes could be \"second-generation,\" formed from the remnants of earlier mergers. \"GW241011 and GW241110 are among the most novel events among the several hundred that the LIGO-Virgo-KAGRA network has observed,\" said Stephen Fairhurst, professor at Cardiff University and spokesperson for the LIGO Scientific Collaboration. \"With both events having one black hole that is both significantly more massive than the other and rapidly spinning, they provide tantalizing evidence that these black holes were formed from previous black hole mergers.\" Researchers noted several intriguing patterns, including large differences in mass between the paired black holes -- the larger being nearly twice as massive as its companion -- and unusual spin directions. These traits suggest that the black holes formed through a process called hierarchical merger, in which black holes in densely populated regions such as star clusters collide multiple times over their lifetimes. \"These two binary black hole mergers offer us some of the most exciting insights yet about the earlier lives of black holes,\" said Thomas Callister, co-author and assistant professor at Williams College. \"They teach us that some black holes exist not just as isolated partners but likely as members of a dense and dynamic crowd. Moving forward, the hope is that these events and other observations will teach us more and more about the astrophysical environments that host these crowds.\" Testing Einstein's Theory Under Extreme Conditions The extraordinary precision of GW241011's detection gave researchers an opportunity to test Einstein's general relativity in one of the most extreme environments ever measured. Because this event was captured so clearly, scientists could compare the results with predictions from Einstein's equations and Roy Kerr's solution describing rotating black holes.  The rapid spin of GW241011 slightly distorted its shape, leaving a unique fingerprint in the gravitational waves. Analysis of the data showed an exceptional match to Kerr's model, confirming Einstein's predictions with record accuracy. The significant difference in the masses of the colliding black holes also produced a \"higher harmonic,\" a kind of overtone similar to those heard in musical instruments. This rare feature, seen clearly for only the third time, provides another successful test of Einstein's theory. \"The strength of GW241011, combined with the extreme properties of its black hole components provide unprecedented means for testing our understanding of black holes themselves,\" says Haster. \"We now know that black holes are shaped like Einstein and Kerr predicted, and general relativity can add two more checkmarks in its list of many successes. This discovery also means that we're more sensitive than ever to any new physics that might lie beyond Einstein's theory.\" Searching for Clues to New Particles Rapidly rotating black holes like those observed in this study now have yet another application -- in particle physics. Scientists can use them to test whether certain hypothesized light-weight elementary particles exist and how massive they are. These particles, called ultralight bosons, are predicted by some theories that go beyond the Standard Model of particle physics, which describes and classifies all known elementary particles. If ultralight bosons exist, they can extract rotational energy from black holes. How much energy is extracted and how much the rotation of the black holes slows down over time depends on the mass of these particles, which is still unknown. The observation that the massive black hole in the binary system that emitted GW241011 continues to rotate rapidly even millions or billions of years after it formed rules out a wide range of ultralight boson masses. \"Planned upgrades to the LIGO, Virgo, and KAGRA detectors will enable further observations of similar systems, enabling us to better understand both the fundamental physics governing these black hole binaries and the astrophysical mechanisms that lead to their formation,\" said Fairhurst. Joe Giaime, site head for the LIGO Livingston Observatory, noted that LIGO scientists and engineers have made improvements to the detectors in recent years, which has resulted in precision measurements of merger waveforms that allow for the kind of subtle observations that were needed for GW241011 and GW241110. \"Better sensitivity not only allows LIGO to detect many more signals, but also permits deeper understanding of the ones we detect,\" he said.", "release_time": "2025-10-30", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/10/251029100139.htm"}
{"category": "研究前沿", "title": "MIT研究揭示地理因素对美国阿片类药物危机的主导影响", "short_summary": "MIT研究通过移民数据分析，揭示地理因素比个人特质更主导阿片危机蔓延。", "detailed_summary": "MIT研究通过移民数据分析，揭示地理因素比个人特质更主导阿片危机蔓延。\n(1) MIT与斯坦福经济学家合作研究，通过分析美国残疾人保险计划中约300万移民的处方阿片类药物使用数据（2006-2019年）。\n(2) 研究发现，地理环境等地方性因素对导致风险性阿片类药物使用的影响略大于个人特质。\n(3) 研究识别出“成瘾渠道”和“可获得性渠道”，前者（新使用者陷入成瘾）的影响是后者的2.5倍。\n(4) 限制“药厂”诊所的州级法律能将风险性使用降低5%，若在90年代危机初期实施则可降低30%。\n(5) 结论强调成瘾的持续性是该长期危机的核心驱动力，预防成瘾发生比遏制已成瘾者的获取更为关键。", "raw_content": "The U.S. opioid crisis has varied in severity across the country, leading to extended debate about how and why it has spread.Now, a study co-authored by MIT economists sheds new light on these dynamics, examining the role that geography has played in the crisis. The results show how state-level policies inadvertently contributed to the rise of opioid addiction, and how addiction itself is a central driver of the long-term problem.The research analyzes data about people who moved within the U.S., as a way of addressing a leading question about the crisis: How much of the problem is attributable to local factors, and to what extent do people have individual characteristics making them prone to opioid problems?“We find a very large role for place-based factors, but that doesn’t mean there aren’t person-based factors as well,” says MIT economist Amy Finkelstein, co-author of a new paper detailing the study’s findings. “As is usual, it’s rare to find an extreme answer, either one or the other.”In scrutinizing the role of geography, the scholars developed new insights about the spread of the crisis in relation to the dynamics of addiction. The study concludes that laws restricting pain clinics, or “pill mills,” where opioids were often prescribed, reduced risky opioid use by 5 percent over the 2006-2019 study period. Due to the path of addiction, enacting those laws near the onset of the crisis, in the 1990s, could have reduced risky use by 30 percent over that same time.“What we do find is that pill mill laws really matter,” says MIT PhD student Dean Li, a co-author of the paper. “The striking thing is that they mattered a lot, and a lot of the effect was through transitions into opioid addiction.”The paper, “What Drives Risky Prescription Opioid Use: Evidence from Migration,” appears in the Quarterly Journal of Economics. The authors are Finkelstein, who is the John and Jennie S. MacDonald Professor of Economics; Matthew Gentzkow, a professor of economics at Stanford University; and Li, a PhD student in MIT’s Department of Economics.The opioid crisis, as the scholars note in the paper, is one of the biggest U.S. health problems in recent memory. As of 2017, there were more than twice as many U.S. deaths from opioids as from homicide. There were also at least 10 times as many opioid deaths compared to the number of deaths from cocaine during the 1980s-era crack epidemic in the U.S.Many accounts and analyses of the crisis have converged on the increase in medically prescribed opioids starting in the 1990s as a crucial part of the problem; this was in turn a function of aggressive marketing by pharmaceutical companies, among other things. But explanations of the crisis beyond that have tended to fracture. Some analyses emphasize the personal characteristics of those who fall into opioid use, such as a past history of substance use, mental health conditions, age, and more. Other analyses focus on place-based factors, including the propensity of area medical providers to prescribe opioids.To conduct the study, the scholars examined data on prescription opioid use from adults in the Social Security Disability Insurance program from 2006 to 2019, covering about 3 million cases in all. They defined “risky” use as an average daily morphine-equivalent dose of more than 120 milligrams, which has been shown to increase drug dependence.By studying people who move, the scholars were developing a kind of natural experiment — Finkelstein has also used this same method to examine questions about disparities in health care costs and longevity across the U.S. In this case, in focusing on the opioid consumption patterns of the same people as they lived in different places, the scholars can disentangle the extent to which place-based and personal factors drive usage.Overall, the study found a somewhat greater role for place-based factors than for personal characteristics in accounting for the drivers of risky opioid use. To see the magnitude of place-based effects, consider someone moving to a state with a 3.5 percentage point higher rate of risky use — akin to moving from the state with the 10th lowest rate of risky use to the state with the 10th highest rate. On average, that person’s probability of risky opioid use would increase by a full percentage point in the first year, then by 0.3 percentage points in each subsequent year.Some of the study’s key findings involve the precise mechanisms at work beneath these top-line numbers.In the research, the scholars examine what they call the “addiction channel,” in which opioid users fall into addiction, and the “availability channel,” in which the already-addicted find ways to sustain their use. Over the 2006-2019 period, they find, people falling into addiction through new prescriptions had an impact on overall opioid uptake that was 2.5 times as large as that of existing users getting continued access to prescribed opiods.When people who are not already risky users of opioids move to places with higher rates of risky opioid use, Finkelstein observes, “One thing you can see very clearly in the data is that in the addiction channel, there’s no immediate change in behavior, but gradually as they’re in this new place you see an increase in risky opioid use.”She adds: “This is consistent with a model where people move to a new place, have a back problem or car accident and go to a hospital, and if the doctor is more likely to prescribe opioids, there’s more of a risk they’re going to become addicted.”By contrast, Finkelstein says, “If we look at people who are already risky users of opioids and they move to a new place with higher rates of risky opioid use, you see there’s an immediate increase in their opioid use, which suggests it’s just more available. And then you also see the gradual increase indicating more addiction.”By looking at state-level policies, the researchers found this trend to be particularly pronounced in over a dozen states that lagged in enacting restrictions on pain clinics, or “pill mills,” where providers had more latitude to prescribe opioids.In this way the research does not just evaluate the impact of place versus personal characteristics; it quantifies the problem of addiction as an additional dimension of the issue. While many analyses have sought to explain why people first use opioids, the current study reinforces the importance of preventing the onset of addiction, especially because addicted users may later seek out nonprescription opioids, exacerbating the problem even further.“The persistence of addiction is a huge problem,” Li says. “Even after the role of prescription opioids has subsided, the opioid crisis persists. And we think this is related to the persistence of addiction. Once you have this set in, it’s so much harder to change, compared to stopping the onset of addiction in the first place.”Research support was provided by the National Institute on Aging, the Social Security Administration, and the Stanford Institute for Economic Policy Research.", "release_time": "2025-10-30", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/study-reveals-geography-role-opioid-crisis-1030"}
{"category": "研究前沿", "title": "MIT人类洞察协作计划推动跨学科研究创新", "short_summary": "MITHIC通过资助人文与科技交叉项目，加速解决全球性挑战。", "detailed_summary": "MITHIC通过资助人文与科技交叉项目，加速解决全球性挑战。\n（1）MITHIC是MIT校长倡议，旨在提升人文社科研究并促进跨学科合作，自2024年启动已资助31个项目；（2）通过SHASS+连接基金等支持工程与人文领域合作，如利用AI进行低收入地区健康诊断；（3）项目涵盖气候研究、古代乐器重建等前沿课题，提升MIT文化并连接全球议题；（4）未来将扩大资助轮次，深化跨学科影响。", "raw_content": "The MIT Human Insight Collaborative (MITHIC) is a presidential initiative with a mission of elevating human-centered research and teaching and connecting scholars in the humanities, arts, and social sciences with colleagues across the Institute.Since its launch in 2024, MITHIC has funded 31 projects led by teaching and research staff representing 22 different units across MIT. The collaborative is holding its annual event on Nov. 17. In this Q&A, Keeril Makan, associate dean in the MIT School of Humanities, Arts, and Social Sciences, and Maria Yang, interim dean of the MIT School of Engineering, discuss the value of MITHIC and the ways it’s accelerating new research and collaborations across the Institute. Makan is the Michael (1949) Sonja Koerner Music Composition Professor and faculty lead for MITHIC. Yang is the William E. Leonhard (1940) Professor in the Department of Mechanical Engineering and co-chair of MITHIC’s SHASS+ Connectivity Fund.Q: You each come from different areas of MIT. Looking at MITHIC from your respective roles, why is this initiative so important for the Institute?Makan: The world is counting on MIT to develop solutions to some of the world’s greatest challenges, such as artificial intelligence, poverty, and health care. These are all issues that arise from human activity, a thread that runs through much of the research we’re focused on in SHASS. Through MITHIC, we’re embedding human-centered thinking and connecting the Institute’s top scholars in the work needed to find innovative ways of addressing these problems.Yang: MITHIC is very important to MIT, and I think of this from the point of view as an engineer, which is my background. Engineers often think about the technology first, which is absolutely important. But for that technology to have real impact, you have to think about the human insights that make that technology relevant and can be deployed in the world. So really having a deep understanding of that is core to MITHIC and MIT’s engineering enterprise.Q: How does MITHIC fit into MIT’s broader mission? Makan: MITHIC highlights how the work we do in the School of Humanities, Arts, and Social Sciences is aligned with MIT’s mission, which is to address the world’s great problems. But MITHIC has also connected all of MIT in this endeavor. We have faculty from all five schools and the MIT Schwarzman College of Computing involved in evaluating MITHIC project proposals. Each of them represent a different point of view and are engaging with these projects that originate in SHASS, but actually cut across many different fields. Seeing their perspectives on these projects has been inspiring.Yang: I think of MIT’s main mission as using technology and many other things to make impact in the world, especially social impact. The kind of interdisciplinary work that MITHIC catalyzes really enables all of that work to happen in a new and profound way. The SHASS+ Connectivity Fund, which connects SHASS faculty and researchers with colleagues outside of SHASS, has resulted in collaborations that were not possible before. One example is a project being led by professors Mark Rau, who has a shared appointment between Music and Electrical Engineering and Computer Science, and Antoine Allanore in Materials Science and Engineering. The two of them are looking at how they can take ancient unplayable instruments and recreate them using new technologies for scanning and fabrication. They’re also working with the Museum of Fine Arts, so it’s a whole new type of collaboration that exemplifies MITHIC. Q: What has been the community response to MITHIC in its first year?Makan: It’s been very strong. We found a lot of pent-up demand, both from faculty in SHASS and faculty in the sciences and engineering. Either there were preexisting collaborations that they could take to the next level through MITHIC, or there was the opportunity to meet someone new and talk to someone about a problem and how they could collaborate. MITHIC also hosted a series of Meeting of the Minds events, which are a chance to have faculty and members of the community get to know one another on a certain topic. This community building has been exciting, and led to an overwhelming number of applications last year. There has also been significant student involvement, with several projects bringing on UROPs [Undergraduate Research Opportunities Program projects] and PhD students to help with their research. MITHIC gives a real morale boost and a lot of hope that there is a focus upon building collaborations at MIT and on not forgetting that the world needs humanists, artists, and social scientists.Yang: One faculty member told me the SHASS+ Connectivity Fund has given them hope for the kind of research that we do because of the cross collaboration. There’s a lot of excitement and enthusiasm for this type of work.Q: The SHASS+ Connectivity Fund is designed to support interdisciplinary collaborations at MIT. What’s an example of a SHASS+ project that’s worked particularly well? Makan: One exciting collaboration is between professors Jörn Dunkel in Mathematics and In Song Kim in Political science. In Song is someone who has done a lot of work on studying lobbying and its effect upon the legislative process. He met Jörn, I believe, at one of MIT’s daycare centers, so it’s a relationship that started in a very informal fashion. But they found they actually had ways of looking at math and quantitative analysis that could complement one another. Their work is creating a new subfield and taking the research in a direction that would not be possible without this funding.Yang: One of the SHASS+ projects that I think is really interesting is between professors Marzyeh Ghassemi in Electrical Engineering and Computer Science and Esther Duflo in Economics. The two of them are looking at how they can use AI to help health diagnostics in low-resource global settings, where there isn’t a lot of equipment or technology to do basic health diagnostics. They can use handheld, low-cost equipment to do things like predict if someone is going to have a heart attack. And they are not only developing the diagnostic tool, but evaluating the fairness of the algorithm. The project is an excellent example of using a MITHIC grant to make impact in the world.Q: What has been MITHIC’s impact in terms of elevating research and teaching within SHASS?Makan: In addition to the SHASS+ Connectivity Fund, there are two other possibilities to help support both SHASS research as well as educational initiatives: the Humanities Cultivation Fund and the SHASS Education Innovation Fund. And both of these are providing funding in excess of what we normally see within SHASS. It both recognizes the importance of the work of our faculty and it also gives them the means to actually take ideas to a much further place. One of the projects that MITHIC is helping to support is the Compass Initiative. Compass was started by Lily Tsai, one of our professors in Political Science, along with other faculty in SHASS to create essentially an introductory class to the different methodologies within SHASS. So we have philosophers, music historians, etc., all teaching together, all addressing how we interact with one another, what it means to be a good citizen, what it means to be socially aware and civically engaged. This is a class that is very timely for MIT and for the world. And we were able to give it robust funding so they can take this and develop it even further. MITHIC has also been able to take local initiatives in SHASS and elevate them. There has been a group of anthropologists, historians, and urban planners that have been working together on a project called the Living Climate Futures Lab. This is a group interested in working with frontline communities around climate change and sustainability. They work to build trust with local communities and start to work with them on thinking about how climate change affects them and what solutions might look like. This is a powerful and uniquely SHASS approach to climate change, and through MITHIC, we’re able to take this seed effort, robustly fund it, and help connect it to the larger climate project at MIT. Q: What excites you most about the future of MITHIC at MIT?Yang: We have a lot of MIT efforts that are trying to break people out of their disciplinary silos, and MITHIC really is a big push on that front. It’s a presidential initiative, so it’s high on the priority list of what people are thinking about. We’ve already done our first round, and the second round is going to be even more exciting, so it’s only going to gain in force. In SHASS+, we’re actually having two calls for proposals this academic year instead of just one. I feel like there’s still so much possibility to bring together interdisciplinary research across the Institute.Makan: I’m excited about how MITHIC is changing the culture of MIT. MIT thinks of itself in terms of engineering, science, and technology, and this is an opportunity to think about those STEM fields within the context of human activity and humanistic thinking. Having this shift at MIT in how we approach solving problems bodes well for the world, and it places SHASS as this connective tissue at the Institute. It connects the schools and it can also connect the other initiatives, such as manufacturing and health and life sciences. There’s an opportunity for MITHIC to seed all these other initiatives with the work that goes on in SHASS.", "release_time": "2025-10-31", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/qa-how-mithic-fostering-culture-collaboration-at-mit-1030"}
{"category": "研究前沿", "title": "研究揭示产乙醇菌株Z. mobilis应对生物质水解液应激机制", "short_summary": "科学家系统解析Z. mobilis菌株耐受生物质水解液毒性的分子机制与代谢调控网络。", "detailed_summary": "科学家系统解析Z. mobilis菌株耐受生物质水解液毒性的分子机制与代谢调控网络。\n(1) Zymomonas mobilis是一种高效生物能源微生物，能耐受工业发酵压力并天然产乙醇，但无法直接消化原始生物质；\n(2) 研究采用系统生物学方法，分析该菌在不同浓度AFEX预处理柳枝稷水解液中的生理响应；\n(3) 水解液引发复杂应激反应，包括细胞膜脂质组成改变、热休克蛋白和外排转运蛋白上调、运动蛋白下调；\n(4) 意外发现中央碳代谢酶和乙醇发酵途径显著上调，可能与水解液中额外营养可用性有关；\n(5) 该发现为工程化改造耐受性更强、生物质转化效率更高的Z. mobilis菌株提供理论依据。", "raw_content": "The Science     Converting biomass from non-food plants into biofuels and other products requires microbes that are both efficient and able to tolerate the stress of industrial fermentation.  Zymomonas mobilis is a promising bioenergy microbe that can tolerate a broad range of conditions, naturally produces a lot of ethanol, and can be easily modified to produce other types of alcohol and products, such as isobutanol and isoprenoids. But Z. mobilis can’t digest raw biomass, so chemical treatments are required to release sugars that it can ferment. Those treatments often introduce toxic byproducts that slow the microbe’s growth and fermentation rate.  Despite growing interest in Z. mobilis for bioenergy production, scientists have limited understanding of how this treated biomass solution (known as hydrolysate) affects it. So scientists with the Great Lakes Bioenergy Research Center used a systems-level approach to study the microbe’s response to hydrolysate produced from switchgrass treated with a process called ammonia fiber expansion (AFEX). The findings revealed that the hydrolysate triggers a complex stress response, causing changes in the membrane that controls what enters and exits the cell as well as how the microbe digests carbon in the plant sugars.  The Impact Non-food plant fibers — such as trees, grasses, and crop residues — represent a renewable, home-grown source of fuels and chemicals grown on land unsuitable for growing food crops. These insights can inform efforts to engineer new strains of Z. mobilis that are more resistant to toxic byproducts and are better at converting biomass into fuel and products. Summary Researchers grew Z. mobilis in varying concentrations of AFEX-treated switchgrass hydrolysate (0%, 25%, 50%, and 100%) and used lipidomics, proteomics, and microscopy to analyze the physiological response.  Z. mobilis maintained robust growth in hydrolysate. However, hydrolysate exposure induced substantial changes in lipid membrane composition and proteome expression, revealing a broad stress response characterized by the upregulation of heat shock proteins and efflux transporters and the downregulation of cell motility proteins. Unexpectedly, hydrolysate exposure also led to a robust upregulation of the Entner–Doudoroff pathway, the ethanol fermentation pathway, and other central carbon metabolism enzymes, indicating a substantial cellular investment potentially driven by additional nutrient availability in hydrolysate. While there is partial overlap with responses to ethanol and isobutanol exposure, hydrolysate elicits a distinct set of metabolic and regulatory changes, most notably the strong upregulation of central carbon metabolism enzymes.", "release_time": "2025-11-13", "source_institution": "美国能源部大湖生物能源研究中心", "url": "https://www.glbrc.org/news/systems-level-analysis-reveals-how-treated-biomass-affects-fermentation-microbe"}
{"category": "研究前沿", "title": "美日联合实验实现中微子研究重大突破", "short_summary": "T2K与NOvA实验首次联合分析，为揭示宇宙物质起源提供关键数据。", "detailed_summary": "T2K与NOvA实验首次联合分析，为揭示宇宙物质起源提供关键数据。\n(1) 美国NOvA与日本T2K两大中微子实验首次联合分析数据，实现了对中微子振荡现象前所未有的精确测量。\n(2) 研究核心目标是确定中微子质量顺序（正常或倒置）并探寻电荷宇称（CP）对称性破缺迹象。\n(3) 联合分析结合了不同实验设计、能量和距离的优势，获得了任何单一实验无法达到的精确结果。\n(4) 理解中微子行为可能解释宇宙初期物质为何战胜反物质而得以存留这一根本物理问题。\n(5) 此次国际合作成果为未来研究铺平道路，或将挑战现有物理理论，深化对宇宙演化的认知。", "raw_content": "A Michigan State University researcher has helped lead a groundbreaking effort that brings scientists closer to uncovering how the universe came to be.  For the first time, two of the world's largest neutrino experiments -- T2K in Japan and NOvA in the United States -- have combined their data to achieve unprecedented precision in studying neutrinos, the nearly invisible particles that fill the cosmos but rarely interact with anything. Their joint analysis, recently published in Nature, offers the most accurate measurements yet of how neutrinos change from one type to another as they travel through space. This milestone paves the way for future research that could deepen our understanding of the universe's evolution -- or even challenge current scientific theories. Kendall Mahn, a professor of physics and astronomy at Michigan State University and co-spokesperson for T2K, helped coordinate the collaboration. By uniting the strengths of both experiments, the teams achieved results that neither could have reached on its own. \"This was a big victory for our field,\" Mahn said. \"This shows that we can do these tests, we can look into neutrinos in more detail and we can succeed in working together.\" Why Matter Exists at All According to physicists, the early universe should have contained equal amounts of matter and antimatter. If that had been the case, the two would have annihilated each other completely. Yet, matter somehow survived -- and we have no clear reason why.  Many researchers believe the answer may be hidden in the strange behavior of neutrinos, tiny particles that constantly pass through us but rarely interact. Understanding a process called neutrino oscillation, where these particles change \"flavors\" as they move, could help explain why matter triumphed over antimatter. \"Neutrinos are not well understood,\" said MSU postdoctoral associate Joseph Walsh, who worked on the project. \"Their very small masses mean they don't interact very often. Hundreds of trillions of neutrinos from the sun pass through your body every second, but they will almost all pass straight through. We need to produce intense sources or use very large detectors to give them enough chance to interact for us to see them and study them.\" How the Experiments Work Both T2K and NOvA are known as long-baseline experiments. Each sends a focused beam of neutrinos toward two detectors -- one near the source and another hundreds of miles away. By comparing results from both detectors, scientists can track how neutrinos change along the way. Because the experiments differ in design, energy, and distance, combining their data gives researchers a more complete picture. \"By making a joint analysis you can get a more precise measurement than each experiment can produce alone,\" said NOvA collaborator Liudmila Kolupaeva. \"As a rule, experiments in high-energy physics have different designs even if they have the same science goal. Joint analyses allow us to use complementary features of these designs.\" The Puzzle of Neutrino Mass  A major focus of the study is something called \"neutrino mass ordering,\" which asks which neutrino type is the lightest. This isn't as simple as weighing particles on a scale. Neutrinos exist in three mass states, and each flavor of neutrino is actually a mixture of those states. Scientists are trying to determine whether the mass arrangement follows a \"normal\" pattern (two light and one heavy) or an \"inverted\" one (two heavy and one light). In the normal case, muon neutrinos are more likely to become electron neutrinos, while their antimatter partners are less likely to do so. The reverse occurs in the inverted pattern. An imbalance between neutrinos and their antimatter counterparts might mean that these particles violate a principle known as charge-parity (CP) symmetry -- meaning they don't behave exactly the same as their mirror opposites. Such a violation could explain why matter dominates the universe. What the Results Show The combined results from NOvA and T2K don't yet point decisively toward either mass ordering. If future studies confirm the normal ordering, scientists will still need more data to clarify whether CP symmetry is broken. But if the inverted ordering proves correct, this research suggests neutrinos could indeed violate CP symmetry, offering a powerful clue to why matter exists. If neutrinos turn out not to violate CP symmetry, physicists would lose one of their strongest explanations for the existence of matter. While these results don't solve the neutrino mystery outright, they expand what scientists know about these elusive particles and demonstrate the strength of international collaboration in physics. The NOvA collaboration includes over 250 scientists and engineers from 49 institutions in eight countries. The T2K team involves more than 560 members from 75 institutions across 15 nations. The two groups began working together on this analysis in 2019, merging eight years of NOvA data with a decade of T2K results. Both experiments continue to collect new information for future updates. \"These results are an outcome of a cooperation and mutual understanding of two unique collaborations, both involving many experts in neutrino physics, detection technologies and analysis techniques, working in very different environments, using different methods and tools,\" T2K collaborator Tomáš Nosek said.", "release_time": "2025-10-30", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/10/251029100144.htm"}
{"category": "政策计划", "title": "美联储再度降息25个基点，12月政策存分歧", "short_summary": "美联储宣布降息25基点至3.75%-4.00%，鲍威尔称12月是否再降息尚未确定。", "detailed_summary": "美联储宣布降息25基点至3.75%-4.00%，鲍威尔称12月是否再降息尚未确定。\n(1) 美联储于10月29日宣布降息25个基点，将联邦基金利率目标区间下调至3.75%至4.00%。\n(2) 这是自2024年9月以来的第五次降息，也是继9月后再次降息25个基点。\n(3) 美联储主席鲍威尔表示，12月是否进一步降息远未成定局，委员会内部存在截然不同的看法。\n(4) 鲍威尔指出，美国政府\"停摆\"将对经济活动造成影响，且许多消费者对通胀仍非常不满。\n(5) 声明称经济活动温和扩张，但就业增长放缓、失业率略升，通胀率仍处于较高水平。", "raw_content": "当地时间10月29日，美联储宣布降息25个基点。美联储主席杰罗姆·鲍威尔当日在新闻发布会上表示，美联储将继续根据最新数据、不断变化的经济前景以及风险平衡来确定适当的货币政策立场。针对12月的政策走向，本次委员会会议的讨论中存在着截然不同的看法。12月是否进一步降息远未成定局。 鲍威尔指出，美国政府“停摆”将“对经济活动造成影响”。此外，鲍威尔提到，很大一部分美国消费者仍然对通货膨胀“感到非常不满”。 美联储再度降息25个基点 美国联邦储备委员会29日结束为期两天的货币政策会议，宣布将联邦基金利率目标区间下调25个基点到3.75%至4.00%之间。这是美联储继9月17日降息25个基点后再次降息，也是自2024年9月以来第五次降息。 美联储决策机构联邦公开市场委员会发表声明说，现有指标显示，经济活动一直以温和的速度扩张，今年就业增长放缓，失业率略有上升，通胀率自年初以来有所上升，目前仍处于较高水平。鉴于风险平衡变化，委员会决定将联邦基金利率目标区间下调25个基点。 当前，美国联邦政府持续“停摆”导致多项官方经济数据发布推迟。美联储主席鲍威尔此前曾表示，美联储有自己的联系人和数据来源，以监测美国经济健康状况。", "release_time": "2025-10-30", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195504-1.html"}
{"category": "研究前沿", "title": "前沿科学探索：微型大脑、蜘蛛敷料与微塑料影响", "short_summary": "四项创新研究涵盖脑器官培育、实时伤口护理、食品保鲜涂层及微塑料对视网膜影响。", "detailed_summary": "四项创新研究涵盖脑器官培育、实时伤口护理、食品保鲜涂层及微塑料对视网膜影响。\n（1）实验室成功培育三维\"微型大脑\"器官，可生成电活动，为无动物实验研究脑功能提供新工具；\n（2）受蜘蛛启发的手套能实时纺出超薄聚合物纤维，直接覆盖伤口实现即时护理；\n（3）从狼苹果提取的淀粉可制成天然可食用涂层，使胡萝卜在室温下保鲜达15天；\n（4）人类视网膜样本中均检出微塑料颗粒，为研究其对视力和眼健康影响奠定基础。", "raw_content": "Brains, spiders, (were)wolves and slimy eyeballs might sound like props from a horror movie, but these eerie topics come straight from serious scientific research. Studies published in ACS journals are exploring innovative ways to improve human health, from growing brain tissue without animal testing to creating on-demand wound care and developing edible coatings that keep vegetables fresh. Even the human eye is under investigation as scientists uncover how microplastics might affect our vision.  Growing Mini-Brains in the Lab In a study described in ACS Sensors, scientists successfully cultivated a small, three-dimensional \"mini-brain\" in a dish. Over the course of two years, cultured human nerve cells multiplied and organized themselves into a functioning organoid capable of generating electrical activity. This breakthrough allows researchers to explore how brain cells interact and communicate without using animals in experiments. Future advances could make these organoids valuable tools for studying brain function -- or, as the researchers jokingly note, a possible \"lab-grown lunch option for zombies.\" Spider-Inspired Glove Spins Wound Dressings In ACS Applied Materials & Interfaces, scientists took inspiration from spiders to create a unique glove fitted with spinneret-like devices that release ultra-thin polymer fibers. The invention allows medical workers to spin wound dressings directly onto injuries in real time. Such a system could be especially useful in hospitals, sports arenas, or battlefield environments. And in case anyone is wondering, these experiments did not involve any radioactive spider bites. Wolf Apple Coating Keeps Produce Fresher Researchers reporting in ACS Food Science & Technology found that starch extracted from the wolf apple -- a fruit native to Brazil and a favorite of the maned wolf -- can be transformed into a natural, edible coating that helps preserve food. When applied to baby carrots, the coating kept them bright and fresh for up to 15 days at room temperature. The material offers a safe, cost-effective way to extend the shelf life of produce, whether or not there's a full moon. Microplastics Found in Human Retinas In ACS Environmental Science & Technology Letters, scientists examined 12 post-mortem human retinas (no eye of newt required) and discovered microplastic particles in every sample. The plastics varied in type and concentration, revealing how pervasive they have become -- even in such delicate tissue. The researchers say these findings lay important groundwork for future investigations into how microplastics might influence vision and overall eye health.", "release_time": "2025-10-31", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251030075112.htm"}
{"category": "产业应用", "title": "蒙古国央行预测2026年煤炭出口将达9000万吨", "short_summary": "蒙古央行预测2026年煤炭出口9000万吨，旨在改善经济前景并缓解预算压力。", "detailed_summary": "蒙古央行预测2026年煤炭出口9000万吨，旨在改善经济前景并缓解预算压力。\n(1) 蒙古国中央银行预测2026年煤炭出口量将达9000万吨，高于2024年的8370万吨和2025年计划的8500万吨。\n(2) 出口增长预计将改善经济前景，减少经常账户赤字，缓解汇率压力，并支持央行预测的5.6%经济增长率。\n(3) 当前挑战包括全球煤炭价格下跌导致出口收入减少，预计2025年国家预算将出现30亿美元缺口。\n(4) 政府已采取支持措施，包括为国有煤炭公司实施特殊运营制度，使煤炭出口量在短期内增长8倍。\n(5) 其他措施包括调整汇率、加快海关流程、增加对中国市场供应，并探索印度、日本和韩国等新市场。\n(6) 蒙古国正积极与中国企业谈判长期合作，中国是其煤炭最大买家，去年出口金额达86亿美元。", "raw_content": "据俄罗斯媒体10月17日报道的消息，蒙古国中央银行(Central Bank of Mongolia)预测，明年(2026年)蒙古国煤炭出口量将达到9000万吨(今年的出口计划为不少于8500万吨)。这是从银行的货币信贷政策报告中得出的结论。 该消息指出，预测的情景意味着，2026年，蒙古国煤炭实物出口量将达到9000万吨。出口收入的增长将改善经济前景，煤炭出口的增加将减少经常账户赤字，并缓解汇率贬值压力。 煤炭的增产将促进蒙古国的采矿业，并间接刺激更广泛采矿领域的发展。中央银行预测2026年蒙古国经济增长率为5.6%。 早在今年4月，蒙古国政府已报告相关问题，即以货币计算的煤炭出口下降。主要原因在于全球煤炭价格持续下跌以及仓储库存积压。因此，2025年夏季，蒙古国当局决定调整国家预算。在当前情况下，预计预算将出现30亿美元的缺口。 支持该行业的一项措施是，今年7月推出了一项针对国家 “额尔登斯·塔旺陶洛盖” 煤炭公司(Erdenes Tavantolgo)的特殊运营制度。该公司运营着塔瓦纳特煤矿(Tavanych)。蒙古国政府指出，该制度从开始实施到9月30日，已使煤炭出口量增长了8倍。 政府讨论的其它支持措施包括调整汇率、加快海关流程、增加对中国市场的煤炭供应，以及探讨进入包括印度、日本和韩国在内的第三国市场。 据蒙古国媒体报道，8月29日，“额尔登斯·塔旺陶洛盖”公司发布计划通过吸引来自中国的合作伙伴参与投标来扩大煤炭出口。目前有超过400家中国公司正在采购蒙古国煤炭，其中大多数公司将该资源供应给终端消费者。 为增加销售量，“额尔登斯·塔旺陶洛盖”已与中国内蒙古自治区的潜在合作伙伴举行了谈判。谈判参与方中包括十余家主要企业，如SXCoal LLC、山东能源集团、中煤集团，以及一些冶金企业和钢铁厂。潜在合作伙伴对长期合作表示出兴趣，并计划更积极地参与长期合同交易。 根据去年的运行结果，去年全年蒙古国煤炭出口量为8370万吨，总金额达86亿美元。 今年到年底，蒙古国计划出口煤炭至少8500万吨。尽管今年全年出口量有所增加，但由于全球煤炭价格下跌，今年的煤炭出口收入对国家预算的贡献仍将低于去年。 蒙古国预算的主要收入来源是煤炭出口，中国是蒙古国煤炭出口的最大买家。", "release_time": "2025-10-31", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195531-1.html"}
{"category": "产业应用", "title": "Copper推出电池驱动电磁灶推动家庭电气化", "short_summary": "Copper电池电磁灶简化家庭电气化，并可作为电网资产提供清洁电力。", "detailed_summary": "Copper电池电磁灶简化家庭电气化，并可作为电网资产提供清洁电力。\n（1）初创公司Copper开发了配备磷酸铁锂电池的电磁灶，可直接插入标准120伏插座，无需改造电路。\n（2）该产品主要面向大型公寓楼开发商和业主，已发货约1000台，并与纽约市住房管理局签订至少1万台协议。\n（3）电池可在电价低廉时充电，用于烹饪，并在停电时提供备用电源，提升生活品质和电网韧性。\n（4）公司试点项目将家庭电池作为分布式电网资产，在用电高峰向电网供电，替代燃气电厂，降低用电成本。\n（5）创始人Calisch旨在通过电器部署推动电池供应链和电气化进程，将家庭从电力消费者转变为电网参与者。", "raw_content": "As batteries have gotten cheaper and more powerful, they have enabled the electrification of everything from vehicles to lawn equipment, power tools, and scooters. But electrifying homes has been a slower process. That’s because switching from gas appliances often requires ripping out drywall, running new wires, and upgrading the electrical box.Now the startup Copper, founded by Sam Calisch SM ’14, PhD ’19, has developed a battery-equipped kitchen range that can plug into a standard 120-volt wall outlet. The induction range features a lithium iron phosphate battery that charges when energy is cheapest and cleanest, then delivers power when you’re ready to cook.“We’re making ‘going electric’ like an appliance swap instead of a construction project,” says Calisch. “If you have a gas stove today, there is almost certainly an outlet within reach because the stove has an oven light, clock, or electric igniters. That’s big if you’re in a single-family home, but in apartments it’s an existential factor. Rewiring a 100-unit apartment building is such an expensive proposition that basically no one’s doing it.”Copper has shipped about 1,000 of its battery-powered ranges to date, often to developers and owners of large apartment complexes. The company also has an agreement with the New York City Housing Authority for at least 10,000 units.Once installed, the ranges can contribute to a distributed, cleaner, and more resilient energy network. In fact, Copper recently piloted a program in California to offer cheap, clean power to the grid from its home batteries when it would otherwise need to fire up a gas-powered plant to meet spiking electricity demand.“After these appliances are installed, they become a grid asset,” Calisch says. “We can manage the fleet of batteries to help provide firm power and help grids deliver more clean electricity. We use that revenue, in turn, to further drive down the cost of electrification.”Finding a missionCalisch has been working on climate technologies his entire career. It all started at the clean technology incubator Otherlab that was founded by Saul Griffith SM ’01, PhD ’04.“That’s where I caught the bug for technology and product development for climate impact,” Calisch says. “But I realized I needed to up my game, so I went to grad school in [MIT Professor] Neil Gershenfeld’s lab, the Center for Bits and Atoms. I got to dabble in software engineering, mechanical engineering, electrical engineering, mathematical modeling, all with the lens of building and iterating quickly.”Calisch stayed at MIT for his PhD, where he worked on approaches in manufacturing that used fewer materials and less energy. After finishing his PhD in 2019, Calisch helped start a nonprofit called Rewiring America focused on advocating for electrification. Through that work, he collaborated with U.S. Senate offices on the Inflation Reduction Act.The cost of lithium ion batteries has decreased by about 97 percent since their commercial debut in 1991. As more products have gone electric, the manufacturing process for everything from phones to drones, robots, and electric vehicles has converged around an electric tech stack of batteries, electric motors, power electronics, and chips. The countries that master the electric tech stack will be at a distinct manufacturing advantage.Calisch started Copper to boost the supply chain for batteries while contributing to the electrification movement.“Appliances can help deploy batteries, and batteries help deploy appliances,” Calisch says. “Appliances can also drive down the installed cost of batteries.”The company is starting with the kitchen range because its peak power draw is among the highest in the home. Flattening that peak brings big benefits. Ranges are also meaningful: It’s where people gather around and cook each night. People take pride in their kitchen ranges more than, say, a water heater.Copper’s 30-inch induction range heats up more quickly and reaches more precise temperatures than its gas counterpart. Installing it is as easy as swapping a fridge or dishwasher. Thanks to its 5-kilowatt-hour battery, the range even works when the power goes out.“Batteries have become 10 times cheaper and are now both affordable and create tangible improvements in quality of life,” Calisch says. “It’s a new notion of climate impact that isn’t about turning down thermostats and suffering for the planet, it’s about adopting new technologies that are better.”Scaling impactCalisch says there’s no way for the U.S. to maintain resilient energy systems in the future without a lot of batteries. Because of power transmission and regulatory limitations, those batteries can’t all be located out on the grid.“We see an analog to the internet,” Calisch says. “In order to deliver millions of times more information across the internet, we didn’t add millions of times more wires. We added local storage and caching across the network. That’s what increased throughput. We’re doing the same thing for the electric grid.”This summer, Copper raised $28 million to scale its production to meet growing demand for its battery equipped appliances. Copper is also working to license its technology to other appliance manufacturers to help speed the electric transition.“These electric technologies have the potential to improve people’s lives and, as a byproduct, take us off of fossil fuels,” Calisch says. “We’re in the business of identifying points of friction for that transition. We are not an appliance company; we’re an energy company.”Looking back, Calisch credits MIT with equipping him with the knowledge needed to run a technical business.“My time at MIT gave me hands-on experience with a variety of engineering systems,” Calisch. “I can talk to our embedded engineering team or electrical engineering team or mechanical engineering team and understand what they’re saying. That’s been enormously useful for running a company.”He adds: “I also developed an expansive view of infrastructure at MIT, which has been instrumental in launching Copper and thinking about the electrical grid not just as wires on the street, but all of the loads in our buildings. It’s about making homes not just consumers of electricity, but participants in this broader network.”", "release_time": "2025-10-30", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/battery-powered-appliances-make-switch-easy-gas-electric-1030"}
{"category": "研究前沿", "title": "电子束诱导金刚烷转化为纳米金刚石新方法问世", "short_summary": "东京大学实现电子束低温合成纳米金刚石，为量子技术提供新路径。", "detailed_summary": "东京大学实现电子束低温合成纳米金刚石，为量子技术提供新路径。\n（1）东京大学团队开发低温低压电子束辐照技术，成功将金刚烷转化为纳米金刚石；\n（2）通过透射电镜实时观测转化过程，破解了电子束会破坏有机分子的传统认知；\n（3）所得纳米金刚石直径达10纳米，具有立方晶体结构，反应中释放氢气；\n（4）该技术为量子点制造、材料成像和天体钻石成因研究开辟新方向。", "raw_content": "Scientists from the University of Tokyo and their collaborators have created a new approach to forming artificial diamonds that offers surprising advantages. By carefully preparing carbon-based samples and then exposing them to an electron beam, the researchers discovered that their process not only converts the material into diamond but also protects delicate organic substances from beam damage. This advance could pave the way for improved imaging and analysis methods in materials science and biology.  Traditionally, diamond production involves converting carbon at enormous pressures and temperatures, where the diamond form is stable, or by using chemical vapor deposition, where it is not. Professor Eiichi Nakamura and his team at the University of Tokyo's Department of Chemistry pursued a different path. They tested a low-pressure technique using controlled electron irradiation on a molecule known as adamantane (C10H16). Adamantane has a carbon framework that mirrors diamond's tetrahedral structure, making it an appealing starting material for forming nanodiamonds. However, to transform adamantane into diamond, scientists must precisely remove hydrogen atoms (C-H bonds) and replace them with carbon-carbon (C-C) links, arranging the atoms into a three-dimensional diamond lattice. Although this reaction pathway was known in theory, Nakamura explained that \"The real problem was that no one thought it feasible.\" Watching Diamond Formation in Real Time Earlier work using mass spectrometry indicated that single-electron ionization could help break C-H bonds, but that method could only infer structures in the gas phase and could not isolate solid products. To overcome this limitation, Nakamura's group turned to transmission electron microscopy (TEM), a tool that can image materials at atomic resolution. They exposed tiny adamantane crystals to electron beams of 80-200 kiloelectron volts at temperatures between 100-296 kelvins in a vacuum for several seconds. This setup allowed the team to directly observe the process of nanodiamond formation. In addition to demonstrating how electron irradiation drives polymerization and restructuring, the experiment revealed TEM's potential for studying controlled reactions in other organic molecules as well. For Nakamura, who has spent decades in synthetic and computational chemistry, this project represented the culmination of a long-standing goal. \"Computational data gives you 'virtual' reaction paths, but I wanted to see it with my eyes,\" he said. Many believed that electron beams would destroy organic molecules, but Nakamura's persistence since 2004 has shown that, under the right conditions, they can instead trigger stable, predictable reactions.  Building Nanodiamonds Under the Beam Under extended exposure, the process produced nearly perfect nanodiamonds with a cubic crystal structure and diameters up to 10 nanometers, along with the release of hydrogen gas. TEM imaging revealed how chains of adamantane molecules gradually transformed into spherical nanodiamonds, with the reaction rate controlled by the breaking of C-H bonds. Other hydrocarbons failed to produce the same result, underscoring adamantane's unique suitability for diamond growth. The discovery opens up fresh possibilities for manipulating chemical reactions in fields such as electron lithography, surface science, and microscopy. The researchers also suggest that similar high-energy irradiation processes may explain how diamonds form naturally in meteorites or uranium-rich rocks. Beyond this, the method could support the fabrication of doped quantum dots, key components for quantum computing and advanced sensors. A Dream Two Decades in the Making Reflecting on the breakthrough, Nakamura described it as the realization of a 20-year vision. \"This example of diamond synthesis is the ultimate demonstration that electrons do not destroy organic molecules but let them undergo well-defined chemical reactions, if we install suitable properties in molecules to be irradiated,\" he said. His achievement may permanently reshape how scientists use electron beams, offering a clearer window into the chemical transformations that take place under irradiation.", "release_time": "2025-10-29", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/10/251029002917.htm"}
{"category": "产业应用", "title": "日立能源携手黑石投资Shermco，强化北美电网服务", "short_summary": "日立能源战略投资Shermco并注资超10亿美元，提升北美电力基础设施服务能力。", "detailed_summary": "日立能源战略投资Shermco并注资超10亿美元，提升北美电力基础设施服务能力。\n(1) 日立能源与黑石能源转型基金达成战略合作，收购北美电气服务商Shermco的少数股权；  \n(2) 日立能源同步投资超10亿美元扩展全球服务业务，包括推出数字服务方案HMAX及培养超5000名服务专家；  \n(3) 合作整合三方优势：日立能源的电网技术、黑石的资本管理及Shermco的现场服务网络；  \n(4) 旨在应对电网老化、劳动力短缺等挑战，提升数据中心、工业客户电力设施的可靠性与数字化水平；  \n(5) 通过全生命周期服务支持北美能源转型，强化电网韧性并推动电气化进程。", "raw_content": "Hitachi Energy acquires a minority stake in Shermco, a company recently acquired by private equity funds managed by Blackstone, strengthening capabilities to maintain the reliability and safety of North America's power grid. In addition, Hitachi Energy is investing more than $1 billion USD in the organic expansion of its global Service business, developing new digital service solutions, like HMAX, and growing its workforce.     Zurich and New York, October 29, 2025 – Hitachi Energy, a wholly owned subsidiary of Hitachi, Ltd., today announced a strategic partnership with Blackstone Energy Transition Partners (“Blackstone”) to expand and strengthen its Service business, supporting customers in maintaining the reliability and safety of power infrastructure across North America. As part of the partnership, Hitachi Energy will acquire a stake in Shermco – a leading provider of comprehensive maintenance, repair, testing, commissioning, and design services in North America, recently acquired by private equity funds affiliated with Blackstone. The partnership brings together three industry leaders: Hitachi Energy, a global technology leader in electrification; Blackstone, the world's largest alternative asset manager; and Shermco, a leading provider of electrical services in the U.S. and Canada. Together, they will seek to expand service capacity and capabilities to deliver comprehensive lifecycle support for critical energy infrastructure, from power generation and transmission to data centers and industrial electrification. “Investing in Shermco in partnership with Blackstone enables Hitachi Energy to accelerate our growth and expand service capabilities across North America,” said Andreas Schierenbeck, CEO of Hitachi Energy. “Our investment strengthens our service offering as we continue to scale, helping customers maintain and extend the life of existing assets while making the grid stronger, more resilient and fit for the future.” “We're thrilled to welcome Hitachi Energy as a strategic partner alongside Blackstone,” said Phil Petrocelli, CEO of Shermco. “This investment is a testament to our commitment to serving our customers' essential power needs and reputation for safety and excellence. With this additional support and resources, we look forward to expanding our footprint and capabilities to continue to accelerate our growth together.” “Hitachi Energy is a global leader across technology and energy with deep digital and operational expertise,” said David Foley, Global Head of Blackstone Energy Transition Partners. “We are excited to partner with Hitachi Energy to build on Shermco's success alongside Phil Petrocelli and its exceptional management team.” JP Munfa and Darius Sepassi, Senior Managing Directors at Blackstone, added, “Hitachi Energy's investment in Shermco brings together a global technology leader in electrification with one of the leading North American providers of mission-critical maintenance, testing and design services for electrical equipment. We are thrilled to be partnering with Hitachi Energy and look forward to working together to accelerate Shermco's next phase of growth in an era of rapid electrification and increasing demand.” Hitachi Energy's $1 billion global investment in Service In addition, Hitachi Energy is investing more than $1 billion USD globally to expand its Service footprint, launching new digital service solutions with HMAX Energy, and growing its workforce – including the development and certification of over 5,000 additional service experts worldwide. \"By combining Hitachi Energy's grid expertise and digital solutions with Shermco's nationwide field service presence, we will set a new benchmark for electrical infrastructure services – creating the leading service partner in North America driving asset reliability and performance as well as digital innovation for utilities, industries and data centers alike,\" said Wolf Mueller, Managing Director of Hitachi Energy's Service Business. Strengthening Service capabilities for the electricity era Globally, power grids are aging, and the experienced workforce is retiring, creating significant challenges. As electrification accelerates across industries, transportation, and digital infrastructure, service is the backbone of grid modernization. Much of today's grid infrastructure – more than 70 percent of U.S. transmission lines1 – is decades old, nearing or past its intended lifecycle, leading to higher outage risks, cyber vulnerabilities and costly emergency repairs. Service is critical to help data centers, utilities and industries maintain, upgrade, and optimize their infrastructure and increase the reliability, safety, flexibility and sustainability of energy systems.  1 DOE, What does it take to modernize the U.S. electric grid?  Note to Editors:  (1)Founded in 1974 and headquartered in Texas, Shermco is one of the largest electrical testing organizations accredited by the InterNational Electrical Testing Association (“NETA”), providing comprehensive electrical system maintenance, repair, testing, commissioning and design services, with more than 600 NETA technicians and 200 engineers across 40 service centers in the U.S. and Canada. Shermco provides critical services for data centers, utilities and diversified commercial and industrial end-markets, partnering with customers to enhance the safety, reliability and efficiency of their critical electrical infrastructure, while minimizing downtime and outages. (2)HMAX Energy is Hitachi's upcoming digitally enabled and AI-powered services offering related to the energy sector. As a key pillar of the company's Lumada 3.0 strategy, HMAX Energy integrates digital capabilities, domain expertise, service excellence, and installed base intelligence to maximize uptime, safety, efficiency, and asset lifetime. These capabilities will empower customers to shift from reacting to predicting - future-proofing their energy infrastructure. About Hitachi, Ltd.  Through its Social Innovation Business (SIB) that brings together IT, OT (Operational Technology) and products, Hitachi contributes to a harmonized society where the environment, wellbeing, and economic growth are in balance. Hitachi operates globally in four sectors – Digital Systems & Hitachi Energy is a global technology leader in electrification, powering a sustainable energy future with innovative power grid technologies with digital at the core. Over three billion people depend on our technologies to power their daily lives. Services, Energy, Mobility, and Connective Industries – and the Strategic SIB Business Unit for new growth businesses. With Lumada at its core, Hitachi generates value from integrating data, technology and domain knowledge to solve customer and social challenges. Revenues for FY2024 (ended March 31, 2025) totaled 9,783.3 billion yen, with 618 consolidated subsidiaries and approximately 280,000 employees worldwide. Visit us at www.hitachi.com. About Hitachi Energy  Hitachi Energy is a global technology leader in electrification, powering a sustainable energy future with innovative power grid technologies with digital at the core. Over three billion people depend on our technologies to power their daily lives. With over a century in pioneering mission-critical technologies like high-voltage, transformers, automation, and power electronics, we are addressing the most urgent energy challenge of our time – balancing soaring electricity demand, while decarbonizing the power system. With an unparalleled installed base in over 140 countries, we co-create and build long-term partnerships across the utility, industry, transportation, data centers, and infrastructure sectors. Headquartered in Switzerland, we employ over 50,000 people in 60 countries and generate revenues of around $16 billion USD. About Blackstone Energy Transition Partners  Blackstone Energy Transition Partners is Blackstone's strategy for control-oriented equity investments in energy-related businesses, a leading energy investor with a successful long-term record, having committed over $27 billion of equity globally across a broad range of sectors within the energy industry. Our investment philosophy is based on backing exceptional management teams with flexible capital to provide solutions that help energy companies grow and improve performance, thereby delivering more reliable, affordable and cleaner energy to meet the needs of the global community. In the process, we build stronger, larger scale enterprises, create jobs and generate lasting value for our investors, employees and all stakeholders. Further information is available at https://www.blackstone.com/our-businesses/blackstone-energy-transition-partners/. About Shermco  Headquartered in Irving, TX, Shermco provides electrical testing, maintenance, commissioning and repair services to a wide range of utility, industrial, energy and other end markets. With more than 40 locations, Shermco serves a diversified blue-chip client base across North America. The Company is an active participant in NETA (the InterNational Electrical Testing Association), EASA (Electrical Apparatus Service Association), and ACP (American Clean Power Association). For more information, visit www.shermco.com.  Information contained in this news release is current as of the date of the press announcement, but may be subject to change without prior notice.", "release_time": "2025-11-18", "source_institution": "日本日立", "url": "http://www.hitachi.com/New/cnews/month/2025/10/251030c.html"}
{"category": "产业应用", "title": "国际动力煤市场周度分析：供应扰动与需求复苏交织", "short_summary": "亚太需求支撑国际煤价上行，供应端扰动与冬季预期共同主导市场情绪。", "detailed_summary": "亚太需求支撑国际煤价上行，供应端扰动与冬季预期共同主导市场情绪。\n(1) 国际动力煤市场情绪高涨，价格重心上移，主要受亚太地区需求强劲及供应端扰动支撑，但价格涨幅有所收窄。\n(2) 供应端：印尼受雨季和审批问题制约供应；俄罗斯出口重心转向亚洲，价格稳中有升；澳大利亚因天气和需求强劲价格坚挺；南非现货短缺，供应偏向欧洲。\n(3) 需求端：中国电厂冬季备货带动进口需求，内贸煤价优势明显；印度因节日工业活动放缓需求疲软，但预期节后反弹；欧洲因天然气价低、可再生能源出力好及高库存，煤炭需求低迷。\n(4) 市场展望：参与者普遍看好四季度北半球冬季用煤需求对市场的提振作用，但短期受运费上涨、特定地区需求波动等因素制约。", "raw_content": "过去一周，主要受亚太地区买家需求强劲支撑，国际动力煤市场情绪依旧高涨，价格重心整体继续上移。供应端持续性扰动与主要进口国季节性需求复苏预期相互交织，共同支撑了国际市场的看涨情绪，但价格涨幅较此前有所收窄。同时，随着运费上涨支撑到岸成本上升，买卖双方实际成交受到一定限制。 现阶段，市场参与者普遍关注即将到来的北半球冬季，但短期内，欧洲天然气稳定的价格抑制了燃料转换需求，而印度因节日因素导致的工业活动放缓，暂时压制了现货采购的积极性。总体来看，国际动力煤市场利好和利空因素并存，市场参与者普遍看好四季度北半球用煤需求对市场的提振作用。 —— 供应端 —— | 印尼 过去一周，印尼煤炭供应继续受到主产区天气因素的制约。由于供应链受阻支撑了矿方谨慎情绪，报价持续坚挺。上周晚些时候，12月船期印尼3800大卡巴拿马型动力煤离岸价报48.5-49美元/吨，相同品质小船煤报47美元/吨左右。 截至10月24日，CCI进口3800大卡动力煤离岸价为46.8美元/吨，较前一周上涨1美元/吨，较上月同期上涨2.8美元/吨;CCI进口4700大卡动力煤离岸价为65美元/吨，较前一周上涨1美元/吨，较上月同期上涨3.1美元/吨。     印尼动力煤供应持续受到天气因素的制约。今年雨季提前，尤其是南苏门答腊与加里曼丹地区频繁出现强降雨，不仅直接影响了矿区的开采作业，也阻碍了煤炭通过驳船向大型装载港口的内陆运输。 此外，印尼政府的工作计划和预算(RKAB)审批进度问题，也限制了部分矿商在年底前快速提升产量的能力。为维持出口并适应市场变化，印尼政府近期放宽了煤炭基准价机制，并推出了在线监测平台以提升供应链透明度，同时引入自动审批机制，以确保在当局未在规定时限内批复情况下对计划的审批。这些举措旨在为长期出口的稳定性提供支持。 | 俄罗斯 上周，因东北亚地区买家对俄煤的采购需求有限，因而俄罗斯远东港口高卡动力煤价格略有下降，而南部港口煤炭价格保持稳定。 截至10月24日，CCI俄罗斯5000大卡动力煤远东港离岸价为73.5美元/吨，较前一周上涨3美元/吨，较上月同期上涨7美元/吨;CCI俄罗斯5500大卡动力煤离岸价82美元/吨，较前一周上涨3美元/吨，较前一月同期上涨7美元/吨。 在西方制裁的长期背景下，俄罗斯煤炭出口商成功地将出口重心逐渐向中国、印度和土耳其等市场转移。而近期受国内供应收紧以及能源行业需求稳定等，中国买家对进口煤的采购情绪较为高涨。 俄罗斯能源部长谢尔盖·齐维列夫(Sergei Tsivilev)近期在接受采访时透露，俄能源部正在筹备新的煤炭工业发展规划至2050年，其中一个关键方向可能是包括推动行业向大型公司集中，以提升整个产业的稳定性和竞争力。 | 澳大利亚 上周，受中国及其他亚洲买家需求支撑，澳大利亚动力煤价格坚挺上行。同时，近期部分主产区降雨影响供应收紧，同样有助于支撑煤价走高。截至10月24日，纽卡斯尔港5500大卡动力煤价格为76.34美元/吨，较之前一周上涨2.71美元/吨，较上月同期上涨5.59美元/吨。     一方面，新南威尔士州等主要产区的降雨天气对部分煤矿的生产造成了短期干扰。另一方面，市场结构性紧张支撑了煤炭价格。由于需求强劲，尤其是中国买家对高卡煤的需求稳定，消化了市场上的大部分可用供应，许多主流矿商表示远期货盘已基本售罄。 尽管面临一些生产上的挑战，但澳大利亚生产商普遍对亚太区域、特别是北亚地区冬季刚需持稳定预期，因此维持着较高报价水平。 | 南非 过去一周，亚洲买家对南非动力煤的询货略有增加，但由于现货短缺且大多数矿商11月煤已经售罄，整体交易量依然有限。 截至10月24日，南非理查兹湾5500大卡动力煤离岸价为69.93美元/吨，较前一周上涨0.34美元/吨，较前一月上涨0.39美元/吨。     随着北半球冬季临近，南非矿商正将更多高品质煤炭资源向欧洲市场出售，以期满足该地区潜在的冬季发电需求。 与此同时，对亚洲市场的供应则相对平稳。印度作为南非煤在亚洲的传统最大买家，近期因国内节日假期，采购活动有所放缓，但这被来自韩国、越南等其他亚洲国家询盘部分抵消。南非市场供应虽未出现短缺，但在全球供应链紧张的大背景下，矿方同样没有降价销售的压力。 —— 需求端 —— | 中国 过去一周，中国动力煤市场价格在连续数周大幅上涨之后有所放缓，进口煤价涨幅同样收窄，但较内贸煤价格优势仍然明显，仍对市场采购有一定带动作用。 部分贸易商预计后期海运费有下跌可能，因而市场投标价格略有下降。截至上周晚些时候，贸易商对3800大卡煤投标价普遍回落至舱底含税450元/吨以下。 截至10月24日，CCI进口3800大卡动力煤中国南方港到岸价为56.6美元/吨，较前一周上涨0.3美元/吨;CCI进口4700大卡动力煤到岸价为73.5美元/吨，较前一周上涨1美元/吨;CCI进口5500大卡动力煤到岸价为94.2美元/吨，较前一周上涨2.2美元/吨。         近日，随着华南地区气温下降，电厂日耗明显回落。目前，沿海电厂的库存水平较往年同期偏低，叠加对“冷冬”的预期，促使电厂和贸易商提前启动冬季备货采购，对进口煤的询货和采购积极性较为高涨。 截至10月26日，沿海六大电厂日耗为77.3万吨，较前一周下降4.8%;煤炭库存1402.3万吨，较前一周微增0.58%，存煤可用天数升至18天。 目前，市场参与者对后市看法不甚相同。当前外矿货源稀少，部分贸易商持货看涨。进口市场情绪仍较为坚挺，尽管内贸市场上涨放缓，但在进口价明显的优势下，市场暂无回调基础。不过，随着内贸市场回调，部分贸易商出货意愿较强，进口煤投标增多，但报价重心有所下移。也有进口商表示，当前市场参与者对四季度的传统旺季抱有期待，因此并不过分看空。 | 印度 近日，印度正值排灯节等重要节日假期，工业生产活动显著放缓，电力需求下降，加之印度国内煤炭库存处于高位，短期进口需求疲软。大多数终端用户依靠长期协议货量或消耗现有库存来满足需求，现货市场的采购活动极为有限。 印度中央电力局(CEA)数据显示，截至10月26日，印度电厂煤炭库存为4620.6万吨，较前一周增长3.66%，存煤可用天数增至15.3天，明显高于前一周的14.8天。同时，库存处于临界值的电厂数量大幅下降，截至上周末，有8家电厂处于临界低库存状态，较前一周减少10家。 市场普遍预期，后期随着节日结束、工业生产恢复正常，以及气温变化可能带来的电力需求回升，印度进口需求将在11月初出现报复性反弹。目前，印度买家正密切关注国际市场动态，为即将到来的补库周期做准备。 | 欧洲 过去一段时间内，天然气价格一直维持稳定且相对较低水平，使得燃气发电的经济性远超燃煤发电，欧洲电力调度系统优先使用天然气。 同时，欧洲地区风力、太阳能等可再生能源发电出力良好，进一步挤压了化石能源在电力结构中的份额。另外，由于终端消费能力有限，欧洲ARA三港煤炭库存已攀升至6月以来的高位。 截至上周晚些时候，欧洲ARA三港6000大卡动力煤到岸价上涨至接近95美元/吨，较前一周上涨超3美元/吨。 尽管冬季即将来临，但在当前能源结构和高库存的背景下，欧洲的电力公司缺乏对新货源的采购兴趣，除非出现极端寒冷天气或天然气供应危机，否则欧洲动力煤需求或难有起色。 上周，欧洲天然气价格小幅上涨。截至10月24日，洲际交易所(ICE)TTF基准荷兰天然气11月期货收于32.016欧元/兆瓦时，较前一周的31.816欧元/兆瓦时上涨0.63%。", "release_time": "2025-10-29", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195488-1.html"}
{"category": "政策计划", "title": "国际原子能机构2024年旗舰倡议全球显效", "short_summary": "IAEA四大倡议助力全球癌症治疗、疫病防控、塑料污染治理与粮食安全。", "detailed_summary": "IAEA四大倡议助力全球癌症治疗、疫病防控、塑料污染治理与粮食安全。\n(1) Rays of Hope倡议：为多国提供救命癌症护理设备，并将癌症护理卓越中心网络扩大至11个，以解决全球放疗资源短缺问题。\n(2) ZODIAC倡议：加强全球人畜共患病防控准备，151个成员国指定国家协调员，129个指定实验室，并推出基于云平台的国际合作系统以改进呼吸道疾病检测。\n(3) NUTEC Plastics倡议：开展首次南极科研任务检测微塑料，并在多国建立试点工厂，展示辐射技术升级回收塑料废物的潜力。\n(4) Atoms4Food倡议：与联合国粮农组织合作，制定全面计划，帮助各国利用核技术加强可持续农业食品系统，并根据国家需求进行评估干预。", "raw_content": "Flagship Initiatives Deliver Impact Worldwide  In 2024, the IAEA’s flagship initiatives supported countries in health care, food security and protecting the environment through the peaceful, safe and secure use of nuclear science and technology.   Cancer remains a leading cause of death globally, yet radiotherapy — needed by nearly half of patients — is inaccessible to many.  To address this, the IAEA Rays of Hope initiative facilitated the delivery of life-saving cancer care equipment to many countries and expanded its network of anchor centres —  centres of excellence for cancer care to 11.  The Zoonotic Disease Integrated Action (ZODIAC) initiative continued to strengthen global preparedness for zoonotic diseases, with 151 Member States designating national coordinators and 129 designating laboratories. A cloud-based platform was launched to foster international cooperation using big data to improve respiratory disease detection.  The NUclear TEChnology for Controlling Plastic Pollution (NUTEC Plastics) initiative conducted its first scientific research mission to Antarctica, detecting microplastics in the most remote of places on earth, as part of its  marine environment monitoring. Pilot plants in Argentina, Indonesia, Malaysia and the Philippines demonstrated the potential of radiation technology for the plastic waste upcycling aspect of the initiative.  The IAEA, in partnership with the Food and Agriculture Organization (FAO) of the United Nations is helping countries enhance their food security. Last year, the joint IAEA/FAO Atoms4Food initiative developed a comprehensive plan to expand access to the benefits of nuclear applications for sustainable agri-food systems. Assessment missions carried out under the initiative will help tailor interventions based on national needs.", "release_time": "2025-10-30", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/iaea-unveils-2024-annual-report"}
{"category": "研究前沿", "title": "科学家首次精确测量夸克-胶子等离子体演化温度", "short_summary": "研究团队通过电子对测量技术，揭示宇宙大爆炸后微秒级的极端热物质温度演变。", "detailed_summary": "研究团队通过电子对测量技术，揭示宇宙大爆炸后微秒级的极端热物质温度演变。\n（1）莱斯大学团队利用相对论重离子对撞机测量夸克-胶子等离子体不同演化阶段的温度；\n（2）通过检测电子-正电子对能量分布，获得2.01万亿开尔文（冷却阶段）和3.25万亿开尔文（初始高温阶段）两个明确温度值；\n（3）该突破性测量方法克服了等离子体内部运动造成的测量失真问题；\n（4）研究成果为完善量子色动力学相图提供关键实验数据，深化对早期宇宙物质状态的理解；\n（5）发表于《自然-通讯》杂志，标志着极端物质研究进入新阶段。", "raw_content": "A team led by Rice University physicist Frank Geurts has achieved a major milestone in particle physics by measuring the temperature of quark-gluon plasma (QGP) at different stages of its evolution. This plasma is a form of matter thought to have filled the universe only millionths of a second after the big bang, the event that marks the universe's origin and expansion. The results, published Oct. 14 in Nature Communications, offer a rare look at the extreme conditions that shaped the early cosmos.  Tracking Heat in the Early Universe Measuring temperatures in environments where no instrument can physically survive has long challenged scientists. The team overcame this by studying thermal electron-positron pairs released during high-speed collisions of atomic nuclei at the Relativistic Heavy Ion Collider (RHIC) at Brookhaven National Laboratory in New York. These emissions provided a way to reconstruct how hot the plasma became as it formed and cooled. Earlier temperature estimates had been uncertain, often distorted by motion within the plasma that created Doppler-like shifts or by confusion about whether the readings reflected the plasma itself or later stages of its decay. \"Our measurements unlock QGP's thermal fingerprint,\" said Geurts, a professor of physics and astronomy and co-spokesperson of the RHIC STAR collaboration. \"Tracking dilepton emissions has allowed us to determine how hot the plasma was and when it started to cool, providing a direct view of conditions just microseconds after the universe's inception.\" Opening a New Thermal Window The quark-gluon plasma is a unique state of matter where the basic building blocks of protons and neutrons, quarks and gluons, exist freely rather than being confined inside particles. Its behavior depends almost entirely on temperature. Until now, scientists lacked the tools to peer into this hot, fast-expanding system without distorting the results. With QGP reaching temperatures of several trillion Kelvins, the challenge was to find a \"thermometer\" capable of observing it without interference.  \"Thermal lepton pairs, or electron-positron emissions produced throughout the QGP's lifetime, emerged as ideal candidates,\" Geurts said. \"Unlike quarks, which can interact with the plasma, these leptons pass through it largely unscathed, carrying undistorted information about their environment.\" Detecting these fleeting pairs among countless other particles required extremely sensitive equipment and meticulous calibration. Experimental Breakthrough at RHIC To achieve this, the team refined RHIC's detectors to isolate low-momentum lepton pairs and reduce background noise. They tested the idea that the energy distribution of these pairs could directly reveal the plasma's temperature. The approach, known as a penetrating thermometer, integrates emissions across the QGP's entire lifetime to produce an average thermal profile. Despite challenges in distinguishing genuine thermal signals from unrelated processes, the researchers obtained highly precise measurements. Distinct Temperature Stages Revealed The results showed two clear temperature ranges, depending on the mass of the emitted dielectron pairs. In the low-mass range, the average temperature reached about 2.01 trillion Kelvin, consistent with theoretical predictions and with temperatures observed when the plasma transitions into ordinary matter. In the higher mass range, the average temperature was around 3.25 trillion Kelvin, representing the plasma's earlier, hotter phase.  This contrast suggests that low-mass dielectrons are produced later in the plasma's evolution, while high-mass ones come from its initial, more energetic stage. \"This work reports average QGP temperatures at two distinct stages of evolution and multiple baryonic chemical potentials, marking a significant advance in mapping the QGP's thermodynamic properties,\" Geurts said. Mapping Matter Under Extreme Conditions By precisely measuring the temperature of the QGP at different points in its evolution, scientists gain crucial experimental data needed to complete the \"QCD phase diagram,\" which is essential for mapping out how fundamental matter behaves under immense heat and density, akin to conditions that existed moments after the big bang and are present in cosmic phenomena like neutron stars. \"Armed with this thermal map, researchers can now refine their understanding of QGP lifetimes and its transport properties, thus improving our understanding of the early universe,\" Geurts said. \"This advancement signifies more than a measurement; it heralds a new era in exploring matter's most extreme frontier.\" Contributors to the study include former Rice postdoctoral associate Zaochen Ye (now at South China Normal University), Rice alumnus Yiding Han (now at Baylor College of Medicine), and current Rice graduate student Chenliang Jin. The work was supported by the U.S. Department of Energy Office of Science.", "release_time": "2025-10-29", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251029002907.htm"}
{"category": "政策计划", "title": "巴西风电产业政策宣言：应对危机与规划未来", "short_summary": "巴西风电业发布政策宣言，警示危机并规划复苏路径，呼吁协调行动保障能源转型。", "detailed_summary": "巴西风电业发布政策宣言，警示危机并规划复苏路径，呼吁协调行动保障能源转型。\n（1）巴西风电产业面临宏观与微观双重危机，包括投资下降、弃风限电及分布式发电冲击。\n（2）产业提出2030/2050年复苏愿景，聚焦数据中心、绿氢、海上风电及储能等新增长点。\n（3）宣言呼吁政府与监管机构采取紧急行动，明确风险划分、加强电网规划及刺激需求。", "raw_content": "With COP30 coming up, and Brazil as a co-host, it’s important to engage society and investors in the implementation of climate decisions. Read the English translation below or download the Manifesto in Portuguese here.     WIND ENERGY INDUSTRY STATEMENT  - URGENCY AND SUSTAINABLE RECOVERY    We present this positioning with a deep sense of responsibility and urgency to address the future of the wind energy industry in Brazil. It is well known that the renewables sector, especially wind energy, is the fundamental pillar of our future and is key to the future climate and the global economy. However, the future requires specific care for this sector to survive.      BRAZIL AT THE GLOBAL FOREFRONT AND THE COMMITMENT TO COP 30  With COP 30 approaching, the world is watching. This is the time to demonstrate, with concrete actions, that Brazil is a consistent global climate leader. This leadership is not a mere rhetoric, but rather a practice built on regulatory predictability and the creation of conditions for the continued expansion of the economy's decarbonization. This means strong investment in renewable energy, an essential element for accelerating the energy transition and achieving global goals. We recognize the joint efforts of the government and institutions that, over the past 15 years, have brought credibility to the country, stimulated investment, and consolidated Brazil as a global leader in clean energy by transforming and diversifying its renewable energy matrix through hydroelectric plants and transforming the socioeconomic reality of several regions, generating jobs, income, and local development through investments in wind energy.      THE WARNING: THE CRISIS AND THE RISK OF CURTAILMENT (THE MACRO-CRISIS AND THE MICRO-CRISIS)  The Brazilian wind industry is a success story. Clean, competitive, nationalized, with over 35 GW installed and the second-largest source of electricity generation in Brazil, having already invested over US$42 billion, it is a global benchmark in renewable energy.    However, this historic advancement is under significant threat. Since 2022, we have been experiencing a severe decline in new wind project contracts, worsening in 2023 and 2024.    This decline is not a one-off. It reflects a macro-crisis that combines economic and structural factors: low economic growth, political instability, successive recessions, the prolonged effects of the pandemic, and a sharp rise in the Selic rate, which jumped from 10.5% to 15% from one year to the next, increasing the cost of capital and hindering investment.  But there is a previously silent structural factor that now demands urgent attention: the uncoordinated expansion of distributed micro and mini-generation. Although it represents progress in democratising access to energy, its rise, based on poorly calibrated subsidies, without any corresponding contribution, and systemic management, has generated profound distortions in the Brazilian electricity sector.    DG displaces consumers from the captive market, distorts cost allocation, compromises the predictability of distributors' revenues, and directly threatens the expansion of centralised renewable generation, especially wind power, but also centralised solar power. The result is clear: discouragement of investment, reversal of an industry that was 80% nationalised and had local jobs, mass layoffs on the factory floor, and the decommissioning of several production lines. We are facing a crisis that is not just cyclical. It is a systemic crisis.    In addition, we face a micro-crisis within the renewable sector itself, further exacerbated by the MMGD: generation curtailments, or curtailments. This refers to the forced reduction or shutdown of electricity generation, even when the plant is technically capable of producing, for reasons beyond the control of the National System Operator. In Brazil, this occurs primarily due to excess generation relative to demand, transmission infrastructure limitations, and the need to maintain the stability of the National Interconnected System. However, these curtailments are worrying and cause severe impacts:      They jeopardise the economic and financial sustainability of companies, resulting in billion-dollar losses.  Losses for wind farms of nearly R$6 billion, with 32 TWh curtailed (October 2021 to September 2025). It's like having the equivalent of almost a Belo Monte dam shut down for a year. They discourage the production chain and national industry;  They drive away investors seeking security and stability, increasing the perceived risk of new projects;  And more recently, they threaten the very operation of the Brazilian electrical system, with a real risk of blackouts, given the loss of control over the interconnected system.    Brazil has one of the most integrated and efficient electrical systems in the world. When viewed from the perspective of future economic models, it highlights us as a global benchmark in the energy transition. The SIN is a major achievement for the country, allowing us to take advantage of the highly renewable energy matrix, especially in times of climate variability or seasonality. But we cannot compromise this achievement without appropriate policy adjustments, energy planning, and improved regulation.    Along these lines, this manifesto is an urgent call to action. It is essential to review the legal and regulatory framework for the country's energy industry to ensure balance among the various stakeholders, protect the system's predictability, and preserve the expansion of structuring renewable sources. Wind energy is strategic for Brazil, for decarbonization, energy security, and industrial development, in addition to being key to the global energy transition. We cannot allow a lack of institutional coordination to compromise decades of progress.    3.⁠ ⁠THE VISION OF RECOVERY: NEW FRONTIERS FOR 2030 AND 2050  Despite the difficult times, the industry projects a strong recovery starting in 2027, driven by strategic demands that reinforce the role of our renewable energy matrix as a clean, competitive, and low-carbon source:    Data Centres and AI: The demand for high and continuous energy consumption for Artificial Intelligence is the main short-term focus, with contracts for considerable amounts of energy, some already underway. In just three years, data centers have consolidated themselves as new players, with R$7.7 billion in long-term contracts (between 2021 and 2024) and an average of 330 MW already contracted.  Green Hydrogen (H₂V): The expansion of renewable hydrogen production will be a major growth driver, especially in the medium-term perspective. • Offshore Expansion: Offshore wind energy is the new frontier, with more than 100 projects in licensing and expected to operate after 2030, with the potential to generate hundreds of thousands of jobs and billions in investments.  Energy Storage Systems: Integrating battery storage systems with wind generation represents a milestone in the modernization of the SEB (Brazilian Electricity System). This association will enable curtailment mitigation; stabilization of the SIN (National Electricity System); decarbonisation; and tariff affordability.      THE URGENCY OF THE PRESENT  To transform this vision into reality, urgent and coordinated actions are essential:      It is essential that federal, state, and municipal governments, Congress, and regulators work together to preserve achievements and expand the socioeconomic benefits of wind generation.     Delimiting Generator Risks: It is essential to clearly establish the boundaries of responsibilities and risks between the generator and the electrical system. Generation interruptions resulting from structural or operational limitations of the SIN (National Electricity System) must be duly compensated, ensuring legal certainty and economic predictability for wind investments.  Resuming Planning: The success of wind energy in Brazil was built on planning, long-term vision, and institutional coordination.   We need to restore this standard, with public policies that reflect the complexity of the energy matrix and the strategic value of the sector.     Infrastructure Investment: It is imperative to accelerate the expansion of transmission lines and the introduction of storage systems. Without this, the energy generated by our winds will continue to be cut and wasted. We need to ensure that the energy from our strong winds reaches those who truly need it.  Demand-Based Development: Clean energy needs to be recognized and incorporated as a driver of development. It is urgent to promote policies that stimulate renewable consumption in industry, transportation, and the electrification of the economy, ensuring that demand keeps pace with supply and that Brazil advances as a hub for low-carbon products and services, while contributing to solving the climate crisis.  Brazil has the potential and the duty to lead the global energy transition. This manifesto is a call to collective responsibility. We call on all industry stakeholders, policymakers, investors, and civil society to join forces to ensure that planning and coordination are resumed and that the country's winds blow again to drive our development, our industry, and our energy future.", "release_time": "2025-10-29", "source_institution": "全球风能理事会", "url": "https://www.gwec.net/gwec-news/brazil-wind-power-wind-energy-industry-manifesto"}
{"category": "研究前沿", "title": "MIT研发微型天线实现体内植入设备无线供电", "short_summary": "MIT开发沙粒大小天线，可注射供电心脏起搏器等深部植入设备。", "detailed_summary": "MIT开发沙粒大小天线，可注射供电心脏起搏器等深部植入设备。\n(1) MIT媒体实验室研发出200微米微型天线，尺寸如沙粒，可通过注射植入人体；\n(2) 天线采用磁致伸缩与压电薄膜层压技术，在低频（109kHz）工作避免组织加热；\n(3) 相比传统金属线圈天线，功率提升4-5个数量级，支持电池免植入；\n(4) 技术有望用于心脏起搏器、神经调节器和葡萄糖监测等深部医疗设备；\n(5) 外部磁场设备如贴片即可激活，推动微创生物电子设备发展。", "raw_content": "Researchers from the MIT Media Lab have developed an antenna — about the size of a fine grain of sand — that can be injected into the body to wirelessly power deep-tissue medical implants, such as pacemakers in cardiac patients and neuromodulators in people suffering from epilepsy or Parkinson’s disease.“This is the next major step in miniaturizing deep-tissue implants,” says Baju Joy, a PhD student in the Media Lab’s Nano-Cybernetic Biotrek research group. “It enables battery-free implants that can be placed with a needle, instead of major surgery.”A paper detailing this work was published in the October issue of IEEE Transactions on Antennas and Propagation. Joy is joined on the paper by lead author Yubin Cai, PhD student at the Media Lab; Benoît X. E. Desbiolles and Viktor Schell, former MIT postdocs; Shubham Yadav, an MIT PhD student in media arts and sciences; David C. Bono, an instructor in the MIT Department of Materials Science and Engineering; and senior author Deblina Sarkar, the AT&T Career Development Associate Professor at the Media Lab and head of the Nano-Cybernetic Biotrek group.Deep-tissue implants are currently powered either with a several-centimeters-long battery that is surgically implanted in the body, requiring periodic replacement, or with a surgically placed magnetic coil, also of a centimeter-scale size, that can harvest power wirelessly. The coil method functions only at high frequencies, which can cause tissue heating, limiting how much power can be safely delivered to the implant when miniaturized to sub-millimeter sizes.“After that limit, you start damaging the cells,” says Joy.As is stated in the team’s IEEE Transactions on Antennas and Propagation paper, “developing an antenna at ultra-small dimensions (less then 500 micrometers) which can operate efficiently in the low-frequency band is challenging.”The 200-micrometer antenna — developed through research led by Sarkar — operates at low frequencies (109 kHz) thanks to a novel technology in which a magnetostrictive film, which deforms when a magnetic field is applied, is laminated with a piezoelectric film, which converts deformation to electric charge. When an alternating magnetic field is applied, magnetic domains within the magnetostrictive film contort it in the same way that a piece of fabric interwoven with pieces of metal would contort if subjected to a strong magnet. The mechanical strain in the magnetostrictive layer causes the piezoelectric layer to generate electric charges across electrodes placed above and below.“We are leveraging this mechanical vibration to convert the magnetic field to an electric field,” Joy says.Sarkar says the newly developed antenna delivers four to five orders of magnitude more power than implantable antennas of similar size that rely on metallic coils and operate in the GHz frequency range.“Our technology has the potential to introduce a new avenue for minimally invasive bioelectric devices that can operate wirelessly deep within the human body,” she says.The magnetic field that activates the antenna is provided by a device similar to a rechargeable wireless cell phone charger, and is small enough to be applied to the skin as a stick-on patch or slipped into a pocket close to the skin surface.Because the antenna is fabricated with the same technology as a microchip, it can be easily integrated with already-existing microelectronics.“These electronics and electrodes can be easily made to be much smaller than the antenna itself, and they would be integrated with the antenna during nanofabrication,” Joy says, adding that the researchers’ work leverages 50 years of research and development applied to making transistors and other electronics smaller and smaller. “The other components can be tiny, and the entire system can be placed with a needle injection.”Manufacture of the antennas could be easily scaled up, the researchers say, and multiple antennas and implants could be injected to treat large areas of the body.Another possible application of this antenna, in addition to pacemaking and neuromodulation, is glucose sensing in the body. Circuits with an optical sensor for detecting glucose already exist, but the process would benefit greatly with a wireless power supply that can be non-invasively integrated inside of the body.“That’s just one example,” Joy says. “We can leverage all these other techniques that are also developed using the same fabrication methods, and then just integrate them easily to the antenna.”", "release_time": "2025-10-30", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/injectable-antenna-could-safely-power-deep-tissue-medical-implants-1029"}
{"category": "研究前沿", "title": "MIT研究揭示睡眠不足致注意力丧失机制", "short_summary": "睡眠不足引发脑脊液波动清除代谢废物，但导致注意力瞬间下降。", "detailed_summary": "睡眠不足引发脑脊液波动清除代谢废物，但导致注意力瞬间下降。\n（1）MIT研究发现睡眠不足时大脑会启动类似睡眠的清洁机制，即脑脊液波动以清除代谢废物；\n（2）这种脑脊液波动会导致注意力瞬间丧失，表现为任务反应变慢或完全错过刺激；\n（3）研究通过结合脑电图和功能磁共振成像技术，监测26名志愿者在睡眠充足和不足状态下的生理指标；\n（4）注意力丧失时还伴随心率下降、呼吸减缓及瞳孔收缩等全身性生理变化；\n（5）研究表明可能存在统一神经回路同时调控高级认知功能（如注意力）和基本生理过程（如脑脊液流动）。", "raw_content": "Nearly everyone has experienced it: After a night of poor sleep, you don’t feel as alert as you should. Your brain might seem foggy, and your mind drifts off when you should be paying attention.A new study from MIT reveals what happens inside the brain as these momentary failures of attention occur. The scientists found that during these lapses, a wave of cerebrospinal fluid (CSF) flows out of the brain — a process that typically occurs during sleep and helps to wash away waste products that have built up during the day. This flushing is believed to be necessary for maintaining a healthy, normally functioning brain.When a person is sleep-deprived, it appears that their body attempts to catch up on this cleansing process by initiating pulses of CSF flow. However, this comes at a cost of dramatically impaired attention.“If you don’t sleep, the CSF waves start to intrude into wakefulness where normally you wouldn’t see them. However, they come with an attentional tradeoff, where attention fails during the moments that you have this wave of fluid flow,” says Laura Lewis, the Athinoula A. Martinos Associate Professor of Electrical Engineering and Computer Science, a member of MIT’s Institute for Medical Engineering and Science and the Research Laboratory of Electronics, and an associate member of the Picower Institute for Learning and Memory.Lewis is the senior author of the study, which appears today in Nature Neuroscience. MIT visiting graduate student Zinong Yang is the lead author of the paper.Flushing the brainAlthough sleep is a critical biological process, it’s not known exactly why it is so important. It appears to be essential for maintaining alertness, and it has been well-documented that sleep deprivation leads to impairments of attention and other cognitive functions.During sleep, the cerebrospinal fluid that cushions the brain helps to remove waste that has built up during the day. In a 2019 study, Lewis and colleagues showed that CSF flow during sleep follows a rhythmic pattern in and out of the brain, and that these flows are linked to changes in brain waves during sleep.That finding led Lewis to wonder what might happen to CSF flow after sleep deprivation. To explore that question, she and her colleagues recruited 26 volunteers who were tested twice — once following a night of sleep deprivation in the lab, and once when they were well-rested.In the morning, the researchers monitored several different measures of brain and body function as the participants performed a task that is commonly used to evaluate the effects of sleep deprivation.During the task, each participant wore an electroencephalogram (EEG) cap that could record brain waves while they were also in a functional magnetic resonance imaging (fMRI) scanner. The researchers used a modified version of fMRI that allowed them to measure not only blood oxygenation in the brain, but also the flow of CSF in and out of the brain. They also measured each subject’s heart rate, breathing rate, and pupil diameter.The participants performed two attentional tasks while in the fMRI scanner, one visual and one auditory. For the visual task, they had to look at a screen that had a fixed cross. At random intervals, the cross would turn into a square, and the participants were told to press a button whenever they saw this happen. For the auditory task, they would hear a beep instead of seeing a visual transformation.Sleep-deprived participants performed much worse than well-rested participants on these tasks, as expected. Their response times were slower, and for some of the stimuli, the participants never registered the change at all.During these momentary lapses of attention, the researchers identified several physiological changes that occurred at the same time. Most significantly, they found a flux of CSF out of the brain just as those lapses occurred. After each lapse, CSF flowed back into the brain.“The results are suggesting that at the moment that attention fails, this fluid is actually being expelled outward away from the brain. And when attention recovers, it’s drawn back in,” Lewis says.The researchers hypothesize that when the brain is sleep-deprived, it begins to compensate for the loss of the cleansing that normally occurs during sleep, even though these pulses of CSF flow come with the cost of attention loss.“One way to think about those events is because your brain is so in need of sleep, it tries its best to enter into a sleep-like state to restore some cognitive functions,” Yang says. “Your brain’s fluid system is trying to restore function by pushing the brain to iterate between high-attention and high-flow states.”A unified circuitThe researchers also found several other physiological events linked to attentional lapses, including decreases in breathing and heart rate, along with constriction of the pupils. They found that pupil constriction began about 12 seconds before CSF flowed out of the brain, and pupils dilated again after the attentional lapse.“What’s interesting is it seems like this isn’t just a phenomenon in the brain, it’s also a body-wide event. It suggests that there’s a tight coordination of these systems, where when your attention fails, you might feel it perceptually and psychologically, but it’s also reflecting an event that’s happening throughout the brain and body,” Lewis says.This close linkage between disparate events may indicate that there is a single circuit that controls both attention and bodily functions such as fluid flow, heart rate, and arousal, according to the researchers.“These results suggest to us that there’s a unified circuit that’s governing both what we think of as very high-level functions of the brain — our attention, our ability to perceive and respond to the world — and then also really basic fundamental physiological processes like fluid dynamics of the brain, brain-wide blood flow, and blood vessel constriction,” Lewis says.In this study, the researchers did not explore what circuit might be controlling this switching, but one good candidate, they say, is the noradrenergic system. Recent research has shown that this system, which regulates many cognitive and bodily functions through the neurotransmitter norepinephrine, oscillates during normal sleep.The research was funded by the National Institutes of Health, a National Defense Science and Engineering Graduate Research Fellowship, a NAWA Fellowship, a McKnight Scholar Award, a Sloan Fellowship, a Pew Biomedical Scholar Award, a One Mind Rising Star Award, and the Simons Collaboration on Plasticity in the Aging Brain.", "release_time": "2025-10-29", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/your-brain-without-sleep-1029"}
{"category": "研究前沿", "title": "MIT研究利用燃烧科学推动能源转型", "short_summary": "MIT团队探索燃烧合成电池材料与金属燃料，助力可再生能源存储与应用。", "detailed_summary": "MIT团队探索燃烧合成电池材料与金属燃料，助力可再生能源存储与应用。\n（1）Sili Deng教授领导MIT研究团队，致力于通过燃烧科学减少对化石燃料的依赖，推动可再生能源存储。\n（2）研究聚焦三个方向：燃烧过程与排放的基础研究、开发铝等金属作为替代燃料、利用火焰合成技术制造电池材料。\n（3）团队开发火焰辅助喷雾热解技术，可降低锂离子电池正极材料制造成本，支持电动汽车和电网储能。\n（4）探索金属燃烧应用，如利用丰富且廉价的铝燃料，旨在优化其燃烧特性用于民用领域。\n（5）研究成果获燃烧学会奖项认可，为能源转型提供创新技术路径。", "raw_content": "Around 80 percent of global energy production today comes from the combustion of fossil fuels. Combustion, or the process of converting stored chemical energy into thermal energy through burning, is vital for a variety of common activities including electricity generation, transportation, and domestic uses like heating and cooking — but it also yields a host of environmental consequences, contributing to air pollution and greenhouse gas emissions.Sili Deng, the Doherty Chair in Ocean Utilization and associate professor of mechanical engineering at MIT, is leading research to drive the transition from the heavy dependence on fossil fuels to renewable energy with storage.“I was first introduced to flame synthesis in my junior year in college,” Deng says. “I realized you can actually burn things to make things, [and] that was really fascinating.”        Play video                         Burning Things to Make Things  Video: Department of Mechanical Engineering                  Deng says she ultimately picked combustion as a focus of her work because she likes the intellectual challenge the concept offers. “In combustion you have chemistry, and you have fluid mechanics. Each subject is very rich in science. This also has very strong engineering implications and applications.”Deng’s research group targets three areas: building up fundamental knowledge on combustion processes and emissions; developing alternative fuels and metal combustion to replace fossil fuels; and synthesizing flame-based materials for catalysis and energy storage, which can bring down the cost of manufacturing battery materials.One focus of the team has been on low-cost, low-emission manufacturing of cathode materials for lithium-ion batteries. Lithium-ion batteries play an increasingly critical role in transportation electrification (e.g., batteries for electric vehicles) and grid energy storage for electricity that is generated from renewable energy sources like wind and solar. Deng’s team has developed a technology they call flame-assisted spray pyrolysis, or FASP, which can help reduce the high manufacturing costs associated with cathode materials.FASP is based on flame synthesis, a technology that dates back nearly 3,000 years. In ancient China, this was the primary way black ink materials were made. “[People burned] vegetables or woods, such that afterwards they can collect the solidified smoke,” Deng explains. “For our battery applications, we can try to fit in the same formula, but of course with new tweaks.”The team is also interested in developing alternative fuels, including looking at the use of metals like aluminum to power rockets. “We’re interested in utilizing aluminum as a fuel for civil applications,” Deng says, because aluminum is abundant in the earth, cheap, and it’s available globally. “What we are trying to do is to understand [aluminum combustion] and be able to tailor its ignition and propagation properties.”Among other accolades, Deng is a 2025 recipient of the Hiroshi Tsuji Early Career Researcher Award from the Combustion Institute, an award that recognizes excellence in fundamental or applied combustion science research.", "release_time": "2025-10-30", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/burning-things-to-make-things-sili-deng-1029"}
{"category": "研究前沿", "title": "MIT研究揭示美国幼儿园阅读筛查效果不佳", "short_summary": "MIT研究发现美国幼儿园阅读能力筛查因教师培训不足等问题未能有效帮助阅读困难儿童。", "detailed_summary": "MIT研究发现美国幼儿园阅读能力筛查因教师培训不足等问题未能有效帮助阅读困难儿童。\n(1) MIT研究人员调查约250名教师，评估美国幼儿园阅读筛查测试的实施效果。\n(2) 研究发现多数教师缺乏足够培训，44%教师培训时间不足一小时或完全无培训。\n(3) 筛查实施环境不佳，80%教师报告测试过程被打断，40%在嘈杂走廊进行测试。\n(4) 对英语学习者的评估存在困难，导致这些学生被过度识别或识别不足。\n(5) 仅44%教师表示学校有根据筛查结果制定正式干预计划的流程，筛查潜力未发挥。\n(6) 研究者建议加强教师培训、改善测试环境、指定专人分析数据以提升筛查效果。", "raw_content": "In most states, schools are required to screen students as they enter kindergarten — a process that is meant to identify students who may need extra help learning to read. However, a new study by MIT researchers suggests that these screenings may not be working as intended in all schools.The researchers’ survey of about 250 teachers found that many felt they did not receive adequate training to perform the tests, and about half reported that they were not confident that children who need extra instruction in reading end up receiving it.When performed successfully, these screens can be essential tools to make sure children get the extra help they need to learn to read. However, the new findings suggest that many school districts may need to tweak how they implement the screenings and analyze the results, the researchers say.“This result demonstrates the need to have a systematic approach for how the basic science on how children learn to read is translated into educational opportunity,” says John Gabrieli, the Grover Hermann Professor of Health Sciences and Technology, a professor of brain and cognitive sciences, and a member of MIT’s McGovern Institute for Brain Research.Gabrieli is the senior author of the new open-access study, which appears today in Annals of Dyslexia. Ola Ozernov-Palchik, an MIT research scientist who is also a research assistant professor at Boston University Wheelock College of Education and Human Development, is the lead author of the study.Boosting literacyOver the past 20 years, national reading proficiency scores in the United States have trended up, but only slightly. In 2022, 33 percent of fourth-graders achieved reading proficiency, compared to 29 percent in 1992, according to the National Assessment of Educational Progress reading report card. (The highest level achieved in the past 20 years was 37 percent, in 2017.)In hopes of boosting those rates, most states have passed laws requiring students to be screened for potential reading struggles early in elementary school. In most cases, the screenings are required two or three times per year, in kindergarten, first grade, and second grade.These tests are designed to identify students who have difficulty with skills such as identifying letters and the sounds they make, blending sounds to make words, and recognizing words that rhyme. Students with low scores in these measures can then be offered extra interventions designed to help them catch up.“The indicators of future reading disability or dyslexia are present as early as within the first few months of kindergarten,” Ozernov-Palchik says. “And there’s also an overwhelming body of evidence showing that interventions are most effective in the earliest grades.”In the new study, the researchers wanted to evaluate how effectively these screenings are being implemented in schools. With help from the National Center for Improving Literacy, they posted on social media sites seeking classroom teachers and reading specialists who are responsible for administering literacy screening tests.The survey respondents came from 39 states and represented public and private schools, located in urban, suburban, and rural areas. The researchers asked those teachers dozens of questions about their experience with the literacy screenings, including questions about their training, the testing process itself, and the results of the screenings.One of the significant challenges reported by the respondents was a lack of training. About 75 percent reported that they received fewer than three hours of training on how to perform the screens, and 44 percent received no training at all or less than an hour of training.“Under ideal conditions, there is an expert who trains the educators, they provide practice opportunities, they provide feedback, and they observe the educators administer the assessment,” Ozernov-Palchik says. “None of this was done in many of the cases.”Instead, many educators reported that they spent their own time figuring out how to give the evaluations, sometimes working with colleagues. And, new hires who arrived at a school after the initial training was given were often left on their own to figure it out.Another major challenge was suboptimal conditions for administering the tests. About 80 percent of teachers reported interruptions during the screenings, and 40 percent had to do the screens in noisy locations such as a school hallway. More than half of the teachers also reported technical difficulties in administering the tests, and that rate was higher among teachers who worked at schools with a higher percentage of students from low socioeconomic (SES) backgrounds.Teachers also reported difficulties when it came to evaluating students categorized as English language learners (ELL). Many teachers relayed that they hadn’t been trained on how to distinguish students who were having trouble reading from those who struggled on the tests because they didn’t speak English well.“The study reveals that there’s a lot of difficulty understanding how to handle English language learners in the context of screening,” Ozernov-Palchik says. “Overall, those kids tend to be either over-identified or under-identified as needing help, but they’re not getting the support that they need.”Unrealized potentialMost concerning, the researchers say, is that in many schools, the results of the screening tests are not being used to get students the extra help that they need. Only 44 percent of the teachers surveyed said that their schools had a formal process for creating intervention plans for students after the screening was performed.“Even though most educators said they believe that screening is important to do, they’re not feeling that it has the potential to drive change the way that it’s currently implemented,” Ozernov-Palchik says.In the study, the researchers recommended several steps that state legislatures or individual school districts can take to make the screening process run more smoothly and successfully.“Implementation is the key here,” Ozernov-Palchik says. “Teachers need more support and professional development. There needs to be systematic support as they administer the screening. They need to have designated spaces for screening, and explicit instruction in how to handle children who are English language learners.”The researchers also recommend that school districts train an individual to take charge of interpreting the screening results and analyzing the data, to make sure that the screenings are leading to improved success in reading.In addition to advocating for those changes, the researchers are also working on a technology platform that uses artificial intelligence to provide more individualized instruction in reading, which could help students receive help in the areas where they struggle the most.The research was funded by Schmidt Futures, the Chan Zuckerberg Initiative for the Reach Every Reader project, and the Halis Family Foundation.", "release_time": "2025-10-30", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/study-identifying-kids-who-need-help-learning-read-isnt-easy-1029"}
{"category": "研究前沿", "title": "量子传感器网络实现高精度暗物质探测", "short_summary": "东北大学团队利用超导量子比特网络提升传感器灵敏度，为暗物质探测开辟新途径。", "detailed_summary": "东北大学团队利用超导量子比特网络提升传感器灵敏度，为暗物质探测开辟新途径。\n（1）日本东北大学研究团队提出利用超导量子比特构建网络化量子传感器的新方法；\n（2）通过环状、线状等网络结构优化，结合变分量子计量学与贝叶斯估计技术提升探测精度；\n（3）实验证明四比特和九比特网络在噪声环境下仍优于传统探测方案；\n（4）该技术有望应用于暗物质探测、引力波监测及量子雷达等领域；\n（5）研究成果发表于2025年10月《物理评论D》，为精密测量技术提供新范式。", "raw_content": "Detecting dark matter, the invisible substance thought to keep galaxies intact, remains one of the most enduring mysteries in physics. Although it cannot be directly observed or touched, researchers suspect that dark matter leaves behind faint traces. These subtle signals might be detectable using advanced quantum technologies that can sense extremely small disturbances.  A team at Tohoku University has proposed a new strategy to make quantum sensors more powerful by linking them together in carefully designed networks. These sensors rely on the principles of quantum physics to measure minute fluctuations that ordinary instruments would miss. By connecting them in optimized patterns, the researchers believe it may be possible to detect the elusive fingerprints of dark matter with unprecedented precision. Superconducting Qubits Become Cosmic Detectors The research centers on superconducting qubits, tiny electronic circuits kept at extremely low temperatures. These qubits are typically used in quantum computers, but in this case they act as ultrasensitive detectors. The concept is similar to teamwork -- while a single sensor might struggle to pick up a weak signal, a coordinated network of qubits can amplify and identify it far more effectively. To test this concept, the team experimented with several types of network structures, including ring, line, star, and fully connected configurations. They built systems using four and nine qubits and then applied variational quantum metrology (a technique that works much like training a machine-learning algorithm) to fine-tune how quantum states were prepared and measured. To further improve accuracy, they used Bayesian estimation to reduce noise, similar to sharpening a blurred photograph. Strong Results Show Real-World Potential The optimized networks consistently outperformed conventional approaches, even when realistic noise was added. This result suggests that the method could already be implemented on existing quantum devices.  \"Our goal was to figure out how to organize and fine-tune quantum sensors so they can detect dark matter more reliably,\" explained Dr. Le Bin Ho, the study's lead author. \"The network structure plays a key role in enhancing sensitivity, and we've shown it can be done using relatively simple circuits.\" Beyond the hunt for dark matter, these quantum sensor networks could drive major advances in technology. Potential applications include quantum radar, gravitational wave detection, and highly accurate timekeeping. In the future, the same approach could help improve GPS precision, enhance MRI brain scans, and even reveal hidden underground structures. \"This research shows that carefully designed quantum networks can push the boundaries of what is possible in precision measurement,\" Dr. Ho added. \"It opens the door to using quantum sensors not just in laboratories, but in real-world tools that require extreme sensitivity.\" Next Steps for Quantum Research Looking ahead, the Tohoku University team plans to expand this method to larger sensor networks and develop techniques to make them more resilient against noise. Their findings were published in Physical Review D on October 1, 2025.", "release_time": "2025-10-29", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251029002923.htm"}
{"category": "研究前沿", "title": "氨基酸稳定蛋白药物机制获突破性发现", "short_summary": "国际团队揭示氨基酸稳定蛋白药物通用机制，可显著提升胰岛素等药物有效性。", "detailed_summary": "国际团队揭示氨基酸稳定蛋白药物通用机制，可显著提升胰岛素等药物有效性。\n(1) 国际研究团队在《自然》杂志发表突破性研究，揭示了氨基酸稳定蛋白质药物的通用机制；\n(2) 研究发现氨基酸像\"魔术贴碎片\"附着在蛋白质表面，防止其聚集失效，提高药物生物利用度；\n(3) 实验证明添加脯氨酸可使胰岛素在血液中的有效性提高一倍，糖尿病患者可能减少用药剂量；\n(4) 该理论不仅适用于蛋白质药物，也对其他胶体系统具有稳定作用，为药物配方设计提供新思路；\n(5) 这一发现有望快速应用于生物制药领域，改善胰岛素、疫苗等蛋白药物的安全性和有效性。", "raw_content": "Many modern medicines, including insulin and some vaccines, are made from proteins — complex molecules that perform specific functions in the body. Proteins are delicate: If they stick together or break down, the medicine can become less effective. Scientists have long sought ways to keep these drugs stable during manufacturing, storage, and use.Amino acids have been used as stabilizers for protein-based therapies, but there was no general understanding of how they worked. Now, an international research team has reported new findings that could guide their use and improve the longevity and effectiveness of some pharmaceuticals. For example, adding the amino acid proline to insulin makes it twice as effective in the bloodstream, meaning diabetics could need fewer doses.To understand these results, the researchers developed a general theory explaining how amino acids stabilize proteins. The open-access findings were reported recently in the journal Nature, by a team of researchers at MIT, École Polytechnique Fédérale de Lausanne (EPFL) in Switzerland, and the Southern University of Science and Technology in China.Alfredo Alexander-Katz, the Michael (1949) and Sonja Koerner Professor of Materials Science and Engineering at MIT and a co-corresponding author of the paper, explains that amino acids are part of the life cycle of materials inside living cells. “The cell makes proteins and then breaks them,” he says. “I wouldn’t say it’s a perfect recycler, but it does recycle a lot of the material that it makes.”After making proteins for specific purposes in the cell’s metabolism, the cell breaks them down into their component amino acids once their job is done, ready to be reassembled into new proteins for the next job.The team discovered that free amino acids floating in the cell have an important effect on how proteins and other molecules interact, helping maintain balance and stability. “The regulation of protein-protein interactions is really key,” he says, “I would say it’s important for formulations, but also for the life cycle of cells.”Science that sticksAlthough pharmaceutical makers were aware of the stabilizing effect of amino acids on some treatments, the underlying mechanism was unclear.Inspired by early results from EPFL Professor Francesco Stellacci’s research group, Alexander-Katz, a theorist by training, began investigating. “The original results that Francesco shared with me showed generality — he could stabilize proteins as well as synthetic nanoparticles,” he recalls.That led him to think of proteins as balls with Velcro-like patches: They stick to each other and form clumps, leaving less surface exposed to interact with water and other essential materials, which limits how well protein-based medicines such as insulin can do their job.But if amino acids act like loose bits of Velcro floating around, they can attach to those surface patches on the protein balls, blocking them from clumping and improving the effectiveness of the pharmaceutical protein.After sending his proposed theory off to his collaborators, Alexander-Katz recalls, “I was thinking, ‘Well, this is not going to work. This is too simple.’” But after some clever tweaking by the EPFL team, he received graphs of experimental tests and saw that “the thing works. It fits all our experimental data.”It took nearly another year of experiments and analysis to further confirm the findings. “We were able to corroborate independently that the numbers we were getting from fitting the theory were actually matching numbers that you would get experimentally.”The theory may have even broader implications. These amino acids “will provide stability to proteins, but also to other colloids as well, so it’s not a protein-specific effect.” Colloids are suspensions of solid particles in a liquid — anything from a glass of milk to quicksand. The team also showed that combinations of molecules can produce the same stabilizing effect.In cells, Alexander-Katz says, “somehow, biology uses the ‘trash’ it broke down and makes it into pieces to regulate important processes.”For example, salt is known to destabilize biological systems. “If you put salty water on a plant, it’ll start producing more amino acids. Part of it is to counteract the osmotic effects,” Alexander-Katz explains, describing the stress caused by the salt, “but part of it may very well be to give stability to the protein suspension in the cell. The salt will destabilize the proteins, and the amino acids will counteract by stabilizing them.”The process happens through very weak interactions. “These are interactions that you can barely measure, but there are a lot of them, and this will definitely have a strong effect.” He adds that it happens broadly: “Most amino acids will do it.”A new way to stabilize drugsThe findings could have wide-ranging implications. Biologicals — medicines such as insulin, vaccines, or gene therapies derived from living organisms — are an increasingly important part of medicine, Alexander-Katz says. “More and more, we’re looking into therapeutics that are derived from proteins, and having a method to stabilize them — because you normally want to have them at high concentrations and keep a stable shelf life — that is really important.”“﻿Protein drugs have become some or our most important therapeutics against a variety of diseases, and the need to generate better formulations to improve safety and efficacy of these drug products is only growing,” says Eric Appel, an associate professor of materials science and bioengineering and Lee Otterson Endowed Faculty Scholar at Stanford University, who was not connected to this research.He notes that new approaches like this one are essential for developing next-generation drug products that can address critical unmet medical needs. “I’m excited to see how the approaches developed in this work can lead to new formulations of promising protein drugs that have the potential to improve treatment outcomes and benefit patients.”While amino acids have been used as stabilizers before, “our contribution is that there might be a more rational way to think about this,” Alexander-Katz says. “In the future, we could enable basically rational design of these formulations for pharma or other industries.”Putting theory to the testIn the insulin experiment, the team showed the process works with molecules of great medical interest. By treating the insulin molecules with proline, “it makes it much more bioavailable,” Alexander-Katz says, referring to how much of the drug reaches the bloodstream. “Its activity increases dramatically, so it’s not just more stable, but it’s also more active.”Because the amino acids tested are already in standard medical use, there should be little regulatory issue in applying this new method, Alexander-Katz says. “This could move more quickly into the real world than traditionally.”“There could be really interesting applications of what we learn here for multiple diseases,” he adds, “and I hope the industry embraces this and uses it for the betterment of human health.”The team’s lead authors were Ting Mao, Xufeng Xu, Pamina Winkler, and Cécilia Siri at EPFL, and the corresponding authors, in addition to Alexander-Katz, were Zhi Luo at Southern University of Science and Technology in Shenzhen, China, and Quy Ong and Francesco Stellacci at EPFL.The work was supported by the Swiss National Science Foundation, the Horizon 2020 Research and Innovation program of the European Union, and the Nestlé Research Foundation.", "release_time": "2025-10-29", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/designing-better-longer-lasting-medicines-1028"}
{"category": "研究前沿", "title": "MIT研发新型结晶法大幅降低基因疗法成本", "short_summary": "MIT团队开发高效结晶纯化技术，可将基因疗法药物成本降低5至10倍。", "detailed_summary": "MIT团队开发高效结晶纯化技术，可将基因疗法药物成本降低5至10倍。\n(1) 基因疗法成本高昂，主要因制造过程中高达90%为非活性空衣壳，现有色谱纯化法效率低、耗时长且成本占制造总成本70%。\n(2) MIT研究团队创新性地将小分子制药中使用的优先结晶法应用于蛋白质纯化，利用空衣壳与满载衣壳的电荷密度差异进行分离。\n(3) 新方法纯化时间从40小时缩短至4小时，效率提升10倍，产品损失极低且纯度极高，无需繁琐的前后处理步骤。\n(4) 该技术有望使基因疗法药物成本降低5到10倍，已申请专利并正与药企洽谈试验，预计几年内可实现商业化。", "raw_content": "Some of the most expensive drugs currently in use are gene therapies to treat specific diseases, and their high cost limits their availability for those who need them. Part of the reason for the cost is that the manufacturing process yields as much as 90 percent non-active material, and separating out these useless parts is slow, leads to significant losses, and is not well adapted to large-scale production. Separation accounts for almost 70 percent of the total gene therapy manufacturing cost. But now, researchers at MIT’s Department of Chemical Engineering and Center for Biomedical Innovation have found a way to greatly improve that separation process.The findings are described in the journal ACS Nano, in a paper by MIT Research Scientist Vivekananda Bal, Edward R. Gilliland Professor Richard Braatz, and five others.“Since 2017, there have been around 10,000 clinical trials of gene therapy drugs,” Bal says. Of those, about 60 percent are based on adeno-associated virus, which is used as a carrier for the modified gene or genes. These viruses consist of a sort of shell structure, known as capsids, that protects the genetic material within, but the production systems used to manufacture these drugs tend to produce large quantities of empty capsids with no genetic material inside.These empty capsids, which can make up anywhere from half to 90 percent of the yield, are useless therapeutically, and in fact can be counterproductive because they can add to any immune reaction in the patient without providing any benefit. They must be removed prior to the formulation as a part of the manufacturing process. The existing purification processes are not scalable and involve multiple stages, have long processing times, and incur high product losses and high cost. Separating full from empty capsids is complicated by the fact that in almost every way, they appear nearly identical. “They both have similar structure, the same protein sequences,” Bal says. “They also have similar molecular weight, and similar density.” Given the similarity, it’s extremely challenging to separate them. “How do you come up with a method?”Most systems presently use a method based on chromatography, in which the mixture passes through a column of absorbent material, and slight differences in the properties can cause them to pass through at different rates, so that they can be separated out. Because the differences are so slight, the process requires multiple rounds of processing, in addition to filtration steps, adding to the time and cost. The method is also inefficient, wasting up to 30 or 40 percent of the product, Bal says. And the resulting product is still only about two-thirds pure, with a third of inactive material remaining.There is another purification method that is widely used in the small molecule pharmaceutical industry, which uses a preferential crystallization process instead of chromatography, but this method had not been tried for protein purification — specifically, capsid-based drugs — before. Bal decided to try it, since with this method “its operating time is low and the product loss is also very low, and the purity achieved is very, very high because of the high selectivity,” he says. The method separates out empty from full capsids in the solution, as well as separating out cell debris and other useless material, all in one step, without requiring the significant pre-processing and post-processing steps needed by the other methods.“The time required for purification using the crystallization method is around four hours, compared to that required for the chromatography method, which is about 37 to 40 hours,” he says. “So basically, it is about 10 times more effective in terms of operating time.” This novel method will reduce the cost of gene therapy drugs by five to 10 times, he says.The method relies on a very slight difference in the electrical potential of the full versus empty capsids. DNA molecules have a slight negative charge, whereas the surface of the capsids has a positive charge. “Because of that, the overall charge density distribution of the full capsids will be different from that of the empty capsids,” he says. That difference leads to a difference in the crystallization rates, which can be used to create conditions that favor the crystallization of the full capsids while leaving the empty ones behind.Tests proved the effectiveness of the method, which can be easily adapted to large-scale pharmaceutical manufacturing processes, he says. The team has applied for a patent through MIT’s Technology Licensing Office, and is already in discussions with a number of pharmaceutical companies about beginning trials of the system, which could lead to the system becoming commercialized within a couple of years, Bal says.“They’re basically collaborating,” he says of the companies. “They’re transferring their samples for a trial with our method,” and ultimately the process will either be licensed to a company, or form the basis of a new startup company, he says.In addition to Bal and Braatz, the research team also included Jacqueline Wolfrum, Paul Barone, Stacy Springs, Anthony Sinskey, and Robert Kotin, all of MIT’s Center for Biomedical Innovation. The work was supported by the Massachusetts Life Sciences Center, Sanofi S.A., Sartorius AG, Artemis Life Sciences, and the U.S. Food and Drug Administration.", "release_time": "2025-10-29", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/new-method-could-improve-manufacturing-gene-therapy-drugs-1028"}
{"category": "研究前沿", "title": "IAEA展望：聚变能源未来或占全球电力半壁江山", "short_summary": "MIT模型预测聚变能源未来占比最高可达50%，经济价值达数万亿美元。", "detailed_summary": "MIT模型预测聚变能源未来占比最高可达50%，经济价值达数万亿美元。\n（1）国际原子能机构《世界聚变展望》首次纳入全球聚变能源部署模型。\n（2）麻省理工学院研究探索不同政策、成本和技术假设下聚变能源的未来贡献。\n（3）在最低资本成本情景下，聚变发电占比到2100年最高可达50%。\n（4）即使在最高成本情景下，聚变能源占比仍预计达到10%。\n（5）研究强调聚变能源可满足清洁电力需求，并为全球GDP增加数万亿美元。", "raw_content": "3. Fusion Set to Play Big Role in Future Electricity Mix  Fusion energy is projected to play a significant role in meeting the world’s growing demand for clean, baseload power. For the first time, the IAEA World Fusion Outlook includes global modelling of fusion energy deployment, conducted by the Massachusetts Institute of Technology (MIT). The study explores how fusion could contribute to the future electricity mix under diverse policy, cost and technological assumptions. In the lowest capital cost scenario of US $2.8K/kW in 2050, fusion’s share of electricity generation could reach up to 50% by 2100. Even in the highest cost scenario of US $11.3K/kW, fusion energy is projected to reach 10% of global electricity generation by 2100.  The modelling also highlights fusion’s economic value: with a rise in demand for clean electricity generation, fusion could add trillions of dollars to global GDP.", "release_time": "2025-10-29", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/fusion-energy-in-2025-six-global-trends-to-watch"}
{"category": "产业应用", "title": "日立铁路全球首发NVIDIA IGX Thor平台赋能智慧交通", "short_summary": "日立铁路引入NVIDIA最强AI平台，提升铁路边缘计算与预测性维护能力。", "detailed_summary": "日立铁路引入NVIDIA最强AI平台，提升铁路边缘计算与预测性维护能力。\n（1）日立铁路成为全球首家运输公司采用NVIDIA IGX Thor平台，并将其集成至HMAX数字资产管理平台；\n（2）IGX Thor提供高达8倍AI算力和2倍连接性，实现关键任务的实时边缘AI处理；\n（3）该技术将数据处理时间从十天缩短至实时，优化列车、信号和基础设施的性能与预测性维护；\n（4）此举契合日立集团利用Lumada 3.0解决方案推动AI基础设施的战略，强化交通生态系统；\n（5）合作旨在提升铁路可靠性、效率和可持续性，支持全球交通数字化转型。", "raw_content": "Hitachi Rail the first transport company globally to adopt NVIDIA IGX Thor platform and will offer the world-leading technology to its customers through its HMAX digital asset management platform IGX Thor offers up to 8x higher AI compute and 2x better connectivity while delivering real-time sensor processing, AI reasoning, functional safety and long-term enterprise support Initiative with NVIDIA complements the Hitachi Group's strategy of harnessing the power of AI with infrastructure expertise, using its Lumada 3.0 solutions      Washington, D.C., October 28, 2025 Hitachi Rail announced today that it is to become the first transportation company in the world to include NVIDIA's latest and most powerful platform - NVIDIA IGX Thor – in is its AI-led digital asset management platform, HMAX. The new IGX Thor platform will provide up to 8x higher AI compute and 2x better connectivity for Hitachi Rail's HMAX products. The world-leading industrial-grade system is enabling Hitachi Rail to offer customers enhanced, real-time edge AI processing for mission critical applications – that are fundamental to the operational running and optimizing the performance of trains, signalling and infrastructure. The integration of the NVIDIA IGX Thor platform in Hitachi Rail's HMAX platform allows powerful real time processing of very large volumes of data at the 'edge' (on the trains or infrastructure). Without this edge capability it could take up to ten days for data to be processed in Hitachi Rail's maintenance locations. By using cutting edge AI based algorithms, the HMAX platform ensures only relevant information is sent back to the operational control centers. This improved capability enables an unprecedented improvement in the speed that actionable insights can be shared with transport operators, dramatically enhancing the potential for railway optimization and predictive maintenance. Giuseppe Marino, Group CEO of Hitachi Rail, said: “AI and data are transforming railways. By adopting NVIDIA IGX Thor, we are bringing the world's most powerful industrial-grade, real-time AI performance directly to the edge, enabling operators better optimize their railways and infrastructure. This capability will strengthen reliability, efficiency and optimization for passengers and operators alike.” The adoption of IGX Thor aligns with Hitachi's broader programme to apply trusted AI and data technologies across the transport ecosystem. In September 2024, the company launched HMAX, a digital asset management suite for trains, signalling and infrastructure. In September 2025, Hitachi Rail officially opened its $100M lighthouse digital factory just outside Washington D.C. to deliver the next generation of high quality metro trains for North America, while achieving operational excellence through Group's expertise and deployment of “physical-world AI”. This latest initiative with NVIDIA builds on the Hitachi Group's focus to harness the power of AI infrastructure through its Lumada 3.0 solutions. Earlier this month, Hitachi Ltd. announced a partnership with OpenAI to develop sustainable power and cooling infrastructure for future AI data centres – reinforcing the Group's commitment to responsible, industrial-scale AI. By showcasing powerful digital and transformative technologies for customers and partners, the Hitachi Group aims to address customer challenges internationally as One Hitachi, further expanding and deploying HMAX across a wide range of industries and business sectors. About Hitachi, Ltd.  Through its Social Innovation Business (SIB) that brings together IT, OT(Operational Technology) and products, Hitachi contributes to a harmonized society where the environment, wellbeing, and economic growth are in balance. Hitachi operates globally in four sectors – Digital Systems & Services, Energy, Mobility, and Connective Industries – and the Strategic SIB Business Unit for new growth businesses. With Lumada at its core, Hitachi generates value from integrating data, technology and domain knowledge to solve customer and social challenges. Revenues for FY2024 (ended March 31, 2025) totaled 9,783.3 billion yen, with 618 consolidated subsidiaries and approximately 280,000 employees worldwide. Visit us at www.hitachi.com. About Hitachi Rail:  Hitachi Rail is committed to driving the sustainable mobility transition and has a clear focus on partnering with customers to rethink mobility. Its mission is to help every passenger, customer and community enjoy the benefits of more connected, seamless and sustainable transport.  With revenues of over €7bn and 24,000 employees across more than 50 countries, Hitachi Rail is a trusted partner to the world's best transport organisations. The company's reach is global, but the business is local - with success built on developing local talent and investing in people and communities.  Its international capabilities and expertise span every part of the urban, mainline and freight rail ecosystems – from high quality manufacturing and maintenance of rolling stock to secure digital signalling, smart operations and payment systems.  Hitachi Rail, famous for Japan's iconic high speed bullet train, draws on the digital and AI expertise of Hitachi Group companies to accelerate innovation and develop new technologies. Hitachi Group's revenues for FY2024 (ended March 31, 2025) totalled €581.6 bn / ¥9,783.3 bn, with 618 consolidated subsidiaries and approximately 280,000 employees worldwide.  Find out more by visiting hitachirail.com or our press site here.  Information contained in this news release is current as of the date of the press announcement, but may be subject to change without prior notice.", "release_time": "2025-11-18", "source_institution": "日本日立", "url": "http://www.hitachi.com/New/cnews/month/2025/10/251029.html"}
{"category": "产业应用", "title": "日立与美商务部签署电网升级合作备忘录", "short_summary": "日立携手美商务部推进电网现代化与小型核反应堆建设，助力AI革命与能源安全。", "detailed_summary": "日立携手美商务部推进电网现代化与小型核反应堆建设，助力AI革命与能源安全。\n（1）日立公司与美国商务部签署谅解备忘录，旨在促进能源基础设施投资，支持数据中心供电和可持续AI革命；\n（2）合作内容包括扩大变压器生产能力，评估能源技术本地化，并加速审批流程以实现及时投资；\n（3）日立将利用其在核电站设计和制造方面的专业经验，支持小型模块化反应堆BWRX-300的建设；\n（4）此次合作基于日立2025年9月宣布的10亿美元美国投资，以应对AI数据中心带来的电力设备需求增长；\n（5）合作旨在增强美国能源安全、弹性和技术领导力，同时促进高质量就业和创新。", "raw_content": "The signing of the MoU between Hitachi and DOC on strengthening the power grids   Tokyo, Japan, October 28, 2025 - Hitachi, Ltd. (TSE: 6501, “Hitachi”) today announced that it welcomes the strategic investments published by the governments of Japan and the United States. The fact sheet includes essential projects for ensuring stable power supply and advancing AI revolution in the United States, such as initiatives aimed at grid modernization and electrification, and construction for small modular reactors (SMRs), “BWRX-300,” the next generation of nuclear power. Hitachi will contribute to these projects by leveraging its collective business strengths as “True One Hitachi.” To advance grid modernization and electrification initiatives, today, Hitachi signed a Memorandum of Understanding (MoU) with the United States Department of Commerce (“DOC”). This agreement aims to promote investment in energy infrastructure that is essential for powering data centers and drive the sustainable AI revolution. Based on the MoU, Hitachi is exploring further expansion of Hitachi Energy's manufacturing activities, including additional transformer production capacity, and will evaluate further opportunities to localize the production of other energy technologies in the United States. Hitachi strives to enhance energy security, resilience, and technological leadership, while also supporting the growth of high-quality employment and innovation across American communities. Hitachi will also consult with DOC regarding accelerating permitting and approval processes for timely and effective realization of these investments. The BWRX-300 is a small light-water reactor that enhances economic efficiency while maintaining advanced safety. GE Vernova Hitachi Nuclear Energy*1, a subsidiary of GE Vernova is leading its development and overseas deployment. With a proven track record in the design, procurement, and manufacturing of nuclear power plants, and deep technical expertise, Hitachi is committed to supporting SMR construction through the provision of equipment and engineering services - helping to ensure a stable power supply that meets the growing electricity demand.  *1 GE Vernova holds 60% of the shares in GE Vernova Hitachi Nuclear Energy while Hitachi holds 40%.  Toshiaki Tokunaga, President & CEO, Hitachi, Ltd.: “Energy is the lifeblood of economic strength in the 21st century. As strongly supported by today's announcement, Hitachi stands with both governments of Japan and the United States in advancing the global infrastructure and AI innovation. As a trusted partner in social innovation powered by AI, we are committed as True One Hitachi to address U.S. infrastructure challenges to build a better and more sustainable society.” Hitachi's contribution to modernizing the U.S. grid In September 2025, Hitachi already announced a historic $1 billion investment in the United States*2, the largest investment seen in the electrical industry in the country to meet growing demand for power transformers and high-voltage equipment driven by the expansion of AI data centers. In addition to this investment, Hitachi is exploring further expansion of its production capacity in the United States.  *2 Press release on Sep 4, 2025, Hitachi announces historic $1 billion USD manufacturing investment to power America's energy future through production of critical grid infrastructure  Hitachi's contribution to SMR development The BWRX-300 has been selected for the first SMR project in North America, the Darlington New Nuclear Project, and is currently under construction in Canada with GE Vernova Hitachi Nuclear Energy as the technology partner. Ontario Power Generation plans to connect it to the grid by the end of 2030. Committed to contributing to the realization of advanced SMR, Hitachi GE Vernova Nuclear Energy*3, a subsidiary of Hitachi, will provide engineering and leverage its experienced domestic supply chains in Japan to ensure the delivery of reliable key reactor components for the first unit*4, in collaboration with GE Vernova Hitachi Nuclear Energy.  *3 Hitachi holds 80.01% of the shares in Hitachi GE Vernova Nuclear Energy while GE Vernova holds 19.99%. *4 Press release on May 9, 2025, Hitachi-GE Nuclear Energy announces supply of key reactor components for OPG's Darlington New Nuclear Project  About Hitachi, Ltd.  Through its Social Innovation Business (SIB) that brings together IT, OT(Operational Technology) and products, Hitachi contributes to a harmonized society where the environment, wellbeing, and economic growth are in balance. Hitachi operates globally in four sectors – Digital Systems & Services, Energy, Mobility, and Connective Industries – and the Strategic SIB Business Unit for new growth businesses. With Lumada at its core, Hitachi generates value from integrating data, technology and domain knowledge to solve customer and social challenges. Revenues for FY2024 (ended March 31, 2025) totaled 9,783.3 billion yen, with 618 consolidated subsidiaries and approximately 280,000 employees worldwide. Visit us at www.hitachi.com.  Information contained in this news release is current as of the date of the press announcement, but may be subject to change without prior notice.", "release_time": "2025-11-18", "source_institution": "日本日立", "url": "http://www.hitachi.com/New/cnews/month/2025/10/251028b.html"}
{"category": "研究前沿", "title": "日本初创公司实现仿星器核聚变超导线圈突破", "short_summary": "Helical Fusion完成世界首次仿星器全功能HTS超导线圈测试，推动商业化核聚变发电。", "detailed_summary": "Helical Fusion完成世界首次仿星器全功能HTS超导线圈测试，推动商业化核聚变发电。\n（1）日本Helical Fusion公司实现仿星器技术路线里程碑，完成世界首次全功能HTS超导线圈性能测试；\n（2）测试在15K温度、7特斯拉磁场强度下实现40KA稳定超导电流，且线圈无电气绝缘；\n（3）该公司计划2030年代建成全球首个仿星器技术商业核聚变电站，耗资50亿美元；\n（4）商业目标需满足24小时稳定运行、发电量高于输入量及可维护性三大要求。", "raw_content": "快科技10月27日消息，相比当前的核裂变技术，核聚变有着理论上无限的发电能力，是人类无尽能源的终极方案，现在多个大国都在积极建设核聚变发电站，快的甚至2年后就能发发点。    日本在这个领域同样野心勃勃，而且今天他们的一家初创公司Helical Fusion实现了一个新纪录，在核聚变商业化上取得了里程碑，世界首次实现了仿星器技术上的全功能HTS超导线圈性能测试。 理解这个技术需要明白核聚变的2个路线——大家中学时都知道核聚变需要极高的温度，没有金属能承受上亿度的高温，只能采用磁约束，这就有托卡马克及Stellarator仿星器两种技术之分。 具体技术细节说起来很长，国际原子能机构有过简单的解释，托卡马克在保持等离子体温度方面更出色，而仿星器在保持等离子体稳定方面更出色，但它更复杂，难度高。 全球目前大约有60个托卡马克和10个仿星器在运行，而日本这家公司实现的突破就是仿星器路线上的。 Helical Fusion自称是全球唯一一个建立在Helical Stellarator仿星器技术的公司，有着日本研究所和大学60多年的技术积累，过公司正在推动HPLF计划，要实现全球首个使用该技术的商业核聚变发电站。 这次的试验简单来说就是成功验证了HTS超导磁体线圈的性能，主要有三个方面的突破，一个是HTS线圈是基于商业核聚变发电而设计的，而是复现了核聚变装置的磁场环境，包括自生及外部磁场，三是成功进行了超导条件下的电流试验。 这次试验成功验证了15K温度（-258度）下7特斯拉磁场强度下40KA的稳定超导电流，而且HTS线圈没有电气绝缘，这也是世界上首个成功进行无绝缘大规模高温超导线圈测试的。 该公司的计划是2030年代建设全球首个商业化的核聚变发电站，该项目将耗资50亿美元。 此外，它要满足三个商业可行的基本要求，分别是24x7x365稳定运行，产生的电量高于输入电量以及可维护性。", "release_time": "2025-10-28", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195410-1.html"}
{"category": "研究前沿", "title": "MIT学者探究常规战争与核升级风险关联", "short_summary": "Talmadge研究独裁政权军队效能及常规军事行动如何增加核冲突风险。", "detailed_summary": "Talmadge研究独裁政权军队效能及常规军事行动如何增加核冲突风险。\n（1）MIT政治学系副教授Caitlin Talmadge专注研究核安全政策，特别关注常规战争如何引发核升级风险；\n（2）其研究发现独裁政权为\"防政变\"而优化军队内部管控，会削弱对外作战能力，这一理论解释了俄罗斯在乌克兰战争中的表现；\n（3）新书研究主张某些核升级风险是政府有意设计的威慑策略，而非单纯军事计划失控；\n（4）作为MIT核安全政策中心核心成员，她致力于搭建学者与政策制定者的对话平台；\n（5）研究强调控制核风险需更多关注文职政府的战略决策而非单纯军事行为。", "raw_content": "Nuclear security can be a daunting topic: The consequences seem unimaginable, but the threat is real. Some scholars, though, thrive on the close study of the world’s most dangerous weapons. That includes Caitlin Talmadge PhD ’11, an MIT faculty member who is part of the Institute’s standout group of nuclear security specialists.Talmadge, who joined the MIT faculty in 2023, has become a prominent scholar in security studies, conducting meticulous research about militaries’ on-the-ground capabilities and how they are influenced by political circumstances.Earlier in her career, Talmadge studied the military capabilities of armies run by dictatorships. For much of the last decade, though, she has focused on specific issues of nuclear security: When can conventional wars raise risks of nuclear use? In what circumstances will countries ratchet up nuclear threats?“A scenario that’s interested me a lot is one where the conduct of a conventional war actually raises specific nuclear escalation risks,” Talmadge says, noting that military operations may put pressure on an adversary’s nuclear capabilities. “There are many other instabilities in the world. But I’ve gotten pretty interested in what it means that the U.S., unlike in the Cold War when there was more of a bipolar competition, now faces multiple nuclear-armed adversaries.”MIT is a natural intellectual home for Talmadge, who is the Raphael Dorman and Helen Starbuck Associate Professor in MIT’s Department of Political Science. She is also part of MIT’s Security Studies Program, long the home of several of the Institute’s nuclear experts, and a core member of the recently launched MIT Center for Nuclear Security Policy, which supports scholarship as well as engagement with nuclear security officials.“I think dialogue for practitioners and scholars is important for both sides,” says Talmadge, who served on the Defense Policy Board, a panel of outside experts that directly advises senior Pentagon leaders, during the Biden administration. “It’s important for me to do scholarship that speaks to real-world problems. And part of what we do at MIT is train future practitioners. We also sometimes brief current practitioners, meet with them, and get a perspective on the very difficult problems they encounter. That interaction is mutually beneficial.”Why coup-proofing hurts armiesFrom a young age, Talmadge was interested in global events, especially military operations, while growing up in a family that supported her curiosity about the world.“I was fortunate to have parents that encouraged those interests,” Talmadge says. “Education was a really big value in our family. I had great teachers as well.”Talmadge earned her BA degree at Harvard University, where her interests in international relations and military operations expanded.“I didn’t even know the term security studies before I went to college,” she says. “But I did, in college, get very interested in studying the problems that had been left by the Soviet nuclear legacy.”Talmadge then worked at a think tank before deciding to attend graduate school. She had not been fully set on academia, as opposed to, say, working in Washington policy circles. But while earning her PhD at the Institute, she recalls, “it turned out that I really liked research, and I really liked teaching. And I loved being at MIT.”Talmadge is quick to credit MIT’s security studies faculty for their intellectual guidance, citing the encouragement of a slew of faculty, including Barry Posen (her dissertation advisor), Taylor Fravel, Roger Peterson, Cindy Williams, Owen Cote, and Harvey Sapolsky. Her dissertation examined the combat power of armies run by authoritarians.That research became her 2015 book, “The Dictator’s Army: Battlefield Effectiveness in Authoritarian Regimes,” published by Cornell University Press. In it she examines how, for one thing, using a military for domestic “coup-proofing” limits its utility against external forces. In the Iran-Iraq war of the 1980s, to cite one example, Iraq’s military improved in the later years of the war, after coup-proofing measures were dropped, whereas Iran’s army performed worse over time as it became more preoccupied with domestic opposition.“We tend to think of militaries as being designed for external conventional wars, but autocrats use the military for regime-protection tasks, and the more you optimize your military for doing that, sometimes it’s harder to aggregate combat power against an external adversary,” Talmadge says.In the time since that book was published, even more examples have become evident in the world.“It may be why the Russian invasion of Ukraine did so poorly in 2022,” she adds. “When you’re a personalist dictator and divide the military so it can’t be strong enough to overthrow you, and direct the intelligence apparatus internally instead of at Ukraine, it affects what your military can achieve. It was not the only factor in 2022, but I think the authoritarian character of Russia’s civil-military relations has played a role in Russia’s rather surprising underperformance in that war.”On to nuclear escalationAfter earning her PhD from MIT, Talmadge joined the faculty of George Washington University, where she taught from 2011 to 2018; she then served on the faculty at Georgetown University, before returning to MIT. And for the last decade, she has continued to study conventional military operations while also exploring the relationship between those operations and nuclear risk.One issue is that conventional military strikes that might degrade an opponent’s nuclear capabilities. Talmadge is examining why states adopt military postures that threaten adversaries in this way in a book that’s in progress; her co-author is Brendan Rittenhouse Green PhD ’11, a political scientist at the University of Cincinnati.The book focuses on why the U.S. has at times adopted military postures that increase nuclear pressure on opponents. Historically these escalatory postures have been viewed as unintentional, the result of aggressive military planning.“In this book we make a different argument, which is that often these escalatory risks are hardwired into force posture deliberately and knowingly by civilian [government leaders] who at times have strategic rationales,” Talmadge says. “If you’re my opponent and I want to deter you from starting a war, it might be helpful to convince you that if you start that war, you’re eventually going to be backed into a nuclear corner.”This logic may explain why many countries adopt force postures that seem dangerous, and it may offer clues as to how future wars involving the U.S., Russia, China, North Korea, India, or Pakistan could unfold. It also suggests that reining in nuclear escalation risk requires more attention to civilian decisions, not just military behavior.While being in the middle of research, book-writing, teaching, and engaging with others in the field, Talmadge is certain she has landed in an ideal academic home, especially with MIT’s work in her field being bolstered by the Stanton Foundation gift to establish the Center for Nuclear Security Policy.“We’re so grateful for the support of the Stanton Foundation,” Talmadge says. “It’s incredibly invigorating to be in a place with so much talent and just constantly learning from the people around you. It’s really amazing, and I do not take it for granted.”She adds: “It is a little surreal at times to be here because I’m going into the same rooms where I have memories as myself as a grad student, but now I’m the professor. I have a little bit of nostalgia. But one of my primary reasons for coming to MIT, besides the great faculty colleagues, was the students, including the chance to work with the PhD students in the Security Studies Program, and I have not been disappointed. It doesn’t feel like work. It’s a joy to try to have a positive influence helping them become scholars.”", "release_time": "2025-10-28", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/studying-war-new-nuclear-age-caitlin-talmadge-1028"}
{"category": "产业应用", "title": "罗马尼亚煤炭重镇启动3.8亿欧元绿色能源转型", "short_summary": "Turceni煤电站转向农光互补与绿氢项目，推动地区公正能源转型。", "detailed_summary": "Turceni煤电站转向农光互补与绿氢项目，推动地区公正能源转型。\n（1）罗马尼亚煤炭重镇Turceni启动3.8亿欧元绿色能源项目，以取代即将关闭的煤电站；\n（2）项目内容包括农光互补园区、储能设施及绿色氢能的生产储存；\n（3）利用超过370公顷土地，涉及市政与私人土地，获欧洲投资银行等机构支持；\n（4）旨在促进该地区公正转型，应对煤炭淘汰带来的经济威胁；\n（5）项目计划于明年实施，将互补当地其他脱碳投资。", "raw_content": "近日，罗马尼亚煤炭重镇Turceni(图尔切尼)市政当局宣布，当地正转向农光互补、储能和绿色氢能以取代煤电。这座位于罗马尼亚西南部的小镇正启动一项3.8亿欧元的项目。    Turceni(图尔切尼)的煤电站曾是欧洲最大的煤电站之一,装机容量达2.3吉瓦。该电站位于罗马尼亚Gorj(戈尔日)煤炭产区的同名小镇旁,目前仅有两台机组仍在运行,总装机容量为660兆瓦。与此同时,欧洲数十家此类设施正提前关闭。该电站及其相关矿场隶属于Complexul Energetic Turceni(图尔切尼能源综合体),一直是当地经济的支柱,而随着国家逐步淘汰煤炭,当地经济面临毁灭性威胁。 与欧盟其他煤炭产区一样,解决方案在于绿色能源和新技术。市政厅已与欧洲投资银行(European Investment Bank)签署合同,连同罗马尼亚当地一家跨国咨询公司WIDE ADVOCACY SRL开发农光互补园区、储能设施以及绿色氢能的生产和储存。 市长Constantin Popescu(康斯坦丁·波佩斯库)透露,该项目价值高达3.8亿欧元。Turceni(图尔切尼)及其行政区域的居民不到七千人。市长强调,超过123公顷的市政土地(牧场)和超过200公顷的私人土地被指定用于这个可再生能源中心。 该项目的合作伙伴包括Bankwatch Romania(罗马尼亚银行观察组织)和GAL Sudul Gorjului,即Gorj(戈尔日)南部地方行动小组，以及跨国合规咨询公司WIDE ADVOCACY SRL（维德咨询公司）。Bankwatch表示,超过370公顷的土地将转为清洁和可持续能源生产。 WIDE ADVOCACY SRL创始人Ciprian Boboi补充道:\"我们很高兴在制定项目计划、使其符合欧洲环境政策以及申请技术援助方面发挥了重要作用。对于一个数十年来一直是燃煤能源支柱的地区而言,这个项目标志着战略性转型:向基于创新、可持续性和强大合作伙伴关系的未来过渡。\" 项目计划于明年开始实施。Popescu(波佩斯库)市长表示,该项目将通过增加可再生能源发电量,促进该地区的公正转型。他说,这将与地方当局其他正在进行和未来的脱碳投资形成互补。（林嘉欣）", "release_time": "2025-10-27", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195358-1.html"}
{"category": "产业应用", "title": "阿联酋启动全球最大光储一体化项目", "short_summary": "全球最大光储项目奠基，中国电建承建部分工程，助力减排与就业。", "detailed_summary": "全球最大光储项目奠基，中国电建承建部分工程，助力减排与就业。\n(1) 阿联酋启动全球首个且规模最大的太阳能发电与储能一体化项目，装机容量5.2GW、储能19GWh。\n(2) 项目总投资超220亿迪拉姆（约426.56亿元人民币），预计2027年投运，可创造约1万个就业岗位。\n(3) 采用人工智能预测系统、虚拟电厂及智能电网技术，实现1GW清洁电力全天候供应。\n(4) 中国电建负责北侧区块建设，包括2.1GW光伏和7.6GWh储能。\n(5) 项目投运后每年可减少约570万吨二氧化碳排放，助力绿色能源发展。", "raw_content": "据驻阿拉伯联合酋长国经济商务处消息，近日，阿联酋总统办公厅副主任谢赫齐亚布·本·穆罕默德·本·扎耶德·阿勒纳哈扬出席全球首个、规模最大的太阳能发电与储能一体化项目奠基仪式。 该项目由“马斯达尔”和阿联酋水电公司联合开发，装机容量5.2GW、储能19GWh，总投资超220亿迪拉姆(约426.56亿元人民币)，预计2027年投运，可创造约1万个就业岗位，每年减少约570万吨二氧化碳排放。项目采用人工智能预测系统、虚拟电厂及智能电网技术，实现1GW清洁电力全天候供应。 据悉，该项目整个工程分为南北两个区块，中国电建负责其中北侧区块，包括2.1GW光伏和7.6GWh储能。南侧区块由另一家国际公司承建。", "release_time": "2025-10-27", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195322-1.html"}
{"category": "研究前沿", "title": "再生医学先驱杨纳斯逝世 人造皮肤发明者享年90岁", "short_summary": "MIT教授杨纳斯逝世，其发明的人造皮肤开创再生医学领域，拯救无数烧伤患者。", "detailed_summary": "MIT教授杨纳斯逝世，其发明的人造皮肤开创再生医学领域，拯救无数烧伤患者。\n（1）MIT教授Ioannis V. Yannas于10月19日逝世，享年90岁，他是物理化学家和工程师；\n（2）其最大贡献是与John Burke合作发明人造皮肤，使用硅胶外层和牛腱鲨鱼软骨分子支架；\n（3）该发明于1981年成功，成为首例成人器官再生案例，产品Integra广泛用于严重烧伤治疗；\n（4）研究还推进胶原蛋白管治疗周围神经损伤，并开创了再生医学新领域；\n（5）曾获美国国家医学院院士等荣誉，其工作对糖尿病皮肤溃疡等治疗也有重要应用。", "raw_content": "Professor Ioannis V. Yannas SM ’59, a physical chemist and engineer known for the invention of artificial skin for the treatment of severe burns, and a longtime member of the MIT faculty, died on Oct. 19 at the age of 90.“Professor Yannas was a beloved and distinguished colleague, teacher, and mentor. The impact of his inventions, and his legacy on the field of bioengineering was immense,” says John Hart, the Class of 1922 Professor and head of the Department of Mechanical Engineering. Yannas, known to friends and colleagues as Yanni, held appointments in the MIT Department of Mechanical Engineering and the Harvard-MIT Program in Health Sciences and Technology. His principal research interest throughout his career was the process of induced organ regeneration used to replace organs that are either severely injured or terminally diseased. His work also advanced the clinical use of collagen tubes to treat peripheral nerve injuries.In 1969, when Yannas approached the late John Burke of Massachusetts General Hospital to collaborate, Burke took him on a tour of a children’s burn unit. “There was a great deal of human misery that was confronting me, and I felt I had to do something about it,” said Yannas in later interviews. In 1981, the pair announced their success: an amalgam of a silicone outer sheet over a scaffolding of molecular material drawn from cow tendon and shark cartilage. Offering protection from infection and dehydration, the scaffolding enabled healthy skin cells to grow. Their discovery would be transformative for the treatment of burn victims.Their artificial skin, patented and now manufactured as Integra, is still widely used on patients with severe and extensive burns, and for other applications including some types of plastic surgery and the treatment of chronic skin wounds commonly suffered by people with diabetes. The groundbreaking advance, which was later recognized as the first example of organ regeneration in adults, had previously been considered impossible.        Play video                         “Hope Regenerated: A Life-Saving Discovery at MIT MechE” chronicles Professor Ioannis Yannas’ influential discovery that launched the field of regenerative medicine.  Video: Department of Mechanical Engineering                  “Yanni’s boldness in attacking a wide array of medical problems, including spinal cord transection, in his investigations of applications of collagen-based implants, inspired others, including myself, to work toward solutions to devastating conditions such as blindness, stroke, and spinal cord injury,” says Myron Spector, professor emeritus of orthopedic surgery (biomaterials) at Massachusetts General Brigham and Harvard Medical School, and an affiliate of the Harvard-MIT Program in Health Sciences and Technology. Yannas and Spector created several MIT courses together, including 2.79 (Biomaterial-Tissue Interactions).“As we were talking about the content [for 2.79], Yanni proposed that we codify the cell behavior underlying the tissue response to implants,” explains Spector. “Within a short time, we laid out the plan for ‘unit cell processes’ to offer students a code to decipher the often inconceivably complex cellular processes that not only underlie the tissue response to implants, but that can guide the selection of the tools necessary to engineer medical devices and reveal their targets for treatment. This was all Yanni, taking a fundamental concept, the control volume used in chemical engineering to analyze systems, and applying it to cellular processes in the human body. I since use UCPs myself all the time.”As a colleague serving as a collaborator in teaching and in research, Spector says Yannas was eager to help and to learn, bold in his thinking, smart in his choices, able to keep his eye on the goal, respectful of students as well as faculty and other colleagues, and selfless. “These are just the traits that we teach our students to look for when seeking the collaborators who are so necessary in science and engineering.”Yannas was born on April 14, 1935, in Athens, Greece, where he completed his high school education at Athens College. He received a BA in chemistry at Harvard College in 1957, followed by an MS in chemical engineering from MIT in 1959. After a period of industrial research on polymers at W. R. Grace & Co., in Cambridge, Massachusetts, he attended Princeton University, where he completed an MS degree in 1965 and a PhD in 1966, both in physical chemistry. Yannas joined the MIT faculty immediately thereafter and remained at the Institute for the next 59 years until his passing.        Play video                         Ioannis Yannas’ Hall of Fame Induction  Video: National Inventors Hall of Fame                  For his discoveries in organ regeneration, Yannas was elected member of the National Academy of Medicine (1987), the National Inventors Hall of Fame (2015), and the National Academy of Engineering (2017). He was also elected Fellow of the American Institute of Medical and Biomedical Engineering.Further, he was the recipient of many prestigious awards including the Society for Biomaterials Founders Award (1982) and the Society’s Clemson Award for Applied Science and Engineering (1992). He was an author of numerous journal articles, and the sole author of the influential book, “Tissue and Organ Regeneration in Adults.”Yannas’ work, and 2015 induction into the National Inventors Hall of Fame, was the subject of “Hope Regenerated,” a video produced by the MIT Department of Mechanical Engineering. The film chronicles the development of Integra, which was initially characterized as a “failed experiment” but became a life-saving discovery that launched a new field of regenerative medicine.“My father's relationship with MIT was deeply meaningful to him,” says Tania Yannas Kluzak. “He regarded MIT as the ideal partner in his life's work — pioneering lifesaving research in organ regeneration.”Yannas was predeceased by his brother, Pavlos. He is survived by his two children, Tania Kluzak and her husband Gordon, and Alexi Yannas and his wife Maria; his grandchildren — Alexandra, Marina, Sophia, Philippos, and Nefeli; his sister, Elizabeth Sitinas; and many loving relatives and friends. A celebration of life will be announced at a later date.", "release_time": "2025-10-28", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/professor-ioannis-yannas-dies-1027"}
{"category": "研究前沿", "title": "《现代能源体系指数蓝皮书2024》发布，揭示城市能源转型图景", "short_summary": "蓝皮书首评城市能源体系，揭示清洁化推进中安全与脱碳挑战并存。", "detailed_summary": "蓝皮书首评城市能源体系，揭示清洁化推进中安全与脱碳挑战并存。\n（1）《现代能源体系指数蓝皮书2024》由谢克昌院士团队主导编制并正式发布。\n（2）报告首次将评估尺度细化至全国283个地级市，新增“城市篇”。\n（3）引入莫兰指数进行空间分析，识别能源发展的区域集聚模式。\n（4）核心发现：中国能源清洁化进程持续，但能源安全与深度脱碳挑战严峻。\n（5）报告旨在为构建“清洁低碳、安全高效”的现代能源体系提供精准决策依据。", "raw_content": "近日，由中国工程院谢克昌院士、田亚峻研究员带领的泛能源大数据与战略研究中心主导，青岛能源所编制的《现代能源体系指数蓝皮书2024》（以下简称“蓝皮书”）正式发布。该报告首次将评估尺度细化至城市层面，并运用空间大数据分析，揭示了中国能源体系转型的复杂图景：虽然清洁化进程持续推进，但能源安全与深度脱碳仍面临严峻挑战。作为一份连续发布的研究报告，《现代能源体系指数蓝皮书》致力于以量化指数评估我国现代能源体系建设进程，受到广泛关注。2024版蓝皮书新增了“城市篇”，首次将评估范围从全球、国家及省区拓展至全国283个地级市，分析粒度进一步细化。此举有助于精准识别不同类型城市在能源结构优化与能效提升方面的差异，为地方制定差异化政策提供科学依据。此外，蓝皮书首次引入莫兰指数作为空间统计工具，量化区域能源发展的空间关联特征，科学识别“高-高聚类”（发达地区集聚）与“低-低聚类”（落后地区集聚）等空间模式，为跨区域协同治理与精准施策提供数据支撑。蓝皮书指出，当前能源体系建设为迈向“新型能源体系”打下基础。尽管已进入新型能源体系建设阶段，但现代能源体系作为其重要组成部分与核心基石，仍发挥着不可或缺的支撑作用。未来，推进能源转型需统筹发展与安全，在持续推进清洁替代、提升能源效率的同时，重点破解能源安全保障与深度脱碳两大核心瓶颈。通过科技赋能、机制创新与政策协同，最终构建起“清洁低碳、安全高效、多元协同、智能普惠” 的现代能源系统。值得关注的是，2024版蓝皮书的发布，标志着该指数研究正式进入第三季。相较于前两版，新版新增 “城市篇”与空间分析维度，不仅能更细致、全面地揭示能源体系转型的空间差异与内在规律，还能为新型能源体系建设提供更精准的决策依据，其支撑价值与实践意义进一步凸显。（文/图 刘媛媛）", "release_time": "2025-11-11", "source_institution": "青岛生物能源与过程研究所", "url": "https://qibebt.cas.cn/news/kyjz/202510/t20251027_7997844.html"}
{"category": "研究前沿", "title": "气候变化下植物光合作用与光呼吸研究新进展", "short_summary": "研究揭示升温与高CO2对植物光合效率及碳利用的复杂影响。", "detailed_summary": "研究揭示升温与高CO2对植物光合效率及碳利用的复杂影响。\n(1) 植物光合作用利用CO2合成糖类作为生长基础，但高温会导致光呼吸作用增强，错误捕获氧气，降低光合效率。\n(2) 研究使用拟南芥模型，在可控环境中模拟高CO2、高温及干旱条件，通过激光技术监测叶片碳转移过程。\n(3) 结果表明，气候变化下植物虽能适应，但可能改变其生长分布，如小麦带北移至加拿大，影响农业系统布局。\n(4) 该研究为应对气候变化、优化作物种植策略提供了关键科学依据。", "raw_content": "Most high school biology students learn that plants use photosynthesis to turn light into energy. That understanding just scratches the surface, said GLBRC investigator Berkley Walker, an associate professor of plant biology at Michigan State University whose research was spotlighted in a recent story by the university's College of Natural Science. Plants use that energy to capture carbon dioxide, or CO2, from the atmosphere and convert it into sugars. These sugars are the building blocks plants use to grow. From the time a seed sprouts out of the ground, a plant uses CO2 to make every compound it needs for life. \"That fundamental process of grabbing CO2 out of the atmosphere sits at the crux of how our Earth is impacted by changing CO2 and temperatures,\" Walker said. In some respects, giving plants more CO2 is like giving a person more hamburgers. If they eat more, they'll get bigger. The caveat is temperatures are also increasing. When that happens, photosynthesis gets sloppy. Occasionally, instead of grabbing carbon dioxide, a plant grabs oxygen instead. The plant is then stuck dealing with accidental oxygen molecules, a process called photorespiration. Under normal circumstances, photorespiration happens about once out of every five reactions in which a plant is supposed to grab CO2. As temperatures heat up, plants accidentally grab oxygen even more often. The result is wasted energy, and photosynthesis is less efficient. \"That's one big thing my lab looks at,\" Walker said. \"It's this interplay between, what is increasing CO2 going to do? What are increasing temperatures going to do? And how does that affect the total amount of carbon in plants, and what do they do with that carbon once they've turned it into sugars?\" To study the interplay between increasing CO2 and rising temperatures, Walker uses the plant science equivalent of a lab rat — Arabidopsis thaliana, or mouse-eared cress. The plant's six-week life cycle makes it the perfect specimen for quick study results. Walker's lab grows it in chambers that replicate high CO2, high temperature conditions. They use a laser to measure the leaf's CO2 composition before and after, giving them a snapshot of how the plant moves carbon from outside to inside the leaf. Inside the MSU Research Greenhouse Complex, Walker's lab creates programmable droughts. Each pot has its own soil moisture sensor and drip irrigation system. This gives researchers an accurate read on what happens to plants with limited water, another stressful condition that's becoming more common. Understanding how plants respond to stress will be key to preserving agricultural systems as climate change shifts growing zones north. Some models already show the wheat belt moving out of the United States and into Canada, Walker said. \"Looking toward future conditions, I think the plants will be just fine,\" Walker said. \"But as far as having the plants do what we want them to do, where we want them to do that — that may not be the case.\" Read the entire story on MSU's College of Natural Resources website.", "release_time": "2025-10-28", "source_institution": "美国能源部大湖生物能源研究中心", "url": "https://www.glbrc.org/news/seeds-hope"}
{"category": "研究前沿", "title": "MIT在恒星诞生区完成最大分子普查", "short_summary": "MIT团队在TMC-1分子云中发现百余种分子，创星际分子普查新纪录。", "detailed_summary": "MIT团队在TMC-1分子云中发现百余种分子，创星际分子普查新纪录。\n（1）MIT研究团队利用绿岸射电望远镜对金牛座分子云-1进行1400小时观测；\n（2）首次在该恒星形成区检测到102种分子，包含碳氢化合物和富氮化合物；\n（3）发现10种芳香族分子，证实恒星形成早期存在大量活性有机碳；\n（4）研究成果为理解恒星和行星形成初始化学条件提供新基准；\n（5）团队公开完整数据集，推动星际有机分子研究进一步发展。", "raw_content": "MIT researchers recently studied a region of space called the Taurus Molecular Cloud-1 (TMC-1) and discovered more than 100 different molecules floating in the gas there — more than in any other known interstellar cloud. They used powerful radio telescopes capable of detecting very faint signals across a wide range of wavelengths in the electromagnetic spectrum.With over 1,400 observing hours on the Green Bank Telescope (GBT) — the world’s largest fully steerable radio telescope, located in West Virginia — researchers in the group of Brett McGuire collected the astronomical data needed to search for molecules in deep space and have made the full dataset publicly available. From these observations, published in The Astrophysical Journal Supplement Series (ApJS), the team censused 102 molecules in TMC-1, a cold interstellar cloud where sunlike stars are born. Most of these molecules are hydrocarbons (made only of carbon and hydrogen) and nitrogen-rich compounds, in contrast to the oxygen-rich molecules found around forming stars. Notably, they also detected 10 aromatic molecules (ring-shaped carbon structures), which make up a small but significant fraction of the carbon in the cloud.“This project represents the single largest amount of telescope time for a molecular line survey that has been reduced and publicly released to date, enabling the community to pursue discoveries such as biologically relevant organic matter,” said Ci Xue, a postdoc in the McGuire Group and the project’s principal researcher. “This molecular census offers a new benchmark for the initial chemical conditions for the formation of stars and planets.”To handle the immense dataset, the researchers built an automated system to organize and analyze the results. Using advanced statistical methods, they determined the amounts of each molecule present, including variations containing slightly different atoms (such as carbon-13 or deuterium).“The data we’re releasing here are the culmination of more than 1,400 hours of observational time on the GBT, one of the NSF’s premier radio telescopes,” says McGuire, the Class of 1943 Career Development Associate Professor of Chemistry. “In 2021, these data led to the discovery of individual PAH molecules in space for the first time, answering a three-decade-old mystery dating back to the 1980s. In the following years, many more and larger PAHs have been discovered in these data, showing that there is indeed a vast and varied reservoir of this reactive organic carbon present at the earliest stages of star and planet formation. There is still so much more science, and so many new molecular discoveries, to be made with these data, but our team feels strongly that datasets like this should be opened to the scientific community, which is why we’re releasing the fully calibrated, reduced, science-ready product freely for anyone to use.”Overall, this study provides the single largest publicly released molecular line survey to date, enabling the scientific community to pursue discoveries such as biologically relevant molecules. This molecular census offers a new benchmark for understanding the chemical conditions that exist before stars and planets form.", "release_time": "2025-10-28", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/astronomical-data-collection-reveals-over-100-different-molecules-1027"}
{"category": "研究前沿", "title": "2024年全球光伏装机突破2.26TW 同比增长近29%", "short_summary": "全球光伏累计装机超2.26太瓦，2024年新增装机量同比激增29%，新兴市场成增长新动力。", "detailed_summary": "全球光伏累计装机超2.26太瓦，2024年新增装机量同比激增29%，新兴市场成增长新动力。\n(1) 2024年全球光伏累计装机量突破2.26TW，其中超47%为近三年新增；2024年新增装机量最可能达601.1GW，同比增长29%。\n(2) 增长主要驱动因素包括光伏组件降价、投资者信心提升、气候行动紧迫性以及中国消化制造业产能过剩的举措。\n(3) 全球已有35个国家实现GW级年度装机，中国以占比59.4%居首，但其全球市场集中度较三年前有所下降。\n(4) 欧洲2024年新增73.4GW，全球占比降至12%；中东地区沙特以新增3.7GW领跑，非洲则由南非主导新增1.2GW。\n(5) 报告指出离网光伏系统（微电网、独立系统）在亚非地区商业化进程加速，成为传统电网重要补充。", "raw_content": "国际能源署光伏电力系统项目(IEA-PVPS)最新报告显示，受光伏组件降价、投资者信心提升及气候行动紧迫性推动，2024年全球太阳能光伏装机量同比增长近29%。《2024年全球光伏市场快照》同步披露，全球光伏累计装机量已突破2.26TW，其中超47%为过去三年新增。 报告显示，全球已有35个国家实现GW级年度装机，非洲、阿联酋等新兴市场加速扩容，成为全球可再生能源增长的重要动力。经过两年高速增长后，2023年全球装机量已较2022年翻倍，2024年在市场波动背景下，光伏因电力供应稳定、成本可预测的优势更受青睐，增长进一步提速，同时中国在全球市场的集中度较三年前有所下降。 截至2024年末，全球光伏累计装机达2261GW，与此前2246GW的预估基本吻合。2024年新增装机最低为553.3GW，最可能达601.1GW，同比增幅29%。这一增长主要源于气候倡议推进、组件降价及中国消化制造业产能过剩的举措。 一、35国跻身GW级装机行列 目前350-435Wp户用组件已在35国规模化应用，人均拥有量约1-3块。2024年IEA-PVPS成员国装机至少485.3GW，非成员国约贡献87.4GW。其中中国以59.4%的全球装机占比居首，地位类似21世纪中期的德国，累计装机达958.5-1048.5GW。 欧洲2024年新增装机73.4GW，虽绝对值增长，但全球占比降至12%，累计装机达398.7GW。 二、欧洲商用电站光伏加速扩张 商业集中式光伏项目起源于西班牙、德国、法国，现已拓展至罗马尼亚，未来将与企业购电协议协同增长。受中国制造业产能过剩推动，大量组件流向欧洲开放市场，而非美国和印度。 开发商更倾向通过私人协议推进新建项目：或向欧美企业售电，或直供澳大利亚、保加利亚、德国等国电力市场(商用电站光伏)，纳米比亚等非洲国家也有类似布局。 三、沙特引领中东光伏增长 2024年中东新增光伏超6GW，累计达21.5GW。沙特以3.7GW新增量领跑，累计达6.7GW;阿联酋、以色列分别新增500MW、900MW。此前政府补贴制约光伏竞争力，如今伊朗、卡塔尔、沙特等八国均已上调可再生能源目标。 分布式光伏借助政策改革快速发展：埃及、迪拜推行净计量(迪拜2023年调整上限)，巴林、约旦2024年转向净计费;伊朗、以色列等国实施上网电价，卡塔尔、摩洛哥正酝酿相关政策。 阿联酋马斯达尔城、沙特斯帕克和未来城等政府背书项目成为示范标杆。沙特第六轮国家可再生能源计划招标3GW，突尼斯2024年10月推出200MW项目。约旦、埃及等国推进绿氨、绿氢项目，阿联酋聚焦钢铁脱碳，约旦还计划在亚喀巴建530GW太阳能制氨工厂。 四、南非主导非洲光伏发展 2024年非洲光伏累计装机19.2GW，新增2.6GW。因数据统计不全、离网系统未完全纳入，该地区仍是全球最小光伏市场。南非以1.2GW新增量(增速略低于2023年)居首，累计达8.7GW。 科特迪瓦50MW、博茨瓦纳100MW等多国电站项目推进中，冈比亚23MW项目已投产。赞比亚、多哥在开发带储能的电站项目，工商业装机及光伏制氢项目提速，专家认为非洲有望成为低成本绿氢供应地。 非洲电网普遍规模小(不足500MW)、稳定性差，尼日利亚、津巴布韦推广微电网但依赖赠款。尽管投资者因前期成本高持谨慎态度，但太阳能替代偏远地区柴油发电的需求持续上升，太阳能水泵等离网设备正扩大电力覆盖。政策监管被视为支撑电力需求和氢能目标的关键。 五、离网光伏开启商业化进程 在亚非地区，带备用电源的离网系统成为传统电网的重要补充，主要包括微电网和独立系统两类：微电网为家庭、小企业供电，电池延长供电时长;独立式太阳能家庭系统满足个人需求，同样靠电池提升使用效率。 太阳能水泵等离网应用正扩大平价电力覆盖。早期聚焦农村电气化的项目，如美国2005年原住民能源计划、加拿大2018年偏远社区清洁能源计划，现已升级为国家能源转型框架，强调公平性和市场化。澳大利亚2024年《国家原住民清洁能源战略》便是典型代表。", "release_time": "2025-10-27", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195320-1.html"}
{"category": "研究前沿", "title": "MIT团队利用分子实现桌面级原子核探测", "short_summary": "科学家通过测量分子内电子能量微小偏移，实现桌面级原子核内部结构探测。", "detailed_summary": "科学家通过测量分子内电子能量微小偏移，实现桌面级原子核内部结构探测。\n(1) MIT物理学家开发新型桌面级技术，利用分子环境替代传统千米级粒子对撞机探测原子核内部；\n(2) 实验通过精确测量镭-氟分子中电子能量，发现微小偏移证明电子曾短暂进入镭原子核并与核内粒子相互作用；\n(3) 镭原子核具有独特不对称梨形结构，可放大基本对称性破缺信号，有助于解释宇宙物质-反物质不对称之谜；\n(4) 该方法为首次直接探测原子核内部磁分布奠定基础，未来可通过控制分子取向精确测绘核内力场；\n(5) 研究成果发表于《科学》期刊，为在核水平检验基本物理对称性开辟新路径。", "raw_content": "Physicists at MIT have introduced a technique to study the interior of an atom's nucleus by relying on the atom's own electrons as \"messengers\" inside a molecule.  In research published on October 23 in Science, the team precisely measured the energy of electrons orbiting a radium atom that was chemically bound to a fluoride atom, forming radium monofluoride. By using the molecular environment as a microscopic stand-in for a particle collider, they confined the radium atom's electrons and increased the likelihood that some would briefly pass through the nucleus. Traditional experiments that investigate nuclear interiors depend on kilometer-scale accelerators that speed up electron beams to smash into and fragment nuclei. The new molecule-centered approach provides a compact, table-top way to directly probe the inside of a nucleus. Table-Top Method Detects Nuclear \"Messages\" Working with radium monofluoride, the researchers tracked the energies of the radium atom's electrons as they moved within the molecule. They observed a small shift in energy and concluded that some electrons must have briefly entered the nucleus and interacted with what lies inside. As those electrons left, they retained the energy change, effectively carrying a nuclear \"message\" that reveals features of the nucleus's interior. The method opens a path to measuring the nuclear \"magnetic distribution.\" Inside a nucleus, each proton and neutron behaves like a tiny magnet, and their orientations depend on how these particles are arranged. The team plans to use the technique to map this property in radium for the first time, a step that could inform one of cosmology's central puzzles: why the universe contains far more matter than antimatter. \"Our results lay the groundwork for subsequent studies aiming to measure violations of fundamental symmetries at the nuclear level,\" says study co-author Ronald Fernando Garcia Ruiz, who is the Thomas A. Franck Associate Professor of Physics at MIT. \"This could provide answers to some of the most pressing questions in modern physics.\" MIT co-authors include Shane Wilkins, Silviu-Marian Udrescu, and Alex Brinson, together with collaborators from several institutions, including the Collinear Resonance Ionization Spectroscopy Experiment (CRIS) at CERN in Switzerland, where the experiments took place.  Matter-Antimatter Imbalance and Radium's Role According to current understanding, the early universe should have contained nearly equal amounts of matter and antimatter. Yet nearly everything we can detect today is matter built from protons and neutrons inside atomic nuclei. This observation conflicts with expectations from the Standard Model, suggesting that additional sources of fundamental symmetry violation are needed to account for the scarcity of antimatter. Such effects could appear within the nuclei of certain atoms, including radium. Unlike most nuclei, which are close to spherical, radium's nucleus has an asymmetric, pear-like shape. Theorists predict that this geometry can amplify signals of symmetry violation enough to make them potentially observable. \"The radium nucleus is predicted to be an amplifier of this symmetry breaking, because its nucleus is asymmetric in charge and mass, which is quite unusual,\" says Garcia Ruiz, whose group has focused on developing methods to probe radium nuclei for signs of fundamental symmetry violation. Building Ultra-Sensitive Molecular Experiments Peering inside a radium nucleus to test fundamental symmetries is extremely challenging.  \"Radium is naturally radioactive, with a short lifetime and we can currently only produce radium monofluoride molecules in tiny quantities,\" says study lead author Shane Wilkins, a former postdoc at MIT. \"We therefore need incredibly sensitive techniques to be able measure them.\" The team recognized that embedding a radium atom in a molecule could confine and magnify the behavior of its electrons. \"When you put this radioactive atom inside of a molecule, the internal electric field that its electrons experience is orders of magnitude larger compared to the fields we can produce and apply in a lab,\" explains Silviu-Marian Udrescu PhD '24, a study co-author. \"In a way, the molecule acts like a giant particle collider and gives us a better chance to probe the radium's nucleus.\" Energy Shift Reveals Electron-Nucleus Encounters The researchers created radium monofluoride by pairing radium atoms with fluoride atoms. In this molecule, the radium electrons are effectively squeezed, which increases the chance that they will interact with and briefly enter the radium nucleus. They then trapped and cooled the molecules, guided them through vacuum chambers, and illuminated them with lasers tailored to interact with the molecules. This setup allowed precise measurements of electron energies inside each molecule. The measured energies showed a subtle difference from expectations based on electrons that do not enter the nucleus. Although the energy change was only about one millionth of the energy of the laser photon used to excite the molecules, it provided clear evidence that the electrons interacted with protons and neutrons inside the radium nucleus. \"There are many experiments measuring interactions between nuclei and electrons outside the nucleus, and we know what those interactions look like,\" Wilkins explains. \"When we went to measure these electron energies very precisely, it didn't quite add up to what we expected assuming they interacted only outside of the nucleus. That told us the difference must be due to electron interactions inside the nucleus.\" \"We now have proof that we can sample inside the nucleus,\" Garcia Ruiz says. \"It's like being able to measure a battery's electric field. People can measure its field outside, but to measure inside the battery is far more challenging. And that's what we can do now.\" Next Steps: Mapping Forces and Testing Symmetries Going forward, the team plans to apply the new technique to map the distribution of forces inside the nucleus. Their experiments have so far involved radium nuclei that sit in random orientations inside each molecule at high temperature. Garcia Ruiz and his collaborators would like to be able to cool these molecules and control the orientations of their pear-shaped nuclei such that they can precisely map their contents and hunt for the violation of fundamental symmetries. \"Radium-containing molecules are predicted to be exceptionally sensitive systems in which to search for violations of the fundamental symmetries of nature,\" Garcia Ruiz says. \"We now have a way to carry out that search.\" This research was supported, in part, by the U.S. Department of Energy.", "release_time": "2025-10-27", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/10/251026021734.htm"}
{"category": "研究前沿", "title": "单望远镜光子灯笼技术实现恒星高清成像突破", "short_summary": "新型光子灯笼设备助力单望远镜捕获恒星盘高清细节，揭示不对称结构。", "detailed_summary": "新型光子灯笼设备助力单望远镜捕获恒星盘高清细节，揭示不对称结构。\n（1）UCLA团队利用光子灯笼设备将星光分为多通道，通过计算重建实现单望远镜高分辨率成像；\n（2）该技术突破衍射极限，对162光年外的β CMi恒星盘进行观测，精度提升五倍；\n（3）首次发现恒星盘存在不对称结构，为天体物理模型提出新挑战；\n（4）技术结合自适应光学克服大气湍流，为观测更暗更远天体开辟新途径。", "raw_content": "Sharper views from a single telescope: Normally, astronomers link multiple telescopes together to get the clearest images of distant stars and galaxies. A UCLA-led team has now achieved record-breaking detail of the star beta Canis Minoris using just one telescope equipped with a breakthrough device called a photonic lantern. How it works: The photonic lantern divides starlight into many fine channels that capture subtle spatial patterns. Advanced computational techniques then combine these channels to rebuild a high-resolution image filled with details that would otherwise be lost. A new frontier for astronomy: This innovative approach could let scientists explore objects that are smaller, fainter, and farther away than ever before, offering fresh insight into the hidden structure of the universe and sparking new discoveries.A Breakthrough View From a Single Telescope For the first time, astronomers have used a new imaging method on a ground-based telescope to capture the most detailed look ever at the disk surrounding a distant star. Led by UCLA researchers, the achievement revealed hidden structures that had never been seen before. This breakthrough paves the way for scientists to study finer details of stars, planets, and other celestial objects, potentially transforming how we explore the universe. A telescope's ability to reveal faint or distant objects depends on its size. Larger telescopes can collect more light, allowing them to see dimmer targets and produce sharper images. The highest levels of detail are usually reached by linking multiple telescopes together to form an array. Building these large instruments, or connecting them, has long been the key to achieving the precision needed for discovering new cosmic features. Harnessing Light With a Photonic Lantern Using a device called a photonic lantern, astronomers can now make better use of the light gathered by a telescope to produce extremely high-resolution images. The details of this breakthrough appear in Astrophysical Journal Letters. \"In astronomy, the sharpest image details are usually obtained by linking telescopes together. But we did it with a single telescope by feeding its light into a specially designed optical fiber, called a photonic lantern. This device splits the starlight according to its patterns of fluctuation, keeping subtle details that are otherwise lost. By reassembling the measurements of the outputs, we could reconstruct a very high-resolution image of a disk around a nearby star,\" said first author and UCLA doctoral candidate Yoo Jung Kim.  The photonic lantern divides the incoming light into multiple channels based on how the light wavefront is shaped, much like separating the notes of a musical chord. It also divides light by color, creating a rainbow-like spectrum. The device was designed and built by the University of Sydney and the University of Central Florida, and it forms part of the instrument FIRST-PL, developed and led by the Paris Observatory and the University of Hawai'i. This system is installed on the Subaru Coronagraphic Extreme Adaptive Optics instrument at the Subaru Telescope in Hawai'i, which is operated by the National Astronomical Observatory of Japan. \"What excites me most is that this instrument blends cutting-edge photonics with the precision engineering done here in Hawai'i,\" said Sebastien Vievard, a faculty member in the Space Science and Engineering Initiative at the University of Hawai'i who helped lead the build. \"It shows how collaboration across the world, and across disciplines, can literally change the way we see the cosmos.\" Pushing Beyond Traditional Imaging Limits This method of separating and analyzing light enables a new way to see fine detail, achieving sharper resolution than traditional telescope cameras. \"For any telescope of a given size, the wave nature of light limits the fineness of the detail that you can observe with traditional imaging cameras. This is called the diffraction limit, and our team has been working to use a photonic lantern to advance what is achievable at this frontier,\" said UCLA professor of physics and astronomy Michael Fitzgerald. \"This work demonstrates the potential of photonic technologies to enable new kinds of measurement in astronomy,\" said Nemanja Jovanovic, a co-leader of the study at the California Institute of Technology. \"We are just getting started. The possibilities are truly exciting.\" At first, the researchers faced a major challenge: turbulence in Earth's atmosphere. The same shimmering effect that makes distant horizons appear wavy on a hot day causes starlight to flicker and distort as it travels through the air. To correct for this, the Subaru Telescope team used adaptive optics, a technology that continuously adjusts to cancel out these distortions and stabilize the light waves in real time.  \"We need a very stable environment to measure and recover spatial information using this fiber,\" said Kim. \"Even with adaptive optics, the photonic lantern was so sensitive to the wavefront fluctuations that I had to develop a new data processing technique to filter out the remaining atmospheric turbulence.\" Exploring Beta Canis Minoris in Stunning Detail The team put their technique to the test by observing the star beta Canis Minoris (β CMi), located about 162 light-years away in the constellation Canis Minor. This star is surrounded by a fast-spinning hydrogen disk. As the gas in the disk moves, the side rotating toward Earth appears bluer, while the side moving away looks redder, a result of the Doppler effect (the same phenomenon that changes the pitch of a moving car's sound). These color shifts slightly alter the apparent position of the starlight depending on its wavelength. By applying new computational methods, the researchers measured these color-based position shifts with about five times more precision than ever before. In addition to confirming the rotation of the disk, they discovered that it is lopsided. \"We were not expecting to detect an asymmetry like this, and it will be a task for the astrophysicists modeling these systems to explain its presence,\" said Kim. A New Way to See the Universe This innovative approach will allow astronomers to observe smaller and more distant objects with unprecedented clarity. It may help solve long-standing cosmic mysteries and, as in the case of the lopsided disk around β CMi, uncover entirely new ones. The project involved an international collaboration that included scientists from the Space Science and Engineering Initiative at the University of Hawai'i, the National Astronomical Observatory of Japan, the California Institute of Technology, the University of Arizona, the Astrobiology Center in Japan, the Paris Observatory, the University of Central Florida, the University of Sydney, and the University of California Santa Cruz.", "release_time": "2025-10-25", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/10/251025084540.htm"}
{"category": "研究前沿", "title": "科学家首次预测宇宙黑暗时代射电信号可揭示暗物质本质", "short_summary": "通过月球射电望远镜探测早期宇宙氢气波，为暗物质研究开辟新途径。", "detailed_summary": "通过月球射电望远镜探测早期宇宙氢气波，为暗物质研究开辟新途径。\n（1）特拉维夫大学团队首次预测可通过探测宇宙黑暗时代（大爆炸后1亿年）的氢气射电波研究暗物质；\n（2）暗物质密集块吸引氢气产生特定射电信号，其强度分布可反映暗物质属性；\n（3）研究提出月球是理想观测点，因无大气干扰，多国探月计划为此提供机遇；\n（4）该发现为平方公里阵列（SKA）等射电望远镜项目提供新观测目标；\n（5）成功探测将开辟研究原始暗物质的新窗口，有望破解现代物理学核心谜题。", "raw_content": "For the first time, researchers at Tel Aviv University have predicted what might be discovered by detecting radio waves that originated in the early Universe. Their results suggest that during the \"cosmic dark ages,\" dark matter gathered into dense clumps across space, pulling in hydrogen gas that emitted intense radio waves. This new approach could offer a way to investigate one of science's biggest mysteries: the true nature of dark matter.  The work, led by Prof. Rennan Barkana from Tel Aviv University's Sackler School of Physics and Astronomy, involved Ph.D. student Sudipta Sikder and collaborators from Japan, India, and the United Kingdom. Their findings were published in Nature Astronomy. Studying the Cosmic Dark Ages from the Moon According to the researchers, the cosmic dark ages (the period just before the first stars formed) can be explored by detecting radio waves emitted by the hydrogen gas that once filled the Universe. Although everyday antennas easily detect radio waves, the signals from this ancient era are blocked by Earth's atmosphere. Studying them requires instruments in space -- especially on the moon, where the lack of an atmosphere and human-made interference provides ideal conditions. Building a telescope on the lunar surface is a formidable task, but the timing may be right. A global race is underway to return to the moon, with the United States, Europe, China, and India all pursuing new lunar missions. These agencies are seeking meaningful scientific objectives for future moon projects, and this new research underscores the potential of lunar-based radio astronomy to probe the early Universe. Exploring the Universe Before the First Stars Prof. Barkana explains: \"NASA's new James Webb space telescope discovered recently distant galaxies whose light we receive from early galaxies, around 300 million years after the Big Bang. Our new research studies an even earlier and more mysterious era: the cosmic dark ages, only 100 million years after the Big Bang. Computer simulations predict that dark matter throughout the Universe was forming dense clumps, which would later help form the first stars and galaxies. The predicted size of these nuggets depends on, and thus can help illuminate, the unknown properties of dark matter, but they cannot be seen directly. However, these dark matter clumps pulled in hydrogen gas and caused it to emit stronger radio waves. We predict that the cumulative effect of all this can be detected with radio antennas that measure the average radio intensity on the sky.\" These simulations suggest that radio signals from the dark ages, while faint, carry valuable clues about the invisible structures that seeded the formation of galaxies. Detecting them could transform our understanding of the Universe's earliest moments.  From the Cosmic Dark Ages to the Dawn of Stars Although the expected signal is weak, successfully observing it could open a new window for testing theories of dark matter. When the first stars appeared shortly afterward, during a phase known as the \"cosmic dawn,\" their light likely amplified this radio emission dramatically. Signals from that later era should be easier to detect with ground-based telescopes, though they are harder to interpret because star formation introduces additional complexity. To tackle this challenge, scientists are turning to vast radio telescope networks designed to map subtle variations in cosmic radio intensity. One of the largest efforts is the Square Kilometre Array (SKA), a global collaboration involving an array of 80,000 radio antennas currently under construction in Australia. Prof. Barkana plays a key role in this international project, which aims to capture patterns of strong and weak radio emissions that could reveal where dark matter clumps once existed. A New Window Into Dark Matter's Origins The team believes that their predictions may provide an important step forward in understanding dark matter. Today, dark matter is intertwined with galaxies and stars, making its properties difficult to isolate. In contrast, the early Universe offers a pristine setting -- essentially an untouched laboratory -- for investigating how dark matter behaves without interference from later cosmic structures. Prof. Barkana concludes: \"Just as old radio stations are being replaced with newer technology that brings forth websites and podcasts, astronomers are expanding the reach of radio astronomy. When scientists open a new observational window, surprising discoveries usually result. The holy grail of physics is to discover the properties of dark matter, the mysterious substance that we know constitutes most of the matter in the Universe, yet we do not know much about its nature and properties. Understandably, astronomers are eager to start tuning into the cosmic radio channels of the early Universe.\"", "release_time": "2025-10-25", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251024041755.htm"}
{"category": "研究前沿", "title": "激光操控磁振子实现室温量子效应研究突破", "short_summary": "科学家用激光激发磁振子对，首次在室温下操控材料磁性并探索量子效应。", "detailed_summary": "科学家用激光激发磁振子对，首次在室温下操控材料磁性并探索量子效应。\n（1）德国康斯坦茨大学团队开发实验技术，用激光脉冲相干激发磁振子对（自旋波量子）。\n（2）该方法可在室温下非热方式改变材料磁频率和振幅，使其暂时呈现新物质特性。\n（3）使用常见赤铁矿晶体，无需稀有材料或昂贵冷却系统，避免热量堆积问题。\n（4）潜在应用于太赫兹速率数据传输存储及室温玻色-爱因斯坦凝聚等量子研究。\n（5）研究成果发表于《科学进展》，为突破当前信息技术瓶颈提供新路径。", "raw_content": "Imagine being able to alter a material so that it seems to transform into an entirely different one. No magic wand or special potion is needed -- only light. When light interacts with the material, it excites its magnetic states, setting off collective magnetic vibrations. These vibrations can transmit and store information at terahertz speeds. The entire process happens at room temperature and produces almost no heat. Even better, it doesn't rely on rare or exotic materials. Researchers observed the effect in common, naturally grown crystals that are widely available. Now imagine using the same approach to tap into quantum effects -- phenomena so delicate they are typically observed only near absolute zero (around -270 degrees Celsius) -- but doing it at room temperature, with no costly cooling systems required.  It might sound like science fiction, yet this breakthrough is real. A team of physicists at the University of Konstanz, led by Davide Bossini, has developed an experimental technique that makes it possible. By using laser pulses to coherently excite pairs of magnons (quanta of spin waves), the researchers achieved remarkable effects that could influence both information technology and quantum research. Their findings were published in Science Advances. Technology based on magnons Before diving deeper, it helps to understand what magnons are and why they matter. The modern world generates enormous amounts of data through artificial intelligence and the \"Internet of Things.\" Our current information systems are already straining under the pressure, and a data bottleneck threatens to slow technological progress. One proposed solution is to use electron spins -- or even better, waves of many spins moving together -- to carry information. These collective spin oscillations are called magnons. They behave like waves and can be manipulated by lasers, potentially allowing data transmission and storage at terahertz frequencies. So far, however, scientists have only been able to excite magnons at their lowest frequencies using light, which limits their potential. To harness magnons for future technologies, researchers must be able to tune their frequency, amplitude, and lifetime. The team at Konstanz has now found a way to do exactly that. By directly exciting pairs of magnons -- the highest-frequency magnetic resonances in a material -- they discovered a powerful new form of control. A huge surprise \"The result was a huge surprise for us. No theory has ever predicted it,\" says Davide Bossini. Not only does the process work -- it also has spectacular effects. By driving high-frequency magnon pairs via laser pulses, the physicists succeeded in changing the frequencies and amplitudes of other magnons -- and thus the magnetic properties of the material -- in a non-thermal way. \"Every solid has its own set of frequencies: electronic transitions, lattice vibrations, magnetic excitations. Every material resonates in its own way,\" explains Bossini. It is precisely this set of frequencies that can be influenced through the new process. \"It changes the nature of the material, the 'magnetic DNA of the material', so to speak, its 'fingerprint'. It has practically become a different material with new properties for the time being,\" says Bossini.  \"The effects are not caused by laser excitation. The cause is light, not temperature,\" confirms Bossini: \"We can change the frequencies and properties of the material in a non-thermal way.\" The advantages are obvious: The method could be used for future data storage and for fast data transmission at terahertz rates without the systems being slowed down by the pileup of heat. No spectacular high-tech materials or rare earths are required as the basis for the process, but rather naturally grown crystals -- namely the iron ore haematite. \"Haematite is widespread. Centuries ago, it was already used for compasses in seafaring,\" explains Bossini. It is perfectly possible that haematite will now also be used for quantum research in the future. The results of the Konstanz team suggest that, using the new method, researchers will be able to produce light-induced Bose-Einstein condensates of high-energy magnons at room temperature. This would pave the way to researching quantum effects without the need for extensive cooling. Sounds like magic, but it is just technology and cutting-edge research. The project was carried out in the context of the Collaborative Research Centre SFB 1432 \"Fluctuations and Nonlinearities in Classical and Quantum Matter beyond Equilibrium.\"", "release_time": "2025-10-24", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251024041822.htm"}
{"category": "产业应用", "title": "特斯拉储能业务创收新高，三季度装机量达12.5吉瓦时", "short_summary": "特斯拉三季度储能装机量创新高，能源业务收入增长44%，并发布新一代工业储能产品。", "detailed_summary": "特斯拉三季度储能装机量创新高，能源业务收入增长44%，并发布新一代工业储能产品。\n（1）特斯拉2025年第三季度总收入281亿美元，同比增长12%，自由现金流40亿美元，均创纪录。\n（2）能源与储能业务收入34.15亿美元，同比增长44%；储能产品装机量达12.5吉瓦时，创历史新高。\n（3）上海超级工厂作为全球出口中心，产能释放助推业务增长；储能业务毛利11亿美元创新高。\n（4）发布新一代工业储能产品Megablock，包含四台Megapack 3系统，计划2026年在休斯顿工厂量产。\n（5）在美国推出“太阳能+Powerwall”租赁新方案，并看好人工智能产业推动储能需求增长。", "raw_content": "10月23日，特斯拉发布2025年第三季度财报。公司第三季度总收入281亿美元，同比增长12%，自由现金流40亿美元，创下了收入和自由现金流的纪录。 其中，能源与储能业务收入34.15亿美元，同比增长44%。 针对储能业务，特斯拉介绍，位于临港的上海超级工厂是特斯拉的全球出口中心，支撑亚太市场扩张，其产能释放持续助推业务增长。 得益于特斯拉上海储能超级工厂产能的持续爬产及Powerwall家用储能系统装机量创纪录，第三季度特斯拉储能产品装机量达到12.5吉瓦时，创历史新高。毛利11亿美元，创下新纪录。   特斯拉储能装机增长(GWh)   能源服务及其他业务毛利润(百万美元) 在储能产品方面，特斯拉于2025年9月发布了新一代工业储能产品Megablock，这是一款预先设计的中压成套设备，包含四台Megapack 3储能系统。按计划，Megapack 3将于2026年在休斯顿超级工厂启动量产，年产能最高可达50GWh。 为推进户储市场发展，特斯拉在美国推出“太阳能(4.640, 0.05, 1.09%) + Powerwall(家用储能电池)”租赁新方案，该方案月付金额不仅低于贷款购买所需的还款额，而且特斯拉为整个租赁期内的系统提供售后保障，五年后，消费者可自主选择是否购买。 特斯拉还介绍，看好人工智能产业的发展带来能源产品需求的增长——超大规模企业与公用事业公司已认识到Megapack产品的优势——它能提升供电可靠性，同时缓解电网压力，为数据中心提供稳定的供电。这与宁德时代早些日子在三季报中发表的观点一致。", "release_time": "2025-10-24", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195242-1.html"}
{"category": "研究前沿", "title": "MIT学者用厨房科学启发AI节能计算新路径", "short_summary": "材料科学家从姜饼屋实验延伸到神经形态计算，探索降低AI能耗的仿脑方案。", "detailed_summary": "材料科学家从姜饼屋实验延伸到神经形态计算，探索降低AI能耗的仿脑方案。\n（1）MIT材料科学研究生通过姜饼屋实验演示材料结构对性能的影响，发现减少黄油用量可增强姜饼结构强度；\n（2）其研究聚焦神经形态计算，开发模拟大脑突触的镁离子电化学器件，实现信息处理与存储一体化；\n（3）该技术旨在解决AI训练的高能耗问题，较人脑学习能效提升显著；\n（4）研究面临跨学科整合及数据解读挑战，通过团队协作推进创新；\n（5）成果获MathWorks奖学金认可，为可持续计算与科学教育提供新范式。", "raw_content": "How can you use science to build a better gingerbread house?That was something Miranda Schwacke spent a lot of time thinking about. The MIT graduate student in the Department of Materials Science and Engineering (DMSE) is part of Kitchen Matters, a group of grad students who use food and kitchen tools to explain scientific concepts through short videos and outreach events. Past topics included why chocolate “seizes,” or becomes difficult to work with when melting (spoiler: water gets in), and how to make isomalt, the sugar glass that stunt performers jump through in action movies.Two years ago, when the group was making a video on how to build a structurally sound gingerbread house, Schwacke scoured cookbooks for a variable that would produce the most dramatic difference in the cookies.“I was reading about what determines the texture of cookies, and then tried several recipes in my kitchen until I got two gingerbread recipes that I was happy with,” Schwacke says.She focused on butter, which contains water that turns to steam at high baking temperatures, creating air pockets in cookies. Schwacke predicted that decreasing the amount of butter would yield denser gingerbread, strong enough to hold together as a house.“This hypothesis is an example of how changing the structure can influence the properties and performance of material,” Schwacke said in the eight-minute video.That same curiosity about materials properties and performance drives her research on the high energy cost of computing, especially for artificial intelligence. Schwacke develops new materials and devices for neuromorphic computing, which mimics the brain by processing and storing information in the same place. She studies electrochemical ionic synapses — tiny devices that can be “tuned” to adjust conductivity, much like neurons strengthening or weakening connections in the brain.“If you look at AI in particular — to train these really large models — that consumes a lot of energy. And if you compare that to the amount of energy that we consume as humans when we’re learning things, the brain consumes a lot less energy,” Schwacke says. “That’s what led to this idea to find more brain-inspired, energy-efficient ways of doing AI.”Her advisor, Bilge Yildiz, underscores the point: One reason the brain is so efficient is that data doesn’t need to be moved back and forth.“In the brain, the connections between our neurons, called synapses, are where we process information. Signal transmission is there. It is processed, programmed, and also stored in the same place,” says Yildiz, the Breene M. Kerr (1951) Professor in the Department of Nuclear Science and Engineering and DMSE. Schwacke’s devices aim to replicate that efficiency.Scientific rootsThe daughter of a marine biologist mom and an electrical engineer dad, Schwacke was immersed in science from a young age. Science was “always a part of how I understood the world.”“I was obsessed with dinosaurs. I wanted to be a paleontologist when I grew up,” she says. But her interests broadened. At her middle school in Charleston, South Carolina, she joined a FIRST Lego League robotics competition, building robots to complete tasks like pushing or pulling objects. “My parents, my dad especially, got very involved in the school team and helping us design and build our little robot for the competition.”Her mother, meanwhile, studied how dolphin populations are affected by pollution for the National Oceanic and Atmospheric Administration. That had a lasting impact.“That was an example of how science can be used to understand the world, and also to figure out how we can improve the world,” Schwacke says. “And that’s what I’ve always wanted to do with science.”Her interest in materials science came later, in her high school magnet program. There, she was introduced to the interdisciplinary subject, a blend of physics, chemistry, and engineering that studies the structure and properties of materials and uses that knowledge to design new ones.“I always liked that it goes from this very basic science, where we’re studying how atoms are ordering, all the way up to these solid materials that we interact with in our everyday lives — and how that gives them their properties that we can see and play with,” Schwacke says.As a senior, she participated in a research program with a thesis project on dye-sensitized solar cells, a low-cost, lightweight solar technology that uses dye molecules to absorb light and generate electricity.“What drove me was really understanding, this is how we go from light to energy that we can use — and also seeing how this could help us with having more renewable energy sources,” Schwacke says.After high school, she headed across the country to Caltech. “I wanted to try a totally new place,” she says, where she studied materials science, including nanostructured materials thousands of times thinner than a human hair. She focused on materials properties and microstructure — the tiny internal structure that governs how materials behave — which led her to electrochemical systems like batteries and fuel cells.AI energy challengeAt MIT, she continued exploring energy technologies. She met Yildiz during a Zoom meeting in her first year of graduate school, in fall 2020, when the campus was still operating under strict Covid-19 protocols. Yildiz’s lab studies how charged atoms, or ions, move through materials in technologies like fuel cells, batteries, and electrolyzers.The lab’s research into brain-inspired computing fired Schwacke’s imagination, but she was equally drawn to Yildiz’s way of talking about science.“It wasn’t based on jargon and emphasized a very basic understanding of what was going on — that ions are going here, and electrons are going here — to understand fundamentally what’s happening in the system,” Schwacke says.That mindset shaped her approach to research. Her early projects focused on the properties these devices need to work well — fast operation, low energy use, and compatibility with semiconductor technology — and on using magnesium ions instead of hydrogen, which can escape into the environment and make devices unstable.Her current project, the focus of her PhD thesis, centers on understanding how the insertion of magnesium ions into tungsten oxide, a metal oxide whose electrical properties can be precisely tuned, changes its electrical resistance. In these devices, tungsten oxide serves as a channel layer, where resistance controls signal strength, much like synapses regulate signals in the brain.“I am trying to understand exactly how these devices change the channel conductance,” Schwacke says.Schwacke’s research was recognized with a MathWorks Fellowship from the School of Engineering in 2023 and 2024. The fellowship supports graduate students who leverage tools like MATLAB or Simulink in their work; Schwacke applied MATLAB for critical data analysis and visualization.Yildiz describes Schwacke’s research as a novel step toward solving one of AI’s biggest challenges.“This is electrochemistry for brain-inspired computing,” Yildiz says. “It’s a new context for electrochemistry, but also with an energy implication, because the energy consumption of computing is unsustainably increasing. We have to find new ways of doing computing with much lower energy, and this is one way that can help us move in that direction.”Like any pioneering work, it comes with challenges, especially in bridging the concepts between electrochemistry and semiconductor physics.“Our group comes from a solid-state chemistry background, and when we started this work looking into magnesium, no one had used magnesium in these kinds of devices before,” Schwacke says. “So we were looking at the magnesium battery literature for inspiration and different materials and strategies we could use. When I started this, I wasn’t just learning the language and norms for one field — I was trying to learn it for two fields, and also translate between the two.”She also grapples with a challenge familiar to all scientists: how to make sense of messy data.“The main challenge is being able to take my data and know that I’m interpreting it in a way that’s correct, and that I understand what it actually means,” Schwacke says.She overcomes hurdles by collaborating closely with colleagues across fields, including neuroscience and electrical engineering, and sometimes by just making small changes to her experiments and watching what happens next.Community mattersSchwacke is not just active in the lab. In Kitchen Matters, she and her fellow DMSE grad students set up booths at local events like the Cambridge Science Fair and Steam It Up, an after-school program with hands-on activities for kids.“We did ‘pHun with Food’ with ‘fun’ spelled with a pH, so we had cabbage juice as a pH indicator,” Schwacke says. “We let the kids test the pH of lemon juice and vinegar and dish soap, and they had a lot of fun mixing the different liquids and seeing all the different colors.”She has also served as the social chair and treasurer for DMSE’s graduate student group, the Graduate Materials Council. As an undergraduate at Caltech, she led workshops in science and technology for Robogals, a student-run group that encourages young women to pursue careers in science, and assisted students in applying for the school’s Summer Undergraduate Research Fellowships.For Schwacke, these experiences sharpened her ability to explain science to different audiences, a skill she sees as vital whether she’s presenting at a kids’ fair or at a research conference.“I always think, where is my audience starting from, and what do I need to explain before I can get into what I’m doing so that it’ll all make sense to them?” she says.Schwacke sees the ability to communicate as central to building community, which she considers an important part of doing research. “It helps with spreading ideas. It always helps to get a new perspective on what you’re working on,” she says. “I also think it keeps us sane during our PhD.”Yildiz sees Schwacke’s community involvement as an important part of her resume. “She’s doing all these activities to motivate the broader community to do research, to be interested in science, to pursue science and technology, but that ability will help her also progress in her own research and academic endeavors.”After her PhD, Schwacke wants to take that ability to communicate with her to academia, where she’d like to inspire the next generation of scientists and engineers. Yildiz has no doubt she’ll thrive.“I think she’s a perfect fit,” Yildiz says. “She’s brilliant, but brilliance by itself is not enough. She’s persistent, resilient. You really need those on top of that.”", "release_time": "2025-10-24", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/brain-power-behind-sustainable-ai-miranda-schwacke-1024"}
{"category": "研究前沿", "title": "科学家提出拓扑量子电池新理论模型", "short_summary": "研究团队提出利用拓扑特性设计量子电池，有望实现高效能量存储与传输。", "detailed_summary": "研究团队提出利用拓扑特性设计量子电池，有望实现高效能量存储与传输。\n(1) 国际研究团队提出“拓扑量子电池”理论模型，利用光子波导拓扑特性和量子现象存储能量。\n(2) 该设计旨在解决传统量子系统能量损失和退相干难题，实现近乎完美的能量长距离传输。\n(3) 研究发现耗散在特定条件下可暂时提升充电功率，颠覆能量损失必然有害的传统认知。\n(4) 潜在应用包括纳米级储能、光学量子通信和分布式量子计算系统。\n(5) 该研究为高性能微型储能设备从理论走向实际应用提供了新视角和路径。", "raw_content": "Scientists from the RIKEN Center for Quantum Computing and Huazhong University of Science and Technology have carried out a theoretical study showing how a \"topological quantum battery\" could be efficiently designed. This innovative concept uses the topological characteristics of photonic waveguides and the quantum behavior of two-level atoms to store and transfer energy. Their findings, published in Physical Review Letters, point toward potential applications in nanoscale energy storage, optical quantum communication, and distributed quantum computing systems.  The Promise of Quantum Batteries As environmental sustainability becomes an increasingly urgent global concern, researchers are looking for new approaches to next-generation energy storage. Quantum batteries -- miniaturized theoretical devices that store energy using quantum phenomena such as superposition, entanglement, and coherence rather than traditional chemical reactions -- could redefine how power is stored and transferred. In principle, these batteries could deliver several advantages over conventional ones, including faster charging, higher capacity, and improved efficiency in energy extraction. Overcoming the Challenges of Quantum Energy Systems Despite years of proposals, practical implementation of quantum batteries has remained out of reach. In real-world conditions, these systems are particularly vulnerable to energy loss and decoherence, a process in which quantum systems lose essential properties like entanglement and superposition, leading to reduced performance. In photonic systems that use ordinary (non-topological) waveguides -- channels that direct photons but are sensitive to bends or imperfections -- energy efficiency drops sharply as photons disperse within the guide. Additional challenges such as environmental noise, dissipation, and structural disorder further erode stability and storage efficiency. Harnessing Topology to Improve Battery Performance To address these persistent problems, the international research team used analytical and numerical modeling within a theoretical framework. By taking advantage of topological properties -- material features that remain unchanged even when the structure is twisted or bent -- they showed it is possible to achieve both long-distance energy transfer and immunity to dissipation in quantum batteries. In an unexpected twist, the researchers also discovered that dissipation, which typically weakens performance, can temporarily increase charging power under certain conditions.  Breakthrough Findings and Future Implications The study revealed several promising outcomes that bring topological quantum batteries closer to practical use. The team demonstrated that the topological nature of photonic waveguides enables nearly perfect energy transfer. When the charging source and battery occupy the same site, the system gains dissipation immunity limited to a single sublattice. They also found that when dissipation surpasses a critical level, charging power experiences a brief but significant boost, overturning the long-held assumption that energy loss is always detrimental. Toward Real-World Quantum Batteries \"Our research provides new insights from a topological perspective and gives us hints toward the realization of high-performance micro-energy storage devices. By overcoming the practical performance limitations of quantum batteries caused by long-distance energy transmission and dissipation, we hope to accelerate the transition from theory to practical application of quantum batteries,\" said Zhi-Guang Lu, the first author of the study. \"Looking ahead,\" says Cheng Shang, the corresponding author of the international research team, \"we will continue working to bridge the gap between theoretical study and the practical deployment of quantum devices -- ushering in the quantum era we have long envisioned.\"", "release_time": "2025-10-24", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251023031612.htm"}
{"category": "产业应用", "title": "俄前9月煤炭产量持平 出口增长5.5%", "short_summary": "俄罗斯今年前9月煤炭产量微降，出口增长，全年产量预计与去年持平。", "detailed_summary": "俄罗斯今年前9月煤炭产量微降，出口增长，全年产量预计与去年持平。\n（1）2025年1-9月，俄罗斯煤炭总产量为3.14亿吨，与去年同期基本持平，微降0.9%。\n（2）分煤种看，炼焦煤和无烟煤产量同比下降，而其他烟煤和褐煤产量同比增长。\n（3）9月份单月产量为3450万吨，环比增长9.0%，但同比下降1.1%。\n（4）俄罗斯能源部预计2025年全年煤炭产量将保持2024年4.435亿吨的水平。\n（5）出口方面，前9个月煤炭出口量达1.57亿吨，同比增长5.5%，全年出口预计超2亿吨。", "raw_content": "据俄罗斯联邦统计局(Росстата)10月22日发布的最新工业生产统计月报快报数据显示，2025年1-9月，俄罗斯煤炭产量累计为3.14亿吨，与上年同期基本持平、微增0.1%。   其中，炼焦煤产量7530万吨，较上年同期下降9.1%;其它烟煤(非炼焦烟煤)1.52亿吨，同比增长3.2%;无烟煤产量为1540万吨，同比下降6.6%;褐煤产量7140万吨，同比增长6.2%。 9月份，俄罗斯煤炭产量为3450万吨，同比下降1.1%，环比增长9.0%。其中，炼焦煤产量800万吨，同比下降8.7%，环比增长3.6%;其它烟煤产量1700万吨，同比增长4.2%，环比上升7.2%;无烟煤产量160万吨，同比减少19.3%，环比增长21.2%;褐煤产量790万吨，同比增长1.1%，环比上升17.0%。 俄能源部预计今年煤炭产量将保持去年水平 据塔斯社(TASS)报道的消息，俄罗斯能源部副部长德米特里·伊斯拉莫夫(Dmitry Islamov)在最近举办的“俄罗斯能源周”(Russian Energy Week)上向新闻记者宣布，2025年俄罗斯煤炭产量预计将保持2024年的水平。 据伊斯拉莫夫所称，俄罗斯今年煤炭产量的目标是与去年持平。各地区的情况各不相同。有些地区依靠国内市场复苏，有些地区依靠出口复苏。 根据能源部的最新数据，2025年前9个月，俄罗斯煤炭产量与去年同期相比下降0.9%。伊斯拉莫夫解释称，主要是国内市场受冶金行业影响略有下滑。 近年来俄罗斯煤炭出口变化走势   煤炭出口方面，伊斯拉莫夫透露，今年前9个月，俄罗斯煤炭出口量已达到1.57亿吨，同比增长5.5%。预计到2025年底，全年煤炭出口量将达到2.04亿吨至2.05亿吨。 俄罗斯副总理亚历山大·诺瓦克(Alexander Novak)此前曾在《能源政策》杂志专栏中引用的数据显示，2024年，俄罗斯煤炭产量达到4.435亿吨，出口1.962亿吨。", "release_time": "2025-10-24", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195280-1.html"}
{"category": "产业应用", "title": "IAEA与安大略理工大学续签核能合作中心协议", "short_summary": "IAEA与安大略理工续签四年协议，拓展小型堆与人工智能核安全等合作领域。", "detailed_summary": "IAEA与安大略理工续签四年协议，拓展小型堆与人工智能核安全等合作领域。\n(1)国际原子能机构（IAEA）与加拿大安大略理工大学续签合作中心协议，有效期四年。\n(2)合作范围扩大至信息与计算机安全、人工智能在核安全领域的应用。\n(3)将继续推进小型模块化反应堆、核能与可再生能源结合的混合能源系统及核能热电联产研究。\n(4)安大略理工大学将提供专家支持、开发培训材料并主办IAEA讲习班以加强相关领域能力建设。\n(5)该合作旨在利用新兴技术加强IAEA对成员国的援助，推动核能应用以实现气候适应型未来。", "raw_content": "The IAEA and Ontario Tech University have renewed their Collaborating Centre agreement for four more years, strengthening cooperation on advanced nuclear power development and introducing nuclear security-related topics to their joint work.  The new agreement expands the workplan to include information and computer security as well as artificial intelligence (AI) for nuclear security. Work on integrated energy systems with advanced nuclear power reactors, initiated under the previous agreement, will continue under the 2025-2029 arrangement. “This redesignation is a testament to Ontario Tech University’s scientific and technical excellence at both the national and international level,” said Mikhail Chudakov, IAEA Deputy Director General and Head of the Department of Nuclear Energy. “Ontario Tech has also played an important role in capacity building, including by training young professionals in these and other areas. I commend all involved for their proactive engagement and look forward to celebrating more achievements.” Under the new agreement, concluded at IAEA headquarters on 23 October, Ontario Tech University will continue its work on small modular reactors (SMRs), hybrid energy systems that integrate nuclear power with renewables like solar and wind, and nuclear cogeneration. Cogeneration involves using power reactors both to produce electricity and to process heat for applications such as desalination and district heating. Ontario Tech will also provide experts to support IAEA activities in computer security and AI for nuclear security, two areas with limited expertise. The university will develop training materials, publications and educational resources and host IAEA workshops and training courses to build capacity in these fields.  “Ontario Tech University will support IAEA-driven international cooperation efforts on topics related to information and computer security, as well as artificial intelligence for nuclear security,” said Karine Herviou, IAEA Deputy Director General and Head of the Department of Nuclear Safety and Security. “This expanded collaboration aims to strengthen the IAEA’s assistance to Member States, and specifically capacity building activities, addressing challenges linked to emerging technologies.” Established in 2002, Ontario Tech University is a leader in clean energy research. Its facilities include the Brilliant Energy Institute and the Energy Research Centre, where nuclear power research is conducted, as well as the Wind and Geothermal Laboratory. The university is also preparing to deploy a subcritical assembly, a type of research reactor, to support applied nuclear engineering research and education. Once operational, it will be the only facility of its kind in Canada. “Canada is proud to see Ontario Tech University’s designation as an IAEA Collaborating Centre renewed for another four years,” said Alison Grant, Canada’s Ambassador to Austria and Permanent Representative to the International Organizations in Vienna. “This partnership showcases Canadian excellence in science and innovation and strengthens our capacity to advance technologies for nuclear energy applications, along with nuclear safety and security, towards a climate-resilient future.” “Ontario Tech University is delighted about the redesignation of the IAEA Collaborating Centre for another four years,” said Les Jacobs, Vice President of Research & Innovation at Ontario Tech University.  “As Canada’s first Collaborating Centre, it has been an excellent opportunity for Ontario Tech to provide leadership to build bridges between the IAEA and the main pillars of the Canadian nuclear industry, including Ontario Power Generation, Bruce Nuclear, Canadian Nuclear Laboratories, universities and the Government of Canada.”", "release_time": "2025-10-24", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/iaea-and-ontario-tech-university-expand-scope-of-cooperation-to-include-nuclear-security"}
{"category": "产业应用", "title": "IAEA与俄合办核能学校 强调人才与社区信任", "short_summary": "国际核能学校在莫斯科举办，强调人才与社区信任对核能项目成功至关重要。", "detailed_summary": "国际核能学校在莫斯科举办，强调人才与社区信任对核能项目成功至关重要。\n（1）国际原子能机构与俄罗斯联合在莫斯科举办两所核能学校，由Rosatom技术学院莫斯科分校承办；\n（2）活动汇集来自26个国家的60名参与者，聚焦核能产业能力建设；\n（3）强调核能项目成功不仅依赖先进技术，更需要强有力领导和社区信任；\n（4）IAEA预测全球核电容到2050年可能从377GW增至近1000GW；\n（5）实现增长目标需培养兼具技术专长与社会责任感的领导者。", "raw_content": "Two international schools, jointly organized by the IAEA and the Russian Federation, have concluded in Moscow, marking another milestone in the IAEA’s capacity building efforts.  Hosted at the Moscow branch of the Rosatom Technical Academy, the schools brought together 60 participants from 26 countries. The events highlighted a key message: the success of nuclear power projects depends not only on advanced technology, but also on strong leadership and the trust of communities. “To develop and run a nuclear programme, we need more than technology – we need people,” said Mikhail Chudakov, IAEA Deputy Director General and Head of the Department of Nuclear Energy. “Skilled professionals are the ones who plan, operate, and engage with communities. This is why capacity building is so important.” As the world faces challenges from climate change, energy security and growing electricity demand, nuclear energy is now recognized as part of the solution. The IAEA’s latest projections show that global nuclear capacity could rise from about 377 GW today to nearly 1000 GW by 2050 in the high case scenario. Meeting this goal will require not only technology, but also leaders who combine technical expertise with social responsibility, ensuring that projects are managed effectively and trusted by the communities they serve.", "release_time": "2025-10-24", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/iaea-nuclear-energy-management-and-stakeholder-engagement-schools-conclude-in-moscow"}
{"category": "产业应用", "title": "3D打印控释抗癌药片突破血药浓度难题", "short_summary": "新型药片通过凝胶纤维延长胃内停留时间，实现抗癌药物平稳释放。", "detailed_summary": "新型药片通过凝胶纤维延长胃内停留时间，实现抗癌药物平稳释放。\n（1）Enzian公司开发3D打印纤维药片，遇水形成凝胶结构可在胃中停留12-24小时；\n（2）技术通过缓慢降解纤维实现药物持续释放，避免血药浓度骤升骤降；\n（3）当前已完成动物实验，正开展健康志愿者试验，明年启动癌症患者临床；\n（4）该技术尤其适合酸性环境吸收的抗癌药，如前列腺癌、血癌、乳腺癌药物；\n（5）有望将日服药量降至十分之一，同时提升疗效并减少心脏、肝脏等副作用。", "raw_content": "Pills are by far the most convenient form of cancer treatment, but most oral cancer drugs quickly dissolve in the stomach, delivering a burst of chemicals into the bloodstream all at once. That can cause side effects. It also may limit the drug’s effectiveness because its concentration in the blood may become too low after the initial burst.Now, the startup Enzian Pharmaceutics, founded by Aron Blaesi PhD ’14 and former principal research scientist Nannaji Saka ScD ’74, is developing an oral tablet that delivers drugs into the gastric fluid and the blood steadily over time. The company’s tablets use tiny 3D-printed fibers that turn into a gel-like substance when exposed to water. The tablets have been shown to stay in the stomach of animals for up to a day, slowly degrading while releasing the drug in controlled quantities.The company is currently validating its tablets’ ability to stay in place in a small number of healthy human volunteers. In about a year, it plans to begin testing the technology’s ability to improve the effectiveness and safety of cancer drugs in patients.“A lot of orally delivered cancer drugs could benefit from this,” says Blaesi, who incorporated the company in 2016. “Right now, soon after someone has taken a cancer drug, its concentration in the blood can be up to 50 times greater than when they are supposed to take the next pill. During the peak, the drug goes into the heart, it goes into the liver, the brain, and it can cause a lot of problems, while at the end of the dosing interval the concentration in the blood may be too low. By taking out that peak and increasing the time the drug is released, we could improve the effectiveness of treatments and mitigate certain side effects.”In search of innovationWhen Blaesi came to MIT, he knew he wanted his mechanical engineering PhD work to form the basis of a company. Early on, as part of the Novartis-MIT Center for Continuous Manufacturing, he worked on manufacturing pills with an injection molding machine that melted and solidified the material, in contrast to the traditional process of compacting powder. He noticed injection molding made the pills far less porous.“If you put a typical pill into a fluid or into the stomach, the fluid percolates the pores and quickly dissolves it,” Blaesi explains. “That’s not the case when you have an injection molded product. That’s when Dr. Saka, who I met almost daily to discuss my research with, and I started to realize that microstructure is very important.”The researchers began exploring how different tablet microstructures changed the rate at which drugs are released. For more precision, they moved from injection molding to 3D printing.Using MIT machine shops, Blaesi built a 3D printer and produced tightly wound microstructures that could carry the drugs. He focused on fibrous structures with space between the fibers, because they would allow gastrointestinal fluid to percolate the pill and dissolve rapidly. He tested the structures in both his Cambridge, Massachusetts, apartment and at MIT’s shared facilities.Blaesi then experimented with different carrier materials, finding that the higher the molecular weight, the longer it took the pill to dissolve because the material would absorb water and expand before degrading.“Initially I thought, ‘Oh no, the drug isn’t being dissolved fast enough anymore,’” Blaesi recalls. “Then we thought, ‘Everything has its place.’ This could stay in the stomach for longer because of the expansion. Then it could release the drug over time. We realized this wouldn’t just improve manufacturing, it would improve the product.”In 2019, Blaesi and Saka published the first paper on their expandable fibrous tablets for prolonged drug delivery. It received a mixed reception.“Some reviewers said, ‘Research on similar gastroretentive dosage forms has been done for 40 years and no one’s really succeeded,’” Blaesi recalls. “People said, ‘It will never work. Do experiments in animals and then we’ll talk.’”Blaesi moved back to Switzerland during the Covid-19 pandemic and ran his animal experiments there.“The reviewers were right: What we had didn’t work,” Blaesi says. “But we adjusted the design and showed we could make the pill stay in the stomach for longer.”Inside Enzian’s final tablet design, tiny fibers are arranged in a grid. When water flows into the spaces between the fibers, they expand to form a strong gel-like substance that slowly erodes in the stomach, steadily releasing the drug. In animal studies, Enzian’s team showed its technology allowed tablets to remain in the stomach for 12 to 24 hours before being safely excreted.The team soon found cancer drugs would be a good fit for their technology.“A lot of cancer drugs are only soluble in acidic solutions, so they can only be absorbed while the drug is in the stomach,” Blaesi explains. “But on an empty stomach, the drug may be in the stomach for just 30 or 40 minutes at present. For a full stomach, it’s a few hours. And because you have a short time to deliver the drug, you need to release a high dose immediately. That shoots up the blood concentration, and if you dose every 12 hours, the concentration is going down during the other 10 hours.”From the lab to patientsIn upcoming human trials, Enzian plans to use its tablets to deliver a drug for prostate cancer that Blaesi says is currently dosed at several hundred milligrams a day. He hopes to get down to about a tenth of that with a better therapeutic effect.Enzian also believes its technology could improve treatments for blood, skin, and breast cancers.“This could really be used to improve treatment for a variety of cancers,” Blaesi says. “We believe this is a more efficient and effective way to deliver drugs.”Maximizing effectiveness and minimizing side effects is also important in clinical trials, where a new drug’s superiority over existing treatments must be shown, and a single adverse event can end its development.The upcoming move into patients is the culmination of more than a decade of work for Blaesi, who is confident Enzian can deliver on its promise of improving treatments.“The opportunity is enormous,” Blaesi says. “So many oral cancer drugs have this delivery problem. We still have to do the efficacy and safety studies on patients, but we expect this to be a game changer.”", "release_time": "2025-10-23", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/startups-tablets-deliver-cancer-drugs-more-evenly-over-time-1023"}
{"category": "政策计划", "title": "河南“十四五”能源高质量发展成效显著", "short_summary": "河南可再生能源装机占比过半，电网油气设施升级，能源结构持续优化。", "detailed_summary": "河南可再生能源装机占比过半，电网油气设施升级，能源结构持续优化。\n(1) 河南省政府新闻发布会总结“十四五”能源高质量发展情况，以构建清洁低碳、安全高效的新型能源体系为核心。\n(2) 可再生能源累计装机超8700万千瓦，占发电总装机55%，预计2025年装机将超8800万千瓦，绿电占比接近40%。\n(3) 能源结构优化，非化石能源消费占比提升至18%，地热能供暖面积全国第三，郑汴洛濮氢走廊基本建成。\n(4) 电网投资年均超300亿元，形成“三交两直”特高压格局，农村电网核心指标提前达标；油气管网总里程突破1万公里。\n(5) 改革创新深化，实施源网荷储一体化项目622个，电力现货市场实现经营主体全覆盖，促进绿电消纳和成本降低。", "raw_content": "10月21日，省政府新闻办举行河南省能源高质量发展新闻发布会，全面介绍我省“十四五”时期能源高质量发展的总体情况，并回答记者提问。发布会上，省发展改革委党组书记、主任马健介绍，这五年，全省上下全面落实“四个革命、一个合作”能源安全新战略，立足服务保障全省经济社会发展大局，以非化石能源为供应主体、化石能源为兜底保障、新型电力系统为关键支撑、绿色智慧节约为用能导向，加快建设清洁低碳、安全高效的新型能源体系，能源高质量发展再上新台阶。清洁能源提速发展一方面，河南加快构建清洁高效的能源供给体系，能源保障能力显著增强;另一方面，加快构建绿色低碳的能源消费体系，能源结构持续向绿向新。“截至今年三季度，全省可再生能源累计装机超过8700万千瓦，占发电总装机的55%，是‘十三五’末的2.6倍以上，贡献了‘十四五’以来90%以上的新增电力装机。”省能源规划建设局党组成员、副局长李勇刚介绍，预计到2025年年底，全省可再生能源发电装机将超过8800万千瓦，超额完成“十四五”目标;2025年可再生能源发电量有望突破1400亿千瓦时，绿电占比接近40%。能源开发利用结构更加优化。全省一次能源消费中，煤炭消费占比持续下降，非化石能源消费占比提升至18%，比2020年提升约7个百分点。电能占终端能源消费比重持续提升，可再生能源发电消纳量占总用电量的比重超过35%。全省地热能供暖面积突破1.3亿平方米，居全国第3位;郑汴洛濮氢走廊基本建成，投用加氢站49座，氢能汽车2808辆。煤炭绿色开采方面，据省工业和信息化厅党组成员、副厅长孙永民介绍，我省高标准建成一批绿色矿山，覆岩离层注浆充填、矸石不升井、保水开采等绿色开采技术逐步推广，煤矸石、矿井水等综合利用水平持续提升。推广实施矿井瓦斯全过程抽采，瓦斯抽采、利用量连年增长，圆满完成国家下达的目标任务，实现了“变废为宝”，增加了清洁能源供给。基础设施提质升级电网是连接电力生产和消费的枢纽平台。省能源规划建设局党组成员、副局长王远介绍，“十四五”以来，我省电网投资年均超过300亿元，建成投运驻马店—武汉、南阳—荆门等3回特高压交流线路，全省形成“三交两直”特高压电网供电格局;加快建设豫西—豫中等500千伏主网架优化工程，全省新增投产110千伏及以上线路1.2万公里、变电容量6000万千伏安，电网互济能力持续提升。农村电网供电可靠率、综合电压合格率、户均配变容量等核心指标提前3年实现国家要求的中西部地区2025年规划目标。油气管网设施加速建设，油气资源供应保障能力持续提升。省能源规划建设局副局长范磊介绍，“十四五”以来，我省依托西气东输、榆济线等国家干线，实施一批省内天然气支线管道工程。建成周口—漯河、濮阳—鹤壁、开封—周口、周口—柘城等输气管道，油气管道总里程比“十三五”末增加1300多公里，全省油气长输管道总里程突破1万公里，油气资源供应保障基础更加坚实。改革创新持续深化围绕建立清洁能源为主、多能互补、产销协同的分布式能源体系，河南全面推进源网荷储一体化，拓展新能源就地就近开发利用场景，构建以大电网为支撑、微电网为支点的新型电网形态，为全国构建新型电力系统贡献了“河南方案”。省发展改革委党组成员，省能源规划建设局党组书记、局长夏兴介绍，目前全省已累计实施源网荷储项目622个，总投资约556亿元，新增光伏、风电总装机850万千瓦，新增水电装机1.1万千瓦，新增储能装机约230万千瓦，新增配电线路4346公里，新增配电容量555万千伏安，全部建成后每年可促进绿电消纳148亿千瓦时，减少用电成本近30亿元，在推动能源结构调整、保障能源供应安全、促进新能源消纳、扩大有效投资、降低企业用能成本等方面取得积极成效。加快电力现货市场建设，引导改革红利向用户传导，保障各类经营主体合理收益。“发电侧、用电侧用户全部参与市场，12家独立储能用户直接参与交易，目前已实现电力经营主体‘全覆盖’。”国网河南省电力公司副总经理吴加新说，现货市场开启后，通过竞争形成反映电力在时间和空间上供需关系的市场价格。通过市场优化资源配置，引导经营主体主动参与电网调节，现货市场起到了“保供应、稳价格、促消纳”作用。", "release_time": "2025-11-11", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/zhdt/202511/t20251107_794757.html"}
{"category": "研究前沿", "title": "KIT研发新型高温合金，突破涡轮机效率瓶颈", "short_summary": "新型铬钼硅合金兼具高熔点与室温延展性，有望大幅提升涡轮机效率并降低能耗。", "detailed_summary": "新型铬钼硅合金兼具高熔点与室温延展性，有望大幅提升涡轮机效率并降低能耗。\n（1）传统难熔金属（如钨、钼、铬）熔点高但室温下易脆且易氧化，限制其在高温含氧环境应用。\n（2）现有镍基超合金使用温度上限为1100°C，制约涡轮机等设备效率提升。\n（3）KIT团队开发铬-钼-硅新型合金，熔点约2000°C，兼具室温延展性与抗氧化性。\n（4）该材料可使涡轮机工作温度提升超100°C，预计降低5%燃料消耗，减少航空与发电碳排放。\n（5）成果为基础研究里程碑，需进一步开发方能工业化应用，但为全球高温材料研究提供新方向。", "raw_content": "High-temperature metals are essential for powering aircraft engines, gas turbines, X-ray systems, and other advanced technologies. Among the most heat-resistant are refractory metals like tungsten, molybdenum, and chromium, all of which have melting points around or above 2,000 degrees Celsius (~3600 degrees Fahrenheit). Despite their exceptional heat tolerance, these metals pose major challenges: they are brittle at normal temperatures and quickly oxidize when exposed to oxygen, leading to failure even at 600 to 700 degrees Celsius (~1100 to 1300 degrees Fahrenheit). Because of this, they can only be used in specialized vacuum environments, such as in X-ray rotating anodes.  To overcome these limitations, engineers have long relied on nickel-based superalloys for parts that must withstand hot air or combustion gases. These materials are standard in gas turbines and other high-temperature systems. \"The existing superalloys are made of many different metallic elements including rarely available ones so that they combine several properties. They are ductile at room temperature, stable at high temperatures, and resistant to oxidation,\" explains Professor Martin Heilmaier from KIT's Institute for Applied Materials -- Materials Science and Engineering. \"However -- and there is the rub -- the operating temperatures, i.e. the temperatures in which they can be used safely, are in the range up to 1,100 degrees Celsius maximum. This is too low to exploit the full potential for more efficiency in turbines or other high-temperature applications. The fact is that the efficiency in combustion processes increases with temperature.\" A Chance for a Technological Leap Recognizing this performance limit, Heilmaier's team set out to find a new solution. Within the German Research Foundation's (DFG) \"Materials Compounds from Composite Materials for Applications in Extreme Conditions\" (MatCom-ComMat) research training group, the team developed a novel alloy combining chromium, molybdenum, and silicon. This refractory metal-based material, in whose discovery Dr. Alexander Kauffmann, now professor at the Ruhr University Bochum, played a major role, exhibits properties never seen before. \"It is ductile at room temperature, its melting point is as high as about 2,000 degrees Celsius, and -- unlike refractory alloys known to date -- it oxidizes only slowly, even in the critical temperature range. This nurtures the vision of being able to make components suitable for operating temperatures substantially higher than 1,100 degrees Celsius. Thus, the result of our research has the potential to enable a real technological leap,\" says Kauffmann. This specifically remarkable as resistance to oxidation and ductility still cannot be predicted sufficiently to allow a targeted material design -- despite the great progress that has been achieved in computer-assisted materials development. More Efficiency, Less Consumption \"In a turbine, even a temperature increase of just 100 degrees Celsius can reduce fuel consumption by about five percent,\" explains Heilmaier. \"This is particularly relevant to aviation, as airplanes powered by electricity will hardly be suitable for long-haul flights in the next decades. Thus, a significant reduction of the fuel consumption will be a vital issue. Stationary gas turbines in power plants could also be operated with lower CO2 emissions thanks to more robust materials. In order to be able to use the alloy on an industrial level, many other development steps are necessary,\" says Heilmaier. \"However, with our discovery in fundamental research, we have reached an important milestone. Research groups all over the world can now build on this achievement.\"", "release_time": "2025-10-23", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/10/251023031622.htm"}
{"category": "政策计划", "title": "“十四五”能源绿色变革成就显著", "short_summary": "我国建成全球最大新能源产业链，非化石能源消费占比目标如期完成。", "detailed_summary": "我国建成全球最大新能源产业链，非化石能源消费占比目标如期完成。\n（1）“十四五”期间中国能源生产消费格局发生绿色变革，清洁能源发电量占全社会用电量三分之一；\n（2）建成全球最大清洁能源走廊，六座大型水电站串联长江干流；\n（3）在沙漠、戈壁布局新能源基地，新增光伏板可覆盖53万座足球场；\n（4）特高压电网加速建设，五年开工19条线路，西电东送电量增长70%；\n（5）新型储能首次纳入规划，重力储能等技术成为电网“定海神针”；\n（6）非化石能源消费占比20%的“十四五”目标已如期完成。", "raw_content": "荒无人烟的沙漠、戈壁与荒滩变身巨大的发电场，横跨千里，清洁能源毫秒之间东西“闪送”。“十四五”以来，中国逐“绿”而行，在广袤山河间铺展能源绿色变革的壮阔图景，神州大地上能源生产与消费格局正在改写。这是沙海日出的一瞬间，2.7万面定日镜被同步唤醒，这里每年的发电量相当于替代56万吨燃煤。高原起风的瞬间，93米长的叶片加速转动，每转一圈发出的电足够三口之家用上2天。今天的中国，一年发电超10万亿千瓦时，占全球1/3。全社会用电中，每3度就有1度来自风吹日晒水流的馈赠。这是全球规模最大、影响最深远的绿色奇迹。长江干流上，六座大型水电站拦江而立，串联成世界最大的清洁能源走廊。“沙戈荒”新能源基地里，昔日寸草难生的土地变身蓝色光伏的海洋。“十四五”规划布局的九大清洁能源基地，有七个都在西部地区。如果把五年间全国新增的光伏板铺展开，总面积可以覆盖53万座足球场;把新增的风机叶片依次连接，长度相当于从中国最东端到最西端走一个来回。“十四五”规划中的特高压“能源动脉”也在冲破地理屏障，加速生长。五年间，19条特高压开工建设，织成了一张电力输送的超级网络。如今，从西到东跨区域输送清洁能源电量增长了70%，来自西部的绿电支撑了东中部地区五分之一的用电需求。新型储能第一次出现在“五年规划”中。靠重力储能、靠压缩空气，今年夏天，这些“巨型充电宝”大规模参与“迎峰度夏”战役，成为电网应对“尖峰时刻”的“定海神针”。今天(10月20日)，我国已建成了全球最大、最完整的新能源产业链，非化石能源消费占比20%的“十四五”目标如期完成。", "release_time": "2025-11-11", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/zhdt/202511/t20251107_794777.html"}
{"category": "产业应用", "title": "埃克森美孚发布新一代风机齿轮油，护航风电产业", "short_summary": "埃克森美孚在风能大会发布长效齿轮油，助力风机全生命周期降本增效。", "detailed_summary": "埃克森美孚在风能大会发布长效齿轮油，助力风机全生命周期降本增效。\n（1）埃克森美孚中国在2025北京国际风能大会发布美孚SHCTM齿轮油320 WindPower，油品寿命可达25年。\n（2）新产品旨在实现风机全生命周期润滑管理，提升运行可靠性并降低维护成本。\n（3）公司同步升级主轴承润滑维护方案，并与欧洛斯签约提供专业换油服务。\n（4）此举响应中国“十五五”能源规划，支持风电产业高质量可持续发展。", "raw_content": "明年将步入“十五五”时期，这是全面推进新型能源体系建设、助力如期实现碳达峰目标的关键时期。作为全球能源转型的重要参与者，中国正持续推进风电产业迈向高质量发展。在此背景下，2025北京国际风能大会暨展览会圆满落幕，深入探讨了“十五五”时期风电行业的机遇与挑战。 立足于服务国家“双碳”战略、为全球能源转型作出积极贡献，埃克森美孚(中国)投资有限公司(简称“埃克森美孚中国”)以“一次加注，终身守护”为主题参展，重磅发布全生命周期产品美孚SHCTM齿轮油320 WindPower，全面展示了其作为“风的守护者”护航风电产业高质量发展的实力，为“十五五”新征程贡献专业力量。   埃克森美孚中国展台现场 全新产品发布，守护风机25年黄金寿命 随着技术的持续进步和规模效应的加速释放，风电产业已迈入发展新阶段。在最近的联合国气候变化峰会上，中国宣布了新一轮国家自主贡献，到2035年风电和太阳能发电总装机容量达到2020年的6倍以上、力争达到36亿千瓦。 为响应国家号召，支持全球能源转型，埃克森美孚中国举办了美孚SHCTM齿轮油320 WindPower新产品发布会。埃克森美孚企业用户润滑油业务部全球市场部高级顾问杨东、埃克森美孚中国企业用户润滑油业务部总工程师贺云峰出席本次活动，同时也特别邀请了中国农业机械工业协会风力机械分会副理事长祁和生老师莅临美孚展台，与大家共同见证了这一新品发布。   美孚SHCTM齿轮油320 WindPower发布仪式 作为面向风电市场的新一代全生命周期风机齿轮油，该产品帮助油品使用寿命延长至25年，真正实现了风机的全生命周期润滑管理。其可在多种严苛条件下提供优质的油品性能，不仅保证风机的高效运转与可靠运行，实现节能降耗，更通过减少维护修理及非计划停机所带来的额外成本，为企业全面提升经济效益。 祁和生先生在嘉宾致辞中进一步强调，“随着风电装机规模持续扩大，设备长效运行与全周期经济效益已成为行业关键议题。推动全生命周期管理，正是应对这些挑战、实现高质量发展的关键突破口。”   中国农业机械工业协会风力机械分会副理事长祁和生老师致辞 深化战略合作，共筑风电服务新生态 展会期间，埃克森美孚中国高级技术经理程良在现场主持举办了主轴承润滑管理服务研讨会，分享了美孚全新升级的风机主轴承润滑维护方案。该方案依托美孚力富TMSHC 007主轴承维护产品，可在风机主轴承的正常运行中，有效软化旧滑脂并持续提供可靠的抗磨保护，实现高效专业维护。同时，埃克森美孚中国还提供了智能化、集成化的专业维护设备，支持手机远程操控，可实时监测与报警提醒，显著提升运维效率与安全性。   埃克森美孚中国高级技术经理程良主持研讨会 此外，埃克森美孚中国与风电后市场授权服务商欧洛斯举行战略合作签约仪式。未来，双方将面向广大风电企业提供专业换油服务，共同保障风机长效稳定运行。此次合作不仅进一步推进了风电产业链的协同发展，也为风电后市场服务的进一步升级奠定了坚实基础。欧洛斯风能科技(武汉)有限公司董事长王军在仪式上也充分肯定了埃克森美孚中国的风电润滑产品与技术实力，表示将携手推动客户实现更安全、更经济的风机长期运行。 展望“十五五”，埃克森美孚中国将继续秉持“美孚，为中国风电加油”的理念，整合全球技术与本地服务能力，与产业链各方协同合作，推动中国风电产业高质量、可持续发展，为中国能源体系升级与全球能源转型注入专业动力。     责任编辑：                                                                江晓蓓                                                                   标签：埃克森美孚中国,新一代风机齿轮油,风电产业", "release_time": "2025-10-23", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195232-1.html"}
{"category": "产业应用", "title": "俄罗斯9月煤炭出口量降4% 南部港口对土耳其出口增长", "short_summary": "俄煤炭出口环比下降，但南部港口因土耳其需求增长而表现突出。", "detailed_summary": "俄煤炭出口环比下降，但南部港口因土耳其需求增长而表现突出。\n（1）9月俄罗斯煤炭海上出口量环比下降4%至1570万吨，但同比增长28%；总出口量估计为1710万吨。\n（2）西北港口出口下降9%，远东港口出口下降5%，对印度出口大幅减少31%。\n（3）南部港口运输量增长，主要受土耳其工业活动复苏和哈萨克斯坦煤炭过境影响。\n（4）土耳其市场因物流紧密保持稳定，但炼焦煤供应因钢铁产能有限而下降。\n（5）出口盈利能力为负，因开采成本高企，但出口商为保持市场份额维持供应。", "raw_content": "9月底，由于土耳其需求增长，俄罗斯南部港口的海上煤炭运输量增长。但由于开采成本上升，出口的盈利能力仍然为负。非洲国家可能成为通过南部港口出口的潜在市场，但其采购量波动很大。 根据价格指数中心(CPI)的数据，9月份俄罗斯煤炭海上出口月环比下降4%，至1570万吨。由于基数低的影响，比一年前增长了28%。9月份煤炭出口总量估计为1710万吨。西北港口的航运量下降了9%，至300万吨，主要原因是摩尔曼斯克集群下降了24%，至46万吨。远东港口出口下降5%，至1110万吨，对印度出口下降31%，至50万吨。 阿尔法银行证券市场分析主管鲍里斯·克拉斯诺热诺夫(Boris Krasnozhenov)表示，通过南部港口运送煤炭的增长可能与对土耳其的销售增长有关，土耳其下半年工业活动有所增长。此外，通过南部港口的货运受到哈萨克斯坦煤炭过境欧洲市场的影响。 “专家RA”机构分析师基里尔·利森科(Kirill Lysenko)指出，通过南部港口供应煤炭的最重要方向是印度和土耳其。据他介绍，俄罗斯煤炭由于物流紧密和供应条件灵活，在土耳其市场保持着稳固的地位。在冶金领域，情况则不太稳定：由于土耳其钢铁产能负荷有限，炼焦煤供应量呈现下降趋势。 与此同时，利森科继续说，中东目前对煤炭虽有需求但不稳定，北非地区特别是摩洛哥，干旱时期和高天然气价格虽然刺激了进口，但是需求波动很大。而且出口大幅增长的可能性还会受到对买家实施二级制裁的风险、金融结算和物流困难的限制。 如果我们考虑到在克麦罗沃州开采6000大卡煤炭的平均成本目前约为2600-2800卢布，那么叠加运费等其他成本后，出口可能是无利可图的。如今，出口商大都寻求在国外市场保持市场份额，以期在供应盈利能力恢复时情况好转。", "release_time": "2025-10-23", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195194-1.html"}
{"category": "研究前沿", "title": "科学家用金箔与光首次可视化“自然隐形胶水”", "short_summary": "研究人员开发新型平台，通过金箔悬浮液与光相互作用直接观测纳米尺度作用力。", "detailed_summary": "研究人员开发新型平台，通过金箔悬浮液与光相互作用直接观测纳米尺度作用力。\n（1）瑞典查尔姆斯理工大学团队开发创新实验平台，将微观金箔悬浮于盐溶液并置于镀金玻璃基板上；\n（2）金箔与基板形成纳米级间隙，捕获光线产生彩色图案，使范德华力等纳米作用力实现可视化观测；\n（3）平台揭示卡西米尔力（吸引力）与静电力（排斥力）的动态平衡，实现粒子的自组装过程；\n（4）该方法无需复杂仪器，可通过普通光学显微镜直接研究单个粒子的相互作用力；\n（5）该技术有望推动药物递送、生物传感器和材料科学等多个领域的基础研究突破。", "raw_content": "When dust clings to a surface or a gecko walks across a ceiling, it happens thanks to what scientists call \"nature's invisible glue.\" Researchers at Chalmers University of Technology in Sweden have developed a fast and simple way to observe these hidden forces that hold the tiniest objects in the universe together. By combining gold, salt water, and light, they have built a special platform where these forces can actually be seen as colorful patterns.  In one of Chalmers' physics labs, doctoral student Michaela Hošková demonstrates the setup. She holds a glass container filled with millions of microscopic gold flakes suspended in a salt solution. With a pipette, she places a single drop of this liquid on a gold-coated glass plate positioned under an optical microscope. Almost immediately, the gold flakes are drawn toward the surface, but they stop just short of touching it, leaving behind extremely thin gaps measured in nanometers. These tiny cavities act as miniature light traps, causing light to reflect back and forth and produce vivid colors. When illuminated by the microscope's halogen lamp and analyzed through a spectrometer, the light separates into different wavelengths. On the connected monitor, flakes shimmer and shift between hues of red, green, and gold as they move across the surface. Studying 'nature's glue' using light trapped in tiny cavities \"What we are seeing is how fundamental forces in nature interact with each other. Through these tiny cavities, we can now measure and study the forces we call 'nature's glue' -- what binds objects together at the smallest scales. We don't need to intervene in what is happening, we just observe the natural movements of the flakes,\" says Michaela Hošková, a doctoral student at the Department of Physics at Chalmers University of Technology and first author of the scientific article in the journal PNAS in which the platform is presented. The light confined inside these nanoscopic cavities allows scientists to explore a delicate equilibrium between two competing forces: one that pulls the flakes toward the surface and another that pushes them apart. The attractive force, known as the Casimir effect, causes the gold flakes to draw closer together and toward the substrate. The opposing electrostatic force, generated by the charged particles in the salt solution, prevents them from sticking completely. When these forces reach perfect balance, a process called self-assembly occurs, creating the cavities that make this phenomenon visible. \"Forces at the nanoscale affect how different materials or structures are assembled, but we still do not fully understand all the principles that govern this complex self-assembly. If we fully understood them, we could learn to control self-assembly at the nanoscale. At the same time, we can gain insights into how the same principles govern nature on much larger scales, even how galaxies form,\" says Michaela Hošková. Gold flakes become floating sensors The Chalmers researchers' new platform is a further development of several years of work in Professor Timur Shegai's research group at the Department of Physics. From the discovery four years ago that a pair of gold flakes creates a self-assembled resonator, researchers have now developed a method to study various fundamental forces.  The researchers believe that the platform, in which the self-assembled gold flakes act as floating sensors, could be useful in many different scientific fields such as physics, chemistry and materials science. \"The method allows us to study the charge of individual particles and the forces acting between them. Other methods for studying these forces often require sophisticated instruments which cannot provide information down to the particle level,\" says research leader Timur Shegai. Can provide new knowledge on everything from medicines to biosensors Another way to use the platform, which is important for the development of many technologies, is to gain a better understanding of how individual particles interact in liquids and either remain stable or tend to stick to each other. It can provide new insights into the pathways of medicines through the body, or how to make effective biosensors, or water filters. But it is also important for everyday products that you do not want to clump together, such as cosmetics. \"The fact that the platform allows us to study fundamental forces and material properties shows its potential as a truly promising research platform,\" says Timur Shegai. In the lab, Michaela Hošková opens a box containing a finished sample of the platform. She lifts it with tweezers and shows how easily it can be placed in the microscope. Two thin glass plates hold everything needed to study nature's invisible glue.  \"What I find most exciting is that the measurement itself is so beautiful and easy. The method is simple and fast, based only on the movement of gold flakes and the interaction between light and matter,\" says Michaela Hošková, zooming the microscope in on a gold flake, the colors of which immediately reveal the forces at play. How the researchers study 'nature's invisible glue' Gold flakes approximately 10 micrometers in size are placed in a container filled with a salt solution, i.e. water containing free ions. When a drop of the solution is placed on a glass substrate covered with gold, the flakes are naturally attracted to the substrate and nanometer-sized cavities (100-200 nanometers) appear. Self-assembly occurs as a result of a delicate balance between two forces: the Casimir force, a directly measurable quantum effect that causes objects to be attracted to each other, and the electrostatic force that arises between charged surfaces in a salt solution. When a simple halogen lamp illuminates the tiny cavities, the light inside is captured as if in a trap. This allows the researchers to study the light more closely using an optical microscope connected to a spectrometer. The spectrometer separates the wavelengths of the light so that different colors can be identified. By varying the salinity of the solution and monitoring how the flakes change their distance to the substrate, it is possible to study and measure the fundamental forces at play. To prevent the saline solution with the gold flakes from evaporating, the drop of gold flakes and saline are sealed and then covered with another glass plate. The platform was developed at Chalmers' Nanofabrication Laboratory, Myfab Chalmers, and at the Chalmers Materials Analysis Laboratory (CMAL). More about the research The scientific article Casimir self-assembly:A platform for measuring nanoscale surface interactions in liquids has been published in PNAS (Proceedings of the National Academy of Sciences). It was written by Michaela Hošková, Oleg V. Kotov, Betül Küçüköz and Timur Shegai at the Department of Physics, Chalmers University of Technology, Sweden, and Catherine J. Murphy at the Department of Chemistry, University of Illinois, USA. The research was funded by the Swedish Research Council, the Knut and Alice Wallenberg Foundation, the Vinnova Centre 2D-Tech and Chalmers University of Technology's Nano Area of Advance.", "release_time": "2025-10-23", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/10/251023031607.htm"}
{"category": "研究前沿", "title": "暗物质或留颜色指纹，新研究挑战其不可见性", "short_summary": "研究称暗物质可使光变色，为直接探测提供新途径。", "detailed_summary": "研究称暗物质可使光变色，为直接探测提供新途径。\n（1）英国约克大学研究提出，暗物质可能在与光间接作用时留下红或蓝移\"指纹\"。\n（2）机制类似\"六度分隔\"，通过希格斯玻色子等中间粒子实现间接相互作用。\n（3）此发现挑战暗物质与光无任何相互作用传统观点，为直接探测开辟新窗口。\n（4）下一代望远镜或可探测此效应，有望简化搜索并优化未来实验设计。\n（5）研究成果发表于《Physics Letters B》，可能改变暗物质探测策略。", "raw_content": "Dark matter, the mysterious substance thought to make up most of the Universe, might not be completely invisible after all. A new study suggests it could leave behind a faint red or blue \"fingerprint\" in light that passes through regions filled with it.  Researchers at the University of York propose that light could subtly change color when it encounters dark matter, offering a potential method for detecting it directly. This finding challenges the long-standing belief that dark matter and light do not interact in any measurable way. Rethinking an \"Invisible\" Force Until now, dark matter has been known only through its gravitational influence, which holds galaxies together and shapes their structure. Because it neither emits nor reflects light, scientists have traditionally assumed it cannot be detected through optical means. The new work, however, suggests this view might be incomplete. According to the York team, light traveling through space could acquire a slight red or blue tint depending on the kind of dark matter it encounters. Detecting these subtle variations could open a new window into studying the unseen material that dominates the cosmos. A \"Six Handshake Rule\" for Particles The research is based on a concept similar to the \"six handshake rule.\" This is the idea that any two people are connected by a short chain of acquaintances. The scientists suggest that something comparable might occur among subatomic particles.  Even if dark matter does not interact directly with light, it could still affect it indirectly through other particles. Certain dark matter candidates, called Weakly Interacting Massive Particles (WIMPs), might influence light by connecting through a chain of intermediate particles such as the Higgs boson and the top quark. Traces of Color in the Darkness Dr. Mikhail Bashkanov, from the University of York's School of Physics, Engineering and Technology, explained: \"It's a fairly unusual question to ask in the scientific world, because most researchers would agree that dark matter is dark, but we have shown that even dark matter that is the darkest kind imaginable -- it could still have a kind of color signature. He added: \"It's a fascinating idea, and what is even more exciting is that, under certain conditions, this 'color' might actually be detectable. With the right kind of next-generation telescopes, we could measure it. That means astronomy could tell us something completely new about the nature of dark matter, making the search for it much simpler.\" A New Direction for Dark Matter Detection The study describes how these indirect interactions could be tested in upcoming experiments, allowing scientists to eliminate certain dark matter models while refining others. The team also emphasizes the importance of incorporating these findings into the design of future telescopes. Dark matter remains one of physics' greatest mysteries, revealing itself only through its gravitational pull. Confirming these results could provide an entirely new approach to detecting it and deepen our understanding of how the Universe is held together. Dr. Bashkanov said: \"Right now, scientists are spending billions building different experiments -- some to find WIMPs, others to look for axions or dark photons. Our results show we can narrow down where and how we should look in the sky, potentially saving time and helping to focus those efforts.\" The study was published in the journal Physics Letters B.", "release_time": "2025-10-23", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251022023124.htm"}
{"category": "政策计划", "title": "国家能源局部署“十五五”可再生能源发展重点", "short_summary": "能源局明确“十五五”风电光伏发展路径，聚焦基地建设与国际合作。", "detailed_summary": "能源局明确“十五五”风电光伏发展路径，聚焦基地建设与国际合作。\n（1）国家能源局在2025北京国际风能大会上宣布将科学编制“十五五”可再生能源发展规划。\n（2）重点推进以沙戈荒地区为主的大型风电光伏基地项目建设，坚持本地与外送消纳并重。\n（3）规范省管海域海上风电开发，积极稳妥推进深远海风电工作。\n（4）拓展“风电+”模式，并同上合组织国家实施风光千万千瓦项目，加强国际合作。", "raw_content": "10月21日消息，2025北京国际风能大会暨展览会(CWP  2025)10月20日-22日在京举行。在大会开幕式上，国家能源局新能源和可再生能源司副司长潘慧敏表示，今年是“十四五”的收官之年，也是谋划“十五五”的关键之年，更是开启碳达峰的攻坚之年。下一步，国家能源局将准确把握新能源发展新形势、新要求，积极配合全国人大做好可再生能源法修改工作，科学编制“十五五”可再生能源发展规划，加快出台《可再生能源消费最低比重目标和可再生能源电力消纳责任权重制度实施办法》。潘慧敏谈到，国家能源局将重点推进以下几项工作：一是坚持本地消纳和外送消纳并重，加快推进以沙戈荒地区为重点的大型风电光伏基地项目建设;二是规范有序推动省管海域的海上风电开发，积极稳妥推进深远海海上风电有关工作;三是推动风电集成发展，不断拓展“风电+”模式;四是同上合组织其他国家一道实施新增“千万千瓦光伏”和“千万千瓦风电”项目，依托“一带一路”、南南合作等平台，加强国际交流与合作，深化风电产业链供应链国际合作。", "release_time": "2025-11-11", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/zhdt/202510/t20251028_792236.html"}
{"category": "研究前沿", "title": "MIT突破光学显微镜极限实现原子级定位", "short_summary": "MIT研发DIGIT技术，结合原子网格先验知识使光学显微镜实现0.178埃单原子定位。", "detailed_summary": "MIT研发DIGIT技术，结合原子网格先验知识使光学显微镜实现0.178埃单原子定位。\n（1）MIT团队在《自然·通讯》发表新型计算成像技术DIGIT，突破光学显微镜衍射极限；\n（2）该方法将材料已知原子结构作为先验模板，通过统计分析与超分辨率显微镜数据匹配；\n（3）在钻石晶体实验中成功定位硅原子替代缺陷，精度达0.178埃（1埃=0.1纳米）；\n（4）技术适用于所有已知原子排列的材料（如晶体/蛋白质），代码已开源；\n（5）为量子器件原子精准排布及材料缺陷研究提供新途径。", "raw_content": "If you think of a single atom as a grain of sand, then a wavelength of visible light — which is a thousand times larger than the atom’s width — is comparable to an ocean wave. The light wave can dwarf an atom, missing it entirely as it passes by. This gulf in size has long made it impossible for scientists to see and resolve individual atoms using optical microscopes alone.Only recently have scientists found ways to break this “diffraction limit,” to see features that are smaller than the wavelength of light. With new techniques known as super-resolution microscopy, scientists can see down to the scale of a single molecule.And yet, individual atoms have still been too small for optical microscopes — which are much simpler and less expensive than super-resolution techniques — to distinguish, until now.In an open-access paper appearing today in Nature Communications, MIT scientists present a new computational method that enables optical microscopes to resolve individual atoms and zero in on their exact locations in a crystal structure.The team’s new “discrete grid imaging technique,” or DIGIT, is a computational imaging approach that scientists can apply to optical data to calculate the most probable location of individual atoms based on a very important clue: the material’s known atomic configuration. As long as scientists have an idea of what a material’s physical atomic layout should be, they can use this layout as a sort of map to determine where specific atoms or features must be located.“It’s like you know there’s a seating chart,” says lead author Yuqin “Sophia” Duan, a graduate student in MIT’s Department of Electrical Engineering and Computer Science (EECS). “Previous methods could tell you what section an atom is in. But now we can take this seating chart as prior knowledge, and can pinpoint exactly which seat the atom is in.”With DIGIT, the team can now pinpoint individual atoms with a resolution of 0.178 angstroms. (One angstrom is one-tenth of a nanometer, which is less than half the width of a single atom). The technique enables optical microscopes to localize atomic-scale features in any material that has a known atomic pattern, such as crystalline materials or certain proteins with repeating molecular chains.The team says the method could help guide the design of quantum devices, which often require placing individual atoms precisely within a crystal. Beyond quantum technologies, DIGIT can also provide new insights into how defects and impurities shape the behavior of advanced materials — from semiconductors to superconductors.Duan’s co-authors at MIT are Qiushi Gu, Hanfeng Wang, Yong Hu, Kevin Chen, Matthew Trusheim, and EECS Professor Dirk Englund.Grid supportScientists can image features smaller than a nanometer, and sometimes as small as a single atom, but not with optical microscopes. In these cases, they use transmission or scanning electron microscopes, which send high-energy beams of electrons into a sample to generate an image based on the pattern in which the electrons scatter. These electron-based methods produce highly detailed, near-atomic-scale images, but they require imaging in a vacuum and at high energies, and only work in ultrathin, synthetic, or solid-state materials. Electron-based imaging methods are too harsh for more delicate living specimens.In contrast, optical microscopes work at lower energies, in ambient conditions, and are safe to apply to biological samples. But they cannot discern features past the diffraction limit. Essentially, a microscope is unable to see features that are smaller than half the wavelength of visible light (about 200 to 300 nanometers) that a microscope sends in to probe a sample. Atoms, then, have long eluded optical microscopes.In 2014, however, the Nobel Prize in Chemistry was awarded to developers of a technique to overcome the diffraction limit. Super-resolution microscopy works by shining laser light on a sample at a specific frequency that is known to resonate with a feature of interest, such as a certain molecule. When that molecule resonates, it effectively announces its presence in the material. With this optical manipulation, scientists can visualize features as small as 10 nanometers, on the scale of a single molecule.Duan and Englund looked to resolve even smaller features by combining super-resolution techniques with statistical analysis and knowledge of materials that has often been overlooked.“One thing that gets ignored in imaging optical systems is the physical configuration of your system,” Duan says. “For example, if you want to visualize defects in a diamond system, these defects can only be at certain positions, since they have to follow the grid of the atomic diamond structure. In proteins, there are some structures that grow in an organized grid, and their location must be somewhere along that physical grid.”The researchers suspected that if they had a reasonably accurate map of a material’s atomic structure (imagine the ball-and-stick models of molecules in a chemistry classroom), they might use such maps as a template and try out many different orientations and rotation angles to find the closest match to whatever features are initially visualized using super-resolution microscopy.“No one has ever done this before, to include the physical constraints or system information into the resolution technique,” Duan says.Blurriness, collapsedTo test their idea, the researchers worked with a sample of diamond — a crystal whose microstructure is well-understood and resembles an organized grid, or lattice, of repeating carbon atoms. The researchers blindly knocked out some carbon atoms in the lattice and replaced them with silicon atoms using facilities at MIT.nano. Their goal was to identify and determine the precise locations of the errant silicon atoms.To do so, they first used established techniques of super-resolution microscopy to probe the diamond sample, using lasers set to specific wavelengths at frequencies known to resonate with the silicon atoms but not the carbon atoms. With this technique, researchers produced images that depicted the silicon atoms, but only as a uniform blur.The team then applied DIGIT to further resolve the picture. Knowing that diamond in general has a grid-like configuration of carbon atoms, the researchers took this configuration as a map, or seating chart of sorts, and assumed that any silicon atoms that took the place of a carbon atom must sit within the grid, which has a known spacing between atoms.“Because the silicon atoms are substituting carbon atoms in the lattice, that means they must obey some integer multiple of the atomic spacing of the crystal lattice, separating any two silicon atoms,” Englund says. “That prior knowledge makes the localization different than if you add a purely amorphous material.”The researchers essentially simulated many possibilities of orientations and rotation angles of the diamond lattice, superimposed on the blurry image of atoms that the super-resolution microscopy technique produced.“The trick is that, in certain materials, atoms aren’t spread out randomly — they sit on a grid inside a crystal,” Duan explains. “We used that prior knowledge to sharpen the microscope’s picture. Once we factored in that ‘atomic grid,’ the blurriness collapsed, and we could pinpoint exact positions.”In the end, they found the technique could pinpoint the location of individual silicon atoms within the diamond lattice, with a precision of 0.178 angstroms — the sharpest resolution of any optical-based imaging technique. The team has made the DIGIT code available on GitHub for anyone to apply to their optical measurements, provided their sample of interest has a well-understood atomic structure. Then, they hope that scientists will start to see much finer and detailed features and processes using light.“It’s a big step — it takes optical microscopes into the realm of atomic scale, something people thought only electron microscopes or X-rays could do,” Duan says. “That opens up a whole new way of studying materials and biology.”", "release_time": "2025-10-23", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/seating-chart-atoms-helps-locate-their-positions-materials-1022"}
{"category": "研究前沿", "title": "五位MIT学者当选美国国家医学院院士", "short_summary": "MIT五位学者因在免疫学、数字健康等领域的突破性研究当选美国国家医学院院士。", "detailed_summary": "MIT五位学者因在免疫学、数字健康等领域的突破性研究当选美国国家医学院院士。\n(1) 美国国家医学院宣布选举100名新成员，其中包括MIT教职员Dina Katabi和Facundo Batista及三位MIT校友。\n(2) Facundo Batista因揭示B细胞生物学及推进HIV、疟疾等疾病疫苗研发的贡献当选。\n(3) Dina Katabi因开创非侵入式无线健康监测AI技术及开发帕金森病数字生物标志物当选。\n(4) 另三位当选校友为Christopher S. Chen、Michael E. Matheny和Rebecca R. Richards-Kortum。\n(5) 当选是对学者在解决公共卫生挑战、推动医学发现方面卓越领导力的最高认可之一。", "raw_content": "On Oct. 20 during its annual meeting, the National Academy of Medicine announced the election of 100 new members, including MIT faculty members Dina Katabi and Facundo Batista, along with three additional MIT alumni.Election to the National Academy of Medicine (NAM) is considered one of the highest honors in the fields of health and medicine, recognizing individuals who have demonstrated outstanding professional achievement and commitment to service.Facundo Batista is the associate director and scientific director of the Ragon Institute of MGH, MIT and Harvard, as well as the first Phillip T. and Susan M. Ragon Professor in the MIT Department of Biology. The National Academy of Medicine recognized Batista for “his work unraveling the biology of antibody-producing B cells to better understand how our body’s immune systems responds to infectious disease.” More recently, Facundo’s research has advanced preclinical vaccine and therapeutic development for globally important diseases including HIV, malaria, and influenza.Batista earned a PhD from the International School of Advanced Studies and established his lab in 2002 as a member of the Francis Crick Institute (formerly the London Research Institute), simultaneously holding a professorship at Imperial College London. In 2016, he joined the Ragon Institute to pursue a new research program applying his expertise in B cells and antibody responses to vaccine development, and preclinical vaccinology for diseases including SARS-CoV-2 and HIV. Batista is an elected fellow or member of the U.K. Academy of Medical Sciences, the American Academy of Microbiology, the Academia de Ciencias de América Latina, and the European Molecular Biology Organization, and he is chief editor of The EMBO Journal.Dina Katabi SM ’99, PhD ’03 is the Thuan (1990) and Nicole Pham Professor in the Department of Electrical Engineering and Computer Science at MIT. Her research spans digital health, wireless sensing, mobile computing, machine learning, and computer vision. Katabi’s contributions include efficient communication protocols for the internet, advanced contactless biosensors, and novel AI models that interpret physiological signals. The NAM recognized Katabi for “pioneering digital health technology that enables non-invasive, off-body remote health monitoring via AI and wireless signals, and for developing digital biomarkers for Parkinson’s progression and detection. She has translated this technology to advance objective, sensitive measures of disease trajectory and treatment response in clinical trials.”Katabi is director of the MIT Center for Wireless Networks and Mobile Computing. She is also a member of the Computer Science and Artificial Intelligence Laboratory (CSAIL), where she leads the Networks at MIT Research Group. Katabi received a bachelor’s degree from the University of Damascus and MS and PhD degrees in computer science from MIT. She is a MacArthur Fellow; a member of the American Academy of Arts and Sciences, National Academy of Sciences, and National Academy of Engineering; and a recipient of the ACM Computing Prize. Additional MIT alumni who were elected to the NAM for 2025 are:Christopher S. Chen SM ’93, PhD ’97, an alumnus of the Department of Mechanical Engineering and the Harvard-MIT Program in Health Sciences and Technology; Michael E. Matheny SM ’06, an alumnus of the Harvard-MIT Program in Health Sciences and Technology; and Rebecca R. Richards-Kortum SM ’87, PhD ’90, and alumna of the Department of Physics and the Harvard-MIT Program in Health Sciences and Technology.Established originally as the Institute of Medicine in 1970 by the National Academy of Sciences, the National Academy of Medicine addresses critical issues in health, science, medicine, and related policy, and inspires positive actions across sectors.“I am deeply honored to welcome these extraordinary health and medicine leaders and researchers into the National Academy of Medicine,” says NAM President Victor J. Dzau. “Their demonstrated excellence in tackling public health challenges, leading major discoveries, improving health care, advancing health policy, and addressing health equity will critically strengthen our collective ability to tackle the most pressing health challenges of our time.”", "release_time": "2025-10-23", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/mit-affiliates-elected-national-academy-medicine-1022"}
{"category": "研究前沿", "title": "MIT研究：图表设计特征影响数据信任度", "short_summary": "MIT研究发现人们对数据可视化的信任度受图表设计引发的社会背景推断影响。", "detailed_summary": "MIT研究发现人们对数据可视化的信任度受图表设计引发的社会背景推断影响。\n（1）MIT研究揭示人们对图表的信任度取决于对制作者社会背景的推断，而非仅基于数据本身；\n（2）这种社会推断主要源自图表的设计特征，如颜色搭配、信息排列方式等视觉元素；\n（3）研究通过定性访谈和定量调查发现，即使去除文字说明，人们仍能基于\"氛围\"做出推断；\n（4）这种现象普遍存在，不受数据素养限制，且推断会影响人们对数据的信任与接受程度；\n（5）研究人员建立了分类框架，为科学传播者设计更有效的可视化方案提供参考。", "raw_content": "The degree to which someone trusts the information depicted in a chart can depend on their assumptions about who made the data visualization, according to a pair of studies by MIT researchers.For instance, if someone infers that a graph about a controversial topic like gun violence was produced by an organization they feel is in opposition with their beliefs or political views, they may discredit the information or dismiss the visualization all together.The researchers found that even the clearest visualizations often communicate more than the data they explicitly depict, and can elicit strong judgments from viewers about the social contexts, identities, and characteristics of those who made the chart.Readers make these assessments about the social context of a visualization primarily from its design features, like the color palette or the way information is arranged, rather than the underlying data. Often, these inferences are unintended by the designers.Qualitative and quantitative studies revealed that these social inferences aren’t restricted to certain subgroups, nor are they caused by limited data literacy.The researchers consolidate their findings into a framework that scientists and communicators can use to think critically about how design choices might affect these social assumptions. Ultimately, they hope this work leads to better strategies for scientific communication.“If you are scrolling through social media and you see a chart, and you immediately dismiss it as something an influencer has produced just to get attention, that shapes your entire experience with the chart before you even dig into the data. We’ve shown in these papers that visualizations do more than just communicate the data they are depicting — they also communicate other social signals,” says Arvind Satyanarayan, an associate professor in the MIT Department of Electrical Engineering and Computer Science (EECS) and member of the Computer Science and Artificial Intelligence Laboratory (CSAIL) and co-senior author of this research.He is joined on the paper by co-lead authors Amy Rae Fox, a former CSAIL postdoc, and Michelle Morgenstern, a current postdoc in MIT’s anthropology program; and co-senior author Graham M. Jones, professor of anthropology. Two related papers on this research will be presented at the IEEE Visualization Conference.Charts as social artifactsDuring the height of the Covid-19 pandemic, social media was awash in charts from organizations like the World Health Organization and Centers for Disease Control and Prevention, which were designed to convey information about the spread of disease.The MIT researchers studied how these visualizations were being used to discuss the pandemic. They found that some citizen scientists were using the underlying data to make visualizations of their own, challenging the findings of mainstream science.“This was an unexpected discovery as, previously, citizen scientists were typically aligned with mainstream scientists. It took us a few years to figure out how to study this phenomenon more deeply,” Satyanarayan says.Most research into data visualization studies how charts communicate data. Instead, the researchers wanted to explore visualizations from a social and linguistic perspective to assess the information they convey beyond the data.Linguistic anthropologists have found that, while language allows people to communicate ideas, it also holds social meaning beyond the words people use. For instance, an accent or dialect can indicate that someone is part of a particular community.By “pointing” to certain social meanings, identities, and characteristics, language serves what is known as a socio-indexical function.“We wanted to see if things in the visual language of data communication might point to certain institutions, or the kinds of people in those institutions, that carry a meaning that could be unintended by the makers of the visualization,” Jones says.To do this, the researchers conducted an initial, qualitative study of users on the social media platform Tumblr. During one-on-one interviews, the researchers showed users a variety of real visualizations from online sources, as well as modified visualizations where they removed the textual information, like titles and axes labels.Stripping out the textual information was particularly important, since it mimics the way people often interact with online visualizations.“Our engagement with social media is a few quick seconds. People aren’t taking the time to read the title of a chart or look at the data very carefully,” Satyanarayan says.The interviews revealed that users made detailed inferences about the people or organizations who created the visualizations based on what they called “vibes,” design elements, like colors or the use of certain graphics. These inferences in turn impacted their trust in the data.For instance, after seeing a chart with the flags of Georgia and Texas and a graph with two lines in red and black, but no text, one user said, “This kind of looks like something a Texas Republican (legislator) would put on Twitter or on their website, or as part of a campaign presentation.”A quantitative approachBuilding on this initial work, the researchers used the same methodology in three quantitative studies involving surveys sent to larger groups of people from a variety of backgrounds.They found the same phenomenon: People make inferences about the social context of a visualization based on its design, which can lead to misunderstandings about, and mistrust in, the data it depicts.For instance, users felt some visualizations were so neatly arranged they believed them to be advertisements, and therefore not trustworthy. In another example, one user dismissed a chart by a Pulitzer-prize winning designer because they felt the hand-drawn graphical style indicated it was made by “some female Instagram influencer who is just trying to look for attention.”“If that is the first reaction someone has to a chart, it is going to massively impact the degree to which they trust it,” Satyanarayan says.Moreover, when the researchers reintroduced text in the visualizations from which it had been removed, users still made these social inferences.Typically, in data visualization, the solution to such a problem would be to create clearer charts or educate people about data literacy. But this research points to a completely different kind of data literacy, Jones says.“It is not erroneous for people to be drawing these inferences. It requires a lot of cultural knowledge about where visualizations come from, how they are made, and how they circulate. Drawing these inferences is a feature, not a bug, of the way we use signs,” he says.From these results, they created a classification framework to organize the social inferences users made and the design elements that contributed to them. They hope the typology serves as a tool designers can use to develop more effective visualizations, as well as a starting point for additional studies.Moving forward, the researchers want to continue exploring the role of data visualizations as social artifacts, perhaps by drilling down on each design feature they identified in the typology. They also want to expand the scope of their study to include visualizations in research papers and scientific journals.“Part of the value of this work is a methodological contribution to render a set of phenomena amenable to experimental study. But this work is also important because it showcases an interdisciplinary cross-pollination that is powerful and unique to MIT,” Jones says.This work was supported, in part, by MIT METEOR and PFPFEE fellowships, an Amar G. Bose Fellowship, an Alfred P. Sloan Fellowship, and the National Science Foundation.", "release_time": "2025-10-22", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/charts-can-be-social-artifacts-communicate-more-than-data-1022"}
{"category": "研究前沿", "title": "中科院副院长调研合肥物质院 指导聚变能源研究", "short_summary": "周琪调研合肥物质院大科学装置，强调聚焦国家战略提升科研显示度。", "detailed_summary": "周琪调研合肥物质院大科学装置，强调聚焦国家战略提升科研显示度。\n（1）10月17日，中国科学院副院长周琪赴合肥物质科学研究院调研，考察可控核聚变装置BEST和CRAFT等设施；  \n（2）听取研究院“十五五”规划思路、重大科技任务推进情况汇报，指导高标准推进规划编制；  \n（3）强调聚焦主责主业，围绕国家战略需求设定可回溯目标，提升科研目标聚焦度和成果显示度；  \n（4）要求发挥装置平台优势，促进跨学科交叉融合，弘扬“两弹一星”精神；  \n（5）调研旨在推动高水平科技自立自强，巩固聚变能源等领域优势。", "raw_content": "10月17日，中国科学院副院长、党组成员周琪赴合肥调研中国科学院合肥物质科学研究院，并与单位领导班子成员、科研骨干代表座谈交流。周琪一行实地考察了可控核聚变装置BEST和CRAFT相关设施、磁等离子体电推进实验室等，听取了研究院“十五五”规划思路、重大科技任务推进、关键核心技术攻关、重要平台建设运营等情况的汇报。他指出，合肥物质院要聚焦主责主业，强化顶层设计和体系化布局，高标准推进“十五五”规划编制，持续巩固和扩大在聚变能源等领域的优势。要坚持实事求是，紧密围绕国家战略需求，设定清晰可回溯的阶段性目标，着力提升科研工作的目标聚焦度和成果显示度。要找准科学方向，充分发挥装置设施平台优势，促进跨学科交叉融合发展。要传承弘扬“两弹一星”精神与科学岛的优良传统，胸怀“国之大者”，勇于承担使命，在实现高水平科技自立自强中发挥更大作用。中国科学院前沿科学与基础研究局、直属机关党委有关负责同志陪同调研。周琪一行调研大科学装置建设现场", "release_time": "2025-10-22", "source_institution": "等离子体物理研究所", "url": "http://www.ipp.ac.cn/xwdt/ttxw/202510/t20251022_785306.html"}
{"category": "研究前沿", "title": "研究揭示海洋藻类siphonein色素光保护机制", "short_summary": "科学家发现藻类色素siphonein可高效消散强光损伤，助力光合作用研究与太阳能技术革新。", "detailed_summary": "科学家发现藻类色素siphonein可高效消散强光损伤，助力光合作用研究与太阳能技术革新。\n（1）大阪公立大学团队发现海洋绿藻Codium fragile的siphonein色素能有效保护光合作用系统免受强光损伤；\n（2）通过电子顺磁共振光谱与量子化学模拟，证实siphonein可快速中和叶绿素三重态产生的有害活性氧；\n（3）该色素位于光捕获复合体关键位点，其分子结构特性使其在水下蓝绿光环境中具有高效能量消散能力；\n（4）研究为理解光合生物适应性进化提供新视角，并有望指导自保护型人工光合系统的设计。", "raw_content": "A day of strong sunlight can spoil more than just a beach outing -- it can also harm the process of photosynthesis, the way plants and other organisms convert sunlight into energy. Underwater, however, certain algae have evolved a unique way to stay protected. Researchers from Osaka Metropolitan University and their collaborators discovered that a pigment known as siphonein helps marine green algae continue photosynthesizing efficiently, even under intense light.  Protecting the Machinery of Photosynthesis Photosynthetic organisms use complex molecular systems called light-harvesting complexes (LHCs) to absorb sunlight and convert it into usable energy. When chlorophyll, the green pigment central to photosynthesis, absorbs light, it becomes excited and passes that energy to reaction centers that fuel chemical processes. Under too much light, though, chlorophyll can enter a dangerous \"triplet\" state, producing reactive oxygen molecules that can damage cells. \"Organisms use carotenoids to quickly dissipate excess energy, or quench these triplet states, through a process called triplet-triplet energy transfer (TTET),\" said Ritsuko Fujii, lead author and associate professor at the Graduate School of Science and Research Center for Artificial Photosynthesis at Osaka Metropolitan University. Until recently, the exact details of how this protective process works were not well understood. A Closer Look at Codium fragile To investigate, the research team turned to Codium fragile, a type of marine green alga. Like land plants, it has a light-harvesting antenna complex called LHCII, but it also contains rare carotenoids such as siphonein and siphonaxanthin. These pigments allow the algae to use green light -- common in underwater environments -- for photosynthesis.  \"The key to the quenching mechanism lies in how quickly and efficiently the triplet states can be deactivated,\" said Alessandro Agostini, researcher at the University of Padua, Italy and co-lead author of the study. The researchers used electron paramagnetic resonance (EPR) spectroscopy, a technique that directly measures triplet excited states, to compare spinach with Codium fragile. In spinach, traces of harmful chlorophyll triplet states remained. But in Codium fragile, those signals disappeared entirely, showing that its carotenoids successfully neutralize the damaging energy. \"Our research has revealed that the antenna structure of photosynthetic green algae has an excellent photoprotective function,\" Agostini said. How Siphonein Shields Algae From Sun Damage By combining EPR data with quantum chemical simulations, the researchers identified siphonein, located at a critical binding site in the LHCII complex, as the key pigment responsible for this defense. They also revealed how its molecular structure and positioning make it especially effective at dispersing excess energy. These findings show that marine algae have evolved specialized pigments not only to absorb the blue-green light available underwater but also to withstand the damaging effects of intense sunlight.  From Ocean Discovery to Solar Innovation Beyond improving our understanding of photosynthesis, this research could influence the design of bio-inspired solar technologies that protect themselves from light damage. Such systems might lead to more durable and efficient renewable energy solutions. \"We hope to further clarify the structural characteristics of carotenoids that increase quenching efficiency, ultimately enabling the molecular design of pigments that optimize photosynthetic antennae,\" Fujii said. The study was published in Cell Reports Physical Science.", "release_time": "2025-10-22", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251022023110.htm"}
{"category": "研究前沿", "title": "国际剂量学研讨会聚焦辐射医疗标准与AI创新", "short_summary": "IDOS2026将研讨辐射剂量学新标准与AI技术，推动医疗应用安全发展。", "detailed_summary": "IDOS2026将研讨辐射剂量学新标准与AI技术，推动医疗应用安全发展。\n（1）全球临床电离辐射应用扩展，精准测量与标准化对安全至关重要；\n（2）新技术如蒙特卡洛模型和人工智能正塑造剂量学标准与质保指南；\n（3）IDOS2026国际研讨会将提供论坛，讨论辐射剂量学、医学及防护最新进展；\n（4）会议旨在全面审视创新，应对工具复杂性，并为科学界提供相关建议。", "raw_content": "Where Clinical Reality Meets Standards   As countries around the world expand their clinical use of ionizing radiation, accurate measurement and calculation remain essential for the safe and effective use of radiation-based technologies. Primary and secondary standards laboratories provide reference measurements that allow medical professionals to trace their results directly to the International System of Units — ensuring global consistency. Dosimetry codes of practice reinforce this traceability and enable the optimized application of ionizing radiation in clinical settings.  “Recent technological developments — from new diagnostic approaches to cutting-edge computational methodologies that leverage Monte Carlo models and artificial intelligence (AI) — have shaped dosimetry standards, audit practices and quality assurance guidance,” said Mauro Carrara, IAEA Head of Dosimetry and Medical Radiation Physics and one of the symposia’s scientific secretaries. “For medical physicists, radiation metrologists and other scientists and researchers in the field, there is a critical need to comprehensively review innovations while addressing the growing complexity of available tools.”  “In building on the legacy of previous symposia since 1987, IDOS2026 will provide an international forum to discuss and disseminate the latest advances across radiation dosimetry, radiation medicine, radiation protection and their associated standards,” said Zakithi Msimang, IAEA medical radiation physicist and the event’s other scientific secretary. “Its proceedings and conclusions promise to provide relevant recommendations for the medical and scientific community.”", "release_time": "2025-10-23", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/call-for-abstracts-international-conference-on-medical-radiation-dosimetry"}
{"category": "产业应用", "title": "全球煤炭市场周度分析：欧洲反弹中国走强", "short_summary": "上周全球煤炭市场分化：欧洲煤价触底反弹，中国假期后需求走强，区域价格波动明显。", "detailed_summary": "上周全球煤炭市场分化：欧洲煤价触底反弹，中国假期后需求走强，区域价格波动明显。\n(1) 欧洲动力煤价从四年低点86.8美元/吨反弹至97美元/吨以上，空头平仓推动回升，供暖季提前刺激消费。\n(2) 中国秦皇岛5500大卡煤价涨至101美元/吨，异常天气致火电耗煤创秋季新高，沿海港口库存下降。\n(3) 印尼煤价有跌有涨，降雨影响供应，新在线平台加强行业监管。\n(4) 澳大利亚高热值煤价降至103美元/吨，冶金煤价格回调至188美元/吨。\n(5) 南非煤价反弹至81-82美元/吨，印度需求疲软导致出口转向越南等市场。", "raw_content": "据CCA Analysis 10月20日发布的信息，上周(截至10月19日)，全球煤炭市场价格稳定，贸易大体平稳。 上周，全球煤炭市场呈现出分化态势：欧洲煤价跌至4年低点后反弹回升;中国长假期后煤炭市场报价走强;印尼煤价有跌有涨;澳大利亚方面，高热值动力煤价格下降，中热值煤小幅上涨，而冶金煤价格则出现了回调。 欧洲动力煤价格指数从10月14日触及的四年低点(86.8美元/吨)反弹，回升至每吨97美元以上。此次反弹由纸面市场和实物市场(paper and physical markets)的累积空头头寸积极平仓推动。不过，部分市场参与者认为价格已触底，预计指数在短期和中期将出现反转。 今年欧洲供暖季较往年提前开始，这在利好煤炭价差的背景下意味着煤炭消费量将增长。欧洲供暖季的提前启动，在利好电力和电煤价差(clean dark spreads- CDS)的情况下，刺激着煤炭消费增长。 荷兰TTF交易中心天然气报价上涨至388.31美元/1000立方米，环比上涨1.48美元/1000立方米。欧盟被认为已为2025-2026年冬季做好充分准备，然而，天然气存储库存显著低于去年同期水平和10年平均水平，同时库存气提取量大幅增加。 欧洲ARA三大港口煤炭库存攀升至356万吨，环比增加80万吨，增长2%。 南非高热值6000千卡/千克煤价在2020年12月跌至低点(低于80美元/吨)后，随着欧洲报价的上涨，已反弹至81-82美元/吨水平。 印度买家，尤其是海绵铁行业的买家，由于印度本国煤炭供应充足、钢铁市场需求疲软以及当地全国性假期，几乎未发出任何询盘。因此，南非出口商将重点转向了越南及更小的区域市场。 中国方面，秦皇岛港5500大卡动力煤现货价格每吨上涨2美元，升至每吨101美元以上。动力煤市场在公共假期结束后活跃度加快。价格上涨受到需求增长的支撑，部分地区的供应中断以及可再生能源的减少，迫使发电厂消耗更多煤炭并补充库存。 目前中国北部出现了冻雨和初雪，导致内蒙古和陕西矿区的露天煤矿作业受阻。南部地区气温仍高至33-35°C，空调需求和电力消耗保持高位。受此天气异常影响，火电发电量创下秋季历史新高：该国最大火电厂的煤炭消耗量从410万吨/天增至490万吨/天，6大沿海电力公司的煤炭消耗量从180万吨/天增至230万吨/天。 沿海九大港口的煤炭库存降至2449万吨，环比下降30万吨。六大沿海火电集团的煤炭库存合计1396万吨，环比下降27万吨，而煤炭消耗量增至85.7万吨/天，环比增加1.4万吨/天。 印度尼西亚5,900 GAR煤炭价格小幅下跌至76.5美元/吨，而4,200 GAR价格则上涨至近44美元/吨。随着中国买家和贸易商重返市场，印尼市场活动有所增强，为报价提供了一定支撑。 而持续的降雨限制了印尼的采矿和煤炭物流：驳船停运，导致交货时间延长，并推高了12月船货的价格。与此同时，生产商并不急于签订长期合同，因为他们预计在11月临近时价格会更具吸引力。印尼当局推出了一项新的在线平台，用于更详细地跟踪煤炭行业的各项指标，可能有助于监管机构加强对供应的控制。 澳大利亚高热值6000大卡煤炭价格下调至103美元/吨。10月的前两周，亚洲买家(尤其是日本和韩国)活动较少，而中国市场参与者在节后将重点转向国内货源。此外，印尼6000大卡煤报价比澳大利亚高热值煤炭低10-15美元/吨。 由于冶金煤供应增加和钢铁产品报价下跌，澳大利亚HCC硬焦煤价格指数降至188美元/吨。 中国市场热轧卷板和螺纹钢价格下跌2%-3%。导致高炉利用率降低，煤炭消费量下降。印度的需求因全国性假期而有限。此外，澳大利亚昆士兰州天气改善，主要炼焦煤出口发运港包括海角港(Hay Point)和达尔林普尔湾港(Dalrymple Bay)在内的港口码头煤炭发货量已恢复正常。", "release_time": "2025-10-22", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195155-1.html"}
{"category": "研究前沿", "title": "MIT研究揭示神经活动调控突触发育新机制", "short_summary": "MIT团队发现神经活动通过反馈信号调控果蝇突触成熟，为理解自闭症等疾病提供新视角。", "detailed_summary": "MIT团队发现神经活动通过反馈信号调控果蝇突触成熟，为理解自闭症等疾病提供新视角。\n（1）MIT皮考尔研究所通过果蝇模型追踪突触活性区发育过程，首次实现突触\"生日\"标记；\n（2）研究发现突触成熟需数日时间，经历从自发释放到电刺激触发释放的阶段性发展；\n（3）神经活动缺失会导致突触异常肥大并抑制新突触形成，该过程依赖肌肉侧谷氨酸受体反馈信号；\n（4）Synaptotagmin 1蛋白突变与人类智力障碍、自闭症相关，研究为其病理机制提供解释；\n（5）该基础发现为干预突触功能异常相关神经系统疾病提供了潜在分子靶点。", "raw_content": "Nervous system functions, from motion to perception to cognition, depend on the active zones of neural circuit connections, or “synapses,” sending out the right amount of their chemical signals at the right times. By tracking how synaptic active zones form and mature in fruit flies, researchers at The Picower Institute for Learning and Memory at MIT have revealed a fundamental model for how neural activity during development builds properly working connections.Understanding how that happens is important, not only for advancing fundamental knowledge about how nervous systems develop, but also because many disorders such as epilepsy, autism, or intellectual disability can arise from aberrations of synaptic transmission, says senior author Troy Littleton, the Menicon Professor in The Picower Institute and MIT’s Department of Biology. The new findings, funded in part by a 2021 grant from the National Institutes of Health, provide insights into how active zones develop the ability to send neurotransmitters across synapses to their circuit targets. It’s not instant or predestined, the study shows. It can take days to fully mature, and that is regulated by neural activity.If scientists can fully understand the process, Littleton says, then they can develop molecular strategies to intervene to tweak synaptic transmission when it’s happening too much or too little in disease.“We’d like to have the levers to push to make synapses stronger or weaker, that’s for sure,” Littleton says. “And so knowing the full range of levers we can tug on to potentially change output would be exciting.”Littleton Lab research scientist Yuliya Akbergenova led the study published Oct. 14 in the Journal of Neuroscience.How newborn synapses grow upIn the study, the researchers examined neurons that send the neurotransmitter glutamate across synapses to control muscles in the fly larvae. To study how the active zones in the animals matured, the scientists needed to keep track of their age. That hasn’t been possible before, but Akbergenova overcame the barrier by cleverly engineering the fluorescent protein mMaple, which changes its glow from green to red when zapped with 15 seconds of ultraviolet light, into a component of the glutamate receptors on the receiving side of the synapse. Then, whenever she wanted, she could shine light and all the synapses already formed before that time would glow red, and any new ones that formed subsequently would glow green.With the ability to track each active zone’s birthday, the authors could then document how active zones developed their ability to increase output over the course of days after birth. The researchers actually watched as synapses were built over many hours by tagging each of eight kinds of proteins that make up an active zone. At first, the active zones couldn’t transmit anything. Then, as some essential early proteins accumulated, they could send out glutamate spontaneously, but not if evoked by electrical stimulation of their host neuron (simulating how that neuron might be signaled naturally in a circuit). Only after several more proteins arrived did active zones possess the mature structure for calcium ions to trigger the fusion of glutamate vesicles to the cell membrane for evoked release across the synapse.Activity mattersOf course, construction does not go on forever. At some point, the fly larva stops building one synapse and then builds new ones further down the line as the neuronal axon expands to keep up with growing muscles. The researchers wondered whether neural activity had a role in driving that process of finishing up one active zone and moving on to build the next.To find out, they employed two different interventions to block active zones from being able to release glutamate, thereby preventing synaptic activity. Notably, one of the methods they chose was blocking the action of a protein called Synaptotagmin 1. That’s important because mutations that disrupt the protein in humans are associated with severe intellectual disability and autism. Moreover, the researchers tailored the activity-blocking interventions to just one neuron in each larva because blocking activity in all their neurons would have proved lethal.In neurons where the researchers blocked activity, they observed two consequences: the neurons stopped building new active zones and instead kept making existing active zones larger and larger. It was as if the neuron could tell the active zone wasn’t releasing glutamate and tried to make it work by giving it more protein material to work with. That effort came at the expense of starting construction on new active zones.“I think that what it’s trying to do is compensate for the loss of activity,” Littleton says.Testing indicated that the enlarged active zones the neurons built in hopes of restarting activity were functional (or would have been if the researchers weren’t artificially blocking them). This suggested that the way the neuron sensed that glutamate wasn’t being released was therefore likely to be a feedback signal from the muscle side of the synapse. To test that, the scientists knocked out a glutamate receptor component in the muscle, and when they did, they found that the neurons no longer made their active zones larger.Littleton says the lab is already looking into the new questions the discoveries raise. In particular: What are the molecular pathways that initiate synapse formation in the first place, and what are the signals that tell an active zone it has finished growing? Finding those answers will bring researchers closer to understanding how to intervene when synaptic active zones aren’t developing properly.In addition to Littleton and Akbergenova, the paper’s other authors are Jessica Matthias and Sofya Makeyeva.In addition to the National Institutes of Health, The Freedom Together Foundation provided funding for the study.", "release_time": "2025-10-22", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/neural-activity-helps-circuit-connections-mature-into-optimal-signal-transmitters-1021"}
{"category": "研究前沿", "title": "物理学家发现可自发分裂的旋转晶体", "short_summary": "多国团队揭示旋转粒子晶体具奇弹性，可自发分裂重组，颠覆传统材料行为。", "detailed_summary": "多国团队揭示旋转粒子晶体具奇弹性，可自发分裂重组，颠覆传统材料行为。\n（1）德美多校物理学家在PNAS发表研究，提出\"横向相互作用\"系统理论框架；\n（2）旋转粒子在高浓度下形成固体，展现\"奇弹性\"（受力扭曲而非拉伸）；\n（3）晶体可自发分裂为旋转碎片并能重新组装，颠覆传统晶体生长规律；\n（4）理论模型揭示了临界碎片尺寸与转速的关系，缺陷可外部调控；\n（5）该发现有望应用于新型开关元件，涵盖胶体研究至生物系统领域。", "raw_content": "It may sound unbelievable, but crystals made of rotating particles are real. A group of physicists from Aachen, Düsseldorf, Mainz, and Wayne State University (Detroit, USA) has explored these unusual materials and their remarkable behavior. These crystals can easily split into separate fragments, form unusual grain boundaries, and display controllable structural defects. In a study published in the Proceedings of the National Academy of Sciences (PNAS), the researchers present a broad theoretical framework that can predict several new properties of these so-called \"transverse interaction\" systems.  Rotating Systems in Nature and Technology \"Transverse forces\" can appear not only in engineered materials, such as certain magnetic solids, but also in biological systems. In an experiment at the Massachusetts Institute of Technology (MIT), researchers observed that groups of starfish embryos, through their swimming motions, influenced each other's movement in a way that caused them to rotate around one another. The biological function of this coordinated motion remains unclear, but it shares the same fundamental feature found in these synthetic systems: interacting, rotating objects. Professor Dr. Hartmut Löwen from the Institute of Theoretical Physics II at Heinrich Heine University Düsseldorf (HHU) explains: \"A system of many rotating constituent elements exhibits a qualitatively new behavior that is non-intuitive: At high concentrations, these objects form a solid body of rotors, which possess 'odd' material properties.\" One such property is known as \"odd elasticity.\" Normally, when a material is pulled, it stretches along the direction of the force. In contrast, an odd elastic material does not stretch -- it twists instead. Twisting, Breaking, and Reforming This kind of \"odd\" solid can even disintegrate on its own. When the rotating building blocks rub together strongly enough, the solid can fragment into many smaller spinning crystallites. Even more surprisingly, these fragments can later reassemble themselves into a coherent structure once again.  A research team led by Professor Dr. Zhi-Feng Huang from Wayne State University and Professor Löwen developed a multiscale theoretical model to describe the behavior of these odd crystals. Using this model, they performed simulations that revealed unexpected patterns and possible technological uses for these rotating materials. Reversing the Rules of Crystal Growth The team found that large crystals governed by transverse interactions tend to break down into smaller spinning units, while smaller crystals grow until reaching a specific critical size. This outcome runs counter to conventional crystal growth, where materials typically expand steadily under favorable conditions. Professor Huang explains:\"We have discovered a fundamental property of nature underlying this process which determines the relation between the size of the critical fragments and their rotation speed.\" Study co-author Professor Dr. Raphael Wittkowski of the DWI -- Leibniz Institute for Interactive Materials and of RWTH Aachen University, adds: \"We furthermore demonstrated how defects in the crystals exhibit dynamics of their own. The formation of such defects can be influenced from outside, which allows properties of the crystals to be specifically controlled with a view to usage applications.\" \"Our far-reaching theory encompasses all systems evidencing such transverse interactions. Conceivable applications range from colloid research to biology,\" declares co-author Dr. Michael te Vrugt, Assistant Professor at the University of Mainz.  Professor Löwen adds: \"The model calculations indicate concrete application potential. The novel elastic properties of these new crystals could be exploited to invent new technical switching elements, for example.\" Central vs. Transverse Forces In physics, interactions such as gravity and the Coulomb force are known as central forces because they act along the line connecting the centers of two bodies. These forces cause objects to move toward or away from each other. By contrast, transverse interactions are a recently discovered class of forces that act perpendicular to that central axis. This unusual alignment causes the bodies to start rotating around one another spontaneously -- a dynamic at the heart of these newly discovered rotating crystals.", "release_time": "2025-10-22", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/10/251021083635.htm"}
{"category": "研究前沿", "title": "二维材料中发现天然光学腔效应", "short_summary": "科学家利用新型光谱技术发现二维材料堆叠可自然形成光学腔，为操控量子相提供新途径。", "detailed_summary": "科学家利用新型光谱技术发现二维材料堆叠可自然形成光学腔，为操控量子相提供新途径。\n(1) 研究背景：二维材料的特殊堆叠方式可产生超导等奇异量子效应，但其形成机制与控制方法仍是物理学家面临的挑战。\n(2) 创新方法：团队开发芯片级太赫兹光谱仪，将光波长从1毫米压缩至3微米，首次直接观测二维材料中的电子运动。\n(3) 关键发现：石墨烯等材料边缘可自然充当反射镜，形成等离子体极化激元（光-物质混合准粒子），无需外部镜面即可产生光学腔效应。\n(4) 理论突破：建立仅需几何参数即可预测实验结果的解析理论，实现材料性质的“一键提取”与未来样本的定向设计。\n(5) 研究意义：为理解与操控量子相开辟新路径，有望推动量子技术发展；该光谱技术可广泛应用于探测其他二维材料中的准粒子。", "raw_content": "When arranged in just the right ways, two-dimensional materials can display unusual and valuable quantum effects such as superconductivity and exotic types of magnetism. Understanding why these effects arise, and how to control them, remains one of the biggest challenges for physicists and engineers. A new study published in Nature Physics has uncovered a previously unseen property that may explain how these mysterious quantum phases form and evolve.  Using a novel terahertz (THz) spectroscopy method, researchers found that thin stacks of 2D materials -- commonly used in laboratories worldwide -- can naturally create what are called cavities. These tiny spaces confine both light and electrons into even smaller regions, significantly altering their interactions and behavior. \"We've uncovered a hidden layer of control in quantum materials and opened a path to shaping light-matter interactions in ways that could help us both understand exotic phases of matter and ultimately harness them for future quantum technologies,\" said James McIver, assistant professor of physics at Columbia and lead author of the paper. The work traces its origins to Hamburg, where McIver led a research group at the Max Planck Institute for the Structure and Dynamics of Matter (MPSD). The institute is part of the Max Planck-New York Center on Nonequilibrium Quantum Phenomena, a collaboration among MPSD, Columbia, the Flatiron Institute, and Cornell University. Researchers at the Center study how stable physical systems respond when pushed away from equilibrium. McIver's team explores these questions through light. \"2D materials, with their fascinating macroscopic properties, often behave like black boxes. By shining light on them, we can literally shed light on the hidden behavior of their electrons, revealing details that would otherwise remain unseen,\" said Gunda Kipp, a PhD student at MPSD and first author of the paper. One obstacle, however, is that the wavelengths of light needed to probe 2D materials are far larger than the materials themselves, which are thinner than a human hair. To overcome this scale mismatch, the researchers developed a chip-sized spectroscope that compresses THz light -- the range where many quantum effects occur -- from about 1 millimeter down to just 3 micrometers. This compact design made it possible to directly observe how electrons move within 2D materials. They first tested their approach using graphene, a well-known form of carbon, to measure its optical conductivity. What they found was unexpected: distinct standing waves.  \"Light can couple to electrons to form hybrid light-matter quasiparticles. These quasiparticles move as waves and, under certain conditions, they can become confined, much like the standing wave on a guitar string that produces a distinct note,\" explained MPSD postdoctoral fellow and co-first-author Hope Bretscher. In a guitar, the string's fixed ends define where the wave can form. Pressing a finger on the string shortens the wave, changing the pitch of the note. In optics, a similar process occurs when two mirrors trap light between them, creating a standing wave inside what scientists call a cavity. When a material is placed inside that cavity, the trapped light can repeatedly interact with it, altering its electronic properties. However, the researchers discovered that mirrors might not even be necessary. \"We found that the material's own edges already act as mirrors,\" said Kipp. With their THz spectroscope, they observed that excited streams of electrons reflect off the edges to form a type of hybrid light-matter quasiparticle called a plasmon polariton. The McIver lab studied a device made up of multiple layers, each of which can act as a cavity separated by a few tens of nanometers. The plasmons that form in each layer can, in turn, interact -- often strongly. \"It's like connecting two guitar strings; once linked, the note changes,\" said Bretscher. \"In our case, it changes drastically.\" The next step was to understand what determines the frequencies of these quasiparticles and how tightly light and matter couple together. \"With co-author and MPSD postdoctoral fellow Marios Michael, we developed an analytical theory that only needed a handful of geometric sample parameters to match the observations of our experiments,\" said Kipp. \"With just a click of a button, our theory can extract the properties of a material and will help us design and tailor future samples to obtain specific properties. For example, by tracking resonances as functions of carrier density, temperature, or magnetic field, we may uncover the mechanisms driving different quantum phases.\" While this study focused on plasmons, the new chip-scale THz spectroscope could detect other types of quasiparticles oscillating in many different 2D materials. The team is already testing new samples in both Hamburg and New York. \"This whole project was a bit of a serendipitous discovery. We didn't expect to see these cavity effects, but we're excited to use them to manipulate phenomena in quantum materials going forward,\" said Bretscher. \"And now that we have a technique to see them, we're intrigued to learn how they might be affecting other materials and phases.\"", "release_time": "2025-10-22", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/10/251021083640.htm"}
{"category": "研究前沿", "title": "等离子体所亮相国际聚变能大会展示前沿成果", "short_summary": "等离子体所团队在国际聚变能大会上作多项报告并展览，提升中国研究国际影响力。", "detailed_summary": "等离子体所团队在国际聚变能大会上作多项报告并展览，提升中国研究国际影响力。\n（1）等离子体所50余名科研人员参加在成都举行的世界聚变能源集团部长级会议暨第30届聚变能国际大会。\n（2）李建刚院士作“CRAFT项目综合进展”大会报告，徐国盛、龚先祖研究员分别就EAST装置运行演示和实验成果作口头及大会报告。\n（3）通过海报、模型装置展览及技术交流，展示了在磁约束装置研发、等离子体物理等领域的多项最新进展。\n（4）模型装置展区吸引国际专家关注，进行了深入技术交流，有效提升了中国聚变能研究的国际显示度。\n（5）大会主题聚焦聚变能作为清洁能源未来，涉及磁约束核聚变、惯性约束等多个前沿领域。", "raw_content": "等离子体所参加世界聚变能源集团第2次部长级会议暨国际原子能机构第30届聚变能大会  2025-10-21 | 作者：文/程凉 图/综合 |【大 中 小】【打印】【关闭】   10月14日，世界聚变能源集团第2次部长级会议暨第30届聚变能国际大会在成都举行。等离子体所50余名科研人员参加本次大会，报告内容覆盖磁约束聚变理论与模拟、聚变能源工程技术、ITER计划相关研究等多个专题。李建刚院士作为大会特邀专家应邀出席，并作了题为“CRAFT项目综合进展”的大会报告。徐国盛研究员就“EAST上偏滤器脱靶与无ELM H模兼容的长脉冲运行演示”作口头报告。龚先祖研究员围绕“支持ITER新研究计划的EAST近期实验成果综述”进行大会报告。陆坤研究员参与撰写工程分会会后综述报告，系统总结了磁约束核聚变实验装置在设计、建造与运行维护方面的最新进展，为国际聚变研究提供了重要参考。丁锐研究员作为组委会成员，参与会议报告遴选并主持“托卡马克进展综合”分会场。会议期间，等离子体所还通过海报展示、模型装置展览及技术交流等多种形式，向国际同行介绍了等离子体所在磁约束装置研发、等离子体物理理论与聚变材料技术等方面的最新进展，引发与会代表的广泛关注与深入讨论。此外，等离子体所模型装置展区吸引了多位国际聚变能组织的资深专家、各国研究机构负责人及企业技术代表前来参观。外宾对展示内容表现出浓厚兴趣，并与科研人员围绕相关技术问题进行了深入交流。此次展览有效提升了我国聚变能研究的国际显示度，为拓展实质性国际合作奠定了良好基础。此次世界聚变能源集团第2次部长级会议主题为“聚变能：清洁能源未来”，来自27个国家、6个国际组织的约150人参加会议。国际原子能机构第30届聚变能大会为期5天，主题为“聚变能源的创新与未来——技术、合作与可持续发展”，包括主旨报告、专题会议、技术展览等环节，议题涉及磁约束核聚变实验及验证、理论与模拟、聚变能技术、惯性约束聚变能、其他创新聚变概念等多个领域。等离子体所科研人员作大会报告领导嘉宾参观等离子体所模型装置展区", "release_time": "2025-11-04", "source_institution": "等离子体物理研究所", "url": "http://www.ipp.ac.cn/xwdt/ttxw/202511/t20251104_793643.html"}
{"category": "产业应用", "title": "MIT-IBM人工智能实验室推动产业应用创新", "short_summary": "MIT-IBM实验室通过高效AI模型与跨领域应用，助力企业实现技术转化与生产力提升。", "detailed_summary": "MIT-IBM实验室通过高效AI模型与跨领域应用，助力企业实现技术转化与生产力提升。\n(1) MIT-IBM Watson AI实验室八年合作成果显著，累计产生54项专利披露和12.8万次引用；\n(2) 研发小型化专用AI模型提升效率，如边缘设备语言处理模型和文档理解系统Granite Vision；\n(3) 技术创新涵盖多模态AI、因果推理框架及代码生成优化工具，应用于医疗、化学、金融等领域；\n(4) 通过产学研协同解决企业AI落地难题，预计三年内80%企业将集成生成式AI；\n(5) 培养学生参与产业实践，推动AI技术向可信、高效、实用方向发展。", "raw_content": "When it comes to artificial intelligence, MIT and IBM were there at the beginning: laying foundational work and creating some of the first programs — AI predecessors — and theorizing how machine “intelligence” might come to be.Today, collaborations like the MIT-IBM Watson AI Lab, which launched eight years ago, are continuing to deliver expertise for the promise of tomorrow’s AI technology. This is critical for industries and the labor force that stand to benefit, particularly in the short term: from $3-4 trillion of forecast global economic benefits and 80 percent productivity gains for knowledge workers and creative tasks, to significant incorporations of generative AI into business processes (80 percent) and software applications (70 percent) in the next three years.While industry has seen a boom in notable models, chiefly in the past year, academia continues to drive the innovation, contributing most of the highly cited research. At the MIT-IBM Watson AI Lab, success takes the form of 54 patent disclosures, an excess of 128,000 citations with an h-index of 162, and more than 50 industry-driven use cases. Some of the lab’s many achievements include improved stent placement with AI imaging techniques, slashing computational overhead, shrinking models while maintaining performance, and modeling of interatomic potential for silicate chemistry.“The lab is uniquely positioned to identify the ‘right’ problems to solve, setting us apart from other entities,” says Aude Oliva, lab MIT director and director of strategic industry engagement in the MIT Schwarzman College of Computing. “Further, the experience our students gain from working on these challenges for enterprise AI translates to their competitiveness in the job market and the promotion of a competitive industry.”“The MIT-IBM Watson AI Lab has had tremendous impact by bringing together a rich set of collaborations between IBM and MIT’s researchers and students,” says Provost Anantha Chandrakasan, who is the lab’s MIT co-chair and the Vannevar Bush Professor of Electrical Engineering and Computer Science. “By supporting cross-cutting research at the intersection of AI and many other disciplines, the lab is advancing foundational work and accelerating the development of transformative solutions for our nation and the world.”Long-horizon workAs AI continues to garner interest, many organizations struggle to channel the technology into meaningful outcomes. A 2024 Gartner study finds that, “at least 30% of generative AI projects will be abandoned after proof of concept by the end of 2025,” demonstrating ambition and widespread hunger for AI, but a lack of knowledge for how to develop and apply it to create immediate value.Here, the lab shines, bridging research and deployment. The majority of the lab’s current-year research portfolio is aligned to use and develop new features, capacities, or products for IBM, the lab’s corporate members, or real-world applications. The last of these comprise large language models, AI hardware, and foundation models, including multi-modal, bio-medical, and geo-spatial ones. Inquiry-driven students and interns are invaluable in this pursuit, offering enthusiasm and new perspectives while accumulating domain knowledge to help derive and engineer advancements in the field, as well as opening up new frontiers for exploration with AI as a tool.Findings from the AAAI 2025 Presidential panel on the Future of AI Research support the need for contributions from academia-industry collaborations like the lab in the AI arena: “Academics have a role to play in providing independent advice and interpretations of these results [from industry] and their consequences. The private sector focuses more on the short term, and universities and society more on a longer-term perspective.”Bringing these strengths together, along with the push for open sourcing and open science, can spark innovation that neither could achieve alone. History shows that embracing these principles, and sharing code and making research accessible, has long-term benefits for both the sector and society. In line with IBM and MIT’s missions, the lab contributes technologies, findings, governance, and standards to the public sphere through this collaboration, thereby enhancing transparency, accelerating reproducibility, and ensuring trustworthy advances.The lab was created to merge MIT’s deep research expertise with IBM’s industrial R&D capacity, aiming for breakthroughs in core AI methods and hardware, as well as new applications in areas like health care, chemistry, finance, cybersecurity, and robust planning and decision-making for business.Bigger isn't always betterToday, large foundation models are giving way to smaller, more task-specific models yielding better performance. Contributions from lab members like Song Han, associate professor in the MIT Department of Electrical Engineering and Computer Science (EECS), and IBM Research’s Chuang Gan help make this possible, through work such as once-for-all and AWQ. Innovations such as these improve efficiency with better architectures, algorithm shrinking, and activation-aware weight quantization, letting models like language processing run on edge devices at faster speeds and reduced latency.Consequently, foundation, vision, multimodal, and large language models have seen benefits, allowing for the lab research groups of Oliva, MIT EECS Associate Professor Yoon Kim, and IBM Research members Rameswar Panda, Yang Zhang, and Rogerio Feris to build on the work. This includes techniques to imbue models with external knowledge and the development of linear attention transformer methods for higher throughput, compared to other state-of-the-art systems. Understanding and reasoning in vision and multimodal systems has also seen a boon. Works like “Task2Sim” and “AdaFuse” demonstrate improved vision model performance if pre-training takes place on synthetic data, and how video action recognition can be boosted by fusing channels from past and current feature maps.As part of a commitment to leaner AI, the lab teams of Gregory Wornell, the MIT EECS Sumitomo Electric Industries Professor in Engineering, IBM Research’s Chuang Gan, and David Cox, VP for foundational AI at IBM Research and the lab’s IBM director, have shown that model adaptability and data efficiency can go hand in hand. Two approaches, EvoScale and Chain-of-Action-Thought reasoning (COAT), enable language models to make the most of limited data and computation by improving on prior generation attempts through structured iteration, narrowing in on a better response. COAT uses a meta-action framework and reinforcement learning to tackle reasoning-intensive tasks via self-correction, while EvoScale brings a similar philosophy to code generation, evolving high-quality candidate solutions. These techniques help to enable resource-conscious, targeted, real-world deployment.“The impact of MIT-IBM research on our large language model development efforts cannot be overstated,” says Cox. “We’re seeing that smaller, more specialized models and tools are having an outsized impact, especially when they are combined. Innovations from the MIT-IBM Watson AI Lab help shape these technical directions and influence the strategy we are taking in the market through platforms like watsonx.”For example, numerous lab projects have contributed features, capabilities, and uses to IBM’s Granite Vision, which provides impressive computer vision designed for document understanding, despite its compact size. This comes at a time when there’s a growing need for extraction, interpretation, and trustworthy summarization of information and data contained in long formats for enterprise purposes.Other achievements that extend beyond direct research on AI and across disciplines are not only beneficial, but necessary for advancing the technology and lifting up society, concludes the 2025 AAAI panel.Work from the lab’s Caroline Uhler and Devavrat Shah — both Andrew (1956) and Erna Viterbi Professors in EECS and the Institute for Data, Systems, and Society (IDSS) — along with IBM Research’s Kristjan Greenewald, transcends specializations. They are developing causal discovery methods to uncover how interventions affect outcomes, and identify which ones achieve desired results. The studies include developing a framework that can both elucidate how “treatments” for different sub-populations may play out, like on an ecommerce platform or mobility restrictions on morbidity outcomes. Findings from this body of work could influence the fields of marketing and medicine to education and risk management.“Advances in AI and other areas of computing are influencing how people formulate and tackle challenges in nearly every discipline. At the MIT-IBM Watson AI Lab, researchers recognize this cross-cutting nature of their work and its impact, interrogating problems from multiple viewpoints and bringing real-world problems from industry, in order to develop novel solutions,” says Dan Huttenlocher, MIT lab co-chair, dean of the MIT Schwarzman College of Computing, and the Henry Ellis Warren (1894) Professor of Electrical Engineering and Computer Science.A significant piece of what makes this research ecosystem thrive is the steady influx of student talent and their contributions through MIT’s Undergraduate Research Opportunities Program (UROP), MIT EECS 6A Program, and the new MIT-IBM Watson AI Lab Internship Program. Altogether, more than 70 young researchers have not only accelerated their technical skill development, but, through guidance and support by the lab’s mentors, gained knowledge in AI domains to become emerging practitioners themselves. This is why the lab continually seeks to identify promising students at all stages in their exploration of AI’s potential.“In order to unlock the full economic and societal potential of AI, we need to foster ‘useful and efficient intelligence,’” says Sriram Raghavan, IBM Research VP for AI and IBM chair of the lab. “To translate AI promise into progress, it’s crucial that we continue to focus on innovations to develop efficient, optimized, and fit-for-purpose models that can easily be adapted to specific domains and use cases. Academic-industry collaborations, such as the MIT-IBM Watson AI Lab, help drive the breakthroughs that make this possible.”", "release_time": "2025-10-22", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/creating-ai-that-matters-1021"}
{"category": "研究前沿", "title": "上海应物所研发新型光热水凝胶实现高效海水淡化与发电", "short_summary": "新型水凝胶材料实现太阳能驱动的高效海水淡化、污染物降解及余热发电一体化。", "detailed_summary": "新型水凝胶材料实现太阳能驱动的高效海水淡化、污染物降解及余热发电一体化。\n(1) 中国科学院上海应用物理研究所开发出名为PG@CuSₓ的多功能光热复合水凝胶。\n(2) 采用伽马射线辐照聚合与冷冻干燥技术在常温常压下制备，材料具有垂直多孔微通道结构。\n(3) 在标准太阳光下蒸发速率达8.1 kg·m⁻²·h⁻¹，并可提升至28.7 kg·m⁻²·h⁻¹，实现低于环境温度的\"全冷蒸发\"。\n(4) 具备优异耐盐性与净化能力，海水盐分去除率超99.9%，产水符合饮用水标准，并能高效降解有机污染物。\n(5) 结合热电发电机可实现883 mV电压输出，形成了太阳能蒸汽发电-光催化降解-热电联产三元耦合系统。", "raw_content": "上海应物所辐照技术制备多功能光热水凝胶研究取得进展                                    发布日期：2025/10/21  [ 大 中 小 ] [ 打印 ] [ 关闭 ]    近日，中国科学院上海应用物理研究所在利用高能射线辐照技术制备多功能水凝胶用于太阳能蒸汽发电-光催化降解-热电联产（SSG-PCD-TE）的三元耦合系统取得重要进展，相关成果“All-in-one photothermal hydrogel: Graphene@CuS with microchannels for fast evaporation ，water purification ，and heat reuse.”为题，发表在化工领域国际顶级期刊Chemical Engineering Journal，论文第一作者为上海应物所博士研究生林琳，通讯作者为应用化学部李吉豪副研究员和李林繁研究员。全球淡水资源紧张，太阳能蒸汽发电（SSG）技术因其绿色、低能耗的特点，成为解决水资源短缺的重要方向。然而，传统的光热蒸发材料在高温、高盐或污染水体中易发生结构破坏、性能下降，且难以同时实现高效蒸发、污染物降解和余热利用，限制其实际应用。基于团队前期在石墨烯/银复合水凝胶（Chemical  Engineering Journal ， 2023 ，147249）及石墨烯/MXene复合水凝胶（Desalination ，2025 ，  118657）方面的研究积累，本研究进一步开发出一种名为PG@CuSₓ的“一体化”多功能光热复合水凝胶。该材料以亲水性的聚丙烯酰胺（PAM）为三维网络骨架，整合了具有广谱光吸收能力的还原氧化石墨烯（rGO）和窄带隙半导体硫化铜（CuS）。以上海应物所的伽马射线辐照平台为基础，通过伽马射线辐照聚合与冷冻干燥技术，在常温常压下制备出具有垂直多孔微通道的多功能光热水凝胶。研究发现，该水凝胶具有以下特点：①高效光热蒸发：在标准太阳光强下蒸发速率达8.1  kg·m−2·h−1，通过调控可提升至28.7  kg·m−2·h−1，实现蒸发温度低于环境温度的“全冷蒸发”。②优异耐盐与净化能力：在高浓度盐水中连续光照16h无盐结晶，对海水盐分去除率超过99.9%，产水符合WHO饮用水标准。③污染物降解能力：可高效降解亚甲基蓝等有机污染物，实现“蒸发-净化”一体化。④热电联产功能：结合热电发电机可实现883  mV的电压输出，拓展了太阳能的多级利用途径。该研究实现了太阳能蒸汽发电-光催化降解-热电联产（SSG-PCD-TE）的三元耦合系统，为解决太阳能丰富但淡水匮乏地区的饮水与能源问题提供了全新思路。原文链接： https://doi.org/10.1016/j.cej.2025.167997图1. 伽马射线制备多功能PG@CuSx复合水凝胶材料用于高效海水淡化-污染物降解-热电转换.", "release_time": "2025-10-21", "source_institution": "上海应用物理研究所", "url": "http://www.sinap.cas.cn/xwzx/kydt/202510/t20251021_7993839.html"}
{"category": "政策计划", "title": "加州签署SB80法案加速核聚变能源发展", "short_summary": "加州立法加速核聚变商业化，依托研究优势推动能源独立与经济增长。", "detailed_summary": "加州立法加速核聚变商业化，依托研究优势推动能源独立与经济增长。\n（1）加州签署SB80法案，设立核聚变研发创新计划与专项基金，加速核聚变能源商业化；\n（2）加州拥有DIII-D和NIF等世界级核聚变研究设施，并在圣迭戈形成产学研聚集区；\n（3）法案旨在将科学突破转化为可靠、可持续的能源，提升美国能源独立性；\n（4）通用原子等机构通过合作推动技术革新，如利用人工智能加速研发；\n（5）此举有望吸引投资、创造高技能岗位，巩固加州在全球核聚变领域的领导地位。", "raw_content": "This month marks a defining moment for California and the future of clean energy. With the signing of Senate Bill 80 (SB80), the state has made a bold commitment to accelerate the development of fusion—the same process that powers the sun—and to lead the nation in meeting America’s growing energy demands. As energy needs surge, we face a critical challenge: delivering power that is reliable, sustainable, and ensures true energy independence. Fusion offers limitless potential to meet this challenge while driving economic growth and creating high-skill jobs for the future. California leads the nation in fusion research and development and is home to two world-class facilities: the DIII-D National Fusion Facility in San Diego, operated by General Atomics (GA) for the U.S. Department of Energy—the nation’s only operational fusion tokamak user facility—and the National Ignition Facility (NIF) at Lawrence Livermore National Laboratory, supported by the National Nuclear Security Administration, which became the first in the world to repeatedly achieve fusion ignition. SB80 builds on this legacy by establishing the Fusion Research and Development Innovation Initiative and creating a dedicated fund to accelerate breakthroughs, incentivize commercialization, and cement California’s global leadership in fusion energy. This is more than legislation—it’s a declaration of intent to transform scientific progress into real-world power. Here in San Diego, we are uniquely positioned to seize this opportunity. Institutions such as UC San Diego, and San Diego State University have advanced fusion research for decades. Recent efforts from the City of San Diego and the San Diego Regional Economic Development Council are further establishing our region as a hub for fusion research, engineering, and manufacturing. At GA, we are proud to have played an important role in advancing fusion on several fronts, from delivering precision target assemblies that have enabled the National Ignition Facility’s fusion breakthroughs to building the world’s most powerful pulsed superconducting magnet for the ITER experiment in France. More recently, we have collaborated with UC San Diego to launch the San Diego Fusion Data Science and Digital Engineering Center—uniting academia and industry to accelerate innovation through artificial intelligence and high-performance computing. SB80 recognizes the urgency of turning scientific progress into commercial reality. It will draw investment, spark innovation, and bring California and San Diego closer to achieving commercial fusion energy. The nation that realizes fusion first will define the energy future of humankind. Here in San Diego, we’re building that future—together with our collaborators across government, academia, industry, and the national labs.  Media Contact:Andrew JamesCommunications LeadGeneral Atomics Energy Group andrew.james@ga.com", "release_time": "2025-10-22", "source_institution": "通用原子能公司", "url": "http://www.ga.com/california-s-new-law-fast-tracks-the-race-to-sustainable-limitless-energy"}
{"category": "研究前沿", "title": "新型膜材料实现近乎完美的反向提锂", "short_summary": "研究团队开发卟吩框架膜，通过反向截留策略实现锂离子高效选择性提取。", "detailed_summary": "研究团队开发卟吩框架膜，通过反向截留策略实现锂离子高效选择性提取。\n（1）研究背景：传统锂提取方法因钠钾等竞争离子与锂性质相似，存在选择性和效率低的瓶颈。\n（2）创新方法：提出\"反向提锂\"新策略，选择性抑制锂离子透过膜，而让其他离子通过，实现锂富集。\n（3）材料设计：构建金属氢氧化物-卟吩框架结构膜（MHOPF），其有序孔道可识别并截留锂离子。\n（4）性能验证：该膜对锂离子实现近乎完全截留，同时允许钠钾等离子通过，展现出卓越选择性。\n（5）应用前景：在真实海水和盐湖水测试中验证应用潜力，相关成果发表于《德国应用化学》期刊。", "raw_content": "从盐湖水、地热卤水及海水中高效提取锂，是应对锂资源短缺问题的关键路径之一。传统分离方法因钠、钾等竞争性离子与锂在尺寸和电荷上高度相似，导致它们在分离膜中的迁移行为几乎一致，严重制约了锂的选择性与提取效率。为克服这一瓶颈，研究人员不断探索新材料与新策略，致力于开发兼具高选择性、环境友好性和可持续性的锂提取技术。近期，青岛能源所仿生能源界面技术研究中心的高军、杨丽君，联合山东科技大学王博研究团队，提出了一种创新的“反向提锂”方法，实现了近乎完美的锂离子选择性截留。与传统思路不同，该方法的核心在于选择性抑制锂离子透过，同时允许钠、钾等其他离子自由通过，从而在膜的一侧实现锂离子的高效富集。其理论基础在于不同离子在迁移过程中所需克服的能垒存在差异：锂离子因具有较小的离子半径与较高的电荷密度，通常表现出更高的迁移能垒。通过合理设计膜结构，可有效利用这一差异，调控不同离子的传输行为，实现锂离子的精准分离。基于上述原理，研究团队构建了一种基于卟吩孔道结构的离子传输通道，实现了对锂离子的近乎完全截留。该膜材料以氯化镍与对位四羧基苯基卟啉（TCPP）为前驱体，通过溶剂热反应结合真空辅助抽滤技术制备而成，形成金属氢氧化物-卟吩框架结构膜（MHOPF）（图1）。在该膜中，卟吩孔道高度有序排列，可作为识别并截留锂离子的高效通道。实验结果表明，该膜能有效阻隔锂离子，同时允许钠、钾、钙和镁等离子顺利透过，展现出卓越的锂筛选性能（图2）。图1 MHOPF的制备和表征图2 MHOPF实现几乎完美选择性的反向提锂通过密度泛函理论（DFT）计算，研究人员揭示了该膜选择性运输的机制（图3）。框架中的卟吩腔体与锂离子有着强烈的相互作用，使得锂离子在穿越卟吩腔体时需要克服较高的能量势垒，导致其难以实现跨膜传输。相比之下，钾离子和钠离子与卟吩腔体的相互作用较弱，其穿越卟吩腔体的过程所面临的能量势垒较低，因此能够顺利穿越卟吩腔体，最终实现跨膜运输。这种由离子与卟吩腔体相互作用能差所决定的能量势垒，是该膜能够实现几乎完美选择性反向提锂的关键物理基础。图3 离子选择性机理的密度泛函理论分析研究团队通过真实海水和盐湖水体系测试，验证了MHOPF膜的应用潜力。此外，在使用MHOPF膜进行电渗析实验时，低电压提升了其他竞争离子的渗透性，但仍对锂离子实现几乎完美截留，展示了该膜材料在锂提取技术中的应用潜力（图4）。图4 在电渗析中几乎完美的选择性相关研究成果以“Metal-Hydroxide-Porphin Framework Membrane for Almost Perfectly Selective Li+ Retention”为题发表于Angewandte Chemie International Edition。青岛能源所与山东科技大学2021级联培硕士蹇敏和马婷婷、中国科学院大学王子鑫为文章共同第一作者。研究得到了国家重点研发计划、国家自然科学基金、山东省自然科学基金和山东省重点研发项目等项目的支持。（文/图 杨丽君、高军）原文链接：https://onlinelibrary.wiley.com/doi/10.1002/anie.202515502Min Jian†, Tingting Ma†, Zixin Wang †, Xuan Ding, Hongfei Gao, Shangfa Pan, Bo Wang*, Lijun Yang*, Lei Jiang, Jun Gao*. Metal-Hydroxide-Porphin Framework Membrane for Almost Perfectly Selective Li+ Retention. Angewandte Chemie International Edition 2025，e202515502.DOI:10.1002/anie.202515502", "release_time": "2025-11-04", "source_institution": "青岛生物能源与过程研究所", "url": "https://qibebt.cas.cn/news/kyjz/202510/t20251021_7994033.html"}
{"category": "产业应用", "title": "日立与OpenAI联手推进AI基础设施与数据中心建设", "short_summary": "日立与OpenAI签署备忘录，合作开发可持续AI数据中心，应对电力挑战并加速技术部署。", "detailed_summary": "日立与OpenAI签署备忘录，合作开发可持续AI数据中心，应对电力挑战并加速技术部署。\n（1）日立与OpenAI于2025年10月签署谅解备忘录，建立战略合作伙伴关系；（2）合作重点包括建设下一代AI基础设施、扩展全球数据中心，并探索数据中心内外解决方案；（3）外部合作目标为最小化电网负荷、确保关键设备供应、标准化模块化设计以缩短建设时间；（4）内部合作涉及冷却系统等关键设备的设计与供应，支持AI数据中心快速部署；（5）日立将深化OpenAI大语言模型在Lumada解决方案中的集成，提升数字产品价值。", "raw_content": "Tokyo, Japan, October 21, 2025 - Hitachi, Ltd. (“Hitachi”) and OpenAI, Inc. (“OpenAI”) today announced that they have signed a Memorandum of Understanding (MoU) to establish a strategic partnership focused on building next-generation AI infrastructure and expanding global data centers. The agreement was signed on October 2, 2025. Under this MoU, the two companies will jointly develop plans across several key areas, combining their respective strengths to advance sustainable data center operations and accelerate the deployment of AI technologies that help address societal challenges. Key areas of collaboration  Partnership outside data centers  The companies will jointly explore solutions to:   Minimize the load on power transmission and distribution networks and achieve future zero-emission data centers. Secure the supply of critical and long-lead-time equipment for data centers. Standardize prefabricated and modular data center designs to shorten construction timelines.   Partnership within data centers  Hitachi and OpenAI will explore collaboration on the design and supply of essential equipment–such as cooling systems and storage–that supports the fast and reliable deployment of AI data centers. Further utilization of OpenAI technologies  Hitachi will explore deeper integration of OpenAI's large language models (LLMs) into its Lumada solutions, including HMAX, to enhance the value and capabilities of its digital offerings.  Background Hitachi Group, with its global leadership in power grids, clean energy, cooling technologies, data management, and operational services, is well-positioned to support the expansion of AI infrastructure. In the U.S., Hitachi Group has announced investments exceeding USD 1 billion to meet surging demand for transformers and high-voltage equipment driven by AI data center growth.  Additionally, Hitachi is accelerating the global rollout of its HMAX solutions, which combine AI and deep domain expertise across its extensive installed base of products and systems to help solve customer and societal challenges. Executive comments Toshiaki Tokunaga, President & CEO, Hitachi, Ltd.  “Through our Social Innovation Business, Hitachi has long contributed to creating a more sustainable society. While AI is driving rapid innovation, it also brings challenges such as power shortages. Through this strategic partnership, we aim to deliver the full capabilities of One Hitachi to support OpenAI's groundbreaking technologies, working together toward the realization of a harmonized society.” Tadao Nagasaki, President, OpenAI Japan, Ltd.  “OpenAI's mission is to ensure that artificial general intelligence benefits all of humanity. Our strategic partnership with Hitachi is an important step toward that vision. By combining the strengths of both organizations, we will co-create innovative solutions that address global challenges.” About Hitachi, Ltd.  Through its Social Innovation Business (SIB) that brings together IT, OT(Operational Technology) and products, Hitachi contributes to a harmonized society where the environment, wellbeing, and economic growth are in balance. Hitachi operates globally in four sectors – Digital Systems & Services, Energy, Mobility, and Connective Industries – and the Strategic SIB Business Unit for new growth businesses. With Lumada at its core, Hitachi generates value from integrating data, technology and domain knowledge to solve customer and social challenges. Revenues for FY2024 (ended March 31, 2025) totaled 9,783.3 billion yen, with 618 consolidated subsidiaries and approximately 280,000 employees worldwide. Visit us at www.hitachi.com.  Information contained in this news release is current as of the date of the press announcement, but may be subject to change without prior notice.", "release_time": "2025-11-18", "source_institution": "日本日立", "url": "http://www.hitachi.com/New/cnews/month/2025/10/251021c.html"}
{"category": "政策计划", "title": "我国充电设施将三年倍增，满足八千万辆电车需求", "short_summary": "我国充电设施超1800万个，新方案目标2027年达2800万个。", "detailed_summary": "我国充电设施超1800万个，新方案目标2027年达2800万个。\n（1）截至2025年9月，全国电动汽车充电设施总数达1806.3万个，同比增长54.5%；\n（2）公共充电设施447.6万个，私人充电设施1358.7万个；\n（3）六部门联合发布《电动汽车充电设施服务能力“三年倍增”行动方案（2025—2027年）》；\n（4）目标到2027年底建成2800万个充电设施，满足超8000万辆电动汽车需求；\n（5）我国已建成全球最大充电网络，每5辆电动汽车配备2个充电桩。", "raw_content": "昨日(20日)，国家能源局发布9月全国电动汽车充电设施数据。根据国家充电设施监测服务平台数据，截至2025年9月底，我国电动汽车充电基础设施(枪)总数达到1806.3万个，同比增长54.5%。其中，公共充电设施(枪)447.6万个，同比增长40%，公共充电桩额定总功率达到1.99亿千瓦，平均功率约为44.36千瓦;私人充电设施(枪)1358.7万个，同比增长60%，私人充电设施报装用电容量达到1.20亿千伏安。近日，国家发展改革委、国家能源局等六部门联合发布《电动汽车充电设施服务能力“三年倍增”行动方案(2025—2027年)》。行动方案提出，到2027年年底，要在全国范围内建成2800万个充电设施，提供超3亿千瓦的公共充电容量，满足超过8000万辆电动汽车充电需求，实现充电服务能力的翻倍增长。“我国新能源汽车已经进入规模化快速发展阶段，充电设施作为新能源汽车产业的关键支撑，其服务能力直接影响消费者的购买信心。”国家能源局相关负责人表示，“十四五”期间，我国建成了全球最大的电动汽车充电网络，每5辆电动汽车就有2个充电桩。行动方案明确了今后一段时期充电设施发展的目标和行动路径，将助力加快构建高质量充电设施体系，支撑新能源汽车产业发展。", "release_time": "2025-11-11", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/zhdt/202510/t20251028_792227.html"}
{"category": "政策计划", "title": "欧盟批准2028年前逐步停用俄天然气提案", "short_summary": "欧盟批准提案，计划最晚于2028年1月前全面停止进口俄罗斯天然气。", "detailed_summary": "欧盟批准提案，计划最晚于2028年1月前全面停止进口俄罗斯天然气。\n(1) 欧盟理事会批准提案，计划最晚于2028年1月1日前逐步停止进口俄罗斯天然气。\n(2) 具体措施包括自2026年1月1日起禁止签订新的进口合同，并为现有合同设置过渡期。\n(3) 匈牙利外交部长表示该提案将严重破坏其能源安全供应。\n(4) 尽管欧盟已减少管道天然气进口，但俄罗斯天然气目前仍占欧盟进口量约13%，年价值超150亿欧元。\n(5) 该提案尚需欧洲议会批准方可生效。", "raw_content": "新华社布鲁塞尔10月20日电 欧盟理事会20日表示，欧盟成员国支持在2028年1月前逐步停止进口俄罗斯天然气的提案。    当天在卢森堡举行的欧盟理事会会议上，欧盟能源部长们批准了相关提案。自2026年1月1日起，欧盟禁止内部各方与俄罗斯签订新的进口天然气合同；同时为现有合同保留过渡期，短期合同可持续至2026年6月17日，长期合同将在2028年1月1日前终止。该提案还需要经欧洲议会批准。 匈牙利外交与对外经济部长西雅尔多·彼得对记者说，这项提案的实际影响是，匈牙利的能源安全供应将被彻底破坏。 自俄乌冲突爆发以来，欧盟大幅减少经管道从俄罗斯进口天然气，但一些欧洲国家增加了通过海运进口俄罗斯液化天然气的数量。据欧盟估计，目前俄罗斯天然气仍占欧盟进口量的大约13%，年价值超过150亿欧元。", "release_time": "2025-10-21", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195117-1.html"}
{"category": "政策计划", "title": "匈牙利反对欧盟对俄能源禁令并威胁法律行动", "short_summary": "匈牙利外长称将采取法律手段阻止欧盟禁止进口俄罗斯能源的提案。", "detailed_summary": "匈牙利外长称将采取法律手段阻止欧盟禁止进口俄罗斯能源的提案。\n(1) 匈牙利外长西雅尔多在卢森堡表示将采取一切政治和法律手段阻止欧盟\"可再生能源欧盟\"提案。\n(2) 该提案旨在到2028年1月1日彻底停止欧盟进口俄罗斯管道天然气和液化天然气。\n(3) 提案规定自2026年1月1日起禁止签订新的俄天然气进口合同，现有合同有过渡期。\n(4) 匈牙利反对理由是提案违反欧盟法律，认为能源制裁需全体成员国一致通过。\n(5) 尽管匈牙利投票反对，欧洲理事会仍以特定多数票通过了该法规草案。", "raw_content": "匈牙利外长西雅尔多当地时间20日在卢森堡表示，匈牙利将采取一切政治和法律手段，阻止欧盟通过旨在禁止俄罗斯能源进口的“可再生能源欧盟”(REPowerEU)提案。此前，欧洲理事会就逐步停止进口俄罗斯天然气的法规草案达成了谈判立场。 据悉，该法规草案旨在到2028年1月1日彻底停止欧盟进口俄罗斯管道天然气和液化天然气(LNG)。自2026年1月1日起，欧盟禁止内部各方与俄罗斯签订新的进口天然气合同;同时为现有合同保留过渡期，短期合同可持续至2026年6月17日，长期合同将在2028年1月1日前终止。该提案还需要经欧洲议会批准。 西雅尔多称，对此，匈牙利政府可能将诉诸法律，阻止对俄罗斯能源进口的禁令。该方案的通过公然违反欧盟法律，事实上，这是一种制裁措施，因此需要一致通过，而非特定多数票。尽管匈牙利投票反对该倡议，但欧洲理事会仍以特定多数票通过。", "release_time": "2025-10-21", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195076-1.html"}
{"category": "研究前沿", "title": "新型LED光与纳米薄片疗法精准靶向癌细胞", "short_summary": "美葡科学家开发LED驱动纳米薄片疗法，高效摧毁癌细胞且保护健康组织。", "detailed_summary": "美葡科学家开发LED驱动纳米薄片疗法，高效摧毁癌细胞且保护健康组织。\n（1）美国德克萨斯大学奥斯汀分校与葡萄牙波尔图大学合作开发新型光热癌症疗法。\n（2）疗法结合LED光和氧化锡纳米薄片，可精确靶向加热并摧毁癌细胞。\n（3）实验显示，30分钟照射可消灭92%皮肤癌细胞和50%结直肠癌细胞，且不损伤健康细胞。\n（4）相比传统疗法和依赖激光的现有光疗，该方法更安全、成本更低、副作用更少。\n（5）未来目标是开发便携设备，实现居家治疗，并正研发用于乳腺癌的植入式装置。", "raw_content": "Scientists have developed a promising cancer therapy that uses LED light and ultra-thin flakes of tin to eliminate cancer cells while protecting healthy tissue. Unlike traditional chemotherapy and other invasive treatments, this new method avoids the painful side effects patients often endure.  The breakthrough comes from a partnership between The University of Texas at Austin and the University of Porto in Portugal, made possible through the UT Austin Portugal Program. The collaboration aims to make light-based cancer therapies more accessible and affordable. Current versions of these treatments rely on expensive materials, specialized lab setups, and powerful lasers that can sometimes damage surrounding tissue. By switching to LEDs and introducing tin-based \"SnOx nanoflakes\" (\"Sn\" is the chemical symbol for tin), the researchers have created a safer and potentially low-cost alternative. LED Light and Nanoflakes Team Up Against Cancer \"Our goal was to create a treatment that is not only effective but also safe and accessible,\" said Jean Anne Incorvia, a professor in the Cockrell School of Engineering's Chandra Family Department of Electrical and Computer Engineering and one of the leaders on the project. \"With the combination of LED light and SnOx nanoflakes, we've developed a method to precisely target cancer cells while leaving healthy cells untouched.\" In a recent study published in ACS Nano, the approach proved highly effective against both colorectal and skin cancer cells. After only 30 minutes of exposure, the LED-driven treatment destroyed up to 92% of skin cancer cells and 50% of colorectal cancer cells, while leaving healthy human skin cells unharmed. The results highlight the therapy's precision and safety. A Safer Alternative to Conventional Cancer Treatments Cancer remains the second-leading cause of death worldwide, and many existing treatments come with severe side effects. Scientists across the globe are exploring new methods to make therapies safer and more targeted. One of the most promising is near-infrared photothermal therapy, which uses light to heat and destroy cancer cells without the need for surgery or toxic drugs. This principle forms the foundation of the UT Austin-Portugal team's research.  Having shown strong early results, the researchers are now focused on understanding how light and heat interact in the process and on testing other materials that might enhance the treatment. They also plan to design practical medical devices that can deliver the therapy directly to patients. Bringing Light-Based Cancer Care to Patients \"Our ultimate goal is to make this technology available to patients everywhere, especially places where access to specialized equipment is limited, with fewer side effects and lower cost,\" said Artur Pinto, a researcher at the Faculty of Engineering of the University of Porto and lead researcher of the project in Portugal. \"For skin cancers in particular, we envision that one day, treatment could move from the hospital to the patient's home. A portable device could be placed on the skin after surgery to irradiate and destroy any remaining cancer cells, reducing the risk of recurrence.\" Incorvia and Pinto first teamed up through the UT Austin Portugal Program in 2021. Since then, they have exchanged visits between Texas and Portugal and combined their expertise to explore how two-dimensional materials can be used to advance cancer therapies. Expanding the Research Frontier Building on their success, the team recently received additional funding through the UT Austin Portugal Program to create an implant for breast cancer patients using the same LED and nanoflake technology. Their continued collaboration could pave the way for more personalized, affordable, and pain-free cancer treatments in the near future. Other co-authors of the article are: Ph.D. student Hui-Ping Chang (led development of the nanoflakes) and undergraduate student Eva Nance of The University of Texas at Austin; Filipa A.L.S. Silva (performed biological characterization), Susana G. Santos (supervised the work) and professor Fernão Magalhães (contributed to securing funding) of Faculty of Engineering of the University of Porto; and José R. Fernandes of the University of Trás-os-Montes and Alto Douro, who developed the LED systems. The UT Austin Portugal Program is a long-standing science and technology partnership between UT and the Portuguese Foundation of Science and Technology (FCT). Portugal has similar partnerships with two other U.S. universities -- the Massachusetts Institute of Technology and Carnegie Mellon University -- and its 17-year collaboration with UT was recently renewed for another five years.", "release_time": "2025-10-21", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251020092831.htm"}
{"category": "产业应用", "title": "MIT硬科技竞赛助力柔性太阳能初创公司", "short_summary": "MIT纳米竞赛Active Surfaces夺冠，推动柔性光伏技术产业化应用。", "detailed_summary": "MIT纳米竞赛Active Surfaces夺冠，推动柔性光伏技术产业化应用。\n(1) MIT.nano举办首届PITCH.nano硬科技创业竞赛，Active Surfaces凭借轻质柔性太阳能电池技术获得大奖。\n(2) 获奖公司开发超轻即贴式光伏面板，旨在重塑建筑环境中的可再生能源部署方式。\n(3) START.nano项目为初创企业提供MIT.nano设施折扣使用权限，加速硬科技从实验室到市场的转化。\n(4) 竞赛涵盖气候能源、生命科学及量子光子学等领域，12家初创公司展示创新成果。\n(5) 项目五年支持40家公司，证明其在推动硬科技产业化和解决全球挑战方面的成功。", "raw_content": "The inaugural PITCH.nano competition, hosted by MIT.nano’s hard technology accelerator START.nano, provided a platform for early-stage startups to present their innovations to MIT and Boston’s hard-tech startup ecosystem.The grand prize winner was Active Surfaces, a startup that is generating renewable energy exactly where it is going to be used through lightweight, flexible solar cells. Active Surfaces says its ultralight, peel-and-stick panels will reimagine how we deploy photovoltaics in the built environment.Shiv Bhakta MBA ’24, SM ’24, CEO and co-founder, delivered the winning presentation to an audience of entrepreneurs, investors, startup incubators, and industry partners at PITCH.nano on Sept. 30. Active Surfaces received the grand prize of 25,000 nanoBucks — equivalent to $25,000 that can be spent at MIT.nano facilities.Why has MIT.nano chosen to embrace startup activity as much as we do? asked Vladimir Bulović, MIT.nano faculty director, at the start of PITCH.nano. “We need to make sure that entrepreneurs can be born out of MIT and can take the next technical ideas developed in the lab out into the market, so they can make the next millions of jobs that the world needs.”The journey of a hard-tech entrepreneur takes at least 10 years and 100 million dollars, explained Bulović. By linking open tool facilities to startup needs, MIT.nano can make those first few years a little bit easier, bringing more startups to the scale-up stage.“Getting VCs [venture capitalists] to invest in hard tech is challenging,” explained Joyce Wu SM ’00, PhD ’07, START.nano program manager. “Through START.nano, we provide discounted access to MIT.nano’s cleanrooms, characterization tools, and laboratories for startups to build their prototypes and attract investment earlier and with reduced spend. Our goal is to support the translation of fundamental research to real-world solutions in hard tech.”In addition to discounted access to tools, START.nano helps early-stage companies become part of the MIT and Cambridge innovation network. PITCH.nano, inspired by the MIT 100K Competition, was launched as a new opportunity this year to introduce these hard-tech ventures to the investor and industry community. Twelve startups delivered presentations that were evaluated by a panel of four judges who are, themselves, venture capitalists and startup founders.“It is amazing to see the quality, diversity, and ingenuity of this inspiring group of startups,” said judge Brendan Smith PhD ’18, CEO of SiTration, a company that was part of the inaugural START.nano cohort. “Together, these founders are demonstrating the power of fundamental hard-tech innovation to solve the world’s greatest challenges, in a way that is both scalable and profitable.”Startups who presented at PITCH.nano spanned a wide range of focus areas. In the fields of climate, energy, and materials, the audience heard from Addis Energy, Copernic Catalysts, Daqus Energy, VioNano Innovations, Active Surfaces, and Metal Fuels; in life sciences, Acorn Genetics, Advanced Silicon Group, and BioSens8; and in quantum and photonics, Qunett, nOhm Devices, and Brightlight Photonics. The common thread for these companies: They are all using MIT.nano to advance their innovations.“MIT.nano has been instrumental in compressing our time to market, especially as a company building a novel, physical product,” said Bhakta. “Access to world-class characterization tools — normally out of reach for startups — lets us validate scale-up much faster. The START.nano community accelerates problem-solving, and the nanoBucks award is directly supporting the development of our next prototypes headed to pilot.”In addition to the grand prize, a 5,000 nanoBucks audience choice award went to Advanced Silicon Group, a startup that is developing a next-generation biosensor to improve testing in pharma and health tech.Now in its fifth year, START.nano has supported 40 companies spanning a diverse set of market areas — life sciences, clean tech, semiconductors, photonics, quantum, materials, and software. Fourteen START.nano companies have graduated from the program, proving that START.nano is indeed succeeding in its mission to help early-stage ventures advance from prototype to manufacturing. “I believe MIT.nano has a fantastic opportunity here,” said judge Davide Marini, PhD ’03, co-founder and CEO of Inkbit, “to create the leading incubator for hard tech entrepreneurs worldwide.”START.nano accepts applications on a monthly basis. The program is made possible through the generous support of FEMSA.", "release_time": "2025-10-21", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/active-surfaces-wins-inaugural-pitchnano-competition-1020"}
{"category": "研究前沿", "title": "中俄学者共研生物质催化转化技术", "short_summary": "俄专家访穗交流NHC催化技术，推进生物质高值化合作项目。", "detailed_summary": "俄专家访穗交流NHC催化技术，推进生物质高值化合作项目。\n（1）俄罗斯斯科尔科沃科学技术研究院Victor Chernyshev教授和Konstantin Shepelenko博士于10月13日至17日访问广州能源所；\n（2）Victor Chernyshev作专题报告，系统介绍NHC配体在金属催化及生物质衍生物转化中的应用；\n（3）双方召开NSFC-RSF项目进展交流会，汇报碳水化合物脱水、木质纤维素预处理等研究；\n（4）访问华南理工大学，与项目参与单位探讨后续合作与互访安排；\n（5）此次访问推进了项目实施，增进了相互了解，并在实验交流、人才互访等方面形成合作意向。", "raw_content": "应广州能源所生物质高值化利用中心和广东省可再生能源重点实验室邀请，俄罗斯斯科尔科沃科学技术研究院Victor Chernyshev教授和Konstantin Shepelenko博士于10月13日至17日访问广州能源所。生物质能高值化利用中心主任亓伟研究员、科研骨干张宇正高级工程师等人参与交流。 10月14日，Victor Chernyshev作了题为Metal/NHC Catalysis in Fine Organic Synthesis and Functionalization of Biomass-Derived Furan Molecules的专题学术报告。报告会由张宇主持，中心部分科研人员及学生参加。Victor Chernyshev系统介绍了NHC配体在金属催化中的关键作用，阐述了NHC-connected与NHC-disconnected催化机制，并分享了利用可电离阴离子配体提升NHC稳定性的策略。此外，他还详细展示了NHC在催化生物质衍生物（如糠醛和5-羟甲基糠醛）C5和C3位点实现高效、高选择性烷基化与芳基化等方面的最新研究进展。报告内容新颖深入，给在场从事生物质催化转化的科研人员带来了新的思路、思考方向以及有益的启发。在问答环节中，Chernyshev就与会者提出的多个专业问题进行了细致解答。10月15日，双方围绕共同承担的NSFC-RSF项目“木质纤维素定向拆解转化为化学品的过程调控”召开了进展交流会，会议由亓伟主持。会上，Konstantin Shepelenko代表俄方汇报了碳水化合物脱水制呋喃醛及NHC催化呋喃醛成呋喃酸酯等方面的研究进展，张宇代表中方介绍了木质纤维素DES预处理及NHC氧化酯化糠醛制备糠酸甲酯等方面的研究进展，与会人员就项目推进过程中存在的问题及解决方案进行了深入探讨，并就下一阶段的研究计划与目标达成共识。 10月16日，在亓伟和张宇的陪同下，Victor Chernyshev一行访问了NSFC-RSF项目参与单位华南理工大学，与李雪辉教授和任俊莉教授等展开交流。三方分别介绍了各自的研究方向，围绕相关研究内容展开充分讨论，并在后续互访安排与项目合作方面达成初步意向。此次访问有力推进了NSFC-RSF项目的实施，进一步增进了广州能源所与斯科尔科沃科学技术研究院的相互了解。双方在实验交流、人才互访及项目联合申请等方面形成了合作意向，为未来持续深化合作奠定了基础。Victor Chernyshev教授作学术报告项目进展交流会华南理工大学交流现场", "release_time": "2025-10-20", "source_institution": "广州能源研究所", "url": "http://www.giec.cas.cn/xshd2016/202510/t20251020_7993161.html"}
{"category": "研究前沿", "title": "IAEA启动核能人工智能安全研究项目", "short_summary": "国际原子能机构发起新项目，旨在加强核设施人工智能系统的计算机安全策略。", "detailed_summary": "国际原子能机构发起新项目，旨在加强核设施人工智能系统的计算机安全策略。\n（1）国际原子能机构（IAEA）启动一项新的研究项目，旨在增强核领域人工智能（AI）系统的计算机安全。\n（2）项目目标是制定更强健的计算机安全策略，以支持小型模块化反应堆等核设施采用人工智能技术。\n（3）人工智能和机器学习系统在核工业的应用可提升运行效率和威胁检测等安全措施。\n（4）这些技术也带来了新的安全风险，例如用于训练或运行AI系统的数据可能被篡改。\n（5）项目旨在通过稳健的信息安全措施来最小化相关风险。", "raw_content": "The IAEA has launched a new research project to enhance computer security for artificial intelligence systems that may be used in the nuclear sector. The project aims to strengthen computer security strategies to support the adoption of artificial intelligence-enabled technologies by nuclear facilities, including those for small modular reactors and other nuclear applications. Artificial intelligence (AI) and machine learning (ML) systems are being deployed across the nuclear industry, offering potential benefits such as improved operational efficiency and enhanced security measures, including for threat detection. However, these technologies also create new computer security concerns that require innovative solutions. Risks include manipulation of data or information being used to teach or run an AI system. Minimizing such risks will involve robust information security and ensuring it is being used correctly.", "release_time": "2025-10-20", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/new-research-project-on-computer-security-for-nuclear-ai"}
{"category": "研究前沿", "title": "VLBI先驱Alan Whitney逝世，曾推动黑洞成像技术", "short_summary": "MIT科学家Whitney推动VLBI技术革新，为黑洞成像奠定基础。", "detailed_summary": "MIT科学家Whitney推动VLBI技术革新，为黑洞成像奠定基础。\n（1）MIT Haystack Observatory前首席科学家Alan Robert Whitney于9月28日逝世，享年81岁。\n（2）他是甚长基线干涉测量（VLBI）技术的先驱和关键开发者，该技术用于精确测量大陆漂移和研究遥远射电源。\n（3）其领导的Mark系列记录系统不断推动VLBI技术进步，最终发展的Mark 6系统为事件视界望远镜（EHT）首次拍摄黑洞阴影提供了关键技术支持。\n（4）Whitney曾担任观测台副所长和代理所长，并参与澳大利亚默奇森宽场阵列（MWA）等国际项目。\n（5）他于2020年作为EHT合作组成员共同获得基础物理学突破奖，其工作对射电天文学和空间大地测量学产生了深远影响。", "raw_content": "Alan Robert Whitney ’66, SM ’67, PhD ’74, a longtime research scientist at the MIT Haystack Observatory who also served its associate director and interim director, died on Sept. 28 at age 81.Whitney was a key contributor to the accomplishments and reputation of Haystack Observatory, having led the development of innovative technologies to advance the powerful radio science technique of very long baseline interferometry (VLBI). He ascended to the rank of MIT principal research scientist, served for many years as associate director of the observatory, and in 2007–08 took the reins as interim director. In 2011, he was awarded an MIT Excellence award.From an early age, Whitney displayed extraordinary talent. Raised in Wyoming, as a high schooler he won the state science fair in 1962 by building a satellite telemetry receiver, which he designed and built from transistors and other discrete components in a barn on his family’s dairy farm. He enrolled at MIT and completed a five-year master’s degree via a cooperative internship program with Bell Laboratories, subsequently earning his PhD in electrical engineering.Haystack Director Phil Erickson says, “Alan’s personality and enthusiasm were infectious, and his work represented the best ideals of the Haystack and MIT research enterprise — innovative, curious, and exploring the frontiers of basic and applied science and technology.”In the late 1960s, as part of his PhD work, he was heavily involved in the pioneering development of VLBI, an extraordinary technique that yielded direct measurements of continental drift and information on distant radio sources at unprecedented angular resolution. A landmark paper led by Whitney demonstrated the presence of apparent superluminal (faster than light) motion of radio sources, which was explained as highly relativistic motion aligned toward the Earth. He spent the rest of his long and productive career at Haystack, pushing forward VLBI technology to ever-greater heights and ever-more impactful scientific capabilities.“Alan was a technology pillar, a stalwart builder and worldwide ambassador of Haystack, and a leading figure of the VLBI geodetic community who inspired generations of scientists and engineers,” says Pedro Elosegui, leader of the Haystack geodesy group. “He contributed fundamentally to the vision and design of the VLBI Geodetic Observing System, outlining a path to a next-generation VLBI system with unprecedented new capabilities to address emerging space geodesy science needs such as global sea-level rise.”The early days of VLBI demanded heroic and grueling efforts, traveling the world with exotic devices in hand-carried luggage, mounting and dismounting thousands of magnetic tapes every couple of minutes for hours on end, troubleshooting complex and sensitive instrumentation, and writing highly specialized software for the mainframe computers of the day. Whitney was fully engaged on all these fronts. By the early 1980s, the Mark III recording and correlation systems, whose development was led by Whitney, were established as the state of the art in VLBI technology, and a standard around which the global VLBI community coalesced.Whitney later led the transition to VLBI disk-based recording. Specialized and robust Mark V systems optimized for shipping logistics and handling were transferred to industry for commercialization, leading once again to widespread global adoption of Haystack-developed VLBI technology. Consistently across all these developments, Whitney identified and exploited the most relevant and practical emerging technologies for the Haystack VLBI mission in hardware, software, and computing infrastructure.In the latter part of his career, Whitney continued to innovate, pushing the technical boundaries of VLBI. A key advance was the Mark 6 (Mk6) recording system, capable of yet faster recording, higher sensitivity, and more robustness. The Mk6 recorders’ essential capability allowed the creation of the Event Horizon Telescope, which famously yielded the first image of the shadow of a black hole. Mk6 recorders are now used to routinely record data roughly 100,000 times faster than the computer tapes used at the start of his career.As a senior technical and scientific leader, Whitney provided broad leadership and consultation to Haystack, and worked on a number of projects outside of the VLBI world. He served as interim Haystack director from January 2007 until a permanent director was appointed in September 2008. He also engaged with the development project for the international Murchison Widefield Array (MWA) in Australia, focused on frontier research studying early universe development. Whitney assumed the role of MWA project director from 2008 until groups in Australia took over the construction phase of the project a few years later. Until his full retirement in 2012, Whitney continued to provide invaluable technical insights and support at Haystack, and was a trusted and wise counsel to the Haystack Director’s Office. In 2020, Whitney was a co-recipient of the 2020 Breakthrough Prize in Fundamental Physics awarded to the Event Horizon Telescope Collaboration.Alan Whitney was a top-notch technologist with a broad perspective that allowed him to guide Haystack to decades of influential leadership in the development and refinement of the VLBI technique. His dedication at MIT to the observatory, its people, and its mission were a source of inspiration to many at Haystack and well beyond. He was widely admired for the clarity of his thought, the sharpness of his intellect, and his genial and friendly nature. His numerous local, national, and global colleagues will feel his absence.", "release_time": "2025-10-21", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/alan-whitney-radio-astronomer-dies-1020"}
{"category": "研究前沿", "title": "青岛能源所实现双原子催化剂精准可控合成", "short_summary": "研究提出种子介导新策略，成功构建Ag-Pd双原子催化剂并显著提升催化性能。", "detailed_summary": "研究提出种子介导新策略，成功构建Ag-Pd双原子催化剂并显著提升催化性能。\n(1) 双原子催化剂（DACs）能产生协同效应优化催化性能，但精准合成是挑战。\n(2) 青岛能源所团队开发种子介导策略，利用Pd1/CeO2上残留Cl物种定向吸附Ag离子，成功构建明确Ag1-Pd1/CeO2双原子构型。\n(3) 该催化剂在3-硝基苯乙烯催化转移加氢反应中表现出比单原子催化剂更优异的活性和高选择性。\n(4) 机理研究表明Ag1-Pd1双原子位点与Ce3+-OV位点协同促进反应路径。\n(5) 该工作为原子级精准构建DACs提供了新策略，研究成果发表于《Applied Catalysis B: Environment and Energy》。", "raw_content": "双原子催化剂（DACs）作为单原子催化剂（SACs）的延伸和升级，通过将两种不同的金属原子以配对的形式锚定在载体上，利用配对金属原子间的电子相互作用，产生“1+1>2”的协同效应。这种催化剂可以显著优化反应路径、提升催化活性和选择性，已成为多相催化领域前沿的研究热点。然而，常规合成过程中，难以精确控制两种金属前驱体在载体上的吸附、成核与稳定化过程，导致金属原子随机分散，形成彼此孤立的单原子或金属团簇/纳米颗粒的混合物。这种不可控的分散状态严重制约了DACs的本征催化性能探索和构效关系研究。因此，发展一种能够实现原子级精准操控，确保两种金属原子以特定模式配位的合成策略尤为重要。近日，青岛能源所多孔催化材料研究组提出了一种新型的种子介导策略，成功构建了具有明确Ag1-Pd1双原子构型的Ag1-Pd1/CeO2催化剂。研究团队首先利用K2PdCl4作为前体，合成了单原子Pd1/CeO2催化剂。随后，借助Pd1/CeO2催化剂Pd1键合的残留Cl物种实现对Ag离子的定向吸附。在后续焙烧过程中，Pd-Cl-Ag之间的相互作用促使Ag1-Pd1双原子构型的形成，有效避免了两种单原子在CeO2表面的随机分散。与单原子Pd1/CeO2相比，Ag1-Pd1/CeO2在3-硝基苯乙烯的催化转移加氢（CTH）反应中表现出更优异的催化活性，且在长时间反应条件下仍能保持对3-乙烯基苯胺的高选择性。图1 Ag1-Pd1/CeO2的合成与结构表征机理研究表明，Ag1-Pd1双原子位点不仅可与邻近的Ce3+-OV位点协同促进硝基芳烃的偶联缩合反应，还能有效驱动缩合中间体向目标芳香胺的选择性转化。此外，研究还发现CeO2负载的SACs和DACs对硝基芳烃CTH反应的活性具有显著的金属负载量依赖性，表明优化金属负载量是提升催化效率的关键。本工作为原子级精准构建DACs提供了一种新策略，证明了双原子位点的可控构筑在提升硝基芳烃CTH反应性能中的重要作用。相关研究成果发表在Applied Catalysis B: Environment and Energy上。文章第一作者为青岛能源所博士研究生张潜和内蒙古大学张铭元，通讯作者为王光辉研究员、刘健教授和高瑞教授。该研究工作得到了国家自然科学基金项目的支持。（文/图 张潜）原文链接：https://doi.org/10.1016/j.apcatb.2025.126019Q. Zhang,+ M. Zhang,+ Z. Pan, D.-C. Li, Z. Tian, Y. Ma, R. Gao*, J. Liu*, G.-H. Wang*, Seed-mediated engineering of dual-atom Ag-Pd synergy on CeO2 for selective transfer hydrogenation of nitroarenes, Applied Catalysis B: Environment and Energy, 2026, 382, 126019.", "release_time": "2025-11-04", "source_institution": "青岛生物能源与过程研究所", "url": "https://qibebt.cas.cn/news/kyjz/202510/t20251020_7992829.html"}
{"category": "研究前沿", "title": "热纤梭菌工程菌株实现木质纤维素高效糖化", "short_summary": "青岛能源所改造热纤梭菌，协同增强纤维素与半纤维素降解能力，提升生物炼制经济性。", "detailed_summary": "青岛能源所改造热纤梭菌，协同增强纤维素与半纤维素降解能力，提升生物炼制经济性。\n(1) 研究针对热纤梭菌降解木质纤维素效率不足的问题，通过基因工程改造提升其性能。\n(2) 将外源β-葡萄糖苷酶CaBglA和双功能木聚糖酶/木糖苷酶CcXyl0074整合至基因组，构建工程菌株GBX1。\n(3) 工程菌株实现了纤维素与半纤维素的高效协同降解，纤维素-葡萄糖转化率达94%，木聚糖转化率达84%。\n(4) 优化糖化培养基配方，使成本降低87.3%，显著提升整合生物糖化工艺的技术经济可行性。\n(5) 该成果为木质纤维素生物炼制提供了性能优越的全细胞催化剂，推动了非粮生物质转化技术的产业化应用。", "raw_content": "木质纤维素类非粮生物质是地球上最丰富的可再生有机资源之一，主要由纤维素、半纤维素和木质素组成。整合生物加工（consolidated biprocessing, CBP）和整合生物糖化（consolidated bio-saccharification, CBS）通过整合技术实现高效的木质纤维素转化，不依赖于纤维素酶制剂，可大幅降低过程成本，提升生物炼制的经济可行性。热纤梭菌（Clostridium thermocellum）是基于CBP和CBS策略进行非粮生物质高效生物转化的理想底盘菌株之一，其具有的纤维小体多酶复合体是目前自然界中已知最高效的纤维素降解体系。然而，热纤梭菌的纤维素降解酶系中缺少外泌的β-葡萄糖苷酶（BGL），导致纤维二糖对纤维小体反馈抑制，同时其半纤维素酶系也较弱，不仅影响半纤维素的降解水平，还由于木聚糖对其关键纤维素酶Cel48S的抑制，进一步影响纤维素的降解效率。因此，热纤梭菌仍然需要系统的基因工程改造，以提升其降解纤维素和半纤维素的效率，进而提升CBP和CBS策略的技术经济可行性。青岛能源所先进生物炼制与合成研究组此前通过向热纤梭菌引入外源BGL（CaBglA），解决了纤维二糖的反馈抑制问题，构建了三代CBS工程菌株，显著提升了纤维素糖化性能。近期，研究团队进一步聚焦工程菌株遗传稳定性和半纤维素降解能力不足的问题，构建了第四代CBS工程菌株。研究团队通过基因组整合CaBglA基因构建了工程菌株GB2，相较于第三代基于质粒表达CaBGL的菌株，GB2具备不依赖于抗生素、稳定高效的纤维素降解能力，实现了高达94%的纤维素-葡萄糖转化率。研究团队进一步向GB2中引入来自于明黄梭菌（Clostridium clariflavum）的外源双功能木聚糖酶/木糖苷酶CcXyl0074，以进一步提升热纤梭菌的半纤维素降解能力。结果表明，以预处理的玉米秸秆为底物，质粒表达CcXyl0074的菌株在3天内可将84%的木聚糖转化为单体木糖，说明在保持纤维素高效转化的前提下，CcXyl0074的引入显著增强了热纤梭菌的半纤维素降解能力。此外，研究团队将CcXyl0074和CaBGL共同整合到基因组中，获得工程菌株GBX1，实现了纤维素酶与木聚糖酶活性的同步增强，以及纤维素和半纤维素组分的高效协同降解，最大糖化速率可达GB2的1.5倍。研究人员还对糖化培养基的配方进行了优化，将培养基成本降低了87.3%，提升了CBS工艺的技术经济性。本研究开发的工程菌株为木质纤维素生物炼制提供了性能更优的全细胞生物催化剂，为整合生物糖化技术的产业化应用奠定了重要基础。图1 通过基因组整合β-葡萄糖苷酶CaBglA和双功能木聚糖酶/木糖苷酶CcXyl0074实现纤维素与半纤维素降解能力的共同增强相关研究成果以“Effective conversion of lignocellulose to fermentable sugars using engineered Clostridium thermocellum with co-enhanced cellulolytic and xylanolytic activities”为题发表于Bioresource Technology，研究组博士研究生王晓晴与硕士研究生肖敏为文章共同第一作者，刘亚君研究员与冯银刚研究员为共同通讯作者，日本国际农业科学研究中心的小杉昭彦教授亦对本论文做出重要贡献。论文报道的工程菌株已申请发明专利一项（专利申请号202510997203.0）。该工作得到国家重点研发计划、国家自然科学基金、中国科学院国际合作项目、山东省泰山青年学者、青岛市科技惠民等项目的支持。（文/图 王晓晴）原文链接：https://doi.org/10.1016/j.biortech.2025.133466Xiaoqing Wang#, Min Xiao#, Chao Chen, Kuan Qi, Chaoyang Chen, Qiu Cui, Akihiko Kosugi, Ya-Jun Liu*, Yingang Feng*. Effective conversion of lignocellulose to fermentable sugars using engineered Clostridium thermocellum with co-enhanced cellulolytic and xylanolytic activities. Bioresour. Technol. 2026, 440:133466. doi: 10.1016/j.biortech.2025.133466.发明专利：一种表达双功能酶的热纤梭菌重组菌株及其构建、应用；专利申请号：202510997203.0，发明人：冯银刚、刘亚君、王晓晴、肖敏；申请日：2025.07.17。", "release_time": "2025-11-04", "source_institution": "青岛生物能源与过程研究所", "url": "https://qibebt.cas.cn/news/kyjz/202510/t20251020_7992834.html"}
{"category": "政策计划", "title": "美国能源信息署维持正常数据发布计划", "short_summary": "美国能源信息署宣布其数据收集与发布工作将按计划持续进行。", "detailed_summary": "美国能源信息署宣布其数据收集与发布工作将按计划持续进行。\n(1) 美国能源信息署宣布其数据发布计划将维持正常进度。\n(2) 该机构的数据收集工作也将不受影响地持续进行。\n(3) 此项安排将延续至后续通知发布为止。", "raw_content": "EIA is continuing normal publication schedules and data collection until further notice.", "release_time": "2025-10-21", "source_institution": "美国能源部能源信息署", "url": "http://www.eia.gov/analysis/reports.php/#/T186,T1237"}
{"category": "产业应用", "title": "MIT发布全球首部民用核动力船舶安全手册", "short_summary": "MIT海事联盟发布核动力商船安全手册，旨在建立统一安全标准推动行业脱碳。", "detailed_summary": "MIT海事联盟发布核动力商船安全手册，旨在建立统一安全标准推动行业脱碳。\n(1) MIT海事联盟发布《核动力船舶安全手册》，旨在为商用核动力船舶设计建立首个统一的安全标准框架。\n(2) 该手册整合研究数据与操作经验，填补民用核动力船舶关键部件安全设计指导的空白，应对现有政策过时问题。\n(3) 项目得到ABS等海事行业领袖支持，被视为实现航运业净零排放目标的潜在关键技术路径。\n(4) 手册的发布恰逢美英技术繁荣协议将民用海事核应用纳入合作，有望推动建立现代国际监管框架。\n(5) 此举旨在通过安全技术创新助力美国重振造船业，并促进全球港口与船舶核安全规则的统一。", "raw_content": "Commercial shipping accounts for 3 percent of all greenhouse gas emissions globally. As the sector sets climate goals and chases a carbon-free future, nuclear power — long used as a source for military vessels — presents an enticing solution. To date, however, there has been no clear, unified public document available to guide design safety for certain components of civilian nuclear ships. A new “Nuclear Ship Safety Handbook” by the MIT Maritime Consortium aims to change that and set the standard for safe maritime nuclear propulsion.“This handbook is a critical tool in efforts to support the adoption of nuclear in the maritime industry,” explains Themis Sapsis, the William I. Koch Professor of Mechanical Engineering at MIT, director of the MIT Center for Ocean Engineering, and co-director of the MIT Maritime Consortium. “The goal is to provide a strong basis for initial safety on key areas that require nuclear and maritime regulatory research and development in the coming years to prepare for nuclear propulsion in the maritime industry.”Using research data and standards, combined with operational experiences during civilian maritime nuclear operations, the handbook provides unique insights into potential issues and resolutions in the design efficacy of maritime nuclear operations, a topic of growing importance on the national and international stage. “Right now, the nuclear-maritime policies that exist are outdated and often tied only to specific technologies, like pressurized water reactors,” says Jose Izurieta, a graduate student in the Department of Mechanical Engineering (MechE) Naval Construction and Engineering (2N) Program, and one of the handbook authors. “With the recent U.K.-U.S. Technology Prosperity Deal now including civil maritime nuclear applications, I hope the handbook can serve as a foundation for creating a clear, modern regulatory framework for nuclear-powered commercial ships.”The recent memorandum of understanding signed by the U.S. and U.K calls for the exploration of “novel applications of advanced nuclear energy, including civil maritime applications,” and for the parties to play “a leading role informing the establishment of international standards, potential establishment of a maritime shipping corridor between the Participants’ territories, and strengthening energy resilience for the Participants’ defense facilities.”“The U.S.-U.K. nuclear shipping corridor offers a great opportunity to collaborate with legislators on establishing the critical framework that will enable the United States to invest on nuclear-powered merchant vessels — an achievement that will reestablish America in the shipbuilding space,” says Fotini Christia, the Ford International Professor of the Social Sciences, director of the Institute for Data, Systems, and Society (IDSS), director of the MIT Sociotechnical Systems Research Center, and co-director of the MIT Maritime Consortium.“With over 30 nations now building or planning their first reactors, nuclear energy’s global acceptance is unprecedented — and that momentum is key to aligning safety rules across borders for nuclear-powered ships and the respective ports,” says Koroush Shirvan, the Atlantic Richfield Career Development Professor in Energy Studies at MIT and director of the Reactor Technology Course for Utility Executives.The handbook, which is divided into chapters in areas involving the overlapping nuclear and maritime safety design decisions that will be encountered by engineers, is careful to balance technical and practical guidance with policy considerations.Commander Christopher MacLean, MIT associate professor of the practice in mechanical engineering, naval construction, and engineering, says the handbook will significantly benefit the entire maritime community, specifically naval architects and marine engineers, by providing standardized guidelines for design and operation specific to nuclear powered commercial vessels.“This will assist in enhancing safety protocols, improve risk assessments, and ensure consistent compliance with international regulations,” MacLean says. “This will also help foster collaboration amongst engineers and regulators. Overall, this will further strengthen the reliability, sustainability, and public trust in nuclear-powered maritime systems.”Anthony Valiaveedu, the handbook’s lead author, and co-author Nat Edmonds, are both students in the MIT Master’s Program in Technology and Policy (TPP) within the IDSS. The pair are also co-authors of a paper published in Science Policy Review earlier this year that offered structured advice on the development of nuclear regulatory policies.“It is important for safety and technology to go hand-in-hand,” Valiaveedu explains. “What we have done is provide a risk-informed process to begin these discussions for engineers and policymakers.”“Ultimately, I hope this framework can be used to build strong bilateral agreements between nations that will allow nuclear propulsion to thrive,” says fellow co-author Izurieta.Impact on industry“Maritime designers needed a source of information to improve their ability to understand and design the reactor primary components, and development of the 'Nuclear Ship Safety Handbook' was a good step to bridge this knowledge gap,” says Christopher J. Wiernicki, American Bureau of Shipping (ABS) chair and CEO. “For this reason, it is an important document for the industry.”The ABS, which is the American classification society for the maritime industry, develops criteria and provides safety certification for all ocean-going vessels. ABS is among the founding members of the MIT Maritime Consortium. Capital Clean Energy Carriers Corp., HD Korea Shipbuilding and Offshore Engineering, and Delos Navigation Ltd. are also consortium founding members. Innovation members are Foresight-Group, Navios Maritime Partners L.P., Singapore Maritime Institute, and Dorian LPG.“As we consider a net-zero framework for the shipping industry, nuclear propulsion represents a potential solution. Careful investigation remains the priority, with safety and regulatory standards at the forefront,” says Jerry Kalogiratos, CEO of Capital Clean Energy Carriers Corp. “As first movers, we are exploring all options. This handbook lays the technical foundation for the development of nuclear-powered commercial vessels.”Sangmin Park, senior vice president at HD Korea Shipbuilding and Offshore Engineering, says “The 'Nuclear Ship Safety Handbook' marks a groundbreaking milestone that bridges shipbuilding excellence and nuclear safety. It drives global collaboration between industry and academia, and paves the way for the safe advancement of the nuclear maritime era.”Maritime at MITMIT has been a leading center of ship research and design for over a century, with work at the Institute today representing significant advancements in fluid mechanics and hydrodynamics, acoustics, offshore mechanics, marine robotics and sensors, and ocean sensing and forecasting. Maritime Consortium projects, including the handbook, reflect national priorities aimed at revitalizing the U.S. shipbuilding and commercial maritime industries.The MIT Maritime Consortium, which launched in 2024, brings together MIT and maritime industry leaders to explore data-powered strategies to reduce harmful emissions, optimize vessel operations, and support economic priorities.“One of our most important efforts is the development of technologies, policies, and regulations to make nuclear propulsion for commercial ships a reality,” says Sapsis. “Over the last year, we have put together an interdisciplinary team with faculty and students from across the Institute. One of the outcomes of this effort is this very detailed document providing detailed guidance on how such effort should be implemented safely.”Handbook contributors come from multiple disciplines and MIT departments, labs, and research centers, including the Center for Ocean Engineering, IDSS, MechE’s Course 2N Program, the MIT Technology and Policy Program, and the Department of Nuclear Science and Engineering.MIT faculty members and research advisors on the project include Sapsis; Christia; Shirvan; MacLean; Jacopo Buongiorno, the Battelle Energy Alliance Professor in Nuclear Science and Engineering, director, Center for Advanced Nuclear Energy Systems, and director of science and technology for the Nuclear Reactor Laboratory; and Captain Andrew Gillespy, professor of the practice and director of the Naval Construction and Engineering (2N) Program.“Proving the viability of nuclear propulsion for civilian ships will entail getting the technologies, the economics and the regulations right,” says Buongiorno. “This handbook is a meaningful initial contribution to the development of a sound regulatory framework.”“We were lucky to have a team of students and knowledgeable professors from so many fields,” says Edmonds. “Before even beginning the outline of the handbook, we did significant archival and history research to understand the existing regulations and overarching story of nuclear ships. Some of the most relevant documents we found were written before 1975, and many of them were stored in the bellows of the NS Savannah.”The NS Savannah, which was built in the late 1950s as a demonstration project for the potential peacetime uses of nuclear energy, was the first nuclear-powered merchant ship. The Savannah was first launched on July 21, 1959, two years after the first nuclear-powered civilian vessel, the Soviet ice-breaker Lenin, and was retired in 1971.Historical context for this project is important, because the reactor technologies envisioned for maritime propulsion today are quite different from the traditional pressurized water reactors used by the U.S. Navy. These new reactors are being developed not just in the maritime context, but also to power ports and data centers on land; they all use low-enriched uranium and are passively cooled. For the maritime industry, Sapsis says, “the technology is there, it’s safe, and it’s ready.”“The Nuclear Ship Safety Handbook” is publicly available on the MIT Maritime Consortium website and from the MIT Libraries.", "release_time": "2025-10-21", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/mit-maritime-consortium-nuclear-ship-safety-handbook-1020"}
{"category": "产业应用", "title": "日立推出高温适用无油涡旋空压机G系列", "short_summary": "日立发布耐高温无油空压机，支持数字化管理并节省安装空间。", "detailed_summary": "日立发布耐高温无油空压机，支持数字化管理并节省安装空间。\n（1）日立工业设备系统公司推出新型无油涡旋空气压缩机“G系列”，功率覆盖1.5kW至3.7kW；\n（2）产品突破性支持45°C高温环境运行，50°C时可自动降压持续工作；\n（3）采用紧凑设计，3.7kW型号安装面积较旧款减少23%，支持贴墙安装；\n（4）集成蓝牙通信和Modbus接口，支持FitLive数字化监控服务；\n（5）通过提升能效和数字化管理，助力制造业应对产线调整和维护优化需求。", "raw_content": "New Oil-Free Scroll Air Compressor \"G Series\" (3.7kW)    Tokyo, Oct 20, 2025 Hitachi Industrial Equipment Systems Co., Ltd. (HIES) will begin selling its new oil-free scroll air compressor \"G Series\" (oil-free 1.5kW/2.2kW/3.7kW models) capable of operation even in high ambient temperature environments (45°C). By improving both the core components and the overall package of the oil-free scroll air compressor, we will meet a wider range of customer needs, further enhancing efficiency in industry, and reducing environmental impact.  HIES is advancing its strategy of \"Integrated Industry Automation\" by expanding its lineup of digitally-connected equipment (digitalized assets). This includes launching the new oil-free \"G Series\" air compressor and offering \"HMAX for Industry,\" a digital service that embodies Lumada 3.0 by using AI, domain knowledge and data from this equipment to help customers in key growth industries operate more efficiently.   Overview of the New Oil-Free Scroll Air Compressor \"G Series\"   Air compressors are widely used in factories as a critical source of compressed air for manufacturing equipment and other applications. They supply compressed air stably and efficiently in diverse installation environments. In recent years, there is a growing need for flexible adaptation to line expansions and modifications, as well as for streamlining maintenance and management through IoT-enabled operational visibility, ultimately leading to improved productivity.     While scroll compressors are generally known for their quiet operation and low vibration, the \"G Series\" features significantly enhanced heat resistance. Combined with HIES' unique packaging technology, this also improves the intake and exhaust structure, enabling operation in high-temperature environments up to 45°C ambient temperature. The new Heat Safety Mode automatically reduces the set pressure even at ambient temperatures of 50°C, enabling continued operation*1.  The product is compact and can be installed without clearance from walls, significantly reducing installation space (for the 3.7kW model, installation area is reduced by 23% compared to previous HIES models). It supports FitLive*2, a Lumada*3 solution, via Bluetooth®*4 communication. It also comes standard with an external Modbus®*5 communication terminal block, enabling operation management and condition monitoring of the product within the customer's facility.    *1 Maintenance cycles shorten during operation at temperatures of 40°C or higher. *2 Equipment monitoring service provided by Hitachi Industrial Equipment Systems. *3 A collective term for Hitachi's advanced digital technology solutions, systems, and technologies that create value  from customer data and accelerate digital innovation. *4 The Bluetooth word mark and logo are registered trademarks owned by Bluetooth SIG, Inc., and HIES uses these marks under license. Other trademarks and trade names are the property of their respective owners. *5 A communication protocol widely used for data transmission in industrial equipment. Modbus is a registered trademark of Schneider Electric USA Inc.  About HIES  Hitachi Industrial Equipment Systems enhances productivity across various industries – including data centers, batteries, electronics and semiconductors and pharmaceuticals – through high-efficiency products such as compressed air systems, grid edge solutions, drives and coding and marking equipment. Our innovative solutions and services integrate digital technology to drive customer success and contribute to a more sustainable society. We support customers throughout the entire product lifecycle, from maintenance to recycling. For more information on Hitachi Industrial Equipment Systems, please visit our website at https://www.hitachi-ies.com/ Business Contact  Hitachi Industrial Equipment Systems  Global Air Power Group Marketing & Sales Management Division  Marketing & Strategic Planning Dept.  Information contained in this news release is current as of the date of the press announcement, but may be subject to change without prior notice.", "release_time": "2025-11-14", "source_institution": "日本日立", "url": "http://www.hitachi.com/New/cnews/month/2025/10/251020.html"}
{"category": "研究前沿", "title": "MIT全球种子基金推动国际科研合作创新", "short_summary": "MIT种子基金资助全球前沿研究，促进跨学科合作与创新解决方案。", "detailed_summary": "MIT种子基金资助全球前沿研究，促进跨学科合作与创新解决方案。\n（1）MIT全球种子基金自2008年启动，已资助1300多个项目，总额约3000万美元；\n（2）项目涵盖多个前沿领域，如人工智能预测能耗、mRNA疗法治疗ALS、气候变化对贫血影响等；\n（3）强调“互惠交流”合作模式，促进MIT与全球研究者平等协作；\n（4）案例包括在塞拉利昂开发残疾人辅助设备、佛得角研究气候与健康关联等；\n（5）基金扩展至新国家，如捷克、挪威，并持续接受申请，推动长期合作。", "raw_content": "Since launching in 2008, the MIT Global Seed Funds (GSF) program has awarded roughly $30 million to more than 1,300 high-impact faculty research projects across the world, spurring consequential collaborations on topics that include swine-fever vaccines, deforestation of the Amazon, the impact of “coral mucus” on the Japanese island of Okinawa, and the creation of an AI-driven STEM-education lab within Nigeria’s oldest university.Administered by the MIT Center for International Studies (CIS) and open to MIT faculty and principal investigators, GSF boasts a unique funding structure consisting of both a general fund for unrestricted geographical use and more than 20 different specific funds for individual universities, regions, and countries.GSF projects often tackle critical challenges that require international solutions, culminating in patents, policy changes, and published papers in journals such as Nature and Science. Some faculty-led projects from this year include Professor Hugh Herr’s modular crutches for people with disabilities in Sierra Leone, Research Scientist Paolo Santi’s large-language models to predict energy consumption in grocery stores, and Professor Ernest Fraenkel’s development of mRNA therapies for the neurodegenerative disease amyotrophic lateral sclerosis (ALS).GSF Assistant Director Justin Leahey, who is managing director of the MIT-Germany and MIT-Switzerland programs, says that GSF has expanded exponentially over the years, including most recently into the Czech Republic, Norway, Slovakia, and — starting in fall 2025 — Hungary. This year there were a grand total of roughly 300 research proposals submitted for consideration, with many of the accepted proposals including the active participation of students at both the graduate and undergraduate level.Central to GSF’s work is “reciprocal exchange” — the concept of collaborators in and out of MIT sharing their work and exchanging ideas in an egalitarian way, rather than bringing a one-sided approach to different research challenges. Frequent collaborator Raffaella Gozzelino, a neurology researcher and principal investigator at NOVA Medical School in Portugal who works closely with Jacquin Niles, an MIT professor of biological engineering, says that research is more impactful “when specialized knowledge integrates local realities and reveals potential solutions to national challenges,” and views the spirit of reciprocal exchange as something that revolves around “sharing knowledge and co-creating solutions that empower one another and build bridges across borders.”For Cindy Xie ’24, MCP ’25, her master’s thesis emerged from the first-ever GSF-supported research internship in Cape Verde, where she worked with Niles and Gozzelino to explore the impact of climate change on anemia in the country of 500,000 people, focusing specifically on its largest island of Santiago. Xie says that she was struck by the intertwined intersectional nature of the issues of nutrition, climate, and infection in Santiago, home to the nation’s capital city of Praia. For example, Xie and Gozzelino’s team found that respondents perceived a rise in costs of fresh produce over time, exacerbated by drought and unpredictable agricultural conditions, which in turn impacted existing nutritional deficiencies and increased residents’ susceptibility to mosquito-borne diseases.“Though this multidisciplinary research lens is challenging in terms of actual project implementation, it was meaningful in that it generated insights and connections across fields that allow our research to be better contextualized within the experiences of the communities that it impacts,” Xie says.Gozzelino says that it has been meaningful to witness how scientific research can transcend academic boundaries and generate real impact. She says that, by examining the effects of climate change on infectious diseases and nutrition in Cape Verde, the team will be able to build a framework that can directly inform public policy.“Contributing to a project that underscores the importance of integrating scientific knowledge into decision-making will safeguard vulnerable populations and make them feel included in the society they belong,” Gozzelino says. “This collaboration has revealed the enormous potential of international partnerships to strengthen local research capacity and address global challenges.”During her time in Cape Verde working with Xie and Gozzelino, Amulya Aluru ’23, MEng ’24 got to meet with 20 local officials and connect with new people in a wide range of roles across the country, helping her “recognize the power of interpersonal relationships and collaboration” in public health research. She says that the structure of the GSF grant gave her the unique experience of having mentors and coworkers in three different countries, spanning Cape Verde, the United States, and Portugal.Aluru says that this kind of cross-pollination “enabled me to strengthen my research with different perspectives and challenged me to approach my work in a way that I’d never done before, with a more global mindset.”Xie similarly expresses her deep appreciation for the long-term relationships she has built through the project and the linkages between Santiago and Boston, which itself is home to one of the world’s largest Cape Verdean diasporas. “As a student, this was a valuable experience to inform the approaches to collaboration that I would like to implement in my own future work,” Xie says.More broadly, Gozzelino sees GSF grants like the Cape Verde one as being not simply a vehicle for financial support, but “a catalyst for turning partnerships into long-term impactful collaborations, demonstrating how global networks can aid the development of human capital.”GSF’s long history of reaching across departments and borders has led to multiple meaningful academic collaborations that have since come to span continents — and decades. In 2015, Professor Jörn Dunkel — an applied mathematician at MIT — kicked off work on a data-sharing repository for bacterial biofilms with the interdisciplinary German microbiologist Knut Drescher, then a professor of biophysics at Philipps-Universität Marburg in Germany. Dunkel and Drescher have since co-authored more than 15 papers together in publications like Nature Physics and Science Advances alongside their teams of graduate students and postdocs, even with Drescher having moved locations and crossed country lines to Switzerland as a faculty member at the University of Basel’s Biozentrum Center for Molecular Life Sciences.“Our collaboration often creates great synergy by combining my team’s experiments with the theory from Jörn’s team,” says Drescher. “It is a great joy to see his perspective on the experimental systems we are working on. He is able to really understand and engage with experimental biological data, identifying patterns in seemingly distant biological systems.”In explaining the CIS initiative’s success, Leahey points to the synergistic, academically eclectic, cross-disciplinary nature of the program. “[GSF] is a research fund that doesn’t ‘fund research’ in the conventional sense,” he says. “It seeds early-stage collaboration and lets people explore.”The MIT Global Seed Funds applications are now open, with a deadline of Dec. 16.", "release_time": "2025-10-21", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/global-seed-funds-catalyze-research-1020"}
{"category": "研究前沿", "title": "新研究提出引力波驱动宇宙形成模型", "short_summary": "科学家提出新模型，认为引力波而非暴胀是宇宙结构形成的关键驱动力。", "detailed_summary": "科学家提出新模型，认为引力波而非暴胀是宇宙结构形成的关键驱动力。\n（1）西班牙与意大利科学家在《物理评论研究》发表新模型，挑战传统宇宙暴胀理论。\n（2）该模型认为引力波是宇宙早期演化的主要驱动力，可解释星系、恒星等结构的形成。\n（3）新模型基于广义相对论和量子力学，强调其简单性和可验证性，无需引入未观测的假设元素。\n（4）研究引用De Sitter空间数学构型，并回顾了从爱因斯坦到2015年LIGO探测的引力波研究历史。\n（5）该研究为理解宇宙起源提供了新视角，但宇宙诞生之谜仍需未来探索。", "raw_content": "How did the universe come into existence, and what early processes shaped everything that followed? A new study published in Physical Review Research takes aim at this fundamental question. Scientists from Spain and Italy have introduced a model that reimagines what happened moments after the universe was born. Their approach could upend long-standing ideas about the forces and events that governed the universe's earliest evolution.  To explore these beginnings, the researchers ran advanced computer simulations that question the traditional \"inflation\" theory. According to that theory, the universe expanded at an extraordinary rate within a tiny fraction of a second after it came into existence. The inflation model relies on several interconnected variables, all of which must align to make the theory work. The newly proposed model offers a simpler explanation. It suggests that gravitational waves -- predicted by general relativity -- may be the true driving force behind the universe's formation, giving rise to galaxies, stars, planets, and ultimately life on Earth. The researchers link this idea to a mathematical construct known as De Sitter space, named for Dutch mathematician Willem De Sitter, who collaborated with Albert Einstein in the 1920s on understanding the structure of the cosmos. \"For decades, we have tried to understand the early moments of the Universe using models based on elements we have never observed,\" said Dr. Raúl Jiménez, who studies experimental sciences & mathematics at ICREA in Spain and is a co-author on the study. \"What makes this proposal exciting is its simplicity and verifiability. We are not adding speculative elements but rather demonstrating that gravity and quantum mechanics may be sufficient to explain how the structure of the cosmos came into being.\" The concept of gravitational waves dates back to 1893 and 1905, when Oliver Heaviside and Henri Poincaré first proposed related ideas. Albert Einstein expanded on this in 1916, describing gravitational waves as ripples in the fabric of space-time in his general theory of relativity. These waves can originate from powerful cosmic events such as supernovae, merging black holes, and colliding neutron stars. Because they are incredibly faint, detecting them requires highly sensitive instruments. It was not until September 2015 that scientists at the Laser Interferometer Gravitational-Wave Observatory (LIGO), with facilities in Washington and Louisiana, achieved the first confirmed detection. The birth of the universe continues to be one of science's greatest puzzles. The Big Bang theory remains the prevailing explanation, yet many questions persist -- especially about what might have occurred before that explosive beginning. Carl Sagan once reflected on humanity's deep connection to the cosmos, saying, \"The cosmos is within us. We are made of star-stuff. We are a way for the universe to know itself.\" We may never know exactly how the universe began and the processes responsible for you reading this article right now. But like the simplicity this study presents, perhaps this study is simply a way for us to know the universe itself a little bit better.  What new discoveries about the origins of the universe will researchers make in the coming years and decades? Only time will tell, and this is why we science! As always, keep doing science & keep looking up! Adapted from an article originally published on Universe Today.", "release_time": "2025-10-19", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/10/251018102132.htm"}
{"category": "研究前沿", "title": "挪威团队研发新型高性能芯片激光器", "short_summary": "新型激光器实现高精度测距与气体检测，推动自动驾驶与环境监测技术发展。", "detailed_summary": "新型激光器实现高精度测距与气体检测，推动自动驾驶与环境监测技术发展。\n（1）挪威科技大学团队开发出新型芯片激光器，兼具快速、廉价、强大和易用特性；\n（2）采用先进材料与微光路技术，可稳定发射光束并实现平滑频率调节；\n（3）测距精度达4厘米，适用于自动驾驶汽车的激光雷达环境感知系统；\n（4）成功演示对剧毒氰化氢气体的高灵敏度检测能力；\n（5）基于现有芯片技术可实现低成本量产，有望推动高性能测量与通信工具普及。", "raw_content": "Laser technology plays a vital role in modern life, supporting everything from precise scientific measurements to advanced communication systems. It underpins technologies such as self-driving vehicles, high-speed fiber optic networks, and even tools that detect gases in the atmosphere.  A research team led by Associate Professor Johann Riemensberger from the Department of Electronic Systems at the Norwegian University of Science and Technology (NTNU) has developed a new kind of laser designed to overcome several challenges found in existing models. \"Our results can give us a new type of laser that is both fast, relatively cheap, powerful and easy to use,\" says Riemensberger. The team's findings have been published in Nature Photonics. The project is a collaboration between NTNU, the Swiss École Polytechnique Fédérale de Lausanne (EPFL), and Luxtelligence SA. Self-driving cars and air quality detectors Traditional precision lasers are often bulky, costly, and tricky to fine-tune. \"Our new laser solves several of these problems,\" says Riemensberger.  This improvement could make the technology especially useful in self-driving cars, which rely on a technique known as Lidar to map their surroundings. Lidar works by measuring how long it takes light from a laser to bounce back, or by detecting tiny changes in the light's wave phase. The new laser can perform such measurements with remarkable accuracy -- within about four centimeters. The researchers also demonstrated that their laser can effectively detect hydrogen cyanide gas in the air, a substance commonly referred to as \"hydrocyanic acid.\" Because this compound is extremely toxic even in small amounts, being able to identify it quickly is essential for safety and environmental monitoring. Advanced materials, microsized light circuits The researchers created the new laser with advanced materials and microscopic light circuits. The laser emits a powerful and stable beam of light. Also, among the advantages is that users can easily adjust the frequency quickly and smoothly, without sudden jumps. \"You can also easily control it with just one control instead of many,\" Riemensberger points out. The laser is built using chip technology that is already available. This makes it possible to mass-produce it cheaply. \"Our findings make it possible to create small, inexpensive and user-friendly measuring instruments and communication tools with high performance,\" Riemensberger said. The work was a collaboration between EPFL (experiments), Luxtelligence SA (chip production) and NTNU (design and simulations). It started when Riemensberger was still a postdoctoral fellow at EPFL. The collaboration continues through an EIC Pathfinder OPEN scholarship called ELLIPTIC.", "release_time": "2025-10-20", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251018102116.htm"}
{"category": "研究前沿", "title": "3D打印超材料实现振动抑制新突破", "short_summary": "美研究团队3D打印出几何结构超材料管，可被动抑制振动，具多领域应用潜力。", "detailed_summary": "美研究团队3D打印出几何结构超材料管，可被动抑制振动，具多领域应用潜力。\n（1）美国密歇根大学与空军研究实验室合作，利用3D打印技术制造出管状机械超材料；\n（2）该材料特性源于其独特的内部几何设计（如kagome结构），而非化学成分，属于拓扑材料研究范畴；\n（3）实验证明其能被动抑制振动传播，原理基于麦克斯韦晶格和边界拓扑效应；\n（4）潜在应用包括交通运输、建筑减振等领域，由DARPA和海军研究办公室部分资助；\n（5）目前面临振动抑制与承重能力的权衡挑战，需建立新的测试与设计标准。", "raw_content": "Scientific breakthroughs rarely happen all at once. More often, they evolve slowly, as researchers and engineers build on years of steady progress until the extraordinary eventually becomes routine.  Now, scientists may be reaching a turning point in that gradual journey. Researchers from the University of Michigan and the Air Force Research Laboratory (AFRL) have demonstrated a way to 3D print intricate tubular structures whose unique internal geometry allows them to suppress vibrations in ways never seen in natural materials. These creations belong to a class known as mechanical metamaterials -- engineered substances with properties that come entirely from their design rather than their composition. The ability to block or reduce vibrations could be valuable across many industries, from transportation to construction and beyond. The team's findings, published in Physical Review Applied, build on decades of theory and computer modeling to produce real-world structures that can passively disrupt vibrations traveling through them. \"That's where the real novelty is. We have the realization: We can actually make these things,\" said James McInerney, a research associate at the AFRL. McInerney was previously a postdoctoral fellow at U-M working with Xiaoming Mao, a professor of physics, who is also an author of the new study. \"We're optimistic these can be applied for good purposes. In this case, it's vibration isolation,\" McInerney said. The project received partial funding from the Defense Advanced Research Projects Agency (DARPA) and the Office of Naval Research, and also involved support from the U.S. National Research Council Research Associateship Program, administered by the National Academies of Sciences, Engineering and Medicine. Contributors included Serife Tol, an associate professor of mechanical engineering at U-M; Othman Oudghiri-Idrissi of the University of Texas; and Carson Willey and Abigail Juhl of AFRL.  \"For centuries, humans have improved materials by altering their chemistry. Our work builds on the field of metamaterials, where it is geometry -- rather than chemistry -- that gives rise to unusual and useful properties,\" Mao said. \"These geometric principles can apply from the nanoscale to the macroscale, giving us extraordinary robustness.\" Structural foundations According to McInerney, the study brings together classical structural engineering, modern physics, and cutting-edge manufacturing tools such as 3D printing. \"There's a real probability that we're going to be able to manufacture materials from the ground up with crazy precision,\" he said. \"The vision is that we're going to be able to create very specifically architectured materials and the question we're asking is, 'What can we do with that? How can we create new materials that are different from what we're used to using?'\" As Mao noted, the team is not altering a material's chemistry or molecular makeup. Instead, they are exploring how controlling shape and structure at a fine scale can produce new and advantageous mechanical properties. In nature, this approach already exists. Human bones and plankton shells, for instance, use intricate geometries to gain remarkable strength and resilience from simple materials. With technologies like 3D printing, scientists can now replicate and enhance that natural design principle in metals, polymers, and other substances to achieve effects that were previously out of reach.  \"The idea isn't that we're going to replace steel and plastics, but use them more effectively,\" McInerney said. New-school meets old-school While this work does rely on modern innovations, it has important historical underpinnings. For one, there's the work of the famous 19th century physicist, James Clerk Maxwell. Although he's best known for his work in electromagnetism and thermodynamics, he also dabbled in mechanics and developed useful design considerations for creating stable structures with repeating subunits called Maxwell lattices, McInerney said. Another key concept behind the new study emerged in the latter half of the 20th century, as physicists found that interesting and perplexing behaviors emerged near the edges and boundaries of materials. This led to a new field of study, known as topology, that's still very active and working to explain these behaviors and to help capitalize on them in the real world. \"About a decade ago, there was a seminal publication that found out that Maxwell lattices can exhibit a topological phase,\" McInerney said. Over the last several years, McInerney and colleagues have explored the implications of that study as they pertain to vibration isolation. The team has built up a model explaining that behavior and how to design a real object that would exhibit it. The team has now proved that its model is at its most advanced stage yet by actually making such objects with 3D printed nylon. A cursory look at the structures reveals why making them previously was such a challenge. They resemble a chain-link fence that's been folded over and rolled up into a tube with a connected inner and outer layer. Physicists call these kagome tubes, a reference to traditional Japanese basket weaving that used similar patterns. This is, however, just the first step in realizing the potential of such structures, McInerney said. For instance, the study also showed that the better a structure is at suppressing vibrations, the less weight it can support. That is a costly, potentially even unacceptable, tradeoff in terms of applications, but it highlights interesting opportunities and questions that remain at a fundamental level, he said. As such novel structures are made, scientists and engineers are going to need to build new standards and approaches to test, characterize and assess them, which is a challenge that excites McInerney. \"Because we have such new behaviors, we're still uncovering not just the models, but the way that we would test them, the conclusions we would draw from the tests and how we would implement those conclusions into a design process,\" he said. \"I think those are the questions that honestly need to be answered before we start answering questions about applications.\"", "release_time": "2025-10-18", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251016223106.htm"}
{"category": "产业应用", "title": "IAEA官员推动辐射技术治理塑料污染", "short_summary": "IAEA官员主导NUTEC塑料倡议，运用辐射技术回收塑料并参与全球治理谈判。", "detailed_summary": "IAEA官员主导NUTEC塑料倡议，运用辐射技术回收塑料并参与全球治理谈判。\n（1）Binti-Othman作为IAEA辐射处理官员，专注于将辐射技术应用于现实世界。\n（2）她主要负责NUTEC Plastics倡议，利用核技术从回收和源头两方面解决全球塑料污染。\n（3）她代表IAEA参与制定关于塑料污染的具有国际法律约束力的文书谈判。\n（4）她主导组织了第三届国际辐射科技应用会议（ICARST-2025），吸引了超过1700名参会者。\n（5）其工作深化了对IAEA全球运作的理解，并促进辐射技术在环保领域的创新应用。", "raw_content": "Radiation Science and Applications at the IAEA  As an IAEA Radiation Processing Officer, Binti-Othman focuses on how radiation technologies can be applied to real-world settings. She primarily works on the NUTEC Plastics initiative, which uses nuclear technology to tackle plastic pollution worldwide – both through recycling and at the source. The initiative’s use of radiation technologies in sustainable materials processing aligns directly with her area of expertise.  \"Working on NUTEC Plastics allows me to collaborate with a global network of scientists, researchers and technologists, to grow professionally in a range of areas, and to contribute to innovative, radiation-based solutions for plastic pollution,” she said. Binti-Othman also represents the IAEA at the Intergovernmental Negotiating Committee on Plastic Pollution, which is working toward an international legally binding instrument on plastic pollution both on land and in the marine environment. One of Binti-Othman’s proudest achievements at the IAEA was her key role in organizing the Third International Conference on Applications of Radiation Science and Technology (ICARST-2025). The conference, which showcases developments in radiation science and technology, attracted over 1700 in-person and virtual attendees. Binti-Othman said that experiencing the IAEA from the inside has deepened her appreciation for its global work. “From the outside, the IAEA can seem complex. But being here has helped me better understand the systems and processes behind IAEA activities, and I can bring that knowledge back home with me,” she said.", "release_time": "2025-10-17", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/azillah-binti-othman-her-path-to-a-career-in-radiation-science"}
{"category": "研究前沿", "title": "MIT工程学院迎来新教员团队聚焦前沿研究", "short_summary": "MIT工程学院新聘多位助理教授，研究方向涵盖可持续航空、核聚变、AI算法及仿生机器人等前沿领域。", "detailed_summary": "MIT工程学院新聘多位助理教授，研究方向涵盖可持续航空、核聚变、AI算法及仿生机器人等前沿领域。\n(1) MIT工程学院迎来新教员团队，涉及航空宇航、核科学、计算机科学、材料科学等多个院系。\n(2) 新教员研究方向前沿，包括可持续航空航天技术、核聚变优化、AI算法与推理、超分子水凝胶材料等。\n(3) 多名教员拥有业界或知名实验室经验，如罗尔斯·罗伊斯、Databricks、MIT等离子体科学与聚变中心等。\n(4) 部分教员任职于跨学科学院，体现工程与计算、数据系统等领域的深度融合。\n(5) 此次招聘旨在推动研究卓越性，强化教学与指导，产生现实世界影响力。", "raw_content": "The MIT School of Engineering welcomes new faculty members across six of its academic units. This new cohort of faculty members, who have recently started their roles at MIT, conduct research across a diverse range of disciplines.“We are thrilled to welcome these accomplished scholars to the School of Engineering,” says Maria C. Yang, interim dean of engineering and William E. Leonhard (1940) Professor in the Department of Mechanical Engineering. “Each brings unique expertise across a wide range of fields and is advancing knowledge with real-world impact. They all share a deep commitment to research excellence and a passion for teaching and mentorship.”Faculty with appointments in the Department of Electrical Engineering and Computer Science (EECS) and the Institute for Data, Systems, and Society (IDSS) report into both the School of Engineering and the MIT Stephen A. Schwarzman College of Computing.The new engineering faculty include:Masha Folk joined the Department of Aeronautics and Astronautics as an assistant professor in July 2024 and is currently the Charles Stark Draper Career Development Professor. Her research focuses on sustainable aerospace technology driven by a deep desire to accelerate carbon-neutral aviation. She previously worked as an aerodynamics specialist for Rolls-Royce. Folk received her BS in aerospace engineering from Ohio State University, her MS in aerospace engineering from Purdue University, and her PhD in energy, fluids, and turbomachinery from the University of Cambridge.Sophia Henneberg joined the Department of Nuclear Science and Engineering (NSE) as an assistant professor in September. Her research focuses on developing, utilizing, and extending optimization tools to identify new, promising stellarator designs, which are a promising path toward fusion energy. Previously, she was the principal investigator of EUROfusion’s Stellarator Optimization Theory, Simulation, Validation, and Verification group. Henneberg received a BS in physics at the Goethe-Universität, an MA in physics at the University of Wisconsin at Madison, and a PhD in physics at the University of York.Omar Khattab joined the Department of Electrical Engineering and Computer Science as an assistant professor in July. He is also affiliated with the Computer Science and Artificial Intelligence Laboratory (CSAIL). His research develops new algorithms and abstractions for declarative AI programming and for composing retrieval and reasoning. Khattab previously worked as a research scientist at Databricks. He received a BS in computer science from Carnegie Mellon University and a PhD in computer science from Stanford University.Tania Lopez-Silva joined the Department of Materials Science and Engineering as an assistant professor in July. Her research focuses on supramolecular hydrogels — soft materials made from self-assembling molecules, primarily peptides. Previously, she served as a postdoc at the National Cancer Institute. Lopez-Silva earned her BS in chemistry from Tecnológico de Monterrey and her MA and PhD in chemistry from Rice University.Ethan Peterson ’13 joined the Department of Nuclear Science and Engineering as an assistant professor in July 2024. His research focuses on improving radiation transport and transmutation methods for the design of fusion technologies, as well as whole-facility modeling for fusion power plants. Previously, he worked as a research scientist at MIT’s Plasma Science and Fusion Center. Peterson received his BS in nuclear engineering and physics from MIT and his PhD in plasma physics from the University of Wisconsin at Madison.Dean Price joined the Department of Nuclear Science and Engineering as the Atlantic Richfield Career Development Professor in Energy Studies and an assistant professor in September. His work focuses on the simulation and control of advanced reactors, with expertise in uncertainty quantification, scientific machine learning, and artificial intelligence for nuclear applications. Previously, he was the Russell L. Heath Distinguished Postdoctoral Fellow at Idaho National Laboratory. He earned his BS in nuclear engineering from the University of Illinois and his PhD in nuclear engineering from the University of Michigan.Daniel Varon joined the Department of Aeronautics and Astronautics as the Boeing Assistant Professor, holding an MIT Schwarzman College of Computing shared position with IDSS, in July. Varon’s research focuses on using satellite observations of atmospheric composition to better understand human impacts on the environment and identify opportunities to reduce them. Previously, he held a visiting postdoctoral fellowship at the Princeton School of Public and International Affairs. Varon earned a BS in physics and a BA in English literature from McGill University, and an MS in applied mathematics and PhD in atmospheric chemistry from Harvard University.Raphael Zufferey joined the Department of Mechanical Engineering as an assistant professor in January. He studies bioinspired methods and unconventional designs to solve seamless aerial and aquatic locomotion for applications in ocean sciences. Zufferey previously worked as a Marie Curie postdoc at the École Polytechnique Fédérale de Lausanne (EPFL). He received his BA in micro-engineering and MS in robotics from EPFL and a PhD in robotics and aeronautics from Imperial College London.The School of Engineering is also welcoming a number of faculty in the Department of EECS and the IDSS who hold shared positions with the MIT Schwarzman College of Computing and other departments. These include: Bailey Flanigan, Brian Hedden, Yunha Hwang, Benjamin Lindquist, Paris Smaragdis, Pu “Paul\" Liang, Mariana Popescu, and Daniel Varon. For more information about these faculty members, read the Schwarzman College of Computing’s recent article.Additionally, the School of Engineering has adopted the shared faculty search model to hire its first shared faculty member: Mark Rau. For more information, read the School of Humanities, Arts, and Social Sciences recent article.", "release_time": "2025-10-18", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/school-engineering-welcomes-eight-new-faculty-1017"}
{"category": "产业应用", "title": "东亚冬季煤炭需求反弹，进口量价齐升", "short_summary": "冬季临近推动东亚煤炭需求显著增长，进口量与价格从低位反弹。", "detailed_summary": "冬季临近推动东亚煤炭需求显著增长，进口量与价格从低位反弹。\n（1）冬季临近导致东亚各国煤炭需求增加，8月亚洲动力煤进口量跃升至8534万吨，扭转连续九个月下滑趋势；\n（2）中国、日本和韩国作为主要进口国，中国因遏制产能过剩的检查间接推动进口增长；\n（3）煤炭价格从6、7月的四年低点反弹，未来几个月进口预计进一步增加；\n（4）尽管全球倡导能源转型，煤炭在东亚仍关键，但环保压力与碳中和目标存在矛盾。", "raw_content": "据Eenergiesmedia.com网站10月11日发布的信息，随着冬季的临近，东亚各国的煤炭需求将显著增加。近期，煤炭产量出现大幅下降，同时还有多种因素导致该地区煤炭价格反弹。 煤炭对许多国家的能源需求仍至关重要，尽管欧盟大力倡导向可再生能源转型，但随着北半球寒冷月份的临近，煤炭在东亚地区仍将发挥关键作用。 亚洲煤炭进口扭转了长达连续九个月的下滑趋势 亚洲大陆的许多国家仍然依靠煤炭来满足其能源需求。过去十年间，该地区经历了多起环境灾难，亟需创新解决方案来应对正在发生的能源危机。 煤电明显是全球电力生产的重要选择。然而，世界已对依赖煤炭所产生的环境影响有了深刻认识。尽管人们已显然对我们自身对传统煤炭发电方式的依赖感到不满，但该煤炭行业在经历了九个月的低迷表现后又出现了显著反弹。 大宗商品分析机构克普勒(Kpler)的数据显示，8月份亚洲动力煤进口量跃升至8534万吨，较7月增加640万吨，是自2024年12月以来首次突破8100万吨的月度水平。 这一增长也许是中国政府在内蒙古等煤炭主产区为了遏制产能过剩问题的直接结果。 随着寒冷冬季的临近，可能会看到煤炭更为出色的运行业绩 在任何国家，冬季都会给电力系统带来巨大压力，因为人们试图用电取暖。东亚地区对全球煤炭进口的增长发挥了显著作用，中国、日本和韩国都是世界上最大的煤炭进口采买国之一。 有趣的是，中国由于出现了煤炭供过于求的问题，因此一直在多个煤炭生产区开展一系列的检查。再考虑到东亚地区的煤炭进口数据，进一步突显了煤炭在该地区的地位。 9月份主要海运动力煤品种的进口价格从6月及7月的四年l来的低点反弹。7月煤炭进口到货量较去年同期下降23%，而8月中国煤炭进口又有所增强，全球煤炭行业也许可以从亚洲市场传出的利好消息中获得一些慰藉。 随着进入冬季，未来几个月对煤炭的依赖也将增加，中国本月有望进口海运动力煤2741万吨。而且东亚某些国家也已实施新的措施，通过放宽监管壁垒来缓解能源供应的压力。 因此，预计未来几个月东亚煤炭进口数字还会进一步增长。国际能源署报告称，预计未来几年东南亚的电力需求将大幅激增，到2050年将达到当前水平的两倍。 无论喜欢与否，煤炭将继续在人们的生活中发挥作用 国际能源署(IEA)的报告指出，今年余下的时间里，多个国家的煤炭使用量将继续上升，这将如何影响气候变化仍有待观察。 不过，煤炭行业在世界东方依然充满活力。环保组织呼吁世界各国携手开发新的可再生能源产能，以帮助摆脱对煤炭的依赖。 随着世界多个国家政府承诺要实现碳中和目标，但实际上煤炭使用量的增加，却大大削弱了人们远离煤炭的努力。", "release_time": "2025-10-17", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195015-1.html"}
{"category": "产业应用", "title": "第15届Dii沙漠能源领袖峰会聚焦MENA能源转型实施", "short_summary": "峰会探讨中东能源转型实施路径，关注市场机制与氢能基建等产业应用。", "detailed_summary": "峰会探讨中东能源转型实施路径，关注市场机制与氢能基建等产业应用。\n（1）第15届Dii沙漠能源领袖峰会将于2025年11月6-7日在阿联酋迪拜举行，主题为“MENA能源转型：愿景、实施、就业”。\n（2）会议重点讨论市场驱动机制在推动低成本、气候中和能源解决方案中的关键作用，涵盖项目实施、区域合作等产业应用挑战。\n（3）阿联酋能源和石油事务副部长将发表主旨演讲，阐述该国通过创新、合作和基建实现全球能源领导力的战略。\n（4）峰会将发布两项重要产业研究报告，分别关于数据中心作为清洁能源超级承购方，以及公共用户基础设施如何推动氢能项目可融资性。\n（5）活动汇集了ACWA Power、西门子能源等产业领军企业，通过主题演讲、高管小组讨论和圆桌会议等形式促进产业实践交流。", "raw_content": "Gathering the clean energy Industry, the 15th Dii Desert Energy Leadership Summit, under the patronage of UAE’s Ministry of Energy and Infrastructure, provides a unique platform for the industry’s most innovative, forward-thinking and top-level leaders to accelerate action and engage in bold discussions on the key enablers of the energy transition.   6-7 November 2025 | The W Dubai - The Palm, Dubai, UAE | As the energy transformation in MENA enters exponential growth, much remains to be done to further accelerate. Under the theme of ‘Energy Transformation in MENA: Vision. Implementation. Jobs’, this year’s summit emphasizes the challenges of implementation and highlights the importance of market-driven mechanisms in advancing toward low-cost and climate-neutral energy solutions.   In its 15th edition, across two full days, the Summit program explores what should drive clean energy systems and markets. It delves into the evolving business case for climate-neutral energy, examining the right mix of carrots and sticks needed to shape viable markets – from public sector push to market pull, and the critical role of price signals.   On day two, the Summit will welcome H.E. Eng. Sharif Salim Al Olama, Undersecretary for Energy and Petroleum Affairs, Ministry of Energy and Infrastructure of the United Arab Emirates to deliver the opening keynote on 7th November. The session titled ‘Powering Progress - UAE's Strategy for Global Energy Leadership Through Innovation, Partnerships, and Infrastructure Development’ will focus on cross-border regional cooperation for energy security, where his participation will highlight the UAE’s vision and implementation strategies.     Register for the Summit | Find out more about the Summit | See the full agenda      Keynote highlights Providing a platform for visionary pioneers in the renewables and low emissions ecosystem, the Dii Leadership Summit keynote addresses provide attendees with the opportunity to hear exclusive insights on lighthouse project development and common objectives to make our economies climate neutral.    Powering Progress – UAE's Strategy for Global Energy Leadership Through Innovation, Partnerships, and Infrastructure DevelopmentE. Eng. Sharif Salim Al-Olama, Undersecretary for Energy and Petroleum Affairs, Ministry of Energy and Infrastructure, UAE EU Climate Green Finance, Regional Interconnections and the pan-MENA AgendaE. Lucie Berger, Ambassador to the European Union to the United Arab Emirates Renewables to AI: Advancing Project Development for Data CentersJose Maria Llopis, CEO, Edisun Power Europe AG H2Global 2.0: Update on the Second TenderTimo Bollerhey, CEO, H2Global Holding and Hintco Solar Power for a Resilient Future: Optimizing Energy for Businesses and UtilitiesHamid Rashid Alzayani, Chairman, Midal Solar and Midal Cables Group    Fireside chats On an interactive format, the fireside chats delve into specific projects and latest technology innovations. CEOs will share their vision for the EU-MENA low carbon market, focusing on the Southern routes and MENA’s strategic role as the Renewable Hub for East Asia and Europe  The Southern Corridor – Securing Low-Carbon EnergyWith Egbert Laege, CEO, Securing Energy for Europe (SEFE) The MENA Momentum: MENA’s strategic role as the Renewable Hydrocarbon Hub for East Asia and EuropeWith Thorsten Herdan, CEO, HIF EMEA Beyond the cells: Bosch’s unique integrated strategy in electrolyzer stacksWith Matthias Ziebell, Senior Vice President for Sales, Energy Markets and Business Development, Bosch    Top Executive Panel highlights  Bringing together industry experts and stakeholders, the Summit program covers holistically the energy transition spectrum.    Key Enablers of the Energy Transformation in MENA  Moderator: Dan Feldman, Global Head of Energy, King & Spalding Speakers:  Abdulaziz Al Shidhani, Managing Director, Hydrom; Ebubekir Koyuncu, CEO, Blue Hydrogen Industrial Gases (BHIG) and CEO, Air Products Qudra (APQ); Tarik Mouffadal, CEO, Masen; Gauri Singh, Deputy Director- General, IRENA; Luc Koechlin, CEO Middle East, EDF Group and EDF Power Solutions; Mohammad Abdelqader El Ramahi, Chief Green Hydrogen Office, Masdar   Leading the Way - Project Implementation and Collaboration in MENA's Energy Landscape  Moderator: Paddy Padmanathan, Co-Founder & Vice Chairman, ZheroSpeaker: Nadja Håkansson, Member of the Executive Board/COO thyssenkrupp Decarbon Technologies & CEO, thyssenkrupp Uhde; Cornelius Matthes, CEO, Dii Desert Energy; Ahmed Mulla, Deputy CEO, Infinity Power; Reda Hamedoun, Executive Vice President, NAREVA HOLDING; Thore Lapp, Business Unit Manager Green Energy & Sustainability, Executive Vice President, TÜV SÜD AG  Building Long-Term Storage for Energy Security  Moderator: Frank Wouters, Chair, MENA Hydrogen Alliance Speakers: Pascal Baylocq, CEO, Geostock; Ahmed Ali Al-Ebrahim, Chief Executive Officer, GCC Interconnection Authority; Sebastian Budischin, Senior Vice President of Business Development and Origination, Hydrogen and Clean Energy Business, Securing Energy for Europe (SEFE); Christian Matthies, Executive Director Middle East & Turkey, Linde Gas Middle East LLC    Investments in AI and Data Centers - Assessing Alternatives and Integrated Net-zero solutions  Moderator: Alicia Eastman, Managing Director, APC Investors   Speakers: Dr. Andreas Widl, CEO and Chairman of the Executive Board, SAMSON; Olaf Berlien, President & CEO, INNIO Group; Charlie Sanchez, President - Infrastructure Advisory, Black & Veatch; Andrea Lovato, Chief Development Officer, Datavolt    MENA as a Net-Zero Transport Hub - Ports, Airports & Common User Infrastructure for Energy Transformation  Chairperson & Moderator: Alex Sarac, Partner, Addleshaw Goddard   Speakers: Abdullah Al Abri, Vice President – Sustainability, SOHAR Port and Freezone; Ankit Jain, Chief Investment Officer, Nextgen Infra; Samir Rachidi, Director General, IRESEN; Captain Saif Al Mheiri, CEO, Abu Dhabi Maritime, Chief Sustainability Officer, AD Ports Group; Kenny Kitamura, Chief Representative for the Middle East, Japan Bank for International Cooperation (JBIC)    Funding the Future - Financing Low Emission Projects in MENA  Chairperson & Moderator: Siddharth Malik, Managing Partner, Green Investors AG Speakers: Harry Boyd-Carpenter, Managing Director, Sustainable Infrastructure, EBRD; Trang Huynh, Vice President Structured Finance Middle East, Sumitomo Mitsui Banking Corporation; Sami Neffati, Managing Partner, Investcorp and Aberdeen Standard Infrastructure Partners; Andrei Klevchuk, Director of Project Finance, AMEA Power   See the full list of keynote sessions here.   New Dii Desert Energy’s Studies will be unveiled: Data Centers: ‘The New Super Offtakers of Clean Energy’ with Innio Jenbacher and ‘Unlocking The Hydrogen Economy: How Common User Infrastructure Drives Project Bankability’ with Addleshaw Goddard and ILF Consulting Engineers   Dii Desert Energy conducts in-depth studies on a range of emerging energy transition topics, distinguished by their inclusion of bilateral expert interviews with partners. Providing firsthand insights directly from the market, studies are then analyzed by Dii’s experienced and independent research team. This approach combines academic rigor with the perspectives of top management and practical industry experiences, ensuring that the findings are comprehensive and actionable.  ‘Data Centers: The New Super Offtakers of Clean Energy with Innio Jenbacher’As the Middle East's data center capacity booms, this study explores the synergy between digital infrastructure and the region's world-leading clean energy resources. We analyze pathways to power next-generation AI facilities with renewables and green hydrogen, highlighting how the region can pioneer sustainable, carbon-free digital ecosystems.    ‘Unlocking The Hydrogen Economy: How Common User Infrastructure Drives Project Bankability with Addleshaw Goddard and ILF Consulting Engineers’This paper offers a strategic analysis of how Common User Infrastructure (CUI) is essential for accelerating hydrogen developments. We examine how a CUI model can overcome investment hurdles, mitigate risk and serve as a key tool for creating a structured, competitive hydrogen market.    Dii Style Interactive Roundtables Through the two days, Interactive Roundtables, focused on topics along the emission-free energy value chain, will be held including:  Blockchain, IoT & Emerging TechWith: Raghu Yabaluri, Senior Managing Director & Global Market Leader, Oil & Gas, Infrastructure Advisory, Black & Veatch Decarbonizing Aviation - e-SAF Market TakeoffWith: Adamo Screnci, Vice President Business Development and Strategy, NextChem Localization and Supply Chain ResilienceWith: Heba Rabie, Director MENA, Global Wind Energy Council (GWEC) Electrical Interconnections for an Integrated Energy SystemWith: Antonio Iliceto, Chairman, CIGRE Study Committee C1, Power System Development & Economics  See the full list of roundtables here. The conference is complemented by unique networking opportunities across the two days, including the Drinks & Dinner Reception at the AKIRA Back, hosted by Siemens Energy.   Sponsors and Supporting Partners The 15th Dii Desert Energy Leadership Summit is proudly supported by companies at the highest level of the renewable energies industry:   Platinum Sponsors - ACWA Power, State Grid Corporation of China, Enowa-Neom, Smartenergy, thyssenkruppGold Sponsors - Air Products Qudra, Al Gihaz Holding, AMEA Power, E.on, Envision Energy, Innio, King & Spalding, Nareva, Nextgen Infra, SEFEDinner Host - Siemens EnergySilver Sponsor - Midal SolarSupporting Partners - Global Wind Energy Council, Clean Energy Business Council, Cleanteach Business Club, GH2 India, Global Renewables Alliance, Hydrogen Economist, Hydrogen Europe, LDES Council, IRESEN, MED-GEM, New Energy, UNIDO, ZETA Global     About the annual Dii Desert Energy Leadership Summit Since 2010 the Annual Summits have paved the way for climate neutral, lowest cost and secure energy from the MENA Deserts.   The annual Summit gathers industry leaders along the emission-free value chain, led by the ‘doers of projects’, from key developers, utilities and investors. This makes the Dii Summit a unique high-level meeting in the market with the common objective of kicking-off the creation of a market for zero emission energy.      Contact For more information on the Summit, Contact: Sarah Murray, Marketing Specialist, Dii Desert Energy, sarah@Dii-desertenergy.org   To get involved in the Summit, Contact: Sophia De Francesco, Director of Events, Dii Desert Energy, sophia@dii-desertenergy.org   For speaking opportunities and more information on Dii Desert Energy and its partners, Contact: Valeria Aruffo, Director of External Relations, Dii Desert Energy, valeria@dii-desertenergy.org", "release_time": "2025-10-17", "source_institution": "全球风能理事会", "url": "https://www.gwec.net/gwec-news/agenda-unveiled-for-the-15th-dii-desert-energy-leadership-summit"}
{"category": "研究前沿", "title": "GO-LoW计划：千星星座开启宇宙低频观测新纪元", "short_summary": "NASA资助千星星座项目，利用干涉测量法首次观测宇宙低频无线电波，探索系外行星宜居性。", "detailed_summary": "NASA资助千星星座项目，利用干涉测量法首次观测宇宙低频无线电波，探索系外行星宜居性。\n（1）GO-LoW是由NASA资助的概念研究项目，旨在通过数千颗小型卫星组成星座，观测15米至数公里波长的低频无线电波，填补电磁频谱观测空白。\n（2）项目采用干涉测量技术，将分散的卫星信号组合成虚拟大型望远镜，克服地球电离层干扰和传统大型天线限制。\n（3）科学目标包括首次探测太阳系附近系外行星的磁场、自转速度等特征，为行星可居住性研究提供关键数据。\n（4）技术实现依托小型卫星低成本化、大型运载火箭等趋势，星座将部署于日地拉格朗日点以减少无线电干扰。\n（5）项目目前处于第二阶段，重点解决大规模星座的系统工程和自主运行挑战，由MIT林肯实验室等机构合作推进。", "raw_content": "For centuries, humans have sought to study the stars and celestial bodies, whether through observations made by naked eye or by telescopes on the ground and in space that can view the universe across nearly the entire electromagnetic spectrum. Each view unlocks new information about the denizens of space — X-ray pulsars, gamma-ray bursts — but one is still missing: the low-frequency radio sky.Researchers from MIT Lincoln Laboratory, the MIT Haystack Observatory, and Lowell Observatory are working on a NASA-funded concept study called the Great Observatory for Long Wavelengths, or GO-LoW, that outlines a method to view the universe at as-of-yet unseen low frequencies using a constellation of thousands of small satellites. The wavelengths of these frequencies are 15 meters to several kilometers in length, which means they require a very big telescope in order to see clearly.\"GO-LoW will be a new kind of telescope, made up of many thousands of spacecraft that work together semi-autonomously, with limited input from Earth,\" says Mary Knapp, the principal investigator for GO-LoW at the MIT Haystack Observatory. \"GO-LoW will allow humans to see the universe in a new light, opening up one of the very last frontiers in the electromagnetic spectrum.\"The difficulty in viewing the low-frequency radio sky comes from Earth's ionosphere, a layer of the atmosphere that contains charged particles that prevent very low-frequency radio waves from passing through. Therefore, a space-based instrument is required to observe these wavelengths. Another challenge is that long-wavelength observations require correspondingly large telescopes, which would need to be many kilometers in length if built using traditional dish antenna designs. GO-LoW will use interferometry — a technique that combines signals from many spatially separated receivers that, when put together, will function as one large telescope — to obtain highly detailed data from exoplanets and other sources in space. A similar technique was used to make the first image of a black hole and, more recently, an image of the first known extrasolar radiation belts.Melodie Kao, a member of the team from Lowell Observatory, says the data could reveal details about an exoplanet's makeup and potential for life. \"[The radio wave aurora around an exoplanet] carries important information, such as whether or not the planet has a magnetic field, how strong it is, how fast the planet is rotating, and even hints about what's inside,\" she says. \"Studying exoplanet radio aurorae and the magnetic fields that they trace is an important piece of the habitability puzzle, and it's a key science goal for GO-LoW.\"Several recent trends and technology developments will make GO-LoW possible in the near future, such as the declining cost of mass-produced small satellites, the rise of mega-constellations, and the return of large, high-capacity launch vehicles like NASA's Space Launch System. Go-LoW would be the first mega-constellation that uses interferometry for scientific purposes.The GO-LoW constellation will be built through several successive launches, each containing thousands of spacecraft. Once they reach low-Earth orbit, the spacecraft will be refueled before journeying on to their final destination — an Earth-sun Lagrange point where they will then be deployed. Lagrange points are regions in space where the gravitational forces of two large celestial bodies (like the sun and Earth) are in equilibrium, such that a spacecraft requires minimal fuel to maintain its position relative to the two larger bodies.  At this long distance from Earth (1 astronomical unit, or approximately 93 million miles), there will also be much less radio-frequency interference that would otherwise obscure GO-LoW’s sensitive measurements.\"GO-LoW will have a hierarchical architecture consisting of thousands of small listener nodes and a smaller number of larger communication and computation nodes (CCNs),\" says Kat Kononov, a team member from Lincoln Laboratory's Applied Space Systems Group, who has been working with MIT Haystack staff since 2020, with Knapp serving as her mentor during graduate school. A node refers to an individual small satellite within the constellation. \"The listener nodes are small, relatively simple 3U CubeSats — about the size of a loaf of bread — that collect data with their low-frequency antennas, store it in memory, and periodically send it to their communication and computation node via a radio link.\" In comparison, the CCNs are about the size of a mini-fridge.The CCN will keep track of the positions of the listener nodes in their neighborhood; collect and reduce the data from their respective listener nodes (around 100 of them); and then transmit that data back to Earth, where more intensive data processing can be performed.At full strength, with approximately 100,000 listener nodes, the GO-LoW constellation should be able to see exoplanets with magnetic fields in the solar neighborhood — within 5 to 10 parsecs — many for the very first time.The GO-LoW research team recently published the results of their findings from Phase I of the study, which identified a type of advanced antenna called a vector sensor as the best type for this application. In 2024, Lincoln Laboratory designed a compact deployable version of the sensor suitable for use in space.The team is now working on Phase II of the program, which is to build a multi-agent simulation of constellation operations.\"What we learned during the Phase I study is that the hard part for GO-LoW is not any specific technology … the hard part is the system: the system engineering and the autonomy to run the system,\" says Knapp. \"So, how do we build this constellation such that it's a tractable problem? That's what we’re exploring in this next part of the study.\"GO-LoW is one of many civil space programs at Lincoln Laboratory that aim to harness advanced technologies originally developed for national security to enable new space missions that support science and society. \"By adapting these capabilities to serve new stakeholders, the laboratory helps open novel frontiers of discovery while building resilient, cost-effective systems that benefit the nation and the world,\" says Laura Kennedy, who is the deputy lead of Lincoln Laboratory's Civil Space Systems and Technology Office.\"Like landing on the moon in 1969, or launching Hubble in the 1990s, GO-LoW is envisioned to let us see something we've never seen before and generate scientific breakthroughs,\" says Kononov.Go-LoW is a collaboration between Lincoln Laboratory, Haystack Observatory, and Lowell University, as well as Lenny Paritsky from LeafLabs and Jacob Turner from Cornell University.", "release_time": "2025-10-18", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/lincoln-laboratory-haystack-observatory-to-unveil-hidden-parts-galaxy-1017"}
{"category": "研究前沿", "title": "新型钠基固态电池实现室温至低温稳定运行", "short_summary": "科学家研发出高性能钠基固态电池，性能媲美锂电池且成本更低。", "detailed_summary": "科学家研发出高性能钠基固态电池，性能媲美锂电池且成本更低。\n(1) 研究团队开发出一种钠基固态电池，可在室温至零下低温环境中稳定运行，性能接近锂电池。\n(2) 关键技术是稳定了一种亚稳态结构的氢硼化钠，其离子电导率比文献报道值高出一个数量级。\n(3) 采用成熟的加热后快速冷却技术制备该材料，有利于未来规模化生产和工业应用。\n(4) 该电池设计采用了厚阴极，提高了电池的能量密度。\n(5) 此项研究为利用储量丰富、成本更低的钠替代稀缺的锂提供了可行路径。", "raw_content": "All-solid-state batteries offer a safer and more powerful way to run electric vehicles, power electronics, and store renewable energy from the grid. However, their key ingredient, lithium, is both costly and scarce, and mining it often causes serious environmental harm.  Sodium presents a much cheaper and more abundant alternative, and it is far less damaging to extract. Yet, sodium-based solid-state batteries have long struggled to match lithium's performance at typical temperatures. \"It's not a matter of sodium versus lithium. We need both. When we think about tomorrow's energy storage solutions, we should imagine the same gigafactory can produce products based on both lithium and sodium chemistries,\" said Y. Shirley Meng, Liew Family Professor in Molecular Engineering at the UChicago Pritzker School of Molecular Engineering (UChicago PME). \"This new research gets us closer to that ultimate goal while advancing basic science along the way.\" A new study from Meng's group, published in Joule, takes a major step toward solving that issue. The researchers developed a sodium-based solid-state battery that performs reliably from room temperature to below freezing, setting a new benchmark for the field. According to first author Sam Oh of the A*STAR Institute of Materials Research and Engineering in Singapore, who conducted the work while visiting Meng's Laboratory for Energy Storage and Conversion, the results bring sodium technology much closer to competing with lithium on electrochemical performance. The achievement also represents a fundamental advance in materials science. \"The breakthrough that we have is that we are actually stabilizing a metastable structure that has not been reported,\" Oh said. \"This metastable structure of sodium hydridoborate has a very high ionic conductivity, at least one order of magnitude higher than the one reported in the literature, and three to four orders of magnitude higher than the precursor itself.\" Established technique, new field  To create this structure, the researchers heated a metastable form of sodium hydridoborate until it began to crystallize, then cooled it rapidly to lock the structure in place. The method is well known in other areas of materials science but had not previously been used for solid electrolytes, Oh said. That practical familiarity could make it easier to transition the discovery from laboratory research to industrial production. \"Since this technique is established, we are better able to scale up in future,\" Oh said. \"If you are proposing something new or if there's a need to change or establish processes, then industry will be more reluctant to accept it.\" Pairing that metastable phase with a O3-type cathode that has been coated with a chloride-based solid electrolyte can create thick, high-areal-loading cathodes that puts this new design beyond previous sodium batteries. Unlike design strategies with a thin cathode, this thick cathode would pack less of the inactive materials and more cathode \"meat.\" \"The thicker the cathode is, the theoretical energy density of the battery -- the amount of energy being held within a specific area -- improves,\" Oh said. The current research advances sodium as a viable alternative for batteries, a vital step to combat the rarity and environmental damage of lithium. It's one of many steps ahead. \"It's still a long journey, but what we have done with this research will help open up this opportunity,\" Oh said.", "release_time": "2025-10-17", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251016223116.htm"}
{"category": "研究前沿", "title": "MIT研究颠覆认知：细胞分裂时基因组3D结构未完全消失", "short_summary": "MIT发现细胞分裂中基因调控微区结构得以保留，挑战传统生物学认知。", "detailed_summary": "MIT发现细胞分裂中基因调控微区结构得以保留，挑战传统生物学认知。\n(1) 传统观点认为细胞分裂（有丝分裂）时基因组会失去其控制基因表达的复杂3D结构，分裂完成后才逐渐恢复。\n(2) MIT团队利用高分辨率Region-Capture Micro-C技术发现，连接基因与调控元件的微小3D环状结构（微区室）在分裂过程中不仅存在，反而因染色体压缩而增强。\n(3) 这一发现解释了为何细胞分裂末期会出现短暂的基因转录高峰，并可能帮助细胞将基因调控“记忆”传递至下一代细胞。\n(4) 研究颠覆了将细胞分裂视为“白板”的旧有模型，为理解基因组结构与功能的关系提供了新视角。\n(5) 未来研究将探索细胞形状和大小变化如何影响此3D结构，以及细胞如何选择保留或移除这些微区室以精确控制基因表达。", "raw_content": "Before cells can divide, they first need to replicate all of their chromosomes, so that each of the daughter cells can receive a full set of genetic material. Until now, scientists had believed that as division occurs, the genome loses the distinctive 3D internal structure that it typically forms.Once division is complete, it was thought, the genome gradually regains that complex, globular structure, which plays an essential role in controlling which genes are turned on in a given cell.However, a new study from MIT shows that in fact, this picture is not fully accurate. Using a higher-resolution genome mapping technique, the research team discovered that small 3D loops connecting regulatory elements and genes persist in the genome during cell division, or mitosis.“This study really helps to clarify how we should think about mitosis. In the past, mitosis was thought of as a blank slate, with no transcription and no structure related to gene activity. And we now know that that’s not quite the case,” says Anders Sejr Hansen, an associate professor of biological engineering at MIT. “What we see is that there’s always structure. It never goes away.”The researchers also discovered that these regulatory loops appear to strengthen when chromosomes become more compact in preparation for cell division. This compaction brings genetic regulatory elements closer together and encourages them to stick together. This may help cells “remember” interactions present in one cell cycle and carry it to the next one.“The findings help to bridge the structure of the genome to its function in managing how genes are turned on and off, which has been an outstanding challenge in the field for decades,” says Viraat Goel PhD ’25, the lead author of the study.Hansen and Edward Banigan, a research scientist in MIT’s Institute for Medical Engineering and Science, are the senior authors of the paper, which appears today in Nature Structural and Molecular Biology. Leonid Mirny, a professor in MIT’s Institute for Medical Engineering and Science and the Department of Physics, and Gerd Blobel, a professor at the Perelman School of Medicine at the University of Pennsylvania, are also authors of the study.A surprising findingOver the past 20 years, scientists have discovered that inside the cell nucleus, DNA organizes itself into 3D loops. While many loops enable interactions between genes and regulatory regions that may be millions of base pairs away from each other, others are formed during cell division to compact chromosomes. Much of the mapping of these 3D structures has been done using a technique called Hi-C, originally developed by a team that included MIT researchers and was led by Job Dekker at the University of Massachusetts Chan Medical School. To perform Hi-C, researchers use enzymes to chop the genome into many small pieces and biochemically link pieces that are near each other in 3D space within the cell’s nucleus. They then determine the identities of the interacting pieces by sequencing them.However, that technique doesn’t have high enough resolution to pick out all specific interactions between genes and regulatory elements such as enhancers. Enhancers are short sequences of DNA that can help to activate the transcription of a gene by binding to the gene’s promoter — the site where transcription begins.In 2023, Hansen and others developed a new technique that allows them to analyze 3D genome structures with 100 to 1,000 times greater resolution than was previously possible. This technique, known as Region-Capture Micro-C (RC-MC), uses a different enzyme that cuts the genome into small fragments of similar size. It also focuses on a smaller segment of the genome, allowing for high-resolution 3-D mapping of a targeted genome region.Using this technique, the researchers were able to identify a new kind of genome structure that hadn’t been seen before, which they called “microcompartments.” These are tiny highly connected loops that form when enhancers and promoters located near each other stick together.In that paper, experiments revealed that these loops were not formed by the same mechanisms that form other genome structures, but the researchers were unable to determine exactly how they do form. In hopes of answering that question, the team set out to study cells as they undergo cell division. During mitosis, chromosomes become much more compact, so that they can be duplicated, sorted, and divvied up between two daughter cells. As this happens, larger genome structures called A/B compartments and topologically associating domains (TADs) disappear completely.The researchers believed that the microcompartments they had discovered would also disappear during mitosis. By tracking cells through the entire cell division process, they hoped to learn how the microcompartments appear after mitosis is completed.“During mitosis, it has been thought that almost all gene transcription is shut off. And before our paper, it was also thought that all 3D structure related to gene regulation was lost and replaced by compaction. It’s a complete reset every cell cycle,” Hansen says.However, to their surprise, the researchers found that microcompartments could still be seen during mitosis, and in fact they become more prominent as the cell goes through cell division.“We went into this study thinking, well, the one thing we know for sure is that there’s no regulatory structure in mitosis, and then we accidentally found structure in mitosis,” Hansen says.Using their technique, the researchers also confirmed that larger structures such as A/B compartments and TADs do disappear during mitosis, as had been seen before.“This study leverages the unprecedented genomic resolution of the RC-MC assay to reveal new and surprising aspects of mitotic chromatin organization, which we have overlooked in the past using traditional 3C-based assays. The authors reveal that, contrary to the well-described dramatic loss of TADs and compartmentalization during mitosis, fine-scale “microcompartments” — nested interactions between active regulatory elements — are maintained or even transiently strengthened,” says Effie Apostolou, an associate professor of molecular biology in medicine at Weill Cornell Medicine, who was not involved in the study.A spike in transcriptionThe findings may offer an explanation for a spike in gene transcription that usually occurs near the end of mitosis, the researchers say. Since the 1960s, it had been thought that transcription ceased completely during mitosis, but in 2016 and 2017, a few studies showed that cells undergo a brief spike of transcription, which is quickly suppressed until the cell finishes dividing.In their new study, the MIT team found that during mitosis, microcompartments are more likely to be found near the genes that spike during cell division. They also discovered that these loops appear to form as a result of the genome compaction that occurs during mitosis. This compaction brings enhancers and promoters closer together, allowing them to stick together to form microcompartments.Once formed, the loops that constitute microcompartments may activate gene transcription somewhat by accident, which is then shut off by the cell. When the cell finishes dividing, entering a state known as G1, many of these small loops become weaker or disappear.“It almost seems like this transcriptional spiking in mitosis is an undesirable accident that arises from generating a uniquely favorable environment for microcompartments to form during mitosis,” Hansen says. “Then, the cell quickly prunes and filters many of those loops out when it enters G1.”Because chromosome compaction can also be influenced by a cell’s size and shape, the researchers are now exploring how variations in those features affect the structure of the genome and in turn, gene regulation.“We are thinking about some natural biological settings where cells change shape and size, and whether we can perhaps explain some 3D genome changes that previously lack an explanation,” Hansen says. “Another key question is how does the cell then pick what are the microcompartments to keep and what are the microcompartments to remove when you enter G1, to ensure fidelity of gene expression?”The research was funded in part by the National Institutes of Health, a National Science Foundation CAREER Award, the Gene Regulation Observatory of the Broad Institute, a Pew-Steward Scholar Award for Cancer Research, the Mathers Foundation, the MIT Westaway Fund, the Bridge Project of the Koch Institute and Dana-Farber/Harvard Cancer Center, and the Koch Institute Support (core) Grant from the National Cancer Institute.", "release_time": "2025-10-17", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/surprising-discovery-scientists-find-tiny-loops-genomes-dividing-cells-1017"}
{"category": "政策计划", "title": "印尼动力煤参考价全面上调，分级细化至四级", "short_summary": "印尼10月下半月动力煤参考价全面上调，并细化分级至四个等级。", "detailed_summary": "印尼10月下半月动力煤参考价全面上调，并细化分级至四个等级。\n(1) 印尼能矿部发布2025年10月下半月动力煤参考价(HBA)，所有品种价格较上半月继续全面上调。\n(2) 具体价格调整：6322大卡煤价109.74美元/吨（涨2.6%），5300大卡煤价67.76美元/吨（涨4.5%），4100大卡煤价43.71美元/吨（涨1.4%），新增的3400大卡煤价33.92美元/吨（涨2.9%）。\n(3) 参考价分级由三级细化为四级，新增3200-3600大卡超低卡煤等级，为矿商应对成本上涨提供空间。\n(4) HBA价格发布频率自2025年3月起调整为每月1日和15日各发布一次，采用新的计算公式。", "raw_content": "10月15日，印尼能源与矿产资源部(Energy and Mineral Resources Ministry)发布2025年10月下半月印尼动力煤参考价(HBA)，各品种煤价格较10月上半月价格继续全面上调。 其中，中卡和超低卡煤价格较上期上调幅度较大。根据印尼能矿部，10月下半月所有品种煤分级及参考价具体如下： HBA：高位6322大卡(全水12.26%，全硫0.66%，灰分7.94%)动力煤参考价109.74美元/吨，较上期上调2.8美元/吨，涨幅2.6%，作为发热量6100-6500大卡动力煤参考价。 HBA I：高位5300大卡(全水21.32%，全硫0.75%，灰分6.04%)动力煤参考价67.76美元/吨，较上期上调2.92美元/吨，涨幅4.5%，作为发热量5100-5500大卡动力煤参考价。 HBA II：高位4100大卡(全水35.73%，全硫0.23%，灰分3.90%)动力煤参考价为43.71美元/吨，较上期上调0.59美元/吨，涨幅1.4%，作为发热量3900-4300大卡动力煤参考价。 HBA III：高位3400大卡(全水44.3%，全硫0.24%，灰分3.88%)动力煤参考价为33.92美元/吨，较前一月上调0.97美元/吨，涨幅2.9%，作为发热量3200-3600大卡动力煤参考价。   此前，印尼能矿部自2023年3月份调整的参考价共分三级，用于发热量分别为6200-6400大卡、5200-6000大卡和4100-4300大卡的动力煤参考价。 而在当年8月份最新调整的参考价中，对煤炭发热量的等级区间划分由之前的三级进一步细化为四级，并纳入发热量3200-3600大卡超低卡煤等级参考价。再次调整动力煤参考价分级，为矿商提供了更多空间来适应采矿权税上调导致的生产成本上涨。 在印尼能源与矿产资源部批准了与印尼动力煤参考价(HBA)相挂钩的煤炭出口新规后，已经于2025年3月1日生效，HBA价格由此前的每个月发布一次调整为两次，分别为每月1日和15日发布。 印尼能矿部表示，根据最新调整的参考价公式，每月1日发布的参考价通过两月前第四周至前月第一周价格(占70%)以及两月前第二、三周(30%)来确定;每月15日发布的参考价则通过前月第二、三周(70%)以及两月前第四周至前月第一周(30%)来确定。", "release_time": "2025-10-17", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1195014-1.html"}
{"category": "研究前沿", "title": "MIT研发可重构服装设计系统Refashion", "short_summary": "Refashion软件将服装模块化设计，支持衣物重构以减少时尚浪费。", "detailed_summary": "Refashion软件将服装模块化设计，支持衣物重构以减少时尚浪费。\n（1）MIT与Adobe联合开发Refashion软件系统，将服装设计分解为可重构模块；\n（2）用户可通过绘制形状快速设计可转换服装，如裤子变裙子或孕妇装适配不同阶段；\n（3）系统提供图案编辑器和连接方式（按扣、魔术贴等），支持30分钟内快速原型制作；\n（4）具备3D试穿模拟功能，可适配不同体型，并自动生成组装示意图；\n（5）该技术旨在减少每年9200万吨纺织浪费，推动可持续时尚发展。", "raw_content": "It’s hard to keep up with the ever-changing trends of the fashion world. What’s “in” one minute is often out of style the next season, potentially causing you to re-evaluate your wardrobe.Staying current with the latest fashion styles can be wasteful and expensive, though. Roughly 92 million tons of textile waste are produced annually, including the clothes we discard when they go out of style or no longer fit. But what if we could simply reassemble our clothes into whatever outfits we wanted, adapting to trends and the ways our bodies change?A team of researchers at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) and Adobe are attempting to bring eco-friendly, versatile garments to life. Their new “Refashion” software system breaks down fashion design into modules — essentially, smaller building blocks — by allowing users to draw, plan, and visualize each element of a clothing item. The tool turns fashion ideas into a blueprint that outlines how to assemble each component into reconfigurable clothing, such as a pair of pants that can be transformed into a dress.With Refashion, users simply draw shapes and place them together to develop an outline for adaptable fashion pieces. It’s a visual diagram that shows how to cut garments, providing a straightforward way to design things like a shirt with an attachable hood for rainy days. One could also create a skirt that can then be reconfigured into a dress for a formal dinner, or maternity wear that fits during different stages of pregnancy.“We wanted to create garments that consider reuse from the start,” says Rebecca Lin, MIT Department of Electrical Engineering and Computer Science (EECS) PhD student, CSAIL and Media Lab researcher, and lead author on a paper presenting the project. “Most clothes you buy today are static, and are discarded when you no longer want them. Refashion instead makes the most of our garments by helping us design items that can be easily resized, repaired, or restyled into different outfits.”Modules à la modeThe researchers conducted a preliminary user study where both designers and novices explored Refashion and were able to create garment prototypes. Participants assembled pieces such as an asymmetric top that could be extended into a jumpsuit, or remade into a formal dress, often within 30 minutes. These results suggest that Refashion has the potential to make prototyping garments more approachable and efficient. But what features might contribute to this ease of use?Its interface first presents a simple grid in its “Pattern Editor” mode, where users can connect dots to outline the boundaries of a clothing item. It’s essentially drawing rectangular panels and specifying how different modules will connect to each other.Users can customize the shape of each component, create a straight design for garments (which might be useful for less form-fitting items, like chinos) or perhaps tinkering with one of Refashion’s templates. A user can edit pre-designed blueprints for things like a T-shirt, fitted blouse, or trousers.Another, more creative route is to change the design of individual modules. One can choose the “pleat” feature to fold a garment over itself, similar to an accordion, for starters. It’s a useful way to design something like a maxi dress. The “gather” option adds an artsy flourish, where a garment is crumpled together to create puffy skirts or sleeves. A user might even go with the “dart” module, which removes a triangular piece from the fabric. It allows for shaping a garment at the waist (perhaps for a pencil skirt) or tailor to the upper body (fitted shirts, for instance).While it might seem that each of these components needs to be sewn together, Refashion enables users to connect garments through more flexible, efficient means. Edges can be seamed together via double-sided connectors such as metal snaps (like the buttons used to close a denim jacket) or Velcro dots. A user could also fasten them in pins called brads, which have a pointed side that they stick through a hole and split into two “legs” to attach to another surface; it’s a handy way to secure, say, a picture on a poster board. Both connective methods make it easy to reconfigure modules, should they be damaged or a “fit check” calls for a new look.As a user designs their clothing piece, the system automatically creates a simplified diagram of how it can be assembled. The pattern is divided into numbered blocks, which is dragged onto different parts of a 2D mannequin to specify the position of each component. The user can then simulate how their sustainable clothing will look on 3D models of a range of body types (one can also upload a model).Finally, a digital blueprint for sustainable clothing can extend, shorten, or combine with other pieces. Thanks to Refashion, a new piece could be emblematic of a potential shift in fashion: Instead of buying new clothes every time we want a new outfit, we can simply reconfigure existing ones. Yesterday’s scarf could be today’s hat, and today’s T-shirt could be tomorrow’s jacket.“Rebecca’s work is at an exciting intersection between computation and art, craft, and design,” says MIT EECS professor and CSAIL principal investigator Erik Demaine, who advises Lin. “I’m excited to see how Refashion can make custom fashion design accessible to the wearer, while also making clothes more reusable and sustainable.”Constant changeWhile Refashion presents a greener vision for the future of fashion, the researchers note that they’re actively improving the system. They intend to revise the interface to support more durable items, stepping beyond standard prototyping fabrics. Refashion may soon support other modules, like curved panels, as well. The CSAIL-Adobe team may also evaluate whether their system can use as few materials as possible to minimize waste, and whether it can help “remix” old store-bought outfits.Lin also plans to develop new computational tools that help designers create unique, personalized outfits using colors and textures. She’s exploring how to design clothing by patchwork — essentially, cutting out small pieces from materials like decorative fabrics, recycled denim, and crochet blocks and assembling them into a larger item.“This is a great example of how computer-aided design can also be key in supporting more sustainable practices in the fashion industry,” says Adrien Bousseau, a senior researcher at Inria Centre at Université Côte d'Azur who wasn’t involved in the paper. “By promoting garment alteration from the ground up, they developed a novel design interface and accompanying optimization algorithm that helps designers create garments that can undergo a longer lifetime through reconfiguration. While sustainability often imposes additional constraints on industrial production, I am confident that research like the one by Lin and her colleagues will empower designers in innovating despite these constraints.”Lin wrote the paper with Adobe Research scientists Michal Lukáč and Mackenzie Leake, who is the paper’s senior author and a former CSAIL postdoc. Their work was supported, in part, by the MIT Morningside Academy for Design, an MIT MAKE Design-2-Making Mini-Grant, and the Natural Sciences and Engineering Research Council of Canada. The researchers presented their work recently at the ACM Symposium on User Interface Software and Technology.", "release_time": "2025-10-18", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/refashion-software-designs-eco-friendly-clothing-that-can-reassemble-new-items-1017"}
{"category": "产业应用", "title": "通用原子获美海军合同开发新一代舰载协作战机", "short_summary": "通用原子将为美海军设计模块化协作战机，提升航母舰队作战能力与灵活性。", "detailed_summary": "通用原子将为美海军设计模块化协作战机，提升航母舰队作战能力与灵活性。\n（1）美国通用原子航空系统公司（GA-ASI）获得美国海军合同，负责开发协作作战飞机（CCA）的概念设计。\n（2）CCA是半自主喷气式战斗机，旨在补充和增强有人驾驶战机，具备高产量、低成本、可转移风险等特点。\n（3）设计强调模块化方法，可快速重新配置和升级，以适应不断变化的航母任务需求。\n（4）此合同遵循GA-ASI为美国空军设计首架CCA（YFQ-42A）的成功经验，该公司在无人作战飞机领域拥有超过17年经验。\n（5）项目目标是实现有人/无人平台无缝协同，支持4代、5代机并补充6代机，最大化作战灵活性、成本效益和任务效能。", "raw_content": "SAN DIEGO – 17 October 2025 – General Atomics Aeronautical Systems, Inc. (GA-ASI) has been contracted by the U.S. Navy to develop conceptual designs for a Collaborative Combat Aircraft (CCA) to support the carrier air wing of tomorrow. GA-ASI was selected to work on Navy CCA designs emphasizing a modular approach to platform selection, capable of being rapidly reconfigured and upgraded to meet changing mission requirements, including operations on and from aircraft carriers. GA-ASI's approach supports the Navy's revolutionary acquisition strategy of smaller, frequent purchases that enable rapid technology insertion rather than traditional long-lifecycle programs GA-ASI’s Navy CCA contract follows its selection to design and fly the U.S. Air Force’s first CCA, the YFQ-42A. A production-representative unmanned fighter, YFQ-42A was the first Air Force CCA to begin flight testing in August, another historic achievement for the company. “We’re honored by the vote of confidence from the U.S. Navy and we’re eager to put what we’ve built to work for the future fleet,” said GA-ASI President David R. Alexander. “No one has more experience than we do with unmanned combat aircraft and we’re leveraging that to help the Navy get this capability onto the flight deck fast.” CCAs are highly capable, semi-autonomous jet fighters that complement and enhance traditional, human-piloted combat aircraft. Produced in high quantities at comparatively low cost, they let commanders shift risk away from human flight crews, enhance the sensing and other capabilities of legacy aircraft formations, increase lethality of the air wing, and maximize operational flexibility across the board. GA-ASI has configured all its unmanned combat air vehicles (UCAV) to be AMS-GRA compliant, including XQ-67A, YFQ-42A and MQ-20 Avenger®. GA-ASI rapidly reconfigured and upgraded its modular XQ-67A Off-Board Sensing Station, an autonomous-capable unmanned jet built under contract from the Air Force Research Laboratory that achieved first flight in 2024. GA-ASI has pioneered unmanned jet operations for more than 17 years, beginning with the MQ-20 Avenger in 2008, and has extensive experience working with the U.S. Navy and other nations on carrier-based unmanned aircraft operations. The Navy’s CCA design will emphasize seamless coordination among manned fighters, uncrewed vehicles and support platforms; accommodate elevated risk profiles and reduce risk to crewed platforms; support and enhance 4th- and 5th-generation aircraft and complement 6th-generation aircraft; and maximize operational flexibility, cost efficiency and mission effectiveness. At the UK’s Farnborough Air Show in 2024, GA-ASI announced its company-developed concept for ship-based CCA operations, codenamed Gambit 5. GA-ASI’s Gambit Series envisions multiple CCA variants rapidly reconfigured from a common Gambit Core, enabling substantial commonality for rapid and affordable production at scale. GA-ASI has recorded numerous recent aviation milestones with its aircraft at sea. In 2023, the short takeoff and landing demonstrator known as Mojave launched from and landed aboard the British aircraft carrier HMS Prince of Wales. In 2024, Mojave took off from the South Korean amphibious assault ship Dokdo and flew to a naval base ashore. GA-ASI has developed more than two dozen different types of unmanned aircraft and delivered more than 1,200 units to customers, building more than 100 aircraft per year at its 5 million-square-foot manufacturing facility in Poway, Calif. GA-ASI aircraft have amassed 9 million total flight hours and more than 50 GA-ASI aircraft are aloft around the world every minute of every day. About GA-ASI General Atomics Aeronautical Systems, Inc., is the world’s foremost builder of Unmanned Aircraft Systems (UAS). Logging more than 9 million flight hours, the Predator® line of UAS has flown for over 30 years and includes MQ-9A Reaper®, MQ-1C Gray Eagle®, MQ-20 Avenger®, and MQ-9B SkyGuardian®/SeaGuardian®. The company is dedicated to providing long-endurance, multi-mission solutions that deliver persistent situational awareness and rapid strike. For more information, visit www.ga-asi.com      Avenger, EagleEye, Gray Eagle, Lynx, Predator, Reaper, SeaGuardian, and SkyGuardian are trademarks of General Atomics Aeronautical Systems, Inc. registered in the United States and/or other countries. Distribution Statement A: NAVAIR SPR 2025-0587 is approved for public release; distribution is unlimited", "release_time": "2025-10-18", "source_institution": "通用原子能公司", "url": "http://www.ga.com/ga-asi-selected-to-support-us-navy-cca-design-effort"}
{"category": "产业应用", "title": "美荷签署协议合作开发新型小型无人机系统", "short_summary": "美国通用原子公司与荷兰国防部合作开发低成本多用途小型无人机，强化欧洲防御。", "detailed_summary": "美国通用原子公司与荷兰国防部合作开发低成本多用途小型无人机，强化欧洲防御。\n(1)美国通用原子航空系统公司与荷兰国防部签署协议，合作开发创新型防御能力。\n(2)合作首先聚焦于开发一款低成本、可搭载多种有效载荷的小型无人机系统，用于情报、监视和侦察。\n(3)该项目旨在建立无人机生产能力，是支持乌克兰和北约防御的战略性跨大西洋合作。\n(4)荷兰VDL Defentec公司被选为新型小型无人机的合同制造商。\n(5)新飞机预计在今年年底前首飞，2026年在美国和荷兰开始初始低速率生产。", "raw_content": "WASHINGTON – 16 October 2025 – On October 16, General Atomics Aeronautical Systems, Inc. (GA-ASI) and the Dutch Ministry of Defence (MoD) signed an agreement to develop innovative defense capabilities starting with a small unmanned aircraft system (SUAS) designed to provide multi-role intelligence, surveillance, and reconnaissance (ISR) capabilities. The new platform will be low cost and able to host a variety of operationally relevant payloads and capabilities. The partnership envisions implementing a business model that will enable the platform to scale up to high-volume production to meet demand. “This contract is the first step in a strategic partnership with the Dutch MoD that will ultimately contribute to the defense of Ukraine and NATO by creating a versatile European defense system,” said GA-ASI CEO Linden Blue. GA-ASI is the world leader in UAS products and capabilities. The company is building on its established relationship with the Netherlands to create an urgently needed partnership to help defend Europe. As part of the first phase of the contract, the Dutch MOD will collaborate with GA-ASI to establish UAS manufacturing capability. Minister for Arms Procurement and Personnel Gijs Tuinman mentioned that this partnership is important: “Together with GA we will be increasing innovative SUAS capabilities and advancing technical knowhow in the Netherlands. This project is an example of strategic trans-Atlantic collaboration that supports our defense and technological base as we contribute to the defense of Ukraine and NATO by creating a versatile European defense system and working with a strong U.S. partner.” VDL Defentec has been selected by GA-ASI to provide contract manufacturing of the new SUAS. VDL Defentec is based in the Netherlands and specializes in the development, engineering, subcontracting and production of military and special-purpose vehicles and other platforms. GA-ASI will work closely with VDL and provide detailed knowledge about the design, manufacture, logistics, and support of the new SUAS. “We are excited having been selected by General Atomics and we are proud to support Dutch MOD to create, together with GA-ASI, this unique capability for the Netherlands making our country and our allies more resilient,” said Paul Malcontent, managing director of VDL Defentec. The new aircraft is expected to fly before the end of this year with low-rate initial production expected to commence in 2026 in both the U.S. and the Netherlands. Media ContactJ.I.C.J. Post, Spokesperson for the Minister of Arms Procurement and PersonnelT: +31623859300,JICJ.Post@mindef.nl, www.defensie.nl About GA-ASI General Atomics Aeronautical Systems, Inc., is the world’s foremost builder of Unmanned Aircraft Systems (UAS). Logging more than 9 million flight hours, the Predator® line of UAS has flown for over 30 years and includes MQ-9A Reaper®, MQ-1C Gray Eagle®, MQ-20 Avenger®, and MQ-9B SkyGuardian®/SeaGuardian®. The company is dedicated to providing long-endurance, multi-mission solutions that deliver persistent situational awareness and rapid strike. For more information, visit www.ga-asi.com      Avenger, EagleEye, Gray Eagle, Lynx, Predator, Reaper, SeaGuardian, and SkyGuardian are trademarks of General Atomics Aeronautical Systems, Inc., registered in the United States and/or other countries.", "release_time": "2025-10-17", "source_institution": "通用原子能公司", "url": "http://www.ga.com/ga-asi-and-dutch-ministry-of-defense-sign-agreement-to-develop-new-defense-capabilities"}
{"category": "研究前沿", "title": "MIT新法提升AI个性化对象定位能力", "short_summary": "MIT研究改进视觉语言模型，通过视频数据训练提升个性化对象识别准确率。", "detailed_summary": "MIT研究改进视觉语言模型，通过视频数据训练提升个性化对象识别准确率。\n（1）MIT与MIT-IBM Watson AI Lab研究人员提出新训练方法，解决视觉语言模型难以定位个性化对象（如特定宠物）的问题；\n（2）方法利用视频跟踪数据，通过多帧图像中的上下文线索训练模型，并使用伪名称防止模型依赖预训练知识作弊；\n（3）实验显示，该方法使模型在个性化对象定位任务中的准确率平均提升12%，使用伪名称时提升达21%；\n（4）该技术可应用于对象跟踪、生态监测及辅助视觉障碍用户等领域，增强AI的上下文学习能力。", "raw_content": "Say a person takes their French Bulldog, Bowser, to the dog park. Identifying Bowser as he plays among the other canines is easy for the dog-owner to do while onsite.But if someone wants to use a generative AI model like GPT-5 to monitor their pet while they are at work, the model could fail at this basic task. Vision-language models like GPT-5 often excel at recognizing general objects, like a dog, but they perform poorly at locating personalized objects, like Bowser the French Bulldog.    To address this shortcoming, researchers from MIT and the MIT-IBM Watson AI Lab have introduced a new training method that teaches vision-language models to localize personalized objects in a scene.Their method uses carefully prepared video-tracking data in which the same object is tracked across multiple frames. They designed the dataset so the model must focus on contextual clues to identify the personalized object, rather than relying on knowledge it previously memorized.When given a few example images showing a personalized object, like someone’s pet, the retrained model is better able to identify the location of that same pet in a new image.Models retrained with their method outperformed state-of-the-art systems at this task. Importantly, their technique leaves the rest of the model’s general abilities intact.This new approach could help future AI systems track specific objects across time, like a child’s backpack, or localize objects of interest, such as a species of animal in ecological monitoring. It could also aid in the development of AI-driven assistive technologies that help visually impaired users find certain items in a room.“Ultimately, we want these models to be able to learn from context, just like humans do. If a model can do this well, rather than retraining it for each new task, we could just provide a few examples and it would infer how to perform the task from that context. This is a very powerful ability,” says Jehanzeb Mirza, an MIT postdoc and senior author of a paper on this technique.Mirza is joined on the paper by co-lead authors Sivan Doveh, a graduate student at Weizmann Institute of Science; and Nimrod Shabtay, a researcher at IBM Research; James Glass, a senior research scientist and the head of the Spoken Language Systems Group in the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL); and others. The work will be presented at the International Conference on Computer Vision.An unexpected shortcomingResearchers have found that large language models (LLMs) can excel at learning from context. If they feed an LLM a few examples of a task, like addition problems, it can learn to answer new addition problems based on the context that has been provided.A vision-language model (VLM) is essentially an LLM with a visual component connected to it, so the MIT researchers thought it would inherit the LLM’s in-context learning capabilities. But this is not the case.“The research community has not been able to find a black-and-white answer to this particular problem yet. The bottleneck could arise from the fact that some visual information is lost in the process of merging the two components together, but we just don’t know,” Mirza says.The researchers set out to improve VLMs abilities to do in-context localization, which involves finding a specific object in a new image. They focused on the data used to retrain existing VLMs for a new task, a process called fine-tuning.Typical fine-tuning data are gathered from random sources and depict collections of everyday objects. One image might contain cars parked on a street, while another includes a bouquet of flowers.“There is no real coherence in these data, so the model never learns to recognize the same object in multiple images,” he says.To fix this problem, the researchers developed a new dataset by curating samples from existing video-tracking data. These data are video clips showing the same object moving through a scene, like a tiger walking across a grassland.They cut frames from these videos and structured the dataset so each input would consist of multiple images showing the same object in different contexts, with example questions and answers about its location.“By using multiple images of the same object in different contexts, we encourage the model to consistently localize that object of interest by focusing on the context,” Mirza explains.Forcing the focusBut the researchers found that VLMs tend to cheat. Instead of answering based on context clues, they will identify the object using knowledge gained during pretraining.For instance, since the model already learned that an image of a tiger and the label “tiger” are correlated, it could identify the tiger crossing the grassland based on this pretrained knowledge, instead of inferring from context.To solve this problem, the researchers used pseudo-names rather than actual object category names in the dataset. In this case, they changed the name of the tiger to “Charlie.”“It took us a while to figure out how to prevent the model from cheating. But we changed the game for the model. The model does not know that ‘Charlie’ can be a tiger, so it is forced to look at the context,” he says.The researchers also faced challenges in finding the best way to prepare the data. If the frames are too close together, the background would not change enough to provide data diversity.In the end, finetuning VLMs with this new dataset improved accuracy at personalized localization by about 12 percent on average. When they included the dataset with pseudo-names, the performance gains reached 21 percent.As model size increases, their technique leads to greater performance gains.In the future, the researchers want to study possible reasons VLMs don’t inherit in-context learning capabilities from their base LLMs. In addition, they plan to explore additional mechanisms to improve the performance of a VLM without the need to retrain it with new data.“This work reframes few-shot personalized object localization — adapting on the fly to the same object across new scenes — as an instruction-tuning problem and uses video-tracking sequences to teach VLMs to localize based on visual context rather than class priors. It also introduces the first benchmark for this setting with solid gains across open and proprietary VLMs. Given the immense significance of quick, instance-specific grounding — often without finetuning — for users of real-world workflows (such as robotics, augmented reality assistants, creative tools, etc.), the practical, data-centric recipe offered by this work can help enhance the widespread adoption of vision-language foundation models,” says Saurav Jha, a postdoc at the Mila-Quebec Artificial Intelligence Institute, who was not involved with this work.Additional co-authors are Wei Lin, a research associate at Johannes Kepler University; Eli Schwartz, a research scientist at IBM Research; Hilde Kuehne, professor of computer science at Tuebingen AI Center and an affiliated professor at the MIT-IBM Watson AI Lab; Raja Giryes, an associate professor at Tel Aviv University; Rogerio Feris, a principal scientist and manager at the MIT-IBM Watson AI Lab; Leonid Karlinsky, a principal research scientist at IBM Research; Assaf Arbelle, a senior research scientist at IBM Research; and Shimon Ullman, the Samy and Ruth Cohn Professor of Computer Science at the Weizmann Institute of Science.This research was funded, in part, by the MIT-IBM Watson AI Lab.", "release_time": "2025-10-16", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/method-teaches-generative-ai-models-locate-personalized-objects-1016"}
{"category": "研究前沿", "title": "国际协作推进聚变能诊断技术研究", "short_summary": "美日欧合作开发聚变诊断系统，助力未来聚变电站性能优化。", "detailed_summary": "美日欧合作开发聚变诊断系统，助力未来聚变电站性能优化。\n（1）通用原子公司与日本量子科技机构、欧洲聚变能组织合作，为日本JT-60SA托卡马克提供先进诊断系统；\n（2）该系统采用快离子D-alpha诊断技术，通过光谱分析测量高能离子在等离子体中的运动规律；\n（3）研究旨在解决聚变反应中高能离子引发的不稳定性问题，提升反应堆效率和性能；\n（4）成果将验证计算机模型，为设计下一代商用聚变电站提供关键数据支撑；\n（5）此次合作是JT-60SA首次接纳日欧以外机构的贡献，加速聚变能商业化进程。", "raw_content": "Collaboration aims to boost efficiency and advance fusion power plant performance SAN DIEGO (Oct. 16, 2025)—Researchers at General Atomics (GA) are lending their expertise to address one of fusion energy’s greatest challenges: sustaining the fuel that powers fusion reactions. GA is collaborating with Japan’s National Institutes for Quantum Science and Technology (QST) and the European Union’s Fusion for Energy (F4E) to deliver a state-of-the-art diagnostic system to the world’s largest superconducting tokamak JT-60SA in Naka, Japan. This is among the first contributions to JT-60SA from an institution outside of Japan and Europe. The new diagnostic will measure how high-energy ions—particles that heat and sustain fusion plasma—move and interact inside a reactor, helping scientists design future commercial fusion power plants. “Fusion has the potential to transform the global energy landscape with a safe, sustainable, and virtually limitless power source,” said Dr. Wayne Solomon, vice president of Magnetic Fusion Energy for the General Atomics Energy Group. “By delivering this advanced diagnostic system to JT-60SA, this collaboration will enable researchers to gain deeper insights that will be essential for optimizing performance in next generation fusion power systems.” Fusion, the same process that powers the sun, requires heating plasma, a superheated gas, to more than 100 million degrees. In tokamaks, high-energy particles called fast ions are created by powerful heating beams and by the fusion reactions themselves. These fast ions act as sparks to keep the reactions going. However, those same ions also trigger waves and instabilities that push them off course and reduce the efficiency and performance of the reactor. This international collaboration, established under the Broader Approach Agreement between the European Atomic Energy Community (Euratom) and Japan, includes activities designed to complement the ITER project, the world’s largest fusion experiment, and accelerate the development of fusion. Fusion for Energy (F4E)—the European Union organization responsible for managing Europe’s contribution to ITER, oversees Euratom’s share. Japan’s contribution is implemented by the National Institutes for Quantum and Radiological Science and Technology (QST), a national research institution established in April 2016 to advance quantum science and technology in an integrated and coordinated manner. The project will utilize General Atomics’ Fast-Ion D-alpha (FIDA) diagnostics, a venture funded by the Department of Energy Fusion Energy Science program, to deliver high-resolution measurements of the fast ions’ behavior in JT-60SA’s plasma. By detecting subtle spectroscopic “fingerprints” produced when fast ions collide with a beam of neutral atoms, the system can map their location, speed, and response to plasma waves. These measurements are directly compared with computer models, allowing researchers to validate simulations and identify instabilities that could affect reactor performance. Paired with advanced analysis codes, the diagnostic will effectively transform JT-60SA into a “fast-ion observatory,” providing critical insight into how operating conditions influence fusion plasmas. The results will form a foundation for designing and controlling next-generation fusion reactors, ensuring both stability and efficiency in future power plants. “This work gives us the tools to move from best guesses to reliable prediction and controls,” said Christopher Muscatello, senior scientist for the Center for Advanced Diagnostics and Metrology at the General Atomics Energy Group. “By understanding how fast ions drive or respond to instabilities, we can design reactors that maximize performance, extend component lifetimes, and bring fusion energy closer to reality.” General Atomics is a global leader in fusion technology development and manufacturing. Based in San Diego, the company operates the DIII-D National Fusion Facility for the U.S. Department of Energy—the nation’s largest operating tokamak. GA scientists and engineers also collaborate worldwide to design integrated systems, advanced materials, and custom-built components essential for advancing fusion energy. About General Atomics Since the dawn of the atomic age, General Atomics innovations have advanced the state of the art across the full spectrum of science and technology – from nuclear energy and defense to medicine and high-performance computing. Behind a talented global team of scientists, engineers, and professionals, GA’s unique experience and capabilities continue to deliver safe, sustainable, economical, and innovative solutions to meet growing global demands. Media Contact:Andrew JamesCommunications LeadGeneral Atomics Energy Group andrew.james@ga.com", "release_time": "2025-10-16", "source_institution": "通用原子能公司", "url": "http://www.ga.com/ga-joins-international-effort-to-tackle-one-of-fusion-s-biggest-hurdles-and-unlock-the-secrets-of-fusion-s-hottest-particles"}
{"category": "研究前沿", "title": "新书《碳移除》解析大气二氧化碳清除路径", "short_summary": "专家新书系统阐述二氧化碳移除技术路径，评估其应对气候变化的潜力与挑战。", "detailed_summary": "专家新书系统阐述二氧化碳移除技术路径，评估其应对气候变化的潜力与挑战。\n(1) 新书《碳移除》由MIT和帝国理工学院专家撰写，聚焦于清除已存在于大气中的二氧化碳。\n(2) 阐述了从大气中移除二氧化碳的各种路径，包括直接空气捕获等工程系统和基于自然的植树、海洋增强等方法。\n(3) 提出了评估不同碳移除路径质量的五大关键指标：可计量性、持久性、成本、额外性以及许可与治理。\n(4) 指出目前尚无任何一种碳移除策略在所有评估指标上表现完美，强调其应作为减排努力的补充而非替代。\n(5) 旨在客观分析碳移除的机遇与挑战，推动该前沿领域从理论探讨向大规模部署发展。", "raw_content": "Two leading experts in the field of carbon capture and sequestration (CCS) — Howard J. Herzog, a senior research engineer in the MIT Energy Initiative, and Niall Mac Dowell, a professor in energy systems engineering at Imperial College London — explore methods for removing carbon dioxide already in the atmosphere in their new book, “Carbon Removal.” Published in October, the book is part of the Essential Knowledge series from the MIT Press, which consists of volumes “synthesizing specialized subject matter for nonspecialists” and includes Herzog’s 2018 book, “Carbon Capture.”Burning fossil fuels, as well as other human activities, cause the release of carbon dioxide (CO2) into the atmosphere, where it acts like a blanket that warms the Earth, resulting in climate change. Much attention has focused on mitigation technologies that reduce emissions, but in their book, Herzog and Mac Dowell have turned their attention to “carbon dioxide removal” (CDR), an approach that removes carbon already present in the atmosphere.In this new volume, the authors explain how CO2 naturally moves into and out of the atmosphere and present a brief history of carbon removal as a concept for dealing with climate change. They also describe the full range of “pathways” that have been proposed for removing CO2 from the atmosphere. Those pathways include engineered systems designed for “direct air capture” (DAC), as well as various “nature-based” approaches that call for planting trees or taking steps to enhance removal by biomass or the oceans. The book offers easily accessible explanations of the fundamental science and engineering behind each approach.The authors compare the “quality” of the different pathways based on the following metrics:Accounting. For public acceptance of any carbon-removal strategy, the authors note, the developers need to get the accounting right — and that’s not always easy. “If you’re going to spend money to get CO2 out of the atmosphere, you want to get paid for doing it,” notes Herzog. It can be tricky to measure how much you have removed, because there’s a lot of CO2 going in and out of the atmosphere all the time. Also, if your approach involves, say, burning fossil fuels, you must subtract the amount of CO2 that’s emitted from the total amount you claim to have removed. Then there’s the timing of the removal. With a DAC device, the removal happens right now, and the removed CO2 can be measured. “But if I plant a tree, it’s going to remove CO2 for decades. Is that equivalent to removing it right now?” Herzog queries. How to take that factor into account hasn’t yet been resolved.Permanence. Different approaches keep the CO2 out of the atmosphere for different durations of time. How long is long enough? As the authors explain, this is one of the biggest issues, especially with nature-based solutions, where events such as wildfires or pestilence or land-use changes can release the stored CO2 back into the atmosphere. How do we deal with that?Cost. Cost is another key factor. Using a DAC device to remove CO2 costs far more than planting trees, but it yields immediate removal of a measurable amount of CO2 that can then be locked away forever. How does one monetize that trade-off?Additionality. “You’re doing this project, but would what you’re doing have been done anyway?” asks Herzog. “Is your effort additional to business as usual?” This question comes into play with many of the nature-based approaches involving trees, soils, and so on.Permitting and governance. These issues are especially important — and complicated — with approaches that involve doing things in the ocean. In addition, Herzog points out that some CCS projects could also achieve carbon removal, but they would have a hard time getting permits to build the pipelines and other needed infrastructure.The authors conclude that none of the CDR strategies now being proposed is a clear winner on all the metrics. However, they stress that carbon removal has the potential to play an important role in meeting our climate change goals — not by replacing our emissions-reduction efforts, but rather by supplementing them. However, as Herzog and Mac Dowell make clear in their book, many challenges must be addressed to move CDR from today’s speculation to deployment at scale, and the book supports the wider discussion about how to move forward. Indeed, the authors have fulfilled their stated goal: “to provide an objective analysis of the opportunities and challenges for CDR and to separate myth from reality.”", "release_time": "2025-10-17", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/book-reviews-tech-aiming-to-remove-carbon-from-atmosphere-1016"}
{"category": "研究前沿", "title": "青岛能源所研发Chat-LCA，AI革新碳核算方法", "short_summary": "Chat-LCA融合大语言模型，实现碳核算全流程自动化，效率提升显著。", "detailed_summary": "Chat-LCA融合大语言模型，实现碳核算全流程自动化，效率提升显著。\n(1)青岛能源所提出Chat-LCA系统，融合大型语言模型解决传统生命周期评价方法效率低、依赖人工的瓶颈。\n(2)系统整合检索增强生成、Text2SQL等前沿AI技术，实现从知识问答到报告生成的全流程自动化碳核算。\n(3)经多行业验证，系统问答准确率BERTScore达0.85，报告生成准确率0.9832，可将数周分析任务压缩至数小时。\n(4)应用案例显示，系统能自动识别碳排放热点并提出减排建议，如锂硫电池原料获取阶段占排放47.2%。\n(5)研究成果发表于Journal of Cleaner Production，为“双碳”目标实现提供了可落地的技术支撑和决策工具。", "raw_content": "在“双碳”战略背景下，碳核算的效率与精度面临着更高的要求，传统生命周期评价（Life Cycle Assessment, LCA）方法因高度依赖人工、知识门槛高、流程割裂等痛点，已成为制约碳核算研究与规模化应用的关键瓶颈。为破解这一难题，青岛能源所泛能源大数据与战略研究中心创新性地提出了融合大型语言模型（LLM）的智能LCA解决方案——Chat-LCA。Chat-LCA系统实现了LLM在“知识获取—数据检索—报告生成”全链条的深度融合，显著提升了碳核算的智能化水平。该研究的原创性体现在首次将检索增强生成（RAG）、Text2SQL、思维链（CoT）与代码链（CoC）等前沿AI技术系统整合于LCA全流程，构建了支持自然语言交互的一体化碳核算智能系统。Chat-LCA有效打通了知识壁垒与数据孤岛，实现了从专业问答到报告生成的全流程自动化，突破了现有研究中技术覆盖片面、环节割裂的局限。经多行业、多场景验证，Chat-LCA展现出卓越的准确性与高效性。其问答模块在跨十大行业的专业问题中BERTScore达0.85，Text2SQL模块在真实LCI数据库上的执行准确率达0.9692，报告生成系统的填充准确率达0.9832，可读性评分8.42（满分10）。该系统可将传统耗时数周的LCA分析任务压缩至数小时完成，实现了碳核算效率的质的飞跃。此外，Chat-LCA具有显著的实际应用价值。以锂硫电池碳足迹评估为例，系统自动识别出原料获取（47.2%）与生产阶段（31.3%）为碳排放热点，并提出清洁能源替代等精准减排建议，为企业绿色决策提供了科学依据。该方案大幅降低了碳核算的技术门槛，拓展了LCA方法在工业、政策等多场景的适用性，为“双碳”目标的实现提供了可落地的技术支撑与决策工具。图1 研究方法设计与评价框架研究成果以“Intelligent Application of Large Language Model to Life Cycle Assessment Methodology”为题近期发表于Journal of Cleaner Production。研究由泛能源大数据与战略研究中心主任田亚峻研究员主持完成，工程师赵敬皓和硕士生张晓君等参加了研究，并获山东省自然科学基金、中国工程科技发展战略山东研究院咨询研究项目和天津市科技计划项目等项目支持。(文/图 赵敬皓)原文链接：https://www.sciencedirect.com/science/article/pii/S0959652625021262", "release_time": "2025-10-29", "source_institution": "青岛生物能源与过程研究所", "url": "https://qibebt.cas.cn/news/kyjz/202510/t20251016_7991294.html"}
{"category": "政策计划", "title": "IAEA推出通用路线图支持新兴国家核安全建设", "short_summary": "IAEA会议研讨通用路线图项目，助力新兴国家建立完善核安全基础设施。", "detailed_summary": "IAEA会议研讨通用路线图项目，助力新兴国家建立完善核安全基础设施。\n(1) IAEA召开通用路线图项目会议，支持新兴核能国家发展核安全基础设施；\n(2) 该项目于2020年启动，提供建立和维护国家核安全体系的实践指导；\n(3) 包含培训材料、同行评审服务和专题出版物，整合各国经验教训；\n(4) 会议讨论了从规划到运营各阶段安全基础设施的建立与整合；\n(5) 路线图设计灵活，适用于不同成熟度国家，促进国际监管实践统一。", "raw_content": "An IAEA meeting on the Generic RoadMap project, which supports nuclear newcomer countries in developing nuclear safety infrastructure, highlighted the critical role of capacity building in sustaining national safety infrastructure. “As countries look for ways to address their energy needs,  nuclear power is attracting increasing attention,” said Anna Bradford, Director of the IAEA Division of Nuclear Installation Safety. “New modalities and initiatives are needed to support efforts to strengthen the global nuclear safety regime.” The Generic RoadMap Launched in 2020, the Generic RoadMap (GRM) is part of the IAEA’s efforts to strengthen nuclear safety infrastructure. The GRM guides countries embarking on a nuclear power programme with practical information on how to establish and maintain a comprehensive national nuclear safety infrastructure. This includes practical guidance and information on implementing actions recommended in SSG-16 (Rev.1) to establish and maintain the safety infrastructure for an initial nuclear reactor while meeting all applicable safety requirements. The GRM is supported by training materials, peer review services and a series of topical publications that complement IAEA safety standards. These resources incorporate lessons learned, challenges identified and solutions implemented by countries that have embarked on or expanded nuclear programs. Establishing and Integrating Safety Infrastructure The draft GRM Safety Report, which provides guidance to member countries on meeting IAEA safety standards, was presented to global experts attending the event. The report takes a strategic approach that outlines priorities and associated tasks within a typical timeline from planning to operation. Discussions focused on how to establish and integrate safety infrastructure for a nuclear power plant programme, with presentations on all phases of nuclear reactor projects, from pre-planning to construction and operation.  Designed to be flexible and scalable, the report’s guidance addresses the needs of both embarking and expanding countries. Member countries with established safety infrastructure were encouraged to conduct a tailored gap analysis to ensure that safety measures are adapted according to their specific contexts. “The GRM can be utilized by Member States at various levels of ‘nuclear maturity’ and across different phases to establish or enhance their nuclear safety infrastructure,” said Idris Yau Usman, the meeting's  Co-chair and Chairman of the Nigerian Nuclear Regulatory Authority, adding that “it supports the integration of lessons learned, helps avoid common challenges and promotes the harmonization of international regulatory practices.”", "release_time": "2025-10-17", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/iaeas-generic-roadmap-supports-nuclear-safety-for-newcomer-countries"}
{"category": "研究前沿", "title": "奥本大学研发可调控电子材料，推动量子计算与催化革新", "short_summary": "新型电化物材料实现电子行为精确调控，为量子计算和高效催化开辟新路径。", "detailed_summary": "新型电化物材料实现电子行为精确调控，为量子计算和高效催化开辟新路径。\n（1）奥本大学团队开发出表面固定电化物新材料，通过将溶剂化电子前体附着于金刚石等稳定表面实现电子特性可调。\n（2）该材料能控制电子形成孤立\"岛屿\"用于量子比特或扩展\"海洋\"促进化学反应，突破传统电子束缚限制。\n（3）研究成果基于先进计算模型，解决了早期电化物不稳定和难以规模化的问题。\n（4）应用潜力包括开发强大量子计算机和新型催化剂，可能变革燃料、药品等生产方式。\n（5）这项基础研究获美国国家科学基金会支持，为未来计算和制造技术发展指明新方向。", "raw_content": "Picture a future where factories can create materials and chemical compounds more quickly, at lower cost, and with fewer production steps. Imagine your laptop processing complex data in seconds or a supercomputer learning and adapting as efficiently as the human brain. These possibilities depend on one fundamental factor: how electrons behave inside materials. Researchers at Auburn University have now developed a groundbreaking type of material that allows scientists to precisely control these tiny charged particles. Their findings, published in ACS Materials Letters, describe how the team achieved adjustable coupling between isolated-metal molecular complexes, called solvated electron precursors, where electrons are not tied to specific atoms but instead move freely within open spaces.  Electrons are central to nearly every chemical and technological process. They drive energy transfer, bonding, and electrical conductivity, serving as the foundation for both chemical synthesis and modern electronics. In chemical reactions, electrons enable redox processes, bond formation, and catalytic activity. In technology, managing how electrons move and interact underpins everything from electronic circuits and AI systems to solar cells and quantum computers. Typically, electrons are confined to atoms, which restricts their potential uses. However, in materials known as electrides, electrons move independently, opening the door to remarkable new capabilities. \"By learning how to control these free electrons, we can design materials that do things nature never intended,\" explains Dr. Evangelos Miliordos, Associate Professor of Chemistry at Auburn and senior author of the study, which was based on advanced computational modeling. To achieve this, the Auburn team created innovative material structures called Surface Immobilized Electrides by attaching solvated electron precursors to stable surfaces such as diamond and silicon carbide. This configuration makes the electronic characteristics of the electrides both durable and tunable. By changing how the molecules are arranged, electrons can either cluster into isolated \"islands\" that behave like quantum bits for advanced computing or spread into extended \"seas\" that promote complex chemical reactions. This versatility is what gives the discovery its transformative potential. One version could lead to the development of powerful quantum computers capable of solving problems beyond the reach of today's technology. Another could provide the basis for cutting-edge catalysts that speed up essential chemical reactions, potentially revolutionizing how fuels, pharmaceuticals, and industrial materials are produced. \"As our society pushes the limits of current technology, the demand for new kinds of materials is exploding,\" says Dr. Marcelo Kuroda, Associate Professor of Physics at Auburn. \"Our work shows a new path to materials that offer both opportunities for fundamental investigations on interactions in matter as well as practical applications.\" Earlier versions of electrides were unstable and difficult to scale. By depositing them directly on solid surfaces, the Auburn team has overcome these barriers, proposing a family of materials structures that could move from theoretical models to real-world devices. \"This is fundamental science, but it has very real implications,\" says Dr. Konstantin Klyukin, Assistant Professor of Materials Engineering at Auburn. \"We're talking about technologies that could change the way we compute and the way we manufacture.\" The theoretical study was led by faculty across chemistry, physics, and materials engineering at Auburn University. \"This is just the beginning,\" Miliordos adds. \"By learning how to tame free electrons, we can imagine a future with faster computers, smarter machines, and new technologies we haven't even dreamed of yet.\" The study, \"Electrides with Tunable Electron Delocalization for Applications in Quantum Computing and Catalysis,\" was also coauthored by graduate students Andrei Evdokimov and Valentina Nesterova. It was supported by the U.S. National Science Foundation and Auburn University computing resources.", "release_time": "2025-10-16", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251015230945.htm"}
{"category": "研究前沿", "title": "MIT开发量子材料商业化评估新框架", "short_summary": "MIT团队创建评估体系，结合量子特性与成本环境因素筛选实用材料。", "detailed_summary": "MIT团队创建评估体系，结合量子特性与成本环境因素筛选实用材料。\n(1) MIT研究人员开发出新框架，用于评估量子材料的规模化潜力。\n(2) 该框架首次将材料的量子行为（量子重量）与其成本、供应链韧性、环境足迹等实际因素结合分析。\n(3) 研究团队利用此框架评估了超过16,000种拓扑材料，发现量子性越高的材料往往也更昂贵、对环境更不友好。\n(4) 研究最终筛选出31种在量子功能性和可持续性之间达到最佳平衡的材料候选者，供进一步研究。\n(5) 该方法旨在引导量子材料研究走向更具商业可行性的方向，应用于下一代微电子、能源收集和医疗诊断等领域。", "raw_content": "People tend to think of quantum materials — whose properties arise from quantum mechanical effects — as exotic curiosities. But some quantum materials have become a ubiquitous part of our computer hard drives, TV screens, and medical devices. Still, the vast majority of quantum materials never accomplish much outside of the lab.What makes certain quantum materials commercial successes and others commercially irrelevant? If researchers knew, they could direct their efforts toward more promising materials — a big deal since they may spend years studying a single material.Now, MIT researchers have developed a system for evaluating the scale-up potential of quantum materials. Their framework combines a material’s quantum behavior with its cost, supply chain resilience, environmental footprint, and other factors. The researchers used their framework to evaluate over 16,000 materials, finding that the materials with the highest quantum fluctuation in the centers of their electrons also tend to be more expensive and environmentally damaging. The researchers also identified a set of materials that achieve a balance between quantum functionality and sustainability for further study.The team hopes their approach will help guide the development of more commercially viable quantum materials that could be used for next generation microelectronics, energy harvesting applications, medical diagnostics, and more.“People studying quantum materials are very focused on their properties and quantum mechanics,” says Mingda Li, associate professor of nuclear science and engineering and the senior author of the work. “For some reason, they have a natural resistance during fundamental materials research to thinking about the costs and other factors. Some told me they think those factors are too ‘soft’ or not related to science. But I think within 10 years, people will routinely be thinking about cost and environmental impact at every stage of development.”The paper appears in Materials Today. Joining Li on the paper are co-first authors and PhD students Artittaya Boonkird, Mouyang Cheng, and Abhijatmedhi Chotrattanapituk, along with PhD students Denisse Cordova Carrizales and Ryotaro Okabe; former graduate research assistants Thanh Nguyen and Nathan Drucker; postdoc Manasi Mandal; Instructor Ellan Spero of the Department of Materials Science and Engineering (DMSE); Professor Christine Ortiz of the Department of DMSE; Professor Liang Fu of the Department of Physics; Professor Tomas Palacios of the Department of Electrical Engineering and Computer Science (EECS); Associate Professor Farnaz Niroui of EECS; Assistant Professor Jingjie Yeo of Cornell University; and PhD student Vsevolod Belosevich and Assostant Professor Qiong Ma of Boston College.Materials with impactCheng and Boonkird say that materials science researchers often gravitate toward quantum materials with the most exotic quantum properties rather than the ones most likely to be used in products that change the world.“Researchers don’t always think about the costs or environmental impacts of the materials they study,” Cheng says. “But those factors can make them impossible to do anything with.”Li and his collaborators wanted to help researchers focus on quantum materials with more potential to be adopted by industry. For this study, they developed methods for evaluating factors like the materials’ price and environmental impact using their elements and common practices for mining and processing those elements. At the same time, they quantified the materials’ level of “quantumness” using an AI model created by the same group last year, based on a concept proposed by MIT professor of physics Liang Fu, termed quantum weight.“For a long time, it’s been unclear how to quantify the quantumness of a material,” Fu says. “Quantum weight is very useful for this purpose. Basically, the higher the quantum weight of a material, the more quantum it is.”The researchers focused on a class of quantum materials with exotic electronic properties known as topological materials, eventually assigning over 16,000 materials scores on environmental impact, price, import resilience, and more.For the first time, the researchers found a strong correlation between the material’s quantum weight and how expensive and environmentally damaging it is.“That’s useful information because the industry really wants something very low-cost,” Spero says. “We know what we should be looking for: high quantum weight, low-cost materials. Very few materials being developed meet that criteria, and that likely explains why they don’t scale to industry.”The researchers identified 200 environmentally sustainable materials and further refined the list down to 31 material candidates that achieved an optimal balance of quantum functionality and high-potential impact.The researchers also found that several widely studied materials exhibit high environmental impact scores, indicating they will be hard to scale sustainably. “Considering the scalability of manufacturing and environmental availability and impact is critical to ensuring practical adoption of these materials in emerging technologies,” says Niroui.Guiding researchMany of the topological materials evaluated in the paper have never been synthesized, which limited the accuracy of the study’s environmental and cost predictions. But the authors say the researchers are already working with companies to study some of the promising materials identified in the paper.“We talked with people at semiconductor companies that said some of these materials were really interesting to them, and our chemist collaborators also identified some materials they find really interesting through this work,” Palacios says. “Now we want to experimentally study these cheaper topological materials to understand their performance better.”“Solar cells have an efficiency limit of 34 percent, but many topological materials have a theoretical limit of 89 percent. Plus, you can harvest energy across all electromagnetic bands, including our body heat,” Fu says. “If we could reach those limits, you could easily charge your cell phone using body heat. These are performances that have been demonstrated in labs, but could never scale up. That’s the kind of thing we’re trying to push forward.\"This work was supported, in part, by the National Science Foundation and the U.S. Department of Energy.", "release_time": "2025-10-15", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/why-some-quantum-materials-stall-while-others-scale-1015"}
{"category": "产业应用", "title": "加州领跑核聚变产业，圣地亚哥成创新枢纽", "short_summary": "加州核聚变产业未来十年可创千亿经济价值，圣地亚哥凭借学术与产业合作驱动创新。", "detailed_summary": "加州核聚变产业未来十年可创千亿经济价值，圣地亚哥凭借学术与产业合作驱动创新。\n(1) 美国能源需求未来15年将增超50%，核聚变能源被视为实现能源独立的关键无限潜力来源。\n(2) 加州核聚变产业预计未来十年可产生超过1250亿美元经济影响并支持4.3万个就业岗位。\n(3) 圣地亚哥拥有世界级设施如加州大学圣地亚哥分校，正通过政策与投资巩固其全国聚变研究、工程和制造中心地位。\n(4) GA公司通过提供关键部件支持国家点火装置和ITER实验，并与高校合作成立数据中心加速AI创新。\n(5) 核聚变成为制造业、交通、人工智能等多领域创新催化剂，政府、学界与产业界协同构建未来。", "raw_content": "SAN DIEGO (Oct. 15, 2025) -- As U.S. energy demand is projected to rise more than 50% in the next 15 years, the nation faces a clear challenge: delivering reliable power while achieving true energy independence. Fusion, the same process that powers the sun, offers limitless potential to meet that need. The recent announcement by the San Diego Regional Economic Development Corporation (EDC) confirms what we’ve long known: California is leading the way in fusion energy. With the right mix of policy, investment, and commercialization, the state can turn fusion’s promise into reality—driving economic growth, creating high-skill jobs, and training the workforce of tomorrow. According to the report, available at fusionCA.org, California’s fusion industry could generate more than $125B in economic impact and support up to 43,000 jobs over the next decade. San Diego accounts for a major share of this industry, home to world-class facilities, pioneering research institutes, and a highly skilled workforce. Institutions like UC San Diego and San Diego State University have advanced fusion science for decades, while recent efforts by the City of San Diego and EDC are solidifying the region as a national hub for fusion research, engineering, and manufacturing. With new investment and strategic policy support, California, and San Diego, are poised to help cement America’s global leadership in sustainable energy. At GA, we are proud to have played an important role in advancing fusion on several fronts - from delivering precision target assemblies that have enabled the National Ignition Facility’s fusion breakthroughs to building the world’s most powerful pulsed superconducting magnet for the ITER experiment in France. More recently, we have collaborated with UC San Diego to launch the San Diego Fusion Data Science and Digital Engineering Center, uniting academia and industry to accelerate innovation through artificial intelligence and high-performance computing. Fusion is more than energy, it’s a catalyst for innovation in manufacturing, transportation, AI, and beyond. Here in San Diego, we’re building that future together, with our partners across government, academia, industry, and the national labs.", "release_time": "2025-10-16", "source_institution": "通用原子能公司", "url": "http://www.ga.com/report-california-s-fusion-industry-poised-to-generate-125-billion-and-43000-jobs"}
{"category": "研究前沿", "title": "MIT发现金属原子级化学模式新物理原理", "short_summary": "MIT揭示金属制造中原子非完全随机排列的新原理，为材料性能调控开辟新途径。", "detailed_summary": "MIT揭示金属制造中原子非完全随机排列的新原理，为材料性能调控开辟新途径。\n（1）MIT团队发现标准工业流程制造的金属中持续存在原子级化学排列模式；\n（2）通过大规模分子动力学模拟揭示位错缺陷会引导原子形成稳定非平衡态模式；\n（3）颠覆传统认为金属制造过程会使原子完全随机化的认知；\n（4）新发现的理论模型可预测模式形成，助力航空航天等领域的材料设计优化。", "raw_content": "For years, scientists have known that tiny chemical patterns can form inside metal alloys, but most assumed these patterns were insignificant or disappeared during manufacturing. Recent experiments have shown that in controlled lab conditions, such patterns can actually influence how metals behave -- affecting their strength, durability, heat resistance, and even how well they withstand radiation.  Researchers at MIT have now discovered that these subtle chemical arrangements also persist in metals made through standard industrial processes. The unexpected finding points to a new physical principle that explains why these patterns remain. In a study published in Nature Communications, the MIT team detailed how they identified and analyzed the patterns, uncovering the physics that drives them. They also developed a model that predicts how these patterns form, allowing engineers to potentially adjust them to fine-tune a metal's properties for use in aerospace, semiconductor, or nuclear applications. \"The conclusion is: You can never completely randomize the atoms in a metal. It doesn't matter how you process it,\" explains Rodrigo Freitas, the TDK Assistant Professor in the MIT Department of Materials Science and Engineering. \"This is the first paper showing these non-equilibrium states that are retained in the metal. Right now, this chemical order is not something we're controlling for or paying attention to when we manufacture metals.\" For Freitas, an early-career researcher, the discovery validates his decision to pursue a problem many others thought was already settled. He credits support from the U.S. Air Force Office of Scientific Research's Young Investigator Program and the collaborative effort of his team, which includes three MIT PhD students -- Mahmudul Islam, Yifan Cao, and Killian Sheriff -- as co-first authors. \"There was the question of whether I should even be tackling this specific problem because people have been working on it for a long time,\" Freitas says. \"But the more I learned about it, the more I saw researchers were thinking about this in idealized laboratory scenarios. We wanted to perform simulations that were as realistic as possible to reproduce these manufacturing processes with high fidelity. My favorite part of this project is how non-intuitive the findings are. The fact that you cannot completely mix something together, people didn't see that coming.\" From surprises to theories Freitas and his team began with a simple question: how quickly do elements mix during the processing of metals? Conventional thinking suggested that there comes a point where metals become completely uniform at the atomic level during manufacturing. Finding that point, they believed, could help design alloys with varying levels of short-range atomic order.  Using advanced machine-learning tools, the researchers simulated how millions of atoms moved and rearranged during metal processing. \"The first thing we did was to deform a piece of metal,\" Freitas explains. \"That's a common step during manufacturing: You roll the metal and deform it and heat it up again and deform it a little more, so it develops the structure you want. We did that and we tracked chemical order. The thought was as you deform the material, its chemical bonds are broken and that randomizes the system. These violent manufacturing processes essentially shuffle the atoms.\" Yet the metals didn't behave as expected. Despite extreme processing, the alloys never reached a completely random state. The result puzzled the team since no existing theory could account for it. \"It pointed to a new piece of physics in metals,\" the researchers write in the paper. \"It was one of those cases where applied research led to a fundamental discovery.\" To explore further, they built high-precision computational models to capture how atoms interact and statistical methods to measure how order evolves over time. Through large-scale molecular dynamics simulations, they watched how atoms reorganized during deformation and heating. The team observed that certain atomic arrangements appeared at unexpectedly high temperatures, and even more remarkably, entirely new patterns emerged that had never been seen outside of real-world manufacturing. They described these patterns as \"far-from-equilibrium states.\" They then developed a simplified model to reproduce the main features of the simulations. The model revealed that these patterns originate from defects in metals known as dislocations -- irregular, three-dimensional distortions in the atomic lattice. When the metal is deformed, dislocations twist and shift, nudging nearby atoms into preferred positions. Previously, researchers thought this process destroyed all atomic order, but the MIT team found the opposite: dislocations actually favor certain atomic exchanges, creating subtle but stable patterns.  \"These defects have chemical preferences that guide how they move,\" Freitas says. \"They look for low energy pathways, so given a choice between breaking chemical bonds, they tend to break the weakest bonds, and it's not completely random. This is very exciting because it's a non-equilibrium state: It's not something you'd see naturally occurring in materials. It's the same way our bodies live in non-equilibrium. The temperature outside is always hotter or colder than our bodies, and we're maintaining that steady state equilibrium to stay alive. That's why these states exist in metal: the balance between an internal push toward disorder plus this ordering tendency of breaking certain bonds that are always weaker than others.\" Applying a new theory The researchers are now exploring how these chemical patterns develop across a wide range of manufacturing conditions. The result is a map that links various metal processing steps to different chemical patterns in metal. To date, this chemical order and the properties they tune have been largely considered an academic subject. With this map, the researchers hope engineers can begin thinking of these patterns as levers in design that can be pulled during production to get new properties. \"Researchers have been looking at the ways these atomic arrangements change metallic properties -- a big one is catalysis,\" Freitas says of the process that drives chemical reactions. \"Electrochemistry happens at the surface of the metal, and it's very sensitive to local atomic arrangements. And there have been other properties that you wouldn't think would be influenced by these factors. Radiation damage is another big one. That affects these materials' performance in nuclear reactors.\" Researchers have already told Freitas the paper could help explain other surprise findings about metallic properties, and he's excited for the field to move from fundamental research into chemical order to more applied work. \"You can think of areas where you need very optimized alloys like aerospace,\" Freitas says. \"They care about very specific compositions. Advanced manufacturing now makes it possible to combine metals that normally wouldn't mix through deformation. Understanding how atoms actually shuffle and mix in those processes is crucial, because it's the key to gaining strength while still keeping the low density. So, this could be a huge deal for them.\" This work was supported, in part, by the U.S. Air Force Office of Scientific Research, MathWorks, and the MIT-Portugal Program.", "release_time": "2025-10-15", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251014014427.htm"}
{"category": "研究前沿", "title": "全球冶金煤贸易展望：短期趋稳，结构生变", "short_summary": "报告预测全球冶金煤贸易短期趋稳，中国需求降印度增，价格低位运行。", "detailed_summary": "报告预测全球冶金煤贸易短期趋稳，中国需求降印度增，价格低位运行。\n(1) 报告预测全球冶金煤贸易量在2025年略有下降后，未来两年总体保持稳定，消费量因高炉效率提升而轻微下滑。\n(2) 中国市场方面，国内钢材产量下降及产能过剩政策将导致冶金煤进口量从2024年的1.22亿吨降至2027年的1.03亿吨，蒙古煤凭借成本优势维持主要供应地位。\n(3) 印度市场成为主要增长点，受国家钢铁政策推动，其冶金煤进口量预计将从2024年的7500万吨增至2027年的8500万吨，高炉路线份额将提升。\n(4) 欧洲需求疲软，进口预计在2025年下降后企稳，但2026年碳边界调整机制将利好低碳钢生产。\n(5) 供应端，美国出口因价格低迷而显著下降，俄罗斯出口量保持但利润恶化，澳大利亚出口预计从2024-25财年1.46亿吨增至2026-27财年1.69亿吨。\n(6) 价格展望方面，市场供过于求格局将令冶金煤价格在2027年前保持低位，仅可能略有回升。", "raw_content": "根据澳大利亚工业、科学、能源与资源部首席经济学家办公室发布的最新一期《资源与能源季报》，粗钢产量下滑背景下2025年上半年全球冶金煤贸易略有下降，预计未来两年总体将保持较稳。 报告预计，随着高炉效率提高，全球冶金煤消费量预计将在展望期内下滑轻微。随着需求从中国转向依赖进口的印度，预计2025年冶金煤贸易将下降，到2027年将有所复苏。 据称，近几个月来，利润下降影响电弧炉生产下滑，抬高了需要用煤的高炉路线生产在钢铁总产量中的份额。不过，报告指出，尽管转型的时间可能会推迟，但脱碳政策预计仍将推动新设施向低排放产能扩张。 进口来看，报告预计，中国钢材产量下降将压制全球冶金煤进口需求。今年上半年，对全球经济增长的担忧打压了需求，加之国内产量略有上升以及生铁产量稳定等背景下，中国冶金煤进口量同比下滑8%。 报告也指出，中国政府正致力于减少钢铁行业的产能过剩。另外尽管2025年上半年中国钢材出口有韧性，但预计国际贸易壁垒的增加将对钢材生产构成下行压力。 报告预计，在展望期内，中国钢产量的下降预计将降低其冶金煤进口量。而目前中国冶金煤进口中蒙煤占到大约一半，成本和邻近优势预计将使蒙古在中国进口市场下滑的情况下保持出口量。 虽然煤矿超产核查将有利于进口，但现在判断中国国内供应是否会因此减少还为时过早。总的来说，报告预计中国国内冶金煤产量将比国内消费下降得更缓慢，预计将导致进口量从2024年的1.22亿吨下降到2027年的1.03亿吨。 而报告预计印度及东南亚的冶金煤需求增长将表现强劲。2025年上半年，印度冶金煤进口量增长4%，也是此期间少数几个报告进口增长的国家之一。 按照《2017年国家钢铁政策》，印度计划大幅提高高炉钢铁产能，目标到2030-31财年粗钢产量达到2.55亿吨，这意味着增量将超过1亿吨。报告预计印度高炉将从电弧炉设施中夺取市场份额。 这预计将推动印度对冶金煤的需求，且大部分需求增长将通过进口来满足。报告预计，印度冶金煤进口量将从2024年的7500万吨增长到2027年的8500万吨。 另外，尽管2025年上半年，东南亚对低成本中国钢材的进口激增暂时降低了东南亚冶金煤的需求。但报告指出，印度和除中国以外亚洲新兴国家预计仍将在展望期内推动进口需求。 欧洲方面来看，需求疲软等因素影响下，今年上半年欧洲地区冶金煤进口下滑。欧洲钢铁行业目前低水平的利润，正导致越来越多资本支出被推迟或取消。 高炉-转炉生产的成本通常低于电炉生产，这在短期内为冶金煤需求提供了一些支持，目前的低煤价提高了高炉的竞争力。 但从中期来看，2026年在欧洲引入碳边界调整机制预计将有助于提高低碳钢生产的竞争地位。报告预计，欧盟冶金煤进口将在2025年下降，然后在展望期的余下时间里企稳。 由于价格低迷，全球海运冶金煤供应受到了限制，不过报告预计在许多国家政府对工业的支持越来越多情况下应该会限制供应端大范围的关停。 在价格疲软的环境下，美国2025年上半年的冶金煤出口同比下降了13%。同时美国煤炭运往东亚的运费成本要高于其他地区。报告还指出，美国提高进口关税可能会给生产商带来通胀成本压力。 过去几个月，大多数美国煤炭生产商都宣布了某种程度的供应限制，包括裁员和闲置高成本煤矿。为了帮助减少损失，美国参议院通过了一项修正案，对冶金煤实施2.5%的生产税收抵免，并暂时将联邦煤炭特许权使用费率从12.5%降至7%。 因此，报告预计，2025年美国的冶金煤出口量将下降约800万吨至4400万吨，然后在展望期余下时间内逐渐减少。报告指出，美国煤炭出口量的复苏，似乎要么取决于全球需求的复苏及其带来的价格上涨，要么取决于政府进一步补贴。 尽管全球经济出现逆风，但由于与印度和中国的贸易联系依然强劲，俄罗斯冶金煤出口量在2025年上半年仍有所增长。不过，虽然贸易量强劲，但价格和利润前景已经恶化。 为了抵消部分损失，俄罗斯政府采取了一系列措施。俄罗斯政府的目标是将2025年的煤炭出口量保持在2024年的水平，但如果煤价保持在上半年的水平附近，保持煤炭产量稳定将产生巨大的财政成本。 受一季度严重降雨天气影响，澳大利亚2025年上半年冶金煤出口量同比下降了9%。除了天气影响外，大多数澳大利亚生产商在低迷的价格环境中表现相对有韧性。到目前为止，因利润而关闭冶金煤矿的报道有限。 报告预计，澳大利亚冶金煤出口量预计将从2024-25财年的1.46亿吨增加到2026-27财年的1.69亿吨。 鉴于市场维持供过于求格局，报告预计冶金煤价格将保持低位，在2027年或将略有回升。2025年以来澳大利亚优质硬焦煤现货价格走势平缓，徘徊在170美元至200美元/吨之间。 报告指出，按2025年价格计算，全球海运供应中有一小部分面临亏损，减产主要集中在美国。由于到亚洲的运输成本较低，且利润更高的优质硬焦煤出口比例也更大，澳大利亚生产商的情况要好一些。澳大利亚供应增加海运贸易可用性背景下，展望期内海运冶金煤市场可能会保持过剩。", "release_time": "2025-10-15", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194883-1.html"}
{"category": "产业应用", "title": "MIT与丰田十年合作推动汽车安全技术创新", "short_summary": "MIT与丰田合作研究提升汽车安全与自动驾驶技术，影响全球标准。", "detailed_summary": "MIT与丰田合作研究提升汽车安全与自动驾驶技术，影响全球标准。\n(1) MIT AgeLab与丰田合作超十年，通过真实驾驶数据分析提升车辆安全系统设计；\n(2) 合作项目包括车道居中辅助、自适应巡航控制等自动驾驶技术的人机交互研究；\n(3) 研究成果应用于东京奥运会丰田e-Palette车辆，并纳入ISO自动驾驶通信标准；\n(4) 合作促进全球汽车行业安全策略创新，推动智能出行技术发展。", "raw_content": "A decade-plus collaboration between MIT’s AgeLab and the Toyota Motor Corporation is recognized as a key contributor to advancements in automotive safety and human-machine interaction. Through the AgeLab at the MIT Center for Transportation and Logistics (CTL), researchers have collected and analyzed vast real-world driving datasets that have helped inform Toyota’s vehicle design and safety systems.Toyota recently marked the completion of its 100th project through the Collaborative Safety Research Center (CSRC), celebrating MIT’s role in shaping technologies that enhance driver-assistance features and continue to forge the path for automated mobility. A key foundation for the 100th project is CSRC’s ongoing support for MIT CTL’s Advanced Vehicle Technology (AVT) Consortium.Real-world data, real-world impact“AVT was conceptualized over a decade ago as an academic-industry partnership to promote shared investment in real-world, naturalistic data collection, analysis, and collaboration — efforts aimed at advancing safer, more convenient, and more comfortable automobility,” says Bryan Reimer, founder and co-director of AVT. “Since its founding, AVT has drawn together over 25 organizations — including vehicle manufacturers, suppliers, insurers, and consumer research groups — to invest in understanding how automotive technologies function, how they influence driver behavior, and where further innovation is needed. This work has enabled stakeholders like Toyota to make more-informed decisions in product development and deployment.”“CSRC’s 100th project marks a significant milestone in our collaboration,” Reimer adds. “We deeply value CSRC’s sustained investment, and commend the organization’s commitment to global industry impact and the open dissemination of research to advance societal benefit.”“Toyota, through its Collaborative Safety Research Center, is proud to be a founding member of the AVT Consortium,” says Jason Hallman, senior manager of Toyota CSRC. “Since 2011, CSRC has collaborated with researchers such as AVT and MIT AgeLab on projects that help inform future products and policy, and to promote a future safe mobility society for all. The AVT specifically has helped us to study the real-world use of several vehicle technologies now available.”Among these technologies are lane-centering assistance and adaptive cruise control — widely-used technologies that benefit from an understanding of how drivers interact with automation. “AVT uniquely combines vehicle and driver data to help inform future products and highlight the interplay between the performance of these features and the drivers using them,” says Josh Domeyer, principal scientist at CSRC.Influencing global standards and Olympic-scale innovationInsights from MIT’s pedestrian-driver interaction research with CSRC also helped shape Toyota’s automated vehicle communication systems. “These data helped develop our foundational understanding that drivers and pedestrians use their movements to communicate during routine traffic encounters,” said Domeyer. “This concept informed the deployment of Toyota’s e-Palette at the Tokyo Olympics, and it has been captured as a best practice in an ISO standard for automated driving system communication.”The AVT Consortium's naturalistic driving datasets continue to serve as a foundation for behavioral safety strategies. From identifying moments of distraction to understanding how drivers multitask behind the wheel, the work is guiding subtle but impactful design considerations.“By studying the natural behaviors of drivers and their contexts in the AVT datasets, we hope to identify new ways to encourage safe habits that align with customer preferences,” Domeyer says. “These can include subtle nudges, or modifications to existing vehicle features, or even communication and education partnerships outside of Toyota that reinforce these safe driving habits.”Professor Yossi Sheffi, director of MIT CTL, comments, “This partnership exemplifies the impact of MIT collaborative research on industry to make real, practical innovation possible.” A model for industry-academic collaborationFounded in 2015, the AVT Consortium brings together automotive manufacturers, suppliers, and insurers to accelerate research in driver behavior, safety, and the transition toward automated systems. The consortium’s interdisciplinary approach — integrating engineering, human factors, and data science — has helped generate one of the world’s most unique and actionable real-world driving datasets.As Toyota celebrates its research milestone, MIT reflects on a partnership that exemplifies the power of industry-academic collaboration to shape safer, smarter mobility.", "release_time": "2025-10-16", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/mit-toyota-collaboration-powers-driver-assistance-millions-of-vehicles-1015"}
{"category": "产业应用", "title": "美国首条全自动轻轨檀香山天际线二期开通", "short_summary": "檀香山天际线二期四站开通，连接机场与军事基地，提升交通可持续性。", "detailed_summary": "檀香山天际线二期四站开通，连接机场与军事基地，提升交通可持续性。\n(1) 日立铁路与檀香山合作开通美国首条全自动城市轻轨系统“天际线”二期工程。\n(2) 新增四个车站，关键连接珍珠港-希卡姆联合基地和丹尼尔·井上国际机场。\n(3) 项目作为夏威夷史上最大公共基建，将显著改善居民通勤和游客交通。\n(4) 二期开通仪式举行，官方强调其对解决住房短缺和推动经济发展的长期价值。\n(5) 三期工程预计2031年完成，将进一步连接瓦胡岛西区与市中心。", "raw_content": "Honolulu, HI, October 15,2025 Hitachi Rail, in partnership with the City and County of Honolulu, the Honolulu Authority for Rapid Transportation (HART), and the City's Department of Transportation Services (DTS), announced the opening of Segment 2 of Skyline, the first fully autonomous, urban light railway system in the United States.  This milestone marked the launch of four new stations– Makalapa Joint Base Pearl Harbor-Hickam, Lelepaua Daniel K. Inouye International Airport, Ahua Lagoon Drive, and Kahauiki Kalihi Transit Center–extending the reach of Skyline and enhancing connectivity for both residents and visitors. As the largest public infrastructure project in Hawaii's history, Skyline continues to transform sustainable public transportation across Oahu. Strategic Connectivity to Key Destinations  Makalapa Joint Base Pearl Harbor-Hickam Station serves as a vital center for the Pearl Harbor Naval Base, Hickam Air Force Base, Salt Lake, and surrounding residential communities. It will offer a faster, more reliable commuting option for thousands of military personnel and civilian employees that work on base. Lelepaua Daniel K. Inouye International Airport Station provides a direct connection to Daniel K. Inouye International Airport, supporting over 10,000 airport employees and offering travelers a convenient and efficient transit alternative. In addition, a new public express bus route will connect Skyline riders directly to Waikiki, enhancing accessibility to one of Honolulu's most popular destinations. Kahauiki Middle Street Transit Center Station will serve as a vital transit hub, enabling seamless transfers between Honolulu's rail system and public bus network through the use of a single fare card. This integrated system enhances travel efficiency to downtown Honolulu. By reducing commute times, the new station is expected to significantly benefit passengers traveling between homes, schools, and workplaces.   Celebrating a Milestone To commemorate the opening, a grand opening ceremony was held today at Kahauiki Middle Street Transit Center Station. The event began with an inaugural train ride from Halawa Aloha Stadium Station through the new Segment 2 stations. Upon arrival at Kahauiki Middle Street Transit Center Station, guests were welcomed with a traditional Hawaiian blessing and remarks from Honolulu Mayor Rick Blangiardi. Hitachi Rail USA, President and Country Representative, Joseph Pozza: “The delivery and completion of Skyline, Honolulu Segment 2 – the US' first fully autonomous urban rail system, is another proud moment for the Hitachi Rail team, especially our dedicated team leading on the ground in Honolulu, whose work has been paramount in our success. As we celebrate this milestone, the Hitachi team looks forward to its continued work in ongoing and future operations of the Skyline system, ensuring seamless delivery of reliable, sustainable, and high-capacity transportation for the people of O'ahu, visitors from across the state, and around the globe.” Honolulu Mayor Rick Blangiardi: “Today marks another milestone in Skyline's revolutionary impact on Oahu. Residents and visitors will now be able to reach the Daniel K. Inouye International Airport and Joint Base Pearl Harbor-Hickam, two major destinations that serve as powerful economic, employment, and transportation drivers. Meanwhile, each additional Skyline segment unlocks incredible opportunities to address Oʻahu's housing shortage. The City's Transit Oriented Development plan will pay exponential dividends by creating housing for our residents at strategic locations along the rail line. Skyline is an investment in the future of the City and County of Honolulu and will prove itself to be a game changer for this island over the long term. It has taken bold vision, leadership, and dedication to get Skyline to this point, and it will require those same qualities to complete the task of moving Oahu into the future.” HART Executive Director and CEO Lori Kahikina, PE: “Hitachi has been a critical partner in reaching this next goal of handing over Segment 2 of Skyline to the City and County of Honolulu, Department of Transportation Services. The opening of the second segment of the Honolulu Rail Transit Project, extending service from the Halawa Station at Aloha Stadium to the Kahauiki Station at the Middle Street Transit Center, is a significant milestone for the project, its stakeholders, and the taxpayers. The entire HART Ohana (family) is extremely grateful for the collaborative effort to bring the nation's first fully automated driverless commuter rail system to service the state's two largest employment centers, Joint Base Pearl Harbor-Hickam and the Daniel K. Inouye International Airport.” DTS Director J. Roger Morton: “The opening of Segment 2 is a major milestone in our journey toward a fully integrated, island-wide transit system for Oʻahu. With Skyline now reaching the Airport, Lagoon Drive, and the Kalihi Transit Center, we're enhancing connectivity with our award-winning bus network and delivering on our promise of safe, reliable, and modern transportation. This progress wouldn't be possible without our strong partnership with Hitachi, and we're excited to continue building a better-connected future for our island.” Public Launch and What's Ahead Passenger service on the new Segment 2 stations will officially begin on October 16th. To celebrate, free public ride days will be offered on October 18th and 19th, allowing the community to experience the full Skyline route, now spanning 13 stations across Segments 1 and 2.  Looking ahead, Segment 3 is anticipated to be completed by 2031. There will be six additional stations, further connecting Oahu's west side corridor to downtown Honolulu. About Hitachi, Ltd.  Through its Social Innovation Business (SIB) that brings together IT, OT(Operational Technology) and products, Hitachi contributes to a harmonized society where the environment, wellbeing, and economic growth are in balance. Hitachi operates globally in four sectors – Digital Systems & Services, Energy, Mobility, and Connective Industries – and the Strategic SIB Business Unit for new growth businesses. With Lumada at its core, Hitachi generates value from integrating data, technology and domain knowledge to solve customer and social challenges. Revenues for FY2024 (ended March 31, 2025) totaled 9,783.3 billion yen, with 618 consolidated subsidiaries and approximately 280,000 employees worldwide. Visit us at www.hitachi.com. About Hitachi Rail:   Hitachi Rail is committed to driving the sustainable mobility transition and has a clear focus on partnering with customers to rethink mobility. Its mission is to help every passenger, customer and community enjoy the benefits of more connected, seamless and sustainable transport.  With revenues of over €7bn and 24,000 employees across more than 50 countries, Hitachi Rail is a trusted partner to the world's best transport organisations. The company's reach is global, but the business is local - with success built on developing local talent and investing in people and communities.  Its international capabilities and expertise span every part of the urban, mainline and freight rail ecosystems – from high quality manufacturing and maintenance of rolling stock to secure digital signalling, smart operations and payment systems.  Hitachi Rail, famous for Japan's iconic high speed bullet train, draws on the digital and AI expertise of Hitachi Group companies to accelerate innovation and develop new technologies. Hitachi Group's revenues for FY2024 (ended March 31, 2025) totalled €581.6 bn / ¥9,783.3 bn, with 618 consolidated subsidiaries and approximately 280,000 employees worldwide.  Find out more by visiting hitachirail.com or our press site here.  Information contained in this news release is current as of the date of the press announcement, but may be subject to change without prior notice.", "release_time": "2025-11-18", "source_institution": "日本日立", "url": "http://www.hitachi.com/New/cnews/month/2025/10/251016a.html"}
{"category": "研究前沿", "title": "剑桥大学实现有机半导体莫特绝缘体突破，开启单材料太阳能电池新篇章", "short_summary": "科学家首次在有机材料中观测到莫特-哈伯德行为，实现高效单材料光电流转换。", "detailed_summary": "科学家首次在有机材料中观测到莫特-哈伯德行为，实现高效单材料光电流转换。\n（1）剑桥大学团队在有机半导体P3TTM中首次观测到原本存在于无机材料的莫特-哈伯德绝缘体行为；\n（2）分子紧密排列时未配对电子产生交替自旋排列，光吸收后电子跃迁实现电荷分离；\n（3）基于该材料制作的太阳能电池实现近完美电荷收集效率，无需传统异质结界面；\n（4）突破使单材料制备轻量廉价太阳能电池成为可能，颠覆现有有机光伏设计；\n（5）该发现恰逢莫特诞辰120周年，为凝聚态物理开辟了新研究方向。", "raw_content": "In a breakthrough that connects modern science with ideas first explored a century ago, researchers have witnessed a surprising phenomenon once thought possible only in inorganic metal oxides appearing inside a glowing organic semiconductor molecule. Led by scientists at the University of Cambridge, the discovery reveals a new and efficient way to capture light and convert it into electricity. This finding could reshape the future of solar technology and electronics, paving the way for lightweight, affordable solar panels built from a single material.  The study centers on a spin-radical organic semiconductor known as P3TTM. At the core of each molecule lies one unpaired electron, which gives it distinctive magnetic and electronic behavior. The work is the result of collaboration between Professor Hugo Bronstein's synthetic chemistry group in the Yusuf Hamied Department of Chemistry and Professor Sir Richard Friend's semiconductor physics team in the Department of Physics. These researchers previously designed this family of molecules for their bright luminescence, useful in organic LEDs, but the new paper in Nature Materials reveals something unexpected: when the molecules are packed closely together, their unpaired electrons interact much like those in a Mott-Hubbard insulator. \"This is the real magic,\" explained Biwen Li, the lead researcher at the Cavendish Laboratory. \"In most organic materials, electrons are paired up and don't interact with their neighbors. But in our system, when the molecules pack together the interaction between the unpaired electrons on neighboring sites encourages them to align themselves alternately up and down, a hallmark of Mott-Hubbard behavior. Upon absorbing light one of these electrons hops onto its nearest neighbor creating positive and negative charges which can be extracted to give a photocurrent (electricity).\" To test this effect, the team built a solar cell using a thin film of P3TTM. When exposed to light, the device achieved nearly perfect charge collection efficiency, meaning almost every incoming photon was turned into usable electric current. Traditional organic solar cells require two materials -- one to donate electrons and another to accept them -- and this interface limits efficiency. In contrast, these new molecules perform the entire conversion process within a single substance. After a photon is absorbed, an electron naturally moves to a neighboring molecule of the same type, creating charge separation. The small amount of energy needed for this process, known as the \"Hubbard U,\" represents the electrostatic cost of placing two electrons on the same negatively charged molecule. Dr. Petri Murto in the Yusuf Hamied Department of Chemistry developed molecular structures that allow tuning of the molecule-to-molecule contact and the energy balance governed by Mott-Hubbard physics needed to achieve charge separation. This breakthrough means that it might be possible to fabricate solar cells from a single, low-cost lightweight material. The discovery carries profound historical significance. The paper's senior author, Professor Sir Richard Friend, interacted with Sir Nevill Mott early in his career. This finding emerges in the same year as the 120th anniversary of Mott's birth, paying a fitting tribute to the legendary physicist whose work on electron interactions in disordered systems laid the groundwork for modern condensed matter physics. \"It feels like coming full circle,\" said Prof. Friend. \"Mott's insights were foundational for my own career and for our understanding of semiconductors. To now see these profound quantum mechanical rules manifesting in a completely new class of organic materials, and to harness them for light harvesting, is truly special.\" \"We are not just improving old designs\" said Prof. Bronstein. \"We are writing a new chapter in the textbook, showing that organic materials are able to generate charges all by themselves.\"", "release_time": "2025-10-15", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251014014433.htm"}
{"category": "研究前沿", "title": "音乐神经科学前沿：MIT学者探索音乐干预心理健康", "short_summary": "MIT学者结合音乐与神经科学，开发音乐干预工具并验证其临床效果。", "detailed_summary": "MIT学者结合音乐与神经科学，开发音乐干预工具并验证其临床效果。\n（1）Kimy Lecamwasam为MIT媒体实验室博士生，兼具音乐家与神经科学家双重身份；\n（2）研究方向聚焦音乐对焦虑等心理问题的生理心理影响机制；\n（3）开展AI生成音乐与人类作曲的情感共鸣对比研究；\n（4）与卡内基音乐厅等机构合作验证音乐写作的临床干预效果；\n（5）通过大型音乐会实验评估音乐体验对观众与表演者心理健康的影响。", "raw_content": "Computational neuroscientist and singer/songwriter Kimaya (Kimy) Lecamwasam, who also plays electric bass and guitar, says music has been a core part of her life for as long as she can remember. She grew up in a musical family and played in bands all through high school.“For most of my life, writing and playing music was the clearest way I had to express myself,” says Lecamwasam. “I was a really shy and anxious kid, and I struggled with speaking up for myself. Over time, composing and performing music became central to both how I communicated and to how I managed my own mental health.”Along with equipping her with valuable skills and experiences, she credits her passion for music as the catalyst for her interest in neuroscience.“I got to see firsthand not only the ways that audiences reacted to music, but also how much value music had for musicians,” she says. “That close connection between making music and feeling well is what first pushed me to ask why music has such a powerful hold on us, and eventually led me to study the science behind it.”Lecamwasam earned a bachelor’s degree in 2021 from Wellesley College, where she studied neuroscience — specifically in the Systems and Computational Neuroscience track — and also music. During her first semester, she took a class in songwriting that she says made her more aware of the connections between music and emotions. While studying at Wellesley, she participated in the MIT Undergraduate Research Opportunities Program for three years. Working in the Department of Brain and Cognitive Sciences lab of Emery Brown, the Edward Hood Taplin Professor of Medical Engineering and Computational Neuroscience, she focused primarily on classifying consciousness in anesthetized patients and training brain-computer interface-enabled prosthetics using reinforcement learning.“I still had a really deep love for music, which I was pursuing in parallel to all of my neuroscience work, but I really wanted to try to find a way to combine both of those things in grad school,” says Lecamwasam. Brown recommended that she look into the graduate programs at the MIT Media Lab within the Program in Media Arts and Sciences (MAS), which turned out to be an ideal fit.“One thing I really love about where I am is that I get to be both an artist and a scientist,” says Lecamwasam. “That was something that was important to me when I was picking a graduate program. I wanted to make sure that I was going to be able to do work that was really rigorous, validated, and important, but also get to do cool, creative explorations and actually put the research that I was doing into practice in different ways.”Exploring the physical, mental, and emotional impacts of musicInformed by her years of neuroscience research as an undergraduate and her passion for music, Lecamwasam focused her graduate research on harnessing the emotional potency of music into scalable, non-pharmacological mental health tools. Her master’s thesis focused on “pharmamusicology,” looking at how music might positively affect the physiology and psychology of those with anxiety.The overarching theme of Lecamwasam’s research is exploring the various impacts of music and affective computing — physically, mentally, and emotionally. Now in the third year of her doctoral program in the Opera of the Future group, she is currently investigating the impact of large-scale live music and concert experiences on the mental health and well-being of both audience members and performers. She is also working to clinically validate music listening, composition, and performance as health interventions, in combination with psychotherapy and pharmaceutical interventions.Her recent work, in collaboration with Professor Anna Huang’s Human-AI Resonance Lab, assesses the emotional resonance of AI-generated music compared to human-composed music; the aim is to identify more ethical applications of emotion-sensitive music generation and recommendation that preserve human creativity and agency, and can also be used as health interventions. She has co-led a wellness and music workshop at the Wellbeing Summit in Bilbao, Spain, and has presented her work at the 2023 CHI conference on Human Factors in Computing Systems in Hamburg, Germany and the 2024 Audio Mostly conference in Milan, Italy. Lecamwasam has collaborated with organizations near and far to implement real-world applications of her research. She worked with Carnegie Hall's Weill Music Institute on its Well-Being Concerts and is currently partnering on a study assessing the impact of lullaby writing on perinatal health with the North Shore Lullaby Project in Massachusetts, an offshoot of Carnegie Hall’s Lullaby Project. Her main international collaboration is with a company called Myndstream, working on projects comparing the emotional resonance of AI-generated music to human-composed music and thinking of clinical and real-world applications. She is also working on a project with the companies PixMob and Empatica (an MIT Media Lab spinoff), centered on assessing the impact of interactive lighting and large-scale live music experiences on emotional resonance in stadium and arena settings.Building community“Kimy combines a deep love for — and sophisticated knowledge of — music with scientific curiosity and rigor in ways that represent the Media Lab/MAS spirit at its best,” says Professor Tod Machover, Lecamwasam’s research advisor, Media Lab faculty director, and director of the Opera of the Future group. “She has long believed that music is one of the most powerful and effective ways to create personalized interventions to help stabilize emotional distress and promote empathy and connection. It is this same desire to establish sane, safe, and sustaining environments for work and play that has led Kimy to become one of the most effective and devoted community-builders at the lab.”Lecamwasam has participated in the SOS (Students Offering Support) program in MAS for a few years, which assists students from a variety of life experiences and backgrounds during the process of applying to the Program in Media Arts and Sciences. She will soon be the first MAS peer mentor as part of a new initiative through which she will establish and coordinate programs including a “buddy system,” pairing incoming master’s students with PhD students as a way to help them transition into graduate student life at MIT. She is also part of the Media Lab’s Studcom, a student-run organization that promotes, facilitates, and creates experiences meant to bring the community together.“I think everything that I have gotten to do has been so supported by the friends I’ve made in my lab and department, as well as across departments,” says Lecamwasam. “I think everyone is just really excited about the work that they do and so supportive of one another. It makes it so that even when things are challenging or difficult, I’m motivated to do this work and be a part of this community.”", "release_time": "2025-10-16", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/kimaya-lecamwasam-blending-neuroscience-ai-music-to-create-mental-health-innovations-1015"}
{"category": "产业应用", "title": "澳大利亚报告预测全球动力煤需求将结构性下降", "short_summary": "报告指出全球经济增长放缓将抑制动力煤需求，主要进口国转向自给与清洁能源。", "detailed_summary": "报告指出全球经济增长放缓将抑制动力煤需求，主要进口国转向自给与清洁能源。\n(1) 澳大利亚报告预测未来两年全球经济增长放缓将导致动力煤需求低于预期，全球海运动力煤出口量将逐步下降。\n(2) 需求侧：中国进口需求因国内高产、水电恢复及能源转型而显著萎缩；印度需求增长但进口稳定，受自给政策与可再生能源挤压；日韩台进口受气候波动影响短期增加，但长期因非煤发电能力提升而趋势下降。\n(3) 供给侧：印尼出口受中国需求放缓及政策变动影响，中长期将下降；俄罗斯出口受制裁限制，依赖折扣价和政府补贴；澳大利亚出口受天气及装运问题制约，未来两年出口量与收入预计持续减少。\n(4) 总体判断：全球动力煤市场供需双弱，短期价格宽幅震荡，中长期贸易规模将步入结构性下降通道。", "raw_content": "10月7日，澳大利亚工业、科学与资源部发布最新《资源与能源季报》指出，预计未来两年全球经济增长将放缓，而在经济活动放缓带动能源需求下降之下，全球对动力煤的需求可能会低于预期。 报告指出，继今年早些时候全球贸易低迷之后，预计下半年海运动力煤贸易量将有所增加，但随着需求再次减弱，预计未来两年出口量将逐步下降。 | 需求侧 从主要进口国来看，中国市场的进口需求显著萎缩，今年以来，中国动力煤进口量已低于2023年和2024年水平。报告中未明确国内供需和进口将如何受到影响，但预计2025年下半年中国动力煤进口量或仍将保持低迷。 这一方面源于国内原煤产量的高位运行，甚至是供应过剩，导致库存高企、内贸价格承压。尽管政府出台政策调控，但预计未来产量仍将保持高位。另一方面，水电出力的恢复以及经济面临的不确定性也抑制了动力煤消费。 尽管夏季极端高温一度推高了用煤需求，出于能源安全考虑，中国政府已将国内煤炭产能与快速发展的可再生能源共同视为能源体系的基石，通过灵活性改造使煤电更好地与可再生能源配合，扮演调峰角色。这种高自给率与绿色转型的双重驱动，决定了中国对进口动力煤的需求在可预见的未来将维持弱势。 随着人口增长和经济强劲发展，印度煤炭需求持续攀升。不过，过去十年来印度国内煤炭产量增长近80%，满足了该国大部分需求增长，因而其进口量长期保持相对稳定。2025年上半年，印度降雨量高于往年，限制了电力需求、水电得以提振，从而进一步压制了进口。 报告指出，印度政府一直致力于实现能源供应自给自足，同时可再生能源装机容量也在快速提升。尽管煤炭目前仍占据其发电结构的70%，但进口煤的市场空间预计将被持续挤压，呈现逐步下降的趋势。 在日本和韩国，今夏破纪录的高温天气其刺激了制冷用电需求，从而带动动力煤进口增加，但这仅是短期气候因素下的波动，而今年上半年，日韩两国动力煤进口量已显著低于2023年和2024年同期水平。近年来，两国非煤发电能力不断上升，尤其是可再生能源和核电能力的提升带动煤炭需求普遍放缓。 同时，中国台湾地区也在积极推进能源转型，通过“以气代煤”项目逐步降低对煤炭的依赖。目前，台湾地区正在进行一项大型电厂由煤炭改造为天然气发电的项目，迄今为止该项目已淘汰煤电能力500兆瓦。 总体而言，在这几个东北亚经济体中，煤炭因其可靠性短期内仍将是电力组合中的重要组成部分，但长远来看在能源结构中的份额被逐渐替代的趋势难以逆转。 | 供应侧 主要出口国面临着需求萎缩和政策不确定性的双重挑战。印尼作为最大的动力煤出口国，2025年上半年受中国买家需求放缓的直接影响，印尼煤对华出口量同比大幅下降。 同时，今年年初印尼政府推出的煤炭基准价出口政策在市场供应过剩背景下，对买卖双方均带来了不利影响，进一步抑制了需求。尽管该政策已于8月取消，但其带来的负面影响已实际发生。报告预计，今年下半年随着需求季节性改善，印尼出口将有所回升，但中长期仍将追随主要进口国能源结构调整的大趋势而逐步下降。 在俄罗斯，制裁限制了其出口流向和规模，迫使俄煤以远低于国际市场的折扣价销售，导致众多矿商巨额亏损，债务负担加重。为此，俄罗斯政府不得不持续提供补贴、税收减免等政策支持以维持行业生存。尽管面临严峻挑战，但俄罗斯动力煤仍凭借其价格优势寻到了部分买家，包括中国、印度、土耳其、韩国和台湾等市场，但实际出口体量已明显下降。 受天气及相关因素影响，2025年一季度澳大利亚动力煤出口降至4600万吨低点，二季度回升至4800万吨。不过，纽卡斯尔港因洪水及后续装船机更换造成的长时间船舶积压，短期内限制了实际供应能力，对价格提供了支撑。 报告预计，2025-26年，澳大利亚动力煤出口量将下降至2.03亿吨，2026-27年降至2.01亿吨。同时，出口收入也将由2024-25年的略低于320亿美元降至2025-26年的280亿美元，2026-27年进一步降至260亿美元。未来两年，澳大利亚出口量预计将随全球需求的消退而逐步下降，而国内政策的不确定性也为未来供应前景增加了变数。 综上所述，全球动力煤市场正处于供需格局深刻调整、价格寻求新平衡的关键时期。当前，市场整体表现出供需双弱的基本态势，短期内价格在特定因素支撑下预计将围绕当前水平宽幅震荡，但中长期受能源转型和主要进口国能源自给战略的深刻影响，全球动力煤贸易规模将步入一个结构性的、渐进的下降通道。", "release_time": "2025-10-15", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194882-1.html"}
{"category": "研究前沿", "title": "新方法利用拍频效应区分纳赫兹引力波来源", "short_summary": "学者提出通过引力波拍频分析，辨别脉冲星信号源于宇宙暴涨或黑洞双星。", "detailed_summary": "学者提出通过引力波拍频分析，辨别脉冲星信号源于宇宙暴涨或黑洞双星。\n（1）2023年脉冲星计时阵列合作发现纳赫兹引力波存在的强证据，波周期为数月到数年；\n（2）引力波可能源于早期宇宙暴涨或星系合并形成的超大质量黑洞双星系统；\n（3）朝田秀树团队提出利用双黑洞系统引力波干涉产生的拍频效应进行来源甄别；\n（4）该方法通过分析脉冲星信号相关性中的周期性调制特征实现区分；\n（5）研究成果为未来确认引力波起源提供了新工具，相关论文发表于JCAP期刊。", "raw_content": "Pulsars may be revealing that extremely low-frequency gravitational waves are moving through the universe. Observations reported in 2023 by international pulsar timing array collaborations could be caused by either a background of overlapping gravitational waves from countless distant sources or a single pair of nearby supermassive black holes orbiting each other. To determine which explanation fits, Hideki Asada, a theoretical physicist and Professor at Hirosaki University, and Shun Yamamoto, a researcher at the Graduate School of Science and Technology, Hirosaki University, have proposed a new approach. Their method takes advantage of \"beat\" effects that occur when two gravitational waves have nearly the same frequency, searching for their subtle influence on the arrival times of pulsars' radio signals.  Their findings were recently published in the Journal of Cosmology and Astroparticle Physics (JCAP). The night sky contains remarkably precise \"cosmic clocks\": pulsars, which are dense neutron stars that emit radio pulses at steady intervals, ticking like perfectly timed metronomes. On Earth, radio telescopes track these pulses not only to learn about the pulsars themselves, but also to use them as tools for studying the structure and behavior of the wider universe. If something unseen -- almost a \"cosmic ghost\" -- distorts spacetime between a pulsar and Earth, the timing of its pulses shifts slightly. These changes are not random; several pulsars in certain parts of the sky can show matching variations, as if a slow, invisible wave were passing through space. \"In 2023 several pulsar timing array collaborations -- NANOGrav in the US, and European teams -- announced strong evidence for nanohertz gravitational waves,\" Asada notes. Nanohertz means wave periods of months to years, with wavelengths of several light-years. To probe such scales, we rely on distant, stable pulsars hundreds to thousands of light-years away. \"The signal was statistically reliable but below the 5-sigma threshold that particle physicists usually require,\" he continues. \"It's 'strong evidence' but not yet a confirmed detection, but the cosmology and astrophysics community believes we are approaching the first detection of nanohertz gravitational waves.\" Although the evidence is promising, it still falls short of absolute confirmation. Asada notes that if future data strengthen the result, the next step will be to pinpoint the origin. \"There are two main candidate sources for nanohertz gravitational waves,\" he explains. \"One is cosmic inflation, which would have created spacetime fluctuations in the very early universe, later stretched to cosmic scales. The other is supermassive black hole binaries, which form when galaxies merge. Both scenarios could generate nanohertz gravitational waves.\" Distinguishing between these possibilities has been difficult because the correlation patterns seen in pulsar data -- the way timing differences between pulsars relate to each other -- were once thought to appear similar in both cases. \"In our paper, we explored the situation where a nearby pair of supermassive black holes produces a particularly strong signal,\" Asada says. \"If two such systems have very similar frequencies, their waves can interfere and create a beat pattern, like in acoustics. That feature could, in principle, allow us to distinguish them from the stochastic background of inflation.\" Asada and Yamamoto therefore leverage a familiar acoustic effect: beats. When two waves have almost -- but not exactly -- the same frequency, their superposition produces periodic strengthening and weakening. Applied to gravitational waves, two supermassive-black-hole binaries with similar frequencies would imprint a characteristic modulation in the pulsar-timing signal. The method is to look for this modulation -- the \"beat\" -- in the pulsar correlation patterns. If it's present, that strongly suggests the signal is not a diffuse background but arises from specific, relatively nearby binaries. We now await stronger confirmation of the pulsar signal's nature. \"I think once a confirmed detection at 5-sigma is achieved, maybe within a few years, the next step will be to ask: what is the origin of the waves? At that point, our method could be useful to distinguish whether they come from inflation or from nearby supermassive black hole binaries,\" Asada concludes.", "release_time": "2025-10-16", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251015032302.htm"}
{"category": "研究前沿", "title": "量子关联可稳定时间晶体，维也纳工大发现新机制", "short_summary": "维也纳工大研究揭示量子关联能促进时间晶体形成，颠覆传统认知。", "detailed_summary": "维也纳工大研究揭示量子关联能促进时间晶体形成，颠覆传统认知。\n（1）时间晶体是指量子系统自发形成时间周期性结构的现象；\n（2）传统认为量子关联会破坏时间晶体，但新研究发现其反而起稳定作用；\n（3）研究通过二维激光晶格粒子系统验证了量子相互作用诱导的集体振荡；\n（4）这一发现为量子多体系统理论和新型量子技术开发提供了新视角。", "raw_content": "Nature follows countless rhythms: the changing of the seasons comes from Earth's orbit around the Sun, and the steady tick of a clock arises from the back-and-forth swing of its pendulum. These patterns can be described with simple mathematical laws.  Yet, order can also appear in a far more surprising way -- on its own, without any external timer. When countless particles interact in complex ways, they can spontaneously fall into a repeating rhythm instead of behaving chaotically. This phenomenon is known as a \"time crystal.\" Researchers at TU Wien (Vienna) have now demonstrated that time crystals can form through an entirely different mechanism than scientists had believed possible. Their calculations reveal that quantum correlations between particles, once thought to disrupt these patterns, can in fact help stabilize them. The finding offers a striking new perspective on how collective behaviors emerge in quantum many-particle systems. Space crystals and time crystals When a liquid freezes, its particles shift from disorder to order. In the liquid state, the particles move freely and randomly, showing no particular pattern. As the liquid solidifies, the particles lock into precise positions, forming a regular and repeating spatial structure -- a crystal. A liquid is uniform in every direction, but in a crystal that symmetry breaks: it gains structure, with certain directions becoming distinct from others. Can a similar kind of symmetry breaking happen over time rather than in space? Could a quantum system that initially behaves identically at every moment spontaneously develop a repeating temporal pattern -- a rhythm that marks the emergence of order in time itself? Quantum fluctuations: harmful or useful? \"This question has been the subject of intensive research in quantum physics for over ten years,\" says Felix Russo from the Institute of Theoretical Physics at TU Wien, who is conducting research for his doctoral thesis in Prof. Thomas Pohl's team. In fact, it has been shown that so-called time crystals are possible -- systems in which a temporal rhythm is established without the beat being imposed from outside.  \"However, it was thought that this was only possible in very specific systems, such as quantum gases, whose physics can be well described by mean values without having to take into account the random fluctuations that are inevitable in quantum physics,\" says Felix Russo. \"We have now shown that it is precisely the quantum physical correlations between the particles, which were previously thought to prevent the formation of time crystals, that can lead to the emergence of time-crystalline phases.\" The complex quantum interactions between the particles induce collective behaviour that cannot be explained at the level of individual particles -- similar to how the smoke from an extinguished candle can sometimes form a regular series of smoke rings; a phenomenon whose rhythm is not dictated from outside and which cannot be understood from single smoke particles. Particles in the laser lattice \"We are investigating a two-dimensional lattice of particles held in place by laser beams,\" says Felix Russo. \"And here we can show that the state of the lattice begins to oscillate -- due to the quantum interaction between the particles.\" The research offers the opportunity to better understand the theory of quantum many-body systems -- paving the way for new quantum technologies or high-precision quantum measurement techniques.", "release_time": "2025-10-16", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251015032309.htm"}
{"category": "研究前沿", "title": "MIT研发电化学气泡技术实现细胞无损分离", "short_summary": "MIT开发电化学气泡法按需分离细胞，解决多行业生物附着难题且不损伤细胞活性。", "detailed_summary": "MIT开发电化学气泡法按需分离细胞，解决多行业生物附着难题且不损伤细胞活性。\n（1）MIT研究人员开发出利用电化学生成气泡实现细胞按需分离的新技术；\n（2）该技术通过气泡在界面产生剪切力去除附着细胞，适用于藻类、哺乳动物细胞等多种细胞类型；\n（3）创新性使用质子交换膜隔离电极，避免培养液中氯化钠生成次氯酸盐损伤细胞；\n（4）技术可应用于光生物反应器、制药、生物燃料、食品工业等多个领域；\n（5）该方法无需化学酶处理，具有无损、高效、可扩展和系统通用等优势。", "raw_content": "To help mitigate climate change, companies are using bioreactors to grow algae and other microorganisms that are hundreds of times more efficient at absorbing CO2 than trees. Meanwhile, in the pharmaceutical industry, cell culture is used to manufacture biologic drugs and other advanced treatments, including lifesaving gene and cell therapies.Both processes are hampered by cells’ tendency to stick to surfaces, which leads to a huge amount of waste and downtime for cleaning. A similar problem slows down biofuel production, interferes with biosensors and implants, and makes the food and beverage industry less efficient.Now, MIT researchers have developed an approach for detaching cells from surfaces on demand, using electrochemically generated bubbles. In an open-access paper published in Science Advances, the researchers demonstrated their approach in a lab prototype and showed it could work across a range of cells and surfaces without harming the cells.“We wanted to develop a technology that could be high-throughput and plug-and-play, and that would allow cells to attach and detach on demand to improve the workflow in these industrial processes,” says Professor Kripa Varanasi, senior author of the study. “This is a fundamental issue with cells, and we’ve solved it with a process that can scale. It lends itself to many different applications.”Joining Varanasi on the study are co-first authors Bert Vandereydt, a PhD student in mechanical engineering, and former postdoc Baptiste Blanc.Solving a sticky problem  Credit: Joy Zheng    The researchers began with a mission.“We’ve been working on figuring out how we can efficiently capture CO2 across different sources and convert it into valuable products for various end markets,” Varanasi says. “That’s where this photobioreactor and cell detachment comes into the picture.”Photobioreactors are used to grow carbon-absorbing algae cells by creating tightly controlled environments involving water and sunlight. They feature long, winding tubes with clear surfaces to let in the light algae need to grow. When algae stick to those surfaces, they block out the light, requiring cleaning.“You have to shut down and clean up the entire reactor as frequently as every two weeks,” Varanasi says. “It’s a huge operational challenge.”The researchers realized other industries have similar problem due to many cells’ natural adhesion, or stickiness. Each industry has its own solution for cell adhesion depending on how important it is that the cells survive. Some people scrape the surfaces clean, while others use special coatings that are toxic to cells.In the pharmaceutical and biotech industries, cell detachment is typically carried out using enzymes. However, this method poses several challenges — it can damage cell membranes, is time-consuming, and requires large amounts of consumables, resulting in millions of liters of biowaste.To create a better solution, the researchers began by studying other efforts to clear surfaces with bubbles, which mainly involved spraying bubbles onto surfaces and had been largely ineffective.“We realized we needed the bubbles to form on the surfaces where we don’t want these cells to stick, so when the bubbles detach it creates a local fluid flow that creates shear stress at the interface and removes the cells,” Varanasi explains.Electric currents generate bubbles by splitting water into hydrogen and oxygen. But previous attempts at using electricity to detach cells were hampered because the cell culture mediums contain sodium chloride, which turns into bleach when combined with an electric current. The bleach damages the cells, making it impractical for many applications.“The culprit is the anode — that’s where the sodium chloride turns to bleach,” Vandereydt explained. “We figured if we could separate that electrode from the rest of the system, we could prevent bleach from being generated.”To make a better system, the researchers built a 3-square-inch glass surface and deposited a gold electrode on top of it. The layer of gold is so thin it doesn’t block out light. To keep the other electrode separate, the researchers integrated a special membrane that only allows protons to pass through. The set up allowed the researchers to send a current through without generating bleach.To test their setup, they allowed algae cells from a concentrated solution to stick to the surfaces. When they applied a voltage, the bubbles separated the cells from the surfaces without harming them.The researchers also studied the interaction between the bubbles and cells, finding the higher the current density, the more bubbles were created and the more algae was removed. They developed a model for understanding how much current would be needed to remove algae in different settings and matched it with results from experiments involving algae as well as cells from ovarian cancer and bones.“Mammalian cells are orders of magnitude more sensitive than algae cells, but even with those cells, we were able to detach them with no impact to the viability of the cell,” Vandereydt says.Getting to scaleThe researchers say their system could represent a breakthrough in applications where bleach or other chemicals would harm cells. That includes pharmaceutical and food production.“If we can keep these systems running without fouling and other problems, then we can make them much more economical,” Varanasi says.For cell culture plates used in the pharmaceutical industry, the team envisions their system comprising an electrode that could be robotically moved from one culture plate to the next, to detach cells as they’re grown. It could also be coiled around algae harvesting systems.“This has general applicability because it doesn’t rely on any specific biological or chemical treatments, but on a physical force that is system-agnostic,” Varanasi says. “It’s also highly scalable to a lot of different processes, including particle removal.”Varanasi cautions there is much work to be done to scale up the system. But he hopes it can one day make algae and other cell harvesting more efficient.“The burning problem of our time is to somehow capture CO2 in a way that’s economically feasible,” Varanasi says. “These photobioreactors could be used for that, but we have to overcome the cell adhesion problem.”The work was supported, in part, by Eni S.p.A through the MIT Energy Initiative, the Belgian American Educational Foundation Fellowship, and the Maria Zambrano Fellowship.", "release_time": "2025-10-16", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/mit-engineers-solve-sticky-cell-problem-bioreactors-and-other-industries-1015"}
{"category": "产业应用", "title": "GA-EMS声学监视系统亮相防务展 验证多域作战能力", "short_summary": "Fencepost系统成功演示被动检测低信号空中威胁，提升复杂环境下的态势感知能力。", "detailed_summary": "Fencepost系统成功演示被动检测低信号空中威胁，提升复杂环境下的态势感知能力。\n(1) GA-EMS在AUSA 2025防务展展示Fencepost声学监视系统，该系统在T-REX 25演习中成功验证性能；  \n(2) 演示中被动检测并跟踪低信号空中威胁，包括1-3级无人机和旋翼机，适应复杂地形和射频拥堵环境；  \n(3) 系统具备模块化架构、快速部署、5-7公里探测范围及智能滤波等关键能力，支持与现有战术决策工具集成；  \n(4) 技术强调被动感知优势，弥补雷达和光学系统局限，助力多域作战和分层防御战略；  \n(5) 展示旨在加速自主系统过渡，应对新兴威胁，体现低成本、低特征设计对远征作战的支持。", "raw_content": "SAN DIEGO — Oct. 14, 2025 —General Atomics Electromagnetic Systems (GA-EMS) is showcasing its Fencepost™ acoustic surveillance system at the Association of the United States Army Annual Meeting and Exposition (AUSA 2025), following successful field demonstrations during the Office of the Under Secretary of Defense for Research and Engineering Technology Readiness Experimentation 2025 (T-REX 25) exercise. The system demonstrated its ability to detect low-signature aerial threats in complex terrain and congested radio frequency environments, underscoring its value for passive situational awareness in complex operational environments. T-REX 25 was a defense experimentation event designed to accelerate the evaluation and transition of emerging technologies throughlive, scenario-based demonstrations. GA-EMS participated in the exercise in early August, showcasing Fencepost’s capabilities in operationally relevant environments and engaging directly with military stakeholders. During the exercise, Fencepost passively detected and tracked low-signature aerial threats—including Group 1-3 unmanned aerial systems and rotary-wing aircraft—across complex terrain and congested radio frequency conditions. The system’s modular architecture, rapid deployability and integration with tactical decision aids were key focus areas throughout the experimentation. “These trials confirm Fencepost’s ability to deliver persistent, passive situational awareness where radar and optical systems face limitations,” said Scott Forney, president of GA-EMS. “We’re focused on delivering deployable technologies that close operational gaps and adapt to the realities of modern conflict.” Fencepost’s performance reflects a growing interest in passive sensor technologies that support multi-domain operations and layered defense strategies. Its capabilities align with broader efforts to accelerate the development and transition of autonomous systems to address urgent and emerging threats. Key capabilities include:   Scalable Deployment: Flexible node placement along a customizable perimeter, tailored to mission-specific coverageand objectives Operational Range: Supports Flexible deployment with detection capabilities up to 5–7 km for Group 3 targets Wide Frequency Processing: Handles signals in the 100–4000 Hz range Smart Filtering: Continuous detection algorithm to reduce false alarms Directional Tracking: Estimates signal source via Direction of Arrival (DoA) tracking Noise Suppression: Adaptive cancellation of loud, stationary noise sources Advanced Signal Classification: Uses eigenvector-based feature extraction for prioritization (AI integration planned) Seamless Integration: Plug-and-play compatibility with existing tactical decision aids  Fencepost’s low-cost, low-signature design supports expeditionary operations and rapid response missions. Attendees can learn more about its capabilities and speak directly with GA-EMS at Booth #2725 during AUSA 2025. About General Atomics Electromagnetic Systems General Atomics Electromagnetic Systems (GA-EMS) develops innovative technologies to create breakthrough solutions supporting operational environments from undersea to space. From electromagnetic, power generation and energy storage systems and space systems and satellites, to hypersonic, missile defense, and laser weapon systems, GA-EMS offers an expanding portfolio of capabilities for defense, government, and national security customers. GA-EMS also provides commercial products and services targeting hazardous waste remediation, oil and gas, and nuclear energy industries. For further information, visit www.ga.com/ems Media Contact  EMS-MediaRelations@ga.com", "release_time": "2025-10-14", "source_institution": "通用原子能公司", "url": "http://www.ga.com/fencepost-sensor-tackles-low-signature-threats-in-complex-terrain"}
{"category": "研究前沿", "title": "MIT研发可持续肥料提升农业抗逆性", "short_summary": "乔治·里佐开发新型种子包衣肥料，利用壳聚糖等材料降低农业环境冲击。", "detailed_summary": "乔治·里佐开发新型种子包衣肥料，利用壳聚糖等材料降低农业环境冲击。\n(1) MIT博士后乔治·里佐专注于开发可持续肥料，研究稀土元素增强植物抗逆性；  \n(2) 新型肥料以种子包衣形式应用，使用壳聚糖等天然材料降低成本；  \n(3) 旨在替代高能耗的NPK化肥，减少土壤污染并提升作物产量；  \n(4) 获得Kavanaugh创业奖学金支持，推动技术从实验室走向市场应用；  \n(5) 研究目标为帮助农民在保障土壤健康前提下实现农业可持续发展。", "raw_content": "Born in Palermo, Sicily, Giorgio Rizzo spent his childhood curious about the natural world. “I have always been fascinated by nature and how plants and animals can adapt and survive in extreme environments,” he says. “Their highly tuned biochemistry, and their incredible ability to create ones of the most complex and beautiful structures in chemistry that we still can’t even achieve in our laboratories.”As an undergraduate student, he watched as a researcher mounted a towering chromatography column layered with colorful plant chemicals in a laboratory. When the researcher switched on a UV light, the colors turned into fluorescent shades of blue, green, red and pink. “I realized in that exact moment that I wanted to be the same person, separating new unknown compounds from a rare plant with potential pharmaceutical properties,” he recalls.These experiences set him on a path from a master’s degree in organic chemistry to his current work as a postdoc in the MIT Department of Civil and Environmental Engineering, where he focuses on developing sustainable fertilizers and studying how rare earth elements can boost plant resilience, with the aim of reducing agriculture’s environmental impact.In the lab of MIT Professor Benedetto Marelli, Rizzo studies plant responses to environmental stressors, such as heat, drought, and prolonged UV irradiation. This includes developing new fertilizers that can be applied as seed coating to help plants grow stronger and enhance their resistance.“We are working on new formulations of fertilizers that aim to reduce the huge environmental impact of classical practices in agriculture based on NPK inorganic fertilizers,” Rizzo explains. Although they are fundamental to crop yields, their tendency to accumulate in soil is detrimental to the soil health and microbiome living in it. In addition, producing NPK (nitrogen, phosphorus, and potassium) fertilizers is one of the most energy-consuming and polluting chemical processes in the world.“It is mandatory to reshape our conception of fertilizers and try to rely, at least in part, on alternative products that are safer, cheaper, and more sustainable,” he says.Recently, Rizzo was awarded a Kavanaugh Fellowship, a program that gives MIT graduate students and postdocs entrepreneurial training and resources to bring their research from the lab to the market. “This prestigious fellowship will help me build a concrete product for a company, adding more value to our research,” he says.Rizzo hopes their work will help farmers increase their crop yields without compromising soil quality or plant health. A major barrier to adopting new fertilizers is cost, as many farmers rely heavily on each growing season’s output and cannot risk investing in products that may underperform compared to traditional NPK fertilizers. The fertilizers being developed in the Marelli Lab address this challenge by using chitin and chitosan, abundant natural materials that make them far less expensive to produce, which Rizzo hopes will encourage farmers to try them.“Through the Kavanaugh Fellowship, I will spend this year trying to bring the technology outside the lab to impact the world and meet the need for farmers to support their prosperity,” he says.Mentorship has been a defining part of his postdoc experience. Rizzo describes Professor Benedetto Marelli as “an incredible mentor” who values his research interests and supports him through every stage of his work. The lab spans a wide range of projects — from plant growth enhancement and precision chemical delivery to wastewater treatment, vaccine development for fish, and advanced biochemical processes. “My colleagues created a stimulant environment with different research topics,” he notes. He is also grateful for the work he does with international institutions, which has helped him build a network of researchers and academics around the world.Rizzo enjoys the opportunity to mentor students in the lab and appreciates their curiosity and willingness to learn. “It is one of the greatest qualities you can have as a scientist because you must be driven by curiosity to discover the unexpected,” he says.He describes MIT as a “dynamic and stimulating experience,” but also acknowledges how overwhelming it can be. “You will feel like a small fish in a big ocean,” he says. “But that is exactly what MIT is: an ocean full of opportunities and challenges that are waiting to be solved.”Beyond his professional work, Rizzo enjoys nature and the arts. An avid reader, he balances his scientific work with literature and history. “I never read about science-related topics — I read about it a lot already for my job,” he says. “I like classic literature, novels, essays, history of nations, and biographies. Often you can find me wandering in museums’ art collections.” Classical art, Renaissance, and Pre-Raphaelites are his favorite artistic currents.Looking ahead, Rizzo hopes to shift his professional pathway toward startups or companies focused on agrotechnical improvement. His immediate goal is to contribute to initiatives where research has a direct, tangible impact on everyday life.“I want to pursue the option of being part of a spinout process that would enable my research to have a direct impact in everyday life and help solve agricultural issues,” he adds.", "release_time": "2025-10-15", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/giorgio-rizzo-engineering-next-generation-fertilizers-1014"}
{"category": "研究前沿", "title": "MIT校友捐赠建立罕见脑病研究网络RareNet", "short_summary": "MIT校友捐赠设立罕见脑病研究网络，旨在打破研究壁垒加速疗法开发。", "detailed_summary": "MIT校友捐赠设立罕见脑病研究网络，旨在打破研究壁垒加速疗法开发。\n（1）全球有3亿多人患有罕见疾病，其中多数影响大脑和神经系统且缺乏有效疗法；\n（2）MIT校友捐赠建立RareNet研究网络，由神经科学教授Guoping Feng领导；\n（3）通过建立全球联盟和治疗管道加速器，打破研究碎片化壁垒；\n（4）首批聚焦Rett综合征、朊病毒病等四种罕见脑部疾病；\n（5）旨在加速实验室发现向临床治疗转化，为患者带来新希望。", "raw_content": "More than 300 million people worldwide are living with rare disorders — many of which have a genetic cause and affect the brain and nervous system — yet the vast majority of these conditions lack an approved therapy. Because each rare disorder affects fewer than 65 out of every 100,000 people, studying these disorders and creating new treatments for them is especially challenging.Thanks to a generous philanthropic gift from Ana Méndez ’91 and Rajeev Jayavant ’86, EE ’88, SM ’88, MIT is now poised to fill gaps in this research landscape. By establishing the Rare Brain Disorders Nexus — or RareNet — at MIT's McGovern Institute for Brain Research, the alumni aim to convene leaders in neuroscience research, clinical medicine, patient advocacy, and industry to streamline the lab-to-clinic pipeline for rare brain disorder treatments.“Ana and Rajeev’s commitment to MIT will form crucial partnerships to propel the translation of scientific discoveries into promising therapeutics and expand the Institute’s impact on the rare brain disorders community,” says MIT President Sally Kornbluth. “We are deeply grateful for their pivotal role in advancing such critical science and bringing attention to conditions that have long been overlooked.”Building new coalitionsSeveral hurdles have slowed the lab-to-clinic pipeline for rare brain disorder research. It is difficult to secure a sufficient number of patients per study, and current research efforts are fragmented, since each study typically focuses on a single disorder (there are more than 7,000 known rare disorders, according to the World Health Organization). Pharmaceutical companies are often reluctant to invest in emerging treatments due to a limited market size and the high costs associated with preparing drugs for commercialization.Méndez and Jayavant envision that RareNet will finally break down these barriers. “Our hope is that RareNet will allow leaders in the field to come together under a shared framework and ignite scientific breakthroughs across multiple conditions. A discovery for one rare brain disorder could unlock new insights that are relevant to another,” says Jayavant. “By congregating the best minds in the field, we are confident that MIT will create the right scientific climate to produce drug candidates that may benefit a spectrum of uncommon conditions.”Guoping Feng, the James W. (1963) and Patricia T. Poitras Professor in Neuroscience and associate director of the McGovern Institute, will serve as RareNet’s inaugural faculty director. Feng holds a strong record of advancing studies on therapies for neurodevelopmental disorders, including autism spectrum disorders, Williams syndrome, and uncommon forms of epilepsy. His team’s gene therapy for Phelan-McDermid syndrome, a rare and profound autism spectrum disorder, has been licensed to Jaguar Gene Therapy and is currently undergoing clinical trials. “RareNet pioneers a unique model for biomedical research — one that is reimagining the role academia can play in developing therapeutics,” says Feng.RareNet plans to deploy two major initiatives: a global consortium and a therapeutic pipeline accelerator. The consortium will form an international network of researchers, clinicians, and patient groups from the outset. It seeks to connect siloed research efforts, secure more patient samples, promote data sharing, and drive a strong sense of trust and goal alignment across the RareNet community. Partnerships within the consortium will support the aim of the therapeutic pipeline accelerator: to de-risk early lab discoveries and expedite their translation to clinic. By fostering more targeted collaborations — especially between academia and industry — the accelerator will prepare potential treatments for clinical use as efficiently as possible.MIT labs are focusing on four uncommon conditions in the first wave of RareNet projects: Rett syndrome, prion disease, disorders linked to SYNGAP1 mutations, and Sturge-Weber syndrome. The teams are working to develop novel therapies that can slow, halt, or reverse dysfunctions in the brain and nervous system.These efforts will build new bridges to connect key stakeholders across the rare brain disorders community and disrupt conventional research approaches. “Rajeev and I are motivated to seed powerful collaborations between MIT researchers, clinicians, patients, and industry,” says Méndez. “Guoping Feng clearly understands our goal to create an environment where foundational studies can thrive and seamlessly move toward clinical impact.”“Patient and caregiver experiences, and our foreseeable impact on their lives, will guide us and remain at the forefront of our work,” Feng adds. “For far too long has the rare brain disorders community been deprived of life-changing treatments — and, importantly, hope. RareNet gives us the opportunity to transform how we study these conditions, and to do so at a moment when it’s needed more than ever.”", "release_time": "2025-10-14", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/new-mit-initiative-seeks-transform-rare-brain-disorders-research-1014"}
{"category": "产业应用", "title": "Watershed Bio推出无代码生物信息分析平台加速科研", "short_summary": "云平台助力生物学家无需编程即可分析基因组等数据，大幅提升科研效率。", "detailed_summary": "云平台助力生物学家无需编程即可分析基因组等数据，大幅提升科研效率。\n（1）Watershed Bio开发云平台解决生物学家分析复杂数据的计算瓶颈；\n（2）平台提供工作流模板支持多组学数据分析，包括基因组、转录组等；\n（3）采用无代码设计使非计算机背景研究人员能直接使用先进分析工具；\n（4）创始人Jonathan Wang基于MIT经历发现生物与计算机科学间的效率差距；\n（5）平台已应用于学术和工业界，加速药物研发和科学发现进程。", "raw_content": "As costs for diagnostic and sequencing technologies have plummeted in recent years, researchers have collected an unprecedented amount of data around disease and biology. Unfortunately, scientists hoping to go from data to new cures often require help from someone with experience in software engineering.Now, Watershed Bio is helping scientists and bioinformaticians run experiments and get insights with a platform that lets users analyze complex datasets regardless of their computational skills. The cloud-based platform provides workflow templates and a customizable interface to help users explore and share data of all types, including whole-genome sequencing, transcriptomics, proteomics, metabolomics, high-content imaging, protein folding, and more.“Scientists want to learn about the software and data science parts of the field, but they don’t want to become software engineers writing code just to understand their data,” co-founder and CEO Jonathan Wang ’13, SM ’15 says. “With Watershed, they don’t have to.”Watershed is being used by large and small research teams across industry and academia to drive discovery and decision-making. When new advanced analytic techniques are described in scientific journals, they can be added to Watershed’s platform immediately as templates, making cutting-edge tools more accessible and collaborative for researchers of all backgrounds.“The data in biology is growing exponentially, and the sequencing technologies generating this data are only getting better and cheaper,” Wang says. “Coming from MIT, this issue was right in my wheelhouse: It’s a tough technical problem. It’s also a meaningful problem because these people are working to treat diseases. They know all this data has value, but they struggle to use it. We want to help them unlock more insights faster.”No code discoveryWang expected to major in biology at MIT, but he quickly got excited by the possibilities of building solutions that scaled to millions of people with computer science. He ended up earning both his bachelor’s and master’s degrees from the Department of Electrical Engineering and Computer Science (EECS). Wang also interned at a biology lab at MIT, where he was surprised how slow and labor-intensive experiments were.“I saw the difference between biology and computer science, where you had these dynamic environments [in computer science] that let you get feedback immediately,” Wang says. “Even as a single person writing code, you have so much at your fingertips to play with.”While working on machine learning and high-performance computing at MIT, Wang also co-founded a high frequency trading firm with some classmates. His team hired researchers with PhD backgrounds in areas like math and physics to develop new trading strategies, but they quickly saw a bottleneck in their process.“Things were moving slowly because the researchers were used to building prototypes,” Wang says. “These were small approximations of models they could run locally on their machines. To put those approaches into production, they needed engineers to make them work in a high-throughput way on a computing cluster. But the engineers didn’t understand the nature of the research, so there was a lot of back and forth. It meant ideas you thought could have been implemented in a day took weeks.”To solve the problem, Wang’s team developed a software layer that made building production-ready models as easy as building prototypes on a laptop. Then, a few years after graduating MIT, Wang noticed technologies like DNA sequencing had become cheap and ubiquitous.“The bottleneck wasn’t sequencing anymore, so people said, ‘Let’s sequence everything,’” Wang recalls. “The limiting factor became computation. People didn’t know what to do with all the data being generated. Biologists were waiting for data scientists and bioinformaticians to help them, but those people didn’t always understand the biology at a deep enough level.”The situation looked familiar to Wang.“It was exactly like what we saw in finance, where researchers were trying to work with engineers, but the engineers never fully understood, and you had all this inefficiency with people waiting on the engineers,” Wang says. “Meanwhile, I learned the biologists are hungry to run these experiments, but there is such a big gap they felt they had to become a software engineer or just focus on the science.”Wang officially founded Watershed in 2019 with physician Mark Kalinich ’13, a former classmate at MIT who is no longer involved in day-to-day operations of the company.Wang has since heard from biotech and pharmaceutical executives about the growing complexity of biology research. Unlocking new insights increasingly involves analyzing data from entire genomes, population studies, RNA sequencing, mass spectrometry, and more. Developing personalized treatments or selecting patient populations for a clinical study can also require huge datasets, and there are new ways to analyze data being published in scientific journals all the time.Today, companies can run large-scale analyses on Watershed without having to set up their own servers or cloud computing accounts. Researchers can use ready-made templates that work with all the most common data types to accelerate their work. Popular AI-based tools like AlphaFold and Geneformer are also available, and Watershed’s platform makes sharing workflows and digging deeper into results easy.“The platform hits a sweet spot of usability and customizability for people of all backgrounds,” Wang says. “No science is ever truly the same. I avoid the word product because that implies you deploy something and then you just run it at scale forever. Research isn’t like that. Research is about coming up with an idea, testing it, and using the outcome to come up with another idea. The faster you can design, implement, and execute experiments, the faster you can move on to the next one.”Accelerating biologyWang believes Watershed is helping biologists keep up with the latest advances in biology and accelerating scientific discovery in the process.“If you can help scientists unlock insights not a little bit faster, but 10 or 20 times faster, it can really make a difference,” Wang says.Watershed is being used by researchers in academia and in companies of all sizes. Executives at biotech and pharmaceutical companies also use Watershed to make decisions about new experiments and drug candidates.“We’ve seen success in all those areas, and the common thread is people understanding research but not being an expert in computer science or software engineering,” Wang says. “It’s exciting to see this industry develop. For me, it’s great being from MIT and now to be back in Kendall Square where Watershed is based. This is where so much of the cutting-edge progress is happening. We’re trying to do our part to enable the future of biology.”", "release_time": "2025-10-15", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/helping-scientists-run-complex-data-analyses-without-writing-code-1014"}
{"category": "研究前沿", "title": "MIT学者获Packard奖学金研究土壤微生物代谢物", "short_summary": "MIT两位学者获Packard奖学金，将探索土壤微生物代谢物对农业生态的影响。", "detailed_summary": "MIT两位学者获Packard奖学金，将探索土壤微生物代谢物对农业生态的影响。\n（1）Darcy McRose教授与Mehtaab Sawhney博士获2025年Packard科学工程奖学金；\n（2）McRose研究土壤微生物释放的次级代谢物如何影响植物根系微生物群落；\n（3）研究整合遗传学、化学和地球科学技术探索土壤肥力机制；\n（4）成果有望促进可持续农业发展并改善作物抗病能力；\n（5）获奖者将获得87.5万美元研究经费支持创新探索。", "raw_content": "The David and Lucile Packard Foundation has announced that two MIT affiliates have been named 2025 Packard Fellows for Science and Engineering. Darcy McRose, the Thomas D. and Virginia W. Cabot Career Development Assistant Professor in the MIT Department of Civil and Environmental Engineering, has been honored, along with Mehtaab Sawhney ’20, PhD ’24, a graduate of the Department of Mathematics who is now at Columbia University. The honorees are among 20 junior faculty named among the nation’s most innovative early-career scientists and engineers. Each Packard Fellow receives an unrestricted research grant of $875,000 over five years to support their pursuit of pioneering research and bold new ideas.“I’m incredibly grateful and honored to be awarded a Packard Fellowship,” says McRose. “It will allow us to continue our work exploring how small molecules control microbial communities in soils and on plant roots, with much-appreciated flexibility to follow our imagination wherever it leads us.”McRose and her lab study secondary metabolites — small organic molecules that microbes and plants release into soils. Often known as antibiotics, these compounds do far more than fight infections; they can help unlock soil nutrients, shape microbial communities around plant roots, and influence soil fertility.“Antibiotics made by soil microorganisms are widely used in medicine, but we know surprisingly little about what they do in nature,” explains McRose. “Just as healthy microbiomes support human health, plant microbiomes support plant health, and secondary metabolites can help to regulate the microbial community, suppressing pathogens and promoting beneficial microbes.” Her lab integrates techniques from genetics, chemistry, and geosciences to investigate how these molecules shape interactions between microbes and plants in soil — one of Earth’s most complex and least-understood environments. By using secondary metabolites as experimental tools, McRose aims to uncover the molecular mechanisms that govern processes like soil fertility and nutrient cycling that are foundational to sustainable agriculture and ecosystem health.Studying antibiotics in the environments where they evolved could also yield new strategies for combating soil-borne pathogens and improving crop resilience. “Soil is a true scientific frontier,” McRose says. “Studying these environments has the potential to reveal fascinating, fundamental insights into microbial life — many of which we can’t even imagine yet.”A native of California, McRose earned her bachelor’s and master’s degrees from Stanford University, followed by a PhD in geosciences from Princeton University. Her graduate thesis focused on how bacteria acquire trace metals from the environment. Her postdoctoral research on secondary metabolites at Caltech was supported by multiple fellowships, including the Simons Foundation Marine Microbial Ecology Postdoctoral Fellowship, the L’Oréal USA For Women in Science Fellowship, and a Division Fellowship from Biology and Biological Engineering at Caltech.McRose joined the MIT faculty in 2022. In 2025, she was named a Sloan Foundation Research Fellow in Earth System Science and awarded the Maseeh Excellence in Teaching Award.Past Packard Fellows have gone on to earn the highest honors, including Nobel Prizes in chemistry and physics, the Fields Medal, Alan T. Waterman Awards, Breakthrough Prizes, Kavli Prizes, and elections to the National Academies of Science, Engineering, and Medicine. Each year, the foundation reviews 100 nominations for consideration from 50 invited institutions. The Packard Fellowships Advisory Panel, a group of 12 internationally recognized scientists and engineers, evaluates the nominations and recommends 20 fellows for approval by the Packard Foundation Board of Trustees.", "release_time": "2025-10-16", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/darcy-mcrose-mehtaab-sawhney-named-packard-fellows-1015"}
{"category": "产业应用", "title": "美韩企业合作开发灰鹰短距起降无人机系统", "short_summary": "通用原子与韩华航空合作开发灰鹰STOL无人机，实现快速部署与跑道独立起降。", "detailed_summary": "通用原子与韩华航空合作开发灰鹰STOL无人机，实现快速部署与跑道独立起降。\n（1）通用原子航空系统公司与韩华航空航天公司签署协议，合作开发和生产“灰鹰”短距起降无人机系统；\n（2）该无人机具备跑道独立性，可在简易场地起降，计划2027年首飞、2028年交付；\n（3）项目将在韩国设立生产线，结合双方技术优势加速产品部署；\n（4）灰鹰STOL是同级中唯一具备真正跑道独立性的中空长航时无人机；\n（5）合作旨在通过国际成本分摊降低风险，推动下一代无人机解决方案发展。", "raw_content": "Partnership Will Enable Cost Savings By Manufacturing Unique and Flexible UAS Platform in South Korea SAN DIEGO – 14 October 2025 – General Atomics Aeronautical Systems, Inc. (GA-ASI) and South Korea industry leader Hanwha Aerospace signed an agreement on October 14 to partner in development of the Gray Eagle® Short Takeoff and Landing (GE STOL) unmanned aircraft system (UAS). This landmark agreement marks the beginning of a new phase in U.S.-Korea defense cooperation, extending beyond traditional alliance structures to deliver next-generation, runway-independent UAS solutions that maximize commanders’ options in the face of evolving mission demands. The deal marks the beginning of a co-development and co-production program between GA-ASI and Hanwha, with work set to begin immediately. The GE STOL will be offered to a worldwide customer base, including South Korea Ministry of Defense and the United States War Department. Under the agreement, the two companies will design and build a production representative GE STOL. The maiden flight is scheduled for 2027 and first delivery to customers in 2028. With a GA-ASI-funded prototype already flying, the program has demonstrated its ability to accelerate from development to delivery. By leveraging the trusted Gray Eagle foundation and forward-leaning investments, the partnership offers the fastest path with lowest risk to operational capability. GA-ASI and Hanwha Aerospace will work closely throughout the design phase and establish a production facility in South Korea for final assembly and manufacturing of the GE STOL, with GA-ASI handling the final integration. GA-ASI will continue to produce its other Gray Eagle models in San Diego. “GA-ASI and Hanwha are committed to investing in this project and building development and production capabilities in South Korea,” said GA-ASI President David R. Alexander. “We’ll be leveraging the expertise of both companies to quickly bring the Gray Eagle STOL to global customers.” Gray Eagle STOL is the only medium-altitude, long-endurance UAS in its class to offer true runway independence by operating from semi-improved surfaces, including dirt roads, open fields, beaches, and parking lots. This exponentially increases its operational employment by providing multi-mission capability for Reconnaissance, Surveillance, and Target Acquisition (RSTA), counter UAS, and other missions including Manned-Unmanned Teaming (MUM-T) while leveraging GE STOL’s modular open systems approach. Using the GE STOL demonstrator, called Mojave, GA-ASI recorded several first-of-their-kind aviation milestones, including a 2024 demonstration when GA-ASI and Hanwha flew Mojave from the South Korean Navy’s amphibious landing ship ROKS Dokdo (LPH-6111) as it was underway at sea off the coast of Pohang, South Korea. It has also been launched and recovered aboard the British aircraft carrier HMS Prince of Wales (2023), performed live-fire testing at Yuma Proving Ground, Arizona (2024), and performed dirt strip operations (2023) underscoring GA-ASI’s advances in runway independence and operational flexibility. The initiative is part of Hanwha’s strategic investment plan in its UAS business. This commitment, together with GA-ASI’s continued focus on UAS, demonstrates both companies’ strategy to invest ahead of customer demand, reducing risk and lowering lifecycle costs through international cost-sharing, and ensuring timely delivery of next-generation UAS solutions in Korea and abroad. “Jointly producing GE STOL in South Korea and the U.S. will create jobs and help Hanwha secure talent in related fields as well as foster our domestic (Korean) UAS industry ecosystem. Hanwha is poised to become a comprehensive UAS company capable of executing everything from design to production and maintenance based on our capabilities, which span from fighter jet engines to radar and avionics equipment,” said Mr. Jae-il Son, President and CEO of Hanwha Aerospace. Together, GA-ASI and Hanwha are delivering a low-risk, investment-backed, and innovation-driven UAS solution that provides commanders unmatched flexibility faster and at lower cost. About GA-ASI General Atomics Aeronautical Systems, Inc., is the world’s foremost builder of Unmanned Aircraft Systems (UAS). Logging more than 9 million flight hours, the Predator® line of UAS has flown for over 30 years and includes MQ-9A Reaper®, MQ-1C Gray Eagle®, MQ-20 Avenger®, and MQ-9B SkyGuardian®/SeaGuardian®. The company is dedicated to providing long-endurance, multi-mission solutions that deliver persistent situational awareness and rapid strike. For more information, visit www.ga-asi.com      Avenger, EagleEye, Gray Eagle, Lynx, Predator, Reaper, SeaGuardian, and SkyGuardian are trademarks of General Atomics Aeronautical Systems, Inc., registered in the United States and/or other countries.", "release_time": "2025-10-15", "source_institution": "通用原子能公司", "url": "http://www.ga.com/ga-asi-and-hanwha-finalize-deal-to-produce-gray-eagle-stol-uas"}
{"category": "研究前沿", "title": "科学家发现45亿年前原始地球物质残留", "short_summary": "MIT团队通过钾同位素分析，首次确认地球深处存在原始形成时期的未改变物质。", "detailed_summary": "MIT团队通过钾同位素分析，首次确认地球深处存在原始形成时期的未改变物质。\n(1) MIT等机构科学家在《自然·地球科学》发表研究，首次发现45亿年前原始地球的物质残留证据。\n(2) 研究通过分析古老深层岩石样本中的钾同位素异常，特别是钾-40同位素缺失，识别出不同于现今地球大部分物质的化学特征。\n(3) 这一发现表明原始地球的某些物质在巨大撞击事件后得以保存，挑战了地球内部被完全重置的传统观点，并对理解地球和太阳系早期形成过程具有重要意义。", "raw_content": "Scientists at MIT and elsewhere have discovered extremely rare remnants of “proto Earth,” which formed about 4.5 billion years ago, before a colossal collision irreversibly altered the primitive planet’s composition and produced the Earth as we know today. Their findings, reported today in the journal Nature Geosciences, will help scientists piece together the primordial starting ingredients that forged the early Earth and the rest of the solar system.Billions of years ago, the early solar system was a swirling disk of gas and dust that eventually clumped and accumulated to form the earliest meteorites, which in turn merged to form the proto Earth and its neighboring planets.In this earliest phase, Earth was likely rocky and bubbling with lava. Then, less than 100 million years later, a Mars-sized meteorite slammed into the infant planet in a singular “giant impact” event that completely scrambled and melted the planet’s interior, effectively resetting its chemistry. Whatever original material the proto Earth was made from was thought to have been altogether transformed.But the MIT team’s findings suggest otherwise. The researchers have identified a chemical signature in ancient rocks that is unique from most other materials found in the Earth today. The signature is in the form of a subtle imbalance in potassium isotopes discovered in samples of very old and very deep rocks. The team determined that the potassium imbalance could not have been produced by any previous large impacts or geological processes occurring in the Earth presently.The most likely explanation for the samples’ chemical composition is that they must be leftover material from the proto Earth that somehow remained unchanged, even as most of the early planet was impacted and transformed.“This is maybe the first direct evidence that we’ve preserved the proto Earth materials,” says Nicole Nie, the Paul M. Cook Career Development Assistant Professor of Earth and Planetary Sciences at MIT. “We see a piece of the very ancient Earth, even before the giant impact. This is amazing because we would expect this very early signature to be slowly erased through Earth’s evolution.”The study’s other authors include Da Wang of Chengdu University of Technology in China, Steven Shirey and Richard Carlson of the Carnegie Institution for Science in Washington, Bradley Peters of ETH Zürich in Switzerland, and James Day of Scripps Institution of Oceanography in California.A curious anomalyIn 2023, Nie and her colleagues analyzed many of the major meteorites that have been collected from sites around the world and carefully studied. Before impacting the Earth, these meteorites likely formed at various times and locations throughout the solar system, and therefore represent the solar system’s changing conditions over time. When the researchers compared the chemical compositions of these meteorite samples to Earth, they identified among them a “potassium isotopic anomaly.”Isotopes are slightly different versions of an element that have the same number of protons but a different number of neutrons. The element potassium can exist in one of three naturally-occurring isotopes, with mass numbers (protons plus neutrons) of 39, 40, and 41, respectively. Wherever potassium has been found on Earth, it exists in a characteristic combination of isotopes, with potassium-39 and potassium-41 being overwhelmingly dominant. Potassium-40 is present, but at a vanishingly small percentage in comparison.Nie and her colleagues discovered that the meteorites they studied showed balances of potassium isotopes that were different from most materials on Earth. This potassium anomaly suggested that any material that exhibits a similar anomaly likely predates Earth’s present composition. In other words, any potassium imbalance would be a strong sign of material from the proto Earth, before the giant impact reset the planet’s chemical composition.“In that work, we found that different meteorites have different potassium isotopic signatures, and that means potassium can be used as a tracer of Earth’s building blocks,” Nie explains.“Built different”In the current study, the team looked for signs of potassium anomalies not in meteorites, but within the Earth. Their samples include rocks, in powder form, from Greenland and Canada, where some of the oldest preserved rocks are found. They also analyzed lava deposits collected from Hawaii, where volcanoes have brought up some of the Earth’s earliest, deepest materials from the mantle (the planet’s thickest layer of rock that separates the crust from the core).“If this potassium signature is preserved, we would want to look for it in deep time and deep Earth,” Nie says.The team first dissolved the various powder samples in acid, then carefully isolated any potassium from the rest of the sample and used a special mass spectrometer to measure the ratio of each of potassium’s three isotopes. Remarkably, they identified in the samples an isotopic signature that was different from what’s been found in most materials on Earth.Specifically, they identified a deficit in the potassium-40 isotope. In most materials on Earth, this isotope is already an insignificant fraction compared to potassium’s other two isotopes. But the researchers were able to discern that their samples contained an even smaller percentage of potassium-40. Detecting this tiny deficit is like spotting a single grain of brown sand in a bucket rather than a scoop full of of yellow sand.The team found that, indeed, the samples exhibited the potassium-40 deficit, showing that the materials “were built different,” says Nie, compared to most of what we see on Earth today.But could the samples be rare remnants of the proto Earth? To answer this, the researchers assumed that this might be the case. They reasoned that if the proto Earth were originally made from such potassium-40-deficient materials, then most of this material would have undergone chemical changes — from the giant impact and subsequent, smaller meteorite impacts — that ultimately resulted in the materials with more potassium-40 that we see today. The team used compositional data from every known meteorite and carried out simulations of how the samples’ potassium-40 deficit would change following impacts by these meteorites and by the giant impact. They also simulated geological processes that the Earth experienced over time, such as the heating and mixing of the mantle. In the end, their simulations produced a composition with a slightly higher fraction of potassium-40 compared to the samples from Canada, Greenland, and Hawaii. More importantly, the simulated compositions matched those of most modern-day materials.The work suggests that materials with a potassium-40 deficit are likely leftover original material from the proto Earth.Curiously, the samples’ signature isn’t a precise match with any other meteorite in geologists’ collections. While the meteorites in the team’s previous work showed potassium anomalies, they aren’t exactly the deficit seen in the proto Earth samples. This means that whatever meteorites and materials originally formed the proto Earth have yet to be discovered.“Scientists have been trying to understand Earth’s original chemical composition by combining the compositions of different groups of meteorites,” Nie says. “But our study shows that the current meteorite inventory is not complete, and there is much more to learn about where our planet came from.”This work was supported, in part, by NASA and MIT.", "release_time": "2025-10-14", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/geologists-discover-first-evidence-45-billion-year-old-proto-earth-1014"}
{"category": "产业应用", "title": "MIT研发AI虚拟光谱仪，加速材料质量验证", "short_summary": "SpectroGen AI工具实现光谱模态转换，大幅提升材料检测效率与降低成本。", "detailed_summary": "SpectroGen AI工具实现光谱模态转换，大幅提升材料检测效率与降低成本。\n（1）MIT工程师开发生成式AI工具\"SpectroGen\"，可作为虚拟光谱仪使用；\n（2）该工具能够将材料的一种光谱模态（如红外）转换为另一种模态（如X射线）；\n（3）生成结果与物理仪器扫描匹配度达99%，耗时从数小时缩短至1分钟以内；\n（4）技术基于数学方法解读光谱波形，无需复杂分子结构分析；\n（5）应用前景涵盖制药、半导体、电池制造等行业的质量控制流程优化。", "raw_content": "Manufacturing better batteries, faster electronics, and more effective pharmaceuticals depends on the discovery of new materials and the verification of their quality. Artificial intelligence is helping with the former, with tools that comb through catalogs of materials to quickly tag promising candidates.But once a material is made, verifying its quality still involves scanning it with specialized instruments to validate its performance — an expensive and time-consuming step that can hold up the development and distribution of new technologies.Now, a new AI tool developed by MIT engineers could help clear the quality-control bottleneck, offering a faster and cheaper option for certain materials-driven industries.In a study appearing today in the journal Matter, the researchers present “SpectroGen,” a generative AI tool that turbocharges scanning capabilities by serving as a virtual spectrometer. The tool takes in “spectra,” or measurements of a material in one scanning modality, such as infrared, and generates what that material’s spectra would look like if it were scanned in an entirely different modality, such as X-ray. The AI-generated spectral results match, with 99 percent accuracy, the results obtained from physically scanning the material with the new instrument.Certain spectroscopic modalities reveal specific properties in a material: Infrared reveals a material’s molecular groups, while X-ray diffraction visualizes the material’s crystal structures, and Raman scattering illuminates a material’s molecular vibrations. Each of these properties is essential in gauging a material’s quality and typically requires tedious workflows on multiple expensive and distinct instruments to measure.With SpectroGen, the researchers envision that a diversity of measurements can be made using a single and cheaper physical scope. For instance, a manufacturing line could carry out quality control of materials by scanning them with a single infrared camera. Those infrared spectra could then be fed into SpectroGen to automatically generate the material’s X-ray spectra, without the factory having to house and operate a separate, often more expensive X-ray-scanning laboratory.The new AI tool generates spectra in less than one minute, a thousand times faster compared to traditional approaches that can take several hours to days to measure and validate.“We think that you don’t have to do the physical measurements in all the modalities you need, but perhaps just in a single, simple, and cheap modality,” says study co-author Loza Tadesse, assistant professor of mechanical engineering at MIT. “Then you can use SpectroGen to generate the rest. And this could improve productivity, efficiency, and quality of manufacturing.”The study’s lead author is former MIT postdoc Yanmin Zhu.Beyond bondsTadesse’s interdisciplinary group at MIT pioneers technologies that advance human and planetary health, developing innovations for applications ranging from rapid disease diagnostics to sustainable agriculture.“Diagnosing diseases, and material analysis in general, usually involves scanning samples and collecting spectra in different modalities, with different instruments that are bulky and expensive and that you might not all find in one lab,” Tadesse says. “So, we were brainstorming about how to miniaturize all this equipment and how to streamline the experimental pipeline.”Zhu noted the increasing use of generative AI tools for discovering new materials and drug candidates, and wondered whether AI could also be harnessed to generate spectral data. In other words, could AI act as a virtual spectrometer?A spectroscope probes a material’s properties by sending light of a certain wavelength into the material. That light causes molecular bonds in the material to vibrate in ways that scatter the light back out to the scope, where the light is recorded as a pattern of waves, or spectra, that can then be read as a signature of the material’s structure.For AI to generate spectral data, the conventional approach would involve training an algorithm to recognize connections between physical atoms and features in a material, and the spectra they produce. Given the complexity of molecular structures within just one material, Tadesse says such an approach can quickly become intractable.“Doing this even for just one material is impossible,” she says. “So, we thought, is there another way to interpret spectra?”The team found an answer with math. They realized that a spectral pattern, which is a sequence of waveforms, can be represented mathematically. For instance, a spectrum that contains a series of bell curves is known as a “Gaussian” distribution, which is associated with a certain mathematical expression, compared to a series of narrower waves, known as a “Lorentzian” distribution, that is described by a separate, distinct algorithm. And as it turns out, for most materials infrared spectra characteristically contain more Lorentzian waveforms, while Raman spectra are more Gaussian, and X-ray spectra is a mix of the two.Tadesse and Zhu worked this mathematical interpretation of spectral data into an algorithm that they then incorporated into a generative AI model.“It’s a physics-savvy generative AI that understands what spectra are,” Tadesse says. “And the key novelty is, we interpreted spectra not as how it comes about from chemicals and bonds, but that it is actually math — curves and graphs, which an AI tool can understand and interpret.”Data co-pilotThe team demonstrated their SpectroGen AI tool on a large, publicly available dataset of over 6,000 mineral samples. Each sample includes information on the mineral’s properties, such as its elemental composition and crystal structure. Many samples in the dataset also include spectral data in different modalities, such as X-ray, Raman, and infrared. Of these samples, the team fed several hundred to SpectroGen, in a process that trained the AI tool, also known as a neural network, to learn correlations between a mineral’s different spectral modalities. This training enabled SpectroGen to take in spectra of a material in one modality, such as in infrared, and generate what a spectra in a totally different modality, such as X-ray, should look like.Once they trained the AI tool, the researchers fed SpectroGen spectra from a mineral in the dataset that was not included in the training process. They asked the tool to generate a spectra in a different modality, based on this “new” spectra. The AI-generated spectra, they found, was a close match to the mineral’s real spectra, which was originally recorded by a physical instrument. The researchers carried out similar tests with a number of other minerals and found that the AI tool quickly generated spectra, with 99 percent correlation.“We can feed spectral data into the network and can get another totally different kind of spectral data, with very high accuracy, in less than a minute,” Zhu says.The team says that SpectroGen can generate spectra for any type of mineral. In a manufacturing setting, for instance, mineral-based materials that are used to make semiconductors and battery technologies could first be quickly scanned by an infrared laser. The spectra from this infrared scanning could be fed into SpectroGen, which would then generate a spectra in X-ray, which operators or a multiagent AI platform can check to assess the material’s quality.“I think of it as having an agent or co-pilot, supporting researchers, technicians, pipelines and industry,” Tadesse says. “We plan to customize this for different industries’ needs.”The team is exploring ways to adapt the AI tool for disease diagnostics, and for agricultural monitoring through an upcoming project funded by Google. Tadesse is also advancing the technology to the field through a new startup and envisions making SpectroGen available for a wide range of sectors, from pharmaceuticals to semiconductors to defense.", "release_time": "2025-10-15", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/checking-quality-materials-just-got-easier-new-ai-tool-1014"}
{"category": "研究前沿", "title": "光伏直连铁路电网技术研究取得突破", "short_summary": "德国研究证实光伏可直供铁路电网，年发电潜力远超需求，专用逆变器效率达96.6%。", "detailed_summary": "德国研究证实光伏可直供铁路电网，年发电潜力远超需求，专用逆变器效率达96.6%。\n(1) 研究背景：德国铁路电网目前尚无直接供电的光伏系统，但沿线光伏发电潜力巨大。\n(2) 潜力评估：仅在变电站两公里范围内，光伏装机潜力达37.6GWp，年发电量约3.3万GWh，远超2023年铁路总用电量（7,500GWh）。\n(3) 技术突破：项目开发出适用于16.7Hz铁路电网的2MW中央逆变器，测试效率达96.6%，并制定了电网形成运行规范。\n(4) 连接方案：根据系统规模（5MW至40MW）设计了不同的并网配置，其中12MW以下系统经济性最佳。\n(5) 项目意义：为德国铁路绿色供电提供技术路径，获联邦经济能源部资助，后续将进行实地测试。", "raw_content": "Currently, generating facilities with a capacity of about two gigawatts (GW) are installed on the Deutsche Bahn grid. These are primarily conventional power plants and hydroelectric plants. However, PV systems directly feeding into the railway power grid are not yet in operation in Germany. \"A relevant part of the energy demand in the railway power grid could be covered by photovoltaics, as the PV area potential along the railway lines is many times higher than the amount of energy needed in the railway power grid,\" explains Andreas Hensel, project manager of “PV4Rail” at Fraunhofer ISE. The project team identified suitable areas nationwide and examined their potential with detailed simulations. Even when only areas within a two-kilometer radius of a railway substation were considered, the possible installable rated capacity was 37.6 GWp, and the potential energy yield was 32,920 GWh annually. The electricity demand for train operations in total was around 7,500 GWh in 2023. Inverters developed for direct feed-in Since the railway network operates at a frequency of 16.7 Hz instead of the public grid's 50 Hz, the project partner Vensys Elektrotechnik GmbH developed a central inverter with a capacity of 2 MW, which is divided into two symmetrical power parts of 1 MW each. One of the power parts was tested in the multi-megawatt lab at Fraunhofer ISE, achieving an efficiency of 96.6 percent (including self-consumption for cooling, etc.). Fraunhofer ISE also developed regulations for the grid-forming operation of the inverters in the railway grid. For the connection execution, the team considered various connection configurations depending on the size of the installation: while smaller systems up to 5 MW can feed directly into the overhead line, capacities up to 12 MW are fed into substations via the busbar. This variant shows the least differences in terms of LCOE costs compared to 50 Hz systems. For larger systems up to 40 MW, a dedicated substation with a transformer and switching station must generally be constructed for connection to the 110 kV railway grid. So far, railway power PV systems in Germany are limited to pilot initiatives. In Austria, several systems with more than 10 MWp capacity have already been put into operation on the grid. However, the grid connection conditions at ÖBB differ from those of Deutsche Bahn. Due to the operational requirements of the railway power grid and the compatibility of inverters with control and safety technology, only grid-forming inverters can be used by DB. Grid-forming behavior has already been tested in a simulation environment by researchers at Fraunhofer ISE and could be implemented in a follow-up project. The Fraunhofer ISE enables the development and characterization of inverters in the multi-megawatt range at its Center for Power Electronics and Sustainable Grids. The project was funded by the Federal Ministry for Economic Affairs and Energy.", "release_time": "2025-10-14", "source_institution": "德国弗劳恩霍夫协会太阳能系统研究所", "url": "http://www.ise.fraunhofer.de/en/press-media/press-releases/2025/energy-transition-in-the-railway-power-grid-direct-feed-in-of-solar-power-through-innovative-inverters.html"}
{"category": "产业应用", "title": "澳煤供应中断促俄罗斯扩大韩国市场份额", "short_summary": "澳大利亚煤炭发货延迟，俄罗斯连续两月成韩国最大能源煤供应国，价格优势明显。", "detailed_summary": "澳大利亚煤炭发货延迟，俄罗斯连续两月成韩国最大能源煤供应国，价格优势明显。\n（1）澳大利亚主要港口发货延迟，导致其对韩国能源煤供应中断；\n（2）俄罗斯连续两个月成为韩国能源煤最大供应国，8月出口量同比增长54.6%至376万吨；\n（3）印尼煤炭出口量同步增长50.1%至374万吨，而澳大利亚出口量同比下降；\n（4）俄罗斯煤炭价格优势显著（82美元/吨），低于澳大利亚的101.8美元/吨；\n（5）分析预计俄罗斯供应增长趋势将持续，受冬季库存积累和澳洲不确定性支撑。", "raw_content": "分析人士预计，澳大利亚对韩国能源煤供应的中断可能使俄罗斯煤炭商继续扩大市场份额。俄罗斯连续两个月在向韩国买家运送这种燃料方面排名第一。 澳大利亚主要港口的延迟发货使俄罗斯和印度尼西亚扩大了韩国能源煤炭市场的份额，这一趋势可能会持续下去，Neft Research在一份报告中表示。8月，俄罗斯能源煤炭出口量增长54.6%，达到376万吨。根据标准普尔全球商品洞察(S&P Global Commodity Insights)的数据，印度尼西亚的出口量增长了50.1%，至374万吨，澳大利亚的出口量同比下降了3.76%，至7月下降了26.76%，至270万吨。 俄罗斯今年7月成为韩国能源煤炭供应的领头羊，当时俄罗斯煤炭企业向韩国市场供应了270万吨固体燃料，这是2022年以来的最高月度供应量。 “至少在未来几个月内，俄罗斯煤炭供应的增长趋势将持续下去，因为澳大利亚的替代品价格正在下跌，竞争力明显增强。Neft Research的咨询合伙人Alexander Kotov说：“此外，也观察到澳洲煤炭货运中断。”。根据NEFT Research的数据，截至9月19日，澳大利亚东部6000大卡的能源煤炭价格为101.8美元/吨，俄罗斯同类煤炭价格为82美元/吨。据估计，印尼煤炭的热量为每公斤5500千卡，75.3美元/吨。 Lysenko预测，2025年第四季度俄罗斯供应量将适度增长：冬季季节性库存积累和澳大利亚方向的持续不确定性将支撑俄罗斯和韩国的煤炭贸易，但这种增长可能是有限的。", "release_time": "2025-10-14", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194829-1.html"}
{"category": "研究前沿", "title": "MIT研究揭示地震后地壳恢复存在深度差异", "short_summary": "MIT研究发现浅层地壳震后快速愈合，而中地壳却发生永久性改变。", "detailed_summary": "MIT研究发现浅层地壳震后快速愈合，而中地壳却发生永久性改变。\n(1) MIT研究发表于《科学》杂志，挑战地壳震后平滑恢复的传统认知。\n(2) 基于2019年加州Ridgecrest地震序列数据，通过分析地震波速度变化绘制地壳图。\n(3) 研究发现浅层地壳（约10公里内）在数月内快速愈合恢复原状。\n(4) 中地壳未立即受损，但在浅层恢复期间发生缓慢且可能是永久性的改变。\n(5) 此发现对理解地震能量预算至关重要，未来需研究成熟断层及更长时间尺度。", "raw_content": "Earthquakes often bring to mind images of destruction, of the Earth breaking open and altering landscapes. But after an earthquake, the area around it undergoes a period of post-seismic deformation, where areas that didn’t break experience new stress as a result of the sudden change in the surroundings. Once it has adjusted to this new stress, it reaches a state of recovery.Geologists have often thought that this recovery period was a smooth, continuous process. But MIT research published recently in Science has found evidence that while healing occurs quickly at shallow depths — roughly above 10 km — deeper depths recover more slowly, if at all.“If you were to look before and after in the shallow crust, you wouldn’t see any permanent change. But there’s this very permanent change that persists in the mid-crust,” says Jared Bryan, a graduate student in the MIT Department of Earth, Atmospheric and Planetary Sciences (EAPS) and lead author on the paper.The paper’s other authors include EAPS Professor William Frank and Pascal Audet from the University of Ottawa.Everything but the quakesIn order to assemble a full understanding of how the crust behaves before, during, and after an earthquake sequence, the researchers looked at seismic data from the 2019 Ridgecrest earthquakes in California. This immature fault zone experienced the largest earthquake in the state in 20 years, and tens of thousands of aftershocks over the following year. They then removed seismic data created by the sequence and only looked at waves generated by other seismic activity around the world to see how their paths through the Earth changed before and after the sequence.“One person’s signal is another person’s noise,” says Bryan. They also used general ambient noise from sources like ocean waves and traffic that are also picked up by seismometers. Then, using a technique called a receiver function, they were able to see the speed of the waves as they traveled and how it changed due to conditions in the Earth such as rock density and porosity, much in the same way we use sonar to see how acoustic waves change when they interact with objects. With all this information, they were able to construct basic maps of the Earth around the Ridgecrest fault zone before and after the sequence.What they found was that the shallow crust, extending about 10 km into the Earth, recovered over the course of a few months. In contrast, deeper depths in the mid-crust didn’t experience immediate damage, but rather changed over the same timescale as shallow depths recovered.“What was surprising is that the healing in the shallow crust was so quick, and then you have this complementary accumulation occurring, not at the time of the earthquake, but instead over the post-seismic phase,” says Bryan.Balancing the energy budgetUnderstanding how recovery plays out at different depths is crucial for determining how energy is spent during different parts of the seismic process, which includes activities such as the release of energy as waves, the creation of new fractures, or energy being stored elastically in the surrounding areas. Altogether, this is collectively known as the energy budget, and it is a useful tool for understanding how damage accumulates and recovers over time.What remains unclear is the timescales at which deeper depths recover, if at all. The paper presents two possible scenarios to explain why that might be: one in which the deep crust recovers over a much longer timescale than they observed, or one where it never recovers at all.“Either of those are not what we expected,” says Frank. “And both of them are interesting.”Further research will require more observations to build out a more detailed picture to see at what depth the change becomes more pronounced. In addition, Bryan wants to look at other areas, such as more mature faults that experience higher levels of seismic activity, to see if it changes the results.“We’ll let you know in 1,000 years whether it’s recovered,” says Bryan.", "release_time": "2025-10-15", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/earthquake-damage-deeper-depths-occurs-long-after-initial-activity-1014"}
{"category": "研究前沿", "title": "MIT研究利用数据算法优化印度食物补贴政策", "short_summary": "MIT学者通过扫描印度杂货店交易数据，开发算法优化食物援助计划设计。", "detailed_summary": "MIT学者通过扫描印度杂货店交易数据，开发算法优化食物援助计划设计。\n（1）MIT研究员Ali Aouad获J-WAFS种子基金资助，研究食物补贴优化设计；\n（2）项目收集印度本地杂货店交易数据，开发算法推断消费者偏好；\n（3）旨在通过优化方法为食物援助政策提供新方法论支持；\n（4）面临数据收集成本高和长期行为影响难以衡量等挑战；\n（5）研究成果有望提升粮食安全，但大规模应用仍需克服实施障碍。", "raw_content": "Oct. 16 is World Food Day, a global campaign to celebrate the founding of the Food and Agriculture Organization 80 years ago, and to work toward a healthy, sustainable, food-secure future. More than 670 million people in the world are facing hunger. Millions of others are facing rising obesity rates and struggle to get healthy food for proper nutrition. World Food Day calls on not only world governments, but business, academia, the media, and even the youth to take action to promote resilient food systems and combat hunger. This year, the Abdul Latif Jameel Water and Food Systems Laboratory (J-WAFS) is spotlighting an MIT researcher who is working toward this goal by studying food and water systems in the Global South.J-WAFS seed grants provide funding to early-stage research projects that are unique to prior work. In an 11th round of seed grant funding in 2025, 10 MIT faculty members received support to carry out their cutting-edge water and food research. Ali Aouad PhD ’17, assistant professor of operations management at the MIT Sloan School of Management, was one of those grantees. “I had searched before joining MIT what kind of research centers and initiatives were available that tried to coalesce research on food systems,” Aouad says. “And so, I was very excited about J-WAFS.” Aouad gathered more information about J-WAFS at the new faculty orientation session in August 2024, where he spoke to J-WAFS staff and learned about the program’s grant opportunities for water and food research. Later that fall semester, he attended a few J-WAFS seminars on agricultural economics and water resource management. That’s when Aouad knew that his project was perfectly aligned with the J-WAFS mission of securing humankind’s water and food.Aouad’s seed project focuses on food subsidies. With a background in operations research and an interest in digital platforms, much of his work has centered on aligning supply-side operations with heterogeneous customer preferences. Past projects include ones on retail and matching systems. “I started thinking that these types of demand-driven approaches may be also very relevant to important social challenges, particularly as they relate to food security,” Aouad says. Before starting his PhD at MIT, Aouad worked on projects that looked at subsidies for smallholder farmers in low- and middle-income countries. “I think in the back of my mind, I've always been fascinated by trying to solve these issues,” he noted.His seed grant project, Optimal subsidy design: Application to food assistance programs, aims to leverage data on preferences and purchasing habits from local grocery stores in India to inform food assistance policy and optimize the design of subsidies. Typical data collection systems, like point-of-sales, are not as readily available in India’s local groceries, making this type of data hard to come by for low-income individuals. “Mom-and-pop stores are extremely important last-mile operators when it comes to nutrition,” he explains. For this project, the research team gave local grocers point-of-sale scanners to track purchasing habits. “We aim to develop an algorithm that converts these transactions into some sort of ‘revelation’ of the individuals’ latent preferences,” says Aouad. “As such, we can model and optimize the food assistance programs — how much variety and flexibility is offered, taking into account the expected demand uptake.” He continues, “now, of course, our ability to answer detailed design questions [across various products and prices] depends on the quality of our inference from  the data, and so this is where we need more sophisticated and robust algorithms.”Following the data collection and model development, the ultimate goal of this research is to inform policy surrounding food assistance programs through an “optimization approach.” Aouad describes the complexities of using optimization to guide policy. “Policies are often informed by domain expertise, legacy systems, or political deliberation. A lot of researchers build rigorous evidence to inform food policy, but it’s fair to say that the kind of approach that I’m proposing in this research is not something that is commonly used. I see an opportunity for bringing a new approach and methodological tradition to a problem that has been central for policy for many decades.” The overall health of consumers is the reason food assistance programs exist, yet measuring long-term nutritional impacts and shifts in purchase behavior is difficult. In past research, Aouad notes that the short-term effects of food assistance interventions can be significant. However, these effects are often short-lived. “This is a fascinating question that I don’t think we will be able to address within the space of interventions that we will be considering. However, I think it is something I would like to capture in the research, and maybe develop hypotheses for future work around how we can shift nutrition-related behaviors in the long run.”While his project develops a new methodology to calibrate food assistance programs, large-scale applications are not promised. “A lot of what drives subsidy mechanisms and food assistance programs is also, quite frankly, how easy it is and how cost-effective it is to implement these policies in the first place,” comments Aouad. Cost and infrastructure barriers are unavoidable to this kind of policy research, as well as sustaining these programs. Aouad’s effort will provide insights into customer preferences and subsidy optimization in a pilot setup, but replicating this approach on a real scale may be costly. Aouad hopes to be able to gather proxy information from customers that would both feed into the model and provide insight into a more cost-effective way to collect data for large-scale implementation.There is still much work to be done to ensure food security for all, whether it’s advances in agriculture, food-assistance programs, or ways to boost adequate nutrition. As the 2026 seed grant deadline approaches, J-WAFS will continue its mission of supporting MIT faculty as they pursue innovative projects that have practical and real impacts on water and food system challenges.", "release_time": "2025-10-15", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/optimizing-food-subsidies-applying-digital-platforms-maximize-nutrition-1014"}
{"category": "研究前沿", "title": "韦伯望远镜或发现早期宇宙暗物质恒星", "short_summary": "JWST观测到四个遥远天体，光谱特征与理论预言的超巨暗星一致，或由暗物质湮灭供能。", "detailed_summary": "JWST观测到四个遥远天体，光谱特征与理论预言的超巨暗星一致，或由暗物质湮灭供能。\n（1）研究团队利用詹姆斯·韦伯太空望远镜（JWST）的光谱数据，分析了四个极遥远天体（如JADES-GS-z14-0）；\n（2）这些天体的外观和光谱特征与超巨暗星理论模型一致，超巨暗星由暗物质粒子湮灭提供能量，而非核聚变；\n（3）其中一个天体（JADES-GS-z14-0）的光谱中发现了1640埃吸收特征，可能是暗星的“确凿证据”；\n（4）该发现有望解释JWST观测到的异常明亮早期星系及遥远类星体中超大质量黑洞的起源问题；\n（5）若证实，将开创暗物质恒星研究新领域，并有助于揭示暗物质粒子性质。", "raw_content": "In the early universe, a few hundred million years after the Big Bang, the first stars emerged from vast, untouched clouds of hydrogen and helium. Recent observations from the James Webb Space Telescope (JWST) suggest that some of these early stars may have been unlike the familiar (nuclear fusion-powered) stars that astronomers have studied for centuries. A new study led by Cosmin Ilie of Colgate University, together with Shafaat Mahmud (Colgate '26), Jillian Paulin (Colgate '23) at the University of Pennsylvania, and Katherine Freese at The University of Texas at Austin, has identified four extremely distant objects whose appearance and spectral signatures match what scientists expect from supermassive dark stars.  \"Supermassive dark stars are extremely bright, giant, yet puffy clouds made primarily out of hydrogen and helium, which are supported against gravitational collapse by the minute amounts of self-annihilating dark matter inside them,\" Ilie said. Supermassive dark stars and their black hole remnants could be key to solving two recent astronomical puzzles: i. the larger than expected extremely bright, yet compact, very distant galaxies observed with JWST, and ii. the origin of the supermassive black holes powering the most distant quasars observed. Katherine Freese first proposed the idea of dark stars with Doug Spolyar and Paolo Gondolo, publishing their initial peer-reviewed paper on the concept in Physical Review Letters in 2008. That study outlined how dark stars might grow and eventually collapse into supermassive black holes in the early universe. In 2010, Freese, Ilie, Spolyar, and their collaborators expanded on the theory in The Astrophysical Journal, describing two possible processes that could allow dark stars to reach immense sizes and predicting that they could seed the black holes found in the earliest quasars known to exist. Dark matter is thought to make up roughly a quarter of the universe, yet its nature remains one of science's greatest mysteries. Researchers believe it is composed of a still-undetected type of elementary particle. Decades of experiments have searched for these particles, but so far without success. One leading possibility involves Weakly Interacting Massive Particles (WIMPs). When two WIMPs collide, they are expected to annihilate each other, releasing energy that could heat collapsing hydrogen clouds and cause them to shine as brilliant dark stars. Conditions a few hundred million years after the Big Bang, within dense regions called dark matter halos, appear to have been ideal for forming such stars. These regions are also where the first generation of normal stars was expected to appear. \"For the first time we have identified spectroscopic supermassive dark star candidates in JWST, including the earliest objects at redshift 14, only 300 Myr after the Big Bang,\" said Freese, the Jeff and Gail Kodosky Endowed Chair in Physics and director of the Weinberg Institute and Texas Center for Cosmology and Astroparticle Physics at UT Austin. \"Weighing a million times as much as the Sun, such early dark stars are important not only in teaching us about dark matter but also as precursors to the early supermassive black holes seen in JWST that are otherwise so difficult to explain.\" In a 2023 PNAS study by Ilie, Paulin, and Freese, the first supermassive dark star candidates (JADES-GS-z13-0, JADES-GS-z12-0, and JADES-GS-z11-0) were identified using photometric data from JWST's NIRCam instrument. Since then, spectra from JWST's NIRSpec instrument became available for those, and a few other extremely distant objects. The team, which now also includes Shafaat Mahmud analyzed the spectra and morphology of four of the most distant objects ever observed (including two candidates from the 2023 study): JADES-GS-z14-0, JADES-GS-z14-1, JADES-GS-13-0, and JADES-GS-z11-0 and found that each of them is consistent with a supermassive dark star interpretation.  JADES-GS-z14-1 is not resolved, meaning it is consistent with a point source, such as a very distant supermassive star would be. The other three are extremely compact, and can be modeled by supermassive dark stars powering a nebula (i.e. ionized H and He gas surrounding the star). Each of the four objects analyzed in this study is also consistent with a galaxy interpretation, as shown in the literature. Dark stars have a smoking gun signature, an absorption feature at 1640 Angstrom, due to the large amounts of singly ionized helium in their atmospheres. And in fact, one of the four objects analyzed shows signs of this feature. \"One of the most exciting moments during this research was when we found the 1640 Angstrom absorption dip in the spectrum of JADES-GS-z14-0. While the signal to noise ratio of this feature is relatively low (S/N~2), it is for the first time we found a potential smoking gun signature of a dark star. Which, in itself, is remarkable,\" Ilie said. Astronomers using the Atacama Large Millimeter/submillimeter Array (ALMA) measured the spectrum of the same object, revealing the presence of oxygen, via a nebular emission line. Researchers said that if both spectral features are confirmed, the object cannot be an isolated dark star, but rather may be a dark star embedded in a metal rich environment. This could be the outcome of a merger, where a dark matter halo hosting a dark star merges with a galaxy. Alternatively, dark stars and regular stars could have formed in the same host halo, as the researchers now realized it is possible. The identification of supermassive dark stars would open up the possibility of learning about the dark matter particle based on the observed properties of those objects, and would establish a new field of astronomy: the study of dark matter-powered stars. This published PNAS research is a key step in this direction. Funding Acknowledgments: This research was made possible by generous funding from the following agencies: Colgate University Research Council, The Picker Interdisciplinary Sciences Institute, the U.S. Department of Energy's Office of High Energy Physics program, Swedish Research Council, LSST Discovery Alliance, the Brinson Foundation, the WoodNext Foundation, and the Research Corporation for Science Advancement Foundation.", "release_time": "2025-10-14", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/10/251014014430.htm"}
{"category": "产业应用", "title": "内蒙古绿电首次跨越3000公里送达海南", "short_summary": "内蒙古绿电跨越三千公里首次送至海南，实现南北能源互补与电网协同。", "detailed_summary": "内蒙古绿电跨越三千公里首次送至海南，实现南北能源互补与电网协同。\n（1）内蒙古清洁能源首次实现跨省远距离输送至海南，跨越3000公里；\n（2）交易电量833.5万千瓦时，提升海南\"双节\"期间电力供应保障能力；\n（3）依托全国统一电力市场，通过华北、华中、广东及琼粤跨海联网通道输送；\n（4）内蒙古新能源总装机突破1亿千瓦，外送绿电量占全国三分之一；\n（5）此举标志我国跨经营区能源互补与全国统一电力市场建设取得重要突破。", "raw_content": "10月3日至9日，内蒙古绿电“出塞”首次到海南。来自内蒙古的风、光资源，跨越3000公里“电力天路”，转化为海南岛的万家灯火，标志着内蒙古实现了清洁能源有史以来最远距离的跨省输送。此次跨区域绿电输送由北京电力交易中心、广州电力交易中心共同组织，依托全国统一电力市场，利用跨区跨省输电通道，完成了内蒙古电网与海南电网之间的跨经营区新能源交易。来自内蒙古西部的清洁电能，经由华北、华中、广东及琼粤跨海联网通道，最终送达海南岛，实现纵贯南北的“削峰填谷”与“负荷转移”。本次交易总电量达833.5万千瓦时，有效提升了“双节”期间海南的电力供应保障能力。内蒙古风光资源富集，风能技术可开发量14.6亿千瓦，约占全国的57%;太阳能技术可开发量94亿千瓦，约占全国的21%。近年来，内蒙古充分发挥资源禀赋优势，能源结构绿色转型取得突破性进展，2024年，新能源总装机在全国率先突破1亿千瓦，超过火电装机规模，占电力总装机的52%。作为国家重要能源基地，内蒙古始终承担着“西电东送”“北电南供”的重要使命，外送电量连续多年位居全国首位。2024年，内蒙古外送电量3377亿千瓦时、占全国1/6，其中绿电外送超600亿千瓦时、占全国1/3。为了推动草原绿电惠及全国，内蒙古在区内开展绿电交易试点，并在全国率先开展跨省绿电交易，2024年，内蒙古绿电交易结算电量762亿千瓦时，位居全国第一。2025年6月，蒙西电网绿电首次外送南方电网，将内蒙古的绿电送到广东。截至2025年9月，内蒙古已与8个省区建立了绿电外送交易合作机制。据介绍，此次绿电成功从塞北送至海南，依托跨区域输电通道剩余空间，精准匹配受电端清洁能源需求，实现了全国范围内电力生产力布局的南北贯通和多网协同优化配置。此举充分体现了跨经营区能源互补与协同发展的巨大潜力，是我国通过市场优化电力资源配置、推进全国统一电力市场建设的一次里程碑式探索与实践。", "release_time": "2025-11-11", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/zhdt/202510/t20251028_792216.html"}
{"category": "研究前沿", "title": "科学家首次基于物理原理推导出量子贝叶斯规则", "short_summary": "国际团队从最小变化原则出发，推导出真正的量子贝叶斯规则，验证了佩茨映射。", "detailed_summary": "国际团队从最小变化原则出发，推导出真正的量子贝叶斯规则，验证了佩茨映射。\n（1）国际科学家团队于2025年8月28日在《物理评论快报》发表研究，首次基于核心物理原理推导出真正的量子贝叶斯规则。\n（2）该研究由新加坡国立大学、香港科技大学和日本名古屋大学的教授合作完成，将已有250年历史的贝叶斯概率更新规则引入量子领域。\n（3）研究从量子版的最小变化原则出发，通过最大化量子保真度来最小化信念更新带来的变化。\n（4）推导出的方程在某些情况下与20世纪80年代提出的佩茨恢复映射相符，这是首次从更高原理验证该映射。\n（5）该量子贝叶斯规则在量子计算、量子纠错和机器学习等领域具有潜在应用价值，团队计划进一步探索其在其他量子度量中的应用。", "raw_content": "How likely you think something is to happen depends on what you already believe about the situation. This simple idea forms the basis of Bayes' rule, a mathematical approach to calculating probabilities first introduced in 1763. Now, an international group of scientists has demonstrated how Bayes' rule can also apply in the quantum realm.  \"I would say it is a breakthrough in mathematical physics,\" said Professor Valerio Scarani, Deputy Director and Principal Investigator at the Centre for Quantum Technologies, and member of the team. His co-authors on the work published on 28 August 2025 in Physical Review Letters are Assistant Professor Ge Bai at the Hong Kong University of Science and Technology in China, and Professor Francesco Buscemi at Nagoya University in Japan. \"Bayes' rule has been helping us make smarter guesses for 250 years. Now we have taught it some quantum tricks,\" said Prof Buscemi. Although other researchers had previously suggested quantum versions of Bayes' rule, this team is the first to derive a true quantum Bayes' rule based on a core physical principle. Conditional probability Bayes' rule takes its name from Thomas Bayes, who described his method for calculating conditional probabilities in \"An Essay Towards Solving a Problem in the Doctrine of Chances.\" Imagine someone who tests positive for the flu. They might have suspected illness already, but this new result changes their assessment of the situation. Bayes' rule provides a systematic way to update that belief, factoring in the likelihood of the test being wrong as well as the person's prior assumptions.  The rule treats probabilities as measures of belief rather than absolute facts. This interpretation has sparked debate among statisticians, with some arguing that probability should represent objective frequency rather than subjective confidence. Still, when uncertainty and belief play a role, Bayes' rule is widely recognized as a rational framework for decision-making. It underpins countless applications today, from medical testing and weather forecasting to data science and machine learning. Principle of minimum change When calculating probabilities with Bayes' rule, the principle of minimum change is obeyed. Mathematically, the principle of minimum change minimizes the distance between the joint probability distributions of the initial and updated belief. Intuitively, this is the idea that for any new piece of information, beliefs are updated in the smallest possible way that is compatible with the new facts. In the case of the flu test, for example, a negative test would not imply that the person is healthy, but rather that they are less likely to have the flu. In their work, Prof Scarani, who is also from NUS Department of Physics, Asst Prof Bai, and Prof Buscemi began with a quantum analogue to the minimum change principle. They quantified change in terms of quantum fidelity, which is a measure of the closeness between quantum states. Researchers always thought a quantum Bayes' rule should exist because quantum states define probabilities. For example, the quantum state of a particle provides the probability of it being found at different locations. The goal is to determine the whole quantum state, but the particle is only found at one location when a measurement is performed. This new information will then update the belief, boosting the probability around that location. The team derived their quantum Bayes' rule by maximizing the fidelity between two objects that represent the forward and the reverse process, in analogy with a classical joint probability distribution. Maximizing fidelity is equivalent to minimizing change. They found in some cases their equations matched the Petz recovery map, which was proposed by Dénes Petz in the 1980s and was later identified as one of the most likely candidates for the quantum Bayes' rule based just on its properties. \"This is the first time we have derived it from a higher principle, which could be a validation for using the Petz map,\" said Prof Scarani. The Petz map has potential applications in quantum computing for tasks such as quantum error correction and machine learning. The team plans to explore whether applying the minimum change principle to other quantum measures might reveal other solutions.", "release_time": "2025-10-14", "source_institution": "每日科学", "url": "https://www.sciencedaily.com/releases/2025/10/251013040333.htm"}
{"category": "研究前沿", "title": "光合作用电子传输不对称性谜题获解", "short_summary": "印美科学家揭示光合系统II中电子仅通过D1分支传输的量子机制。", "detailed_summary": "印美科学家揭示光合系统II中电子仅通过D1分支传输的量子机制。\n（1）印度科学院与加州理工学院合作破解光合作用长期谜题：为何电子仅通过光系统II的D1分支传输；\n（2）结合分子动力学模拟、量子分析和马库斯理论，发现D2分支能垒是D1两倍，电子传输阻力高两个数量级；\n（3）蛋白质微环境差异导致D1叶绿素激发态能量更低，更易吸引电子；\n（4）研究为设计高效人工光合系统（如合成叶片、太阳能燃料）提供理论支撑；\n（5）通过调控色素组分可重构电子传输路径，推动可持续能源技术发展。", "raw_content": "Scientists from the Indian Institute of Science (IISc) and the California Institute of Technology (Caltech) have finally solved a long-standing puzzle about the earliest moments of photosynthesis -- the vital process through which plants, algae, and certain bacteria capture sunlight to generate oxygen and energy-rich compounds.  Their research reveals why the first movements of electrons, which are crucial for transferring energy, occur through only one side of a key protein-pigment structure. The findings were published in the Proceedings of the National Academy of Sciences. Photosynthesis is a sequence of reactions in which electrons pass between multiple pigment molecules. Although it has been examined for decades, the process remains difficult to fully explain because it involves numerous intricate components, operates at extremely fast timescales, and varies slightly across different species. Gaining a deeper understanding of these steps could help scientists develop efficient artificial systems, such as synthetic leaves and solar-based fuel technologies, that replicate nature's design. In most life forms that use photosynthesis, the process begins with a protein-pigment complex known as Photosystem II (PSII). This complex captures sunlight and splits water molecules, releasing oxygen and sending electrons onward to other molecules in the chain of energy transfer. PSII contains two nearly identical branches, known as D1 and D2, surrounded by four chlorophyll molecules and two related pigments called pheophytins. These are symmetrically arranged and connected to electron carriers known as plastoquinones. In theory, electrons should move from chlorophyll to pheophytin and then to plastoquinone along both branches. However, experiments have consistently shown that electrons move only through the D1 branch -- a finding that has baffled scientists for years. \"Despite the structural symmetry between the D1 and D2 protein branches in PSII, only the D1 branch is functionally active,\" explains Aditya Kumar Mandal, the study's first author and a PhD student in the Department of Physics at IISc. To investigate this imbalance, the team combined molecular dynamics simulations, quantum mechanical analyses, and Marcus theory (a Nobel Prize-winning model that describes how electrons are transferred) to chart the energy patterns in both pathways. \"We assessed the electron transfer efficiency step-by-step through both D1 and D2 branches,\" says Shubham Basera, PhD student in the Department of Physics and one of the authors.  The team found that the D2 branch has a much higher energy barrier, which makes electron transport energetically unfavourable. Specifically, the transfer of electrons from pheophytin to plastoquinone in D2 requires twice as much activation energy as D1 -- a barrier that electrons seem unable to overcome, preventing energy from flowing forward. The researchers also simulated the current-voltage characteristics of both branches and found that the resistance against electron movement in D2 was two orders of magnitude higher than that in D1. The asymmetry in electron flow may also be influenced by subtle differences in the protein environment around the PSII and how the pigments are embedded in it, the researchers suggest. For example, the chlorophyll pigment in D1 has an excitation state at a lower energy than its D2 counterpart, suggesting that the D1 pigment has a better chance of attracting and transferring electrons. The researchers also suggest that tweaking some of these components can boost or rewire electron flow across PSII. For example, swapping chlorophyll and pheophytin in D2 could overcome the electron block, because chlorophyll needs lower activation energy than pheophytin. \"Our research presents a significant step forward in understanding natural photosynthesis,\" says Prabal K Maiti, Professor at the Department of Physics and one of the corresponding authors of the study. \"These findings may help design efficient artificial photosynthetic systems capable of converting solar energy into chemical fuels, contributing to innovative and sustainable renewable energy solutions.\" This is a beautiful combination of theory at various levels to address a long-standing problem culminating in a new level of understanding, but still leaving mysteries to be challenged, says Bill Goddard, Professor at Caltech and one of the corresponding authors.", "release_time": "2025-10-13", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251012054624.htm"}
{"category": "产业应用", "title": "美国煤炭复兴面临多重挑战前景不明", "short_summary": "美政府支持难抵竞争与排放压力，煤炭发电份额波动复苏前景黯淡。", "detailed_summary": "美政府支持难抵竞争与排放压力，煤炭发电份额波动复苏前景黯淡。\n（1）特朗普政府承诺土地租赁与贷款支持，但煤炭复兴受替代能源竞争、运输成本及排放抵制多重阻碍；\n（2）煤电容量持续萎缩，2010-2024年下降43%，规划新增容量仅0.4吉瓦影响微弱；\n（3）2025年煤电份额反弹至16.3%，主因天然气价格短期波动，但成本优势难以持续；\n（4）可再生能源崛起挤压煤电空间，太阳能与风能新增容量领先且成本更低；\n（5）煤炭排放强度高（每太瓦时95万吨CO₂），环保压力制约其长期发展。", "raw_content": "据美国媒体10月2日发布的信息表示，尽管特朗普政府承诺向煤炭电力提供联邦土地租赁和贷款支持，这可能会使煤炭产业的状况得到暂时且不均衡的改善。然而，还有其他一些因素将决定美国煤炭能否实现持久复苏。 虽然联邦政府做出了承诺，但与替代能源的竞争、从新建矿山到现有电厂运输煤炭的运费，以及对增加排放持续不停的抵制，可能会阻碍煤炭的复兴。 观察煤电产量、排放和消费等主要趋势，将有助于了解最新举措在扭转美国煤炭长期下降趋势方面的有效性。 煤电容量 潜在煤炭使用量的最重要指标是可用的煤炭发电能力。目前，煤炭是美国第三大电力来源，仅次于天然气和核能，但其容量占比已大幅下降，不太可能迅速恢复到先前水平。 根据Ember的数据，2010年至2024年，美国燃煤电厂的发电能力下降了43%，相当于减少了145吉瓦(GW)。 剩余的约194吉瓦煤电装机容量是至少2000年以来的最低水平，与十年前相比，煤炭的整体发电潜力显著下降。 要让煤炭在美国拥有任何实质性的长期复苏前景，就需要开发更多的燃煤发电能力。 据全球能源监测机构(Global Energy Monitor)的报告，目前仅有0.4吉瓦新的燃煤发电能力处于规划阶段。即使完成建设，这些新的发电能力仅能使总燃煤发电能力增加0.2%，意味着它对用于发电的煤炭总量影响很小。 为了提升煤炭在美国能源结构中的地位，则需要新增数十吉瓦的煤炭发电能力。 煤电份额 近年来煤电的产量稳步下降，但其在美国电力生产结构中的占比却是波动变化的，并且最近煤电份额又出现了回升。 2025年1月至8月，燃煤电厂产生的电力约占美国公用事业供电量的16.3%，较去年同期创纪录低水平的14.7%有所回升。这一反弹让煤炭支持者受到鼓舞，他们希望煤炭使用能实现持续复苏。 然而，一些在2025年初有利于煤炭使用的因素，可能会改变其在未来美国电力结构中的吸引力。 煤炭复兴的一个主要因素是天然气价格飙升，这促使电力公司出于削减成本，而增加价格较低的煤炭的使用量。 2025年上半年，煤炭价格比天然气每兆瓦时便宜约1.15美元，这激励发电企业减少天然气发电量，而增加煤炭使用量。 不过，自6月以来，煤炭价格上涨至略微高于天然气的价格，就改变了电力公司的燃料消费模式，导致煤炭在与天然气的竞争中失去了优势。 因此，煤炭为了与其他化石燃料相比能够持续得以使用，就必须继续在成本上具有显著优势，从而鼓励电力公司优先选择煤炭。 由于需要将煤炭从偏远矿井运往遥远的发电厂，通常需要依靠卡车和火车运输，这会带来较高的物流成本，因此要实现持久的价格优势可能具有挑战性。 可再生能源崛起 由于可再生能源的兴起，煤炭的发电份额也因受此挤压有所下降，尤其是在过去的五年中，太阳能和风能发电量已达到创纪录的水平。 过去十年，公用事业部门新增的太阳能和风能电力容量超过了其他任何能源来源，这得益于政府的大量补贴，使可再生能源的成本低于新增化石燃料发电容量的成本。 未来，虽然许多可再生能源补贴可能被削减，但预计公用事业公司仍会继续优先发展太阳能装机容量，因为太阳能能源能够迅速接入电网。 此外，公用事业公司也可能会更加专注于提高电池储能能力，因为这可以最大限度地利用现有的太阳能资源，并增加电力市场的收入。 污染抵制 与其它燃料相比，煤炭的排放量显著更高，这也是煤炭的使用不太可能迅速扩张的另一个原因。 根据 Ember 的数据，燃煤电厂排放量占美国电力行业总排放量的约 40%，而发电量仅占该国发电量的不到 20%。 燃煤电厂每产生一太瓦时的电力约排放95万吨的二氧化碳，而天然气电厂的排放量约为55万吨。", "release_time": "2025-10-13", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194778-1.html"}
{"category": "研究前沿", "title": "上海应物所香樟讲坛探讨AI驱动的量子材料预测", "short_summary": "翁红明研究员分享数据驱动量子材料预测前沿，推动AI与核能科研融合。", "detailed_summary": "翁红明研究员分享数据驱动量子材料预测前沿，推动AI与核能科研融合。\n(1) 上海应物所举办香樟讲坛，翁红明研究员作“量子材料预测：物理指引与数据驱动”主题报告。\n(2) 报告展示了数据驱动材料设计的特点与优势，及中科院凝聚态物质科学数据中心在新范式方面的实践。\n(3) 翁红明长期深耕拓扑物态计算预测，积极倡导数智研究新范式。\n(4) 活动强调AI和大数据在核能科研中的重要作用，鼓励青年科研人员将其融入工作。\n(5) 香樟讲坛旨在打造核科学领域国际化学术交流平台，弘扬科学家精神。", "raw_content": "上海应物所举办香樟讲坛—中国科学院物理研究所翁红明研究员作学术报告                                    发布日期：2025/10/13  [ 大 中 小 ] [ 打印 ] [ 关闭 ]    2025年10月9日，中国科学院上海应用物理研究所成功举办香樟讲坛暨钍基核裂变能重点实验室学术报告。本期讲坛邀请了中国科学院物理研究所翁红明研究员担任主讲人。上海应物所党委书记、副所长李晴暖，党委副书记、纪委书记王茂华，科研与教育处处长林俊以及各技术部青年科技骨干、研究生参加了本期活动。活动由科研与教育处副处长任翠兰主持。李晴暖为本期讲坛致辞，她代表上海应物所对翁红明研究员的莅临指导表示热烈欢迎和诚挚感谢，并向翁红明赠送了“香樟讲坛”特别纪念证书。李晴暖介绍了香樟讲坛的设立背景以及研究所目前的主要研究方向和近年来取得的主要成果。她结合本次活动的主题，特别提到AI和大数据在现在科研中发挥的重要作用，勉励广大青年科研人员、研究生积极思考AI在核能中的应用，并将其融入日常科研工作，让科技赋能科研能力提升。翁红明研究员长期深耕拓扑物态的计算与预测，在拓扑量子材料领域，特别是拓扑半金属的计算预言方面做出了系列开创性的工作，推动了拓扑物态研究的深入。近年来，翁红明积极倡导并实践数智研究新范式，致力于构建拓扑材料数据库并探索机器学习在其中的应用，为凝聚态物理的研究注入了新的活力。本期讲坛，翁红明作“量子材料预测：物理指引与数据驱动”主题报告，介绍了若干拓扑材料的计算设计经历，来展示数据驱动的材料设计的特点、方式和优势以及中国科学院凝聚态物质科学数据中心在推动“大数据+人工智能”研究新范式方面的设想、实践和进展。主题报告结束后，参会人员就AI和大数据及其在核能中的广泛应用等方面与翁老师开展了积极地互动交流。“香樟讲坛”是上海应物所主办的高层次学术交流平台，以研究所发展目标为指引，以弘扬科学家精神和“奋发自强、求实创新、文明团结”的核所精神为宗旨，旨在打造核科学领域具有国际影响力的学术交流平台。欢迎科研人员通过“香樟讲坛”开展学术交流！（钍基核裂变能重点实验室 供稿）李晴暖代表上海应物所向翁红明赠送纪念证书翁红明作学术报告并与科研人员进行交流活动现场", "release_time": "2025-10-13", "source_institution": "上海应用物理研究所", "url": "http://www.sinap.cas.cn/xwzx/kydt/202510/t20251013_7987361.html"}
{"category": "产业应用", "title": "日立支持NVIDIA 800伏直流架构，推动AI工厂高效供电", "short_summary": "日立开发800伏直流电源方案，提升AI数据中心能效，支持全球AI工厂建设。", "detailed_summary": "日立开发800伏直流电源方案，提升AI数据中心能效，支持全球AI工厂建设。\n（1）日立与日立能源宣布支持NVIDIA的800伏直流电源架构，为下一代AI基础设施提供更清洁高效的供电方案；\n（2）该架构简化电网至服务器的电力流动，减少能源浪费和冷却需求，加速超大规模AI设施部署；\n（3）日立能源投资90亿美元扩展制造与研发，包括对美国电网解决方案的10亿美元投资，以应对AI数据中心能源需求；\n（4）合作基于日立百年电网技术经验，旨在平衡电力需求增长与 decarbonization 目标；\n（5）预计2025至2030年全球AI数据中心容量将达125吉瓦，此技术将支撑未来能源基础设施。", "raw_content": "Zurich, October 13, 2025 - Hitachi, Ltd. (TSE:6501, “Hitachi”) and Hitachi Energy, a global leader in electrification, today announced support for the 800-volt direct-current (VDC) power architecture announced by NVIDIA, by developing a cleaner, more efficient way to power the next-generation artificial intelligence (AI) infrastructure. This power architecture paves the way for larger, more energy-efficient “AI factories” at a global scale. Modern AI workloads are pushing data centers beyond the limits of traditional power architectures, which were designed for much smaller compute loads. Hitachi Energy's advanced grid-to-rack architecture supports the 800 VDC rack design and streamlines how electricity flows from the grid into servers. The result is a simpler, more efficient, and more sustainable power system built for modern data centers that cuts energy waste, reduces cooling needs, and accelerates the deployment of hyperscale AI facilities. “As the energy arm of the Hitachi Group, Hitachi Energy brings over a century of expertise in grid technologies and power electronics to this collaboration,” said Jun Taniguchi, Senior Vice President and Executive Officer, CEO of Strategic SIB Business Unit, Hitachi, Ltd. “Through our wider focus on the data center industry, the Hitachi Group's combined expertise enables clean and sustainable development of the AI factories of the future.” It is forecasted that up to 125-gigawatt (GW) of AI data center capacity could be developed globally between 2025 and 20301, comparable to Spain's total installed generation capacity2. Meeting this demand requires unprecedented investment and advances in both computing and energy infrastructure.  1 The cost of compute power: A $7 trillion race | McKinsey 2 Installed capacity | System reports, Red Electrica, January 2024  As the global market leader in transformers, high-voltage technology, digitalized grids, and service, Hitachi Energy is investing $9 billion USD globally, the largest in the industry, to expand manufacturing, R&D, engineering, and partnerships. This includes a historic $1 billion USD investment to advance the production of critical grid solutions in the U.S. The investments will be critical to meeting energy needs, including AI data centers and supporting a robust, future-ready electric grid. Note to editors  Hitachi's Strategic Social Innovation Business (SIB) Business Unit leverages resources across the entire Hitachi Group to capture new growth opportunities, including data centers. Jun Taniguchi, Senior Vice President and Executive Officer, CEO of Strategic SIB Business Unit, Hitachi, Ltd., will lead the Social SIB BU from Silicon Valley, where new technologies and businesses are constantly emerging. In 2024, Hitachi announced a collaboration with NVIDIA to accelerate digital transformation with generative AI. About Hitachi, Ltd.  Through its Social Innovation Business (SIB) that brings together IT, OT (Operational Technology) and products, Hitachi contributes to a harmonized society where the environment, wellbeing, and economic growth are in balance. Hitachi operates globally in four sectors – Digital Systems & Hitachi Energy is a global technology leader in electrification, powering a sustainable energy future with innovative power grid technologies with digital at the core. Over three billion people depend on our technologies to power their daily lives. Services, Energy, Mobility, and Connective Industries – and the Strategic SIB Business Unit for new growth businesses. With Lumada at its core, Hitachi generates value from integrating data, technology and domain knowledge to solve customer and social challenges. Revenues for FY2024 (ended March 31, 2025) totaled 9,783.3 billion yen, with 618 consolidated subsidiaries and approximately 280,000 employees worldwide. Visit us at www.hitachi.com. About Hitachi Energy  Hitachi Energy is a global technology leader in electrification, powering a sustainable energy future with innovative power grid technologies with digital at the core. Over three billion people depend on our technologies to power their daily lives. With over a century in pioneering mission-critical technologies like high-voltage, transformers, automation, and power electronics, we are addressing the most urgent energy challenge of our time – balancing soaring electricity demand, while decarbonizing the power system. With an unparalleled installed base in over 140 countries, we co-create and build long-term partnerships across the utility, industry, transportation, data centers, and infrastructure sectors. Headquartered in Switzerland, we employ over 50,000 people in 60 countries and generate revenues of around $16 billion USD.  Information contained in this news release is current as of the date of the press announcement, but may be subject to change without prior notice.", "release_time": "2025-11-10", "source_institution": "日本日立", "url": "http://www.hitachi.com/New/cnews/month/2025/10/251015c.html"}
{"category": "产业应用", "title": "通用原子远程机动炮弹测试成功", "short_summary": "新型155mm炮弹实现精确制导，提升 artillery 系统射程与打击精度。", "detailed_summary": "新型155mm炮弹实现精确制导，提升 artillery 系统射程与打击精度。\n（1）通用原子电磁系统公司成功测试远程机动炮弹，使用M777榴弹炮平台发射；\n（2）测试验证了弹托分离、减旋稳定、机翼展开和可控下降等关键飞行里程碑；\n（3）该炮弹配备可展开气动控制面和机载制导系统，可在GPS受限环境中机动飞行；\n（4）作为下一代弹药，能显著扩展现有155mm火炮系统的射程和精确打击能力；\n（5）测试数据将支持后续更远射程演示，为美军现代化提供可扩展的战场解决方案。", "raw_content": "SAN DIEGO, Calif. — Oct. 13, 2025 — General Atomics Electromagnetic Systems (GA-EMS) announced the successful test of its Long Range Maneuvering Projectile (LRMP) at the U.S. Army Yuma Proving Ground, achieving key flight milestones when fired from a M777 howitzer platform. During the August test, GA-EMS fired multiple LRMP rounds using M231 powder charges, demonstrating sabot separation, de-spin stabilization, wing deployment and controlled descent. The LRMP is a next-generation munition engineered to extend the range and precision of existing 155mm artillery systems. Equipped with deployable aerodynamic control surfaces and onboard guidance, it can actively maneuver in flight to engage targets at extended distances—even in GPS-denied or degraded environments. Recent test flights matched predictive models and yielded valuable data to support upcoming demonstrations at significantly increased ranges. “This milestone reflects our commitment to delivering disruptive technologies for precision artillery,” said Scott Forney, president of GA-EMS. “As the U.S. faces rising threats from near-peer adversaries and increasingly contested environments, affordable, mass-produced artillery is critical. LRMP meets that need while proving its ability to perform in extreme conditions and reshape long-range firepower.” GA-EMS continues to lead in the development of electromagnetic systems, hypersonics and precision-guided munitions. The LRMP platform supports modernization goals across multiple services and offers a scalable, field-proven solution for future battlefield applications. About General Atomics Electromagnetic SystemsGeneral Atomics Electromagnetic Systems (GA-EMS) develops innovative technologies to create breakthrough solutions supporting operational environments from undersea to space. From electromagnetic, power generation and energy storage systems and space systems and satellites, to hypersonic, missile defense, and laser weapon systems, GA-EMS offers an expanding portfolio of capabilities for defense, government, and national security customers. GA-EMS also provides commercial products and services targeting hazardous waste remediation, oil and gas, and nuclear energy industries.For further information, visit www.ga.com/emsMedia ContactEMS-MediaRelations@ga.com", "release_time": "2025-10-14", "source_institution": "通用原子能公司", "url": "http://www.ga.com/ga-advances-artillery-modernization-with-lrmp-testing"}
{"category": "产业应用", "title": "敦煌新能源基地：风光资源领跑，多能互补发展", "short_summary": "敦煌风光资源富集，新能源装机超280万千瓦，正打造千万千瓦级多能互补基地。", "detailed_summary": "敦煌风光资源富集，新能源装机超280万千瓦，正打造千万千瓦级多能互补基地。\n(1) 敦煌市风光资源优越，太阳能年辐射量属Ⅰ类地区，风电基地风功率密度等级Ⅰ级，戈壁区域潜在装机容量达1.2亿千瓦；\n(2) 矿产资源丰富，五氧化二钒储量253.47万吨，为储能产业奠定基础；\n(3) 2009年以来累计投入超300亿元，吸引30多家企业建设光伏、光热、风电项目，包括多个全国乃至全球首例示范工程；\n(4) 目前已获批新能源指标491万千瓦，并网发电281万千瓦，建成完善的变电站网络支撑外送消纳；\n(5) 按照规划，到2030年基地总装机规模将达1700万千瓦，构建电源、电网、消纳、调峰、装备制造协同发展格局。", "raw_content": "敦煌市“风光”资源无限，土地资源富足，矿产资源丰富。全年日照时数3258小时，年辐射总量达每平方米6882兆焦耳，属于国内太阳能资源丰富的Ⅰ类地区;敦煌北湖风电基地100米高度平均风速7.4米/秒，风功率密度等级Ⅰ级。在2.67万平方公里的总面积中，适宜风电、光电项目建设的戈壁区域超过1万平方公里，潜在装机容量高达1.2亿千瓦。在众多矿产资源中，五氧化二钒金属储量达253.47万吨，为发展钒加工及储能产业筑牢了坚实根基。近年来，敦煌市抢抓国家新能源发展机遇，依托优越的“风光”资源，大力发展新能源产业，壮大绿色经济，逐渐步入生态保护与绿色发展深度融合的新局面。2009年以来，敦煌市先后投入5.5亿元，完成光电产业园区水、电、路、绿化、天然气、通信等基础设施建设。优越的资源条件吸引了30多家大型企业，投入300多亿元在敦煌光电产业园进行新能源项目建设。2009年，全国首个10兆瓦并网光伏发电特许权示范项目在敦煌市开工建设;2016年，全球第三座、亚洲第一座10兆瓦熔盐塔式光热电站并网发电;2018年，全国首个百兆瓦级熔盐塔式光热电站建成投运;2019年，全球首座熔盐线性菲涅尔式光热示范电站建成并网;2022年，全国首批700兆瓦“光热+”示范项目开工建设;敦煌北湖风电基地占地面积达960平方公里，可开发规模超500万千瓦;首个风电项目成功并网发电，拉开了敦煌风电开发的序幕。敦煌市被评为全国首批新能源示范城市、国家高比例新能源示范城市、国家低碳试点城市等。至目前，敦煌市共获批新能源指标491万千瓦，其中光电203万千瓦，风电288万千瓦。已并网发电项目281万千瓦，其中光电193万千瓦、风电88万千瓦。已建成1座750千伏、5座330千伏、13座110千伏变电站，构建起完善的新能源外送及就地消纳电网框架。按照《敦煌市多能互补新能源综合基地规划》要求，到2030年，基地总装机规模将达1700万千瓦，全力构建起电源、电网、消纳、调峰、装备制造多业并举、协调发展的格局。", "release_time": "2025-11-11", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/zhdt/202510/t20251028_792212.html"}
{"category": "产业应用", "title": "俄罗斯煤炭出口面临多重压力，增长前景黯淡", "short_summary": "俄煤出口受内外因素制约，预计将持续下滑，难以重返高位。", "detailed_summary": "俄煤出口受内外因素制约，预计将持续下滑，难以重返高位。\n(1) 预测显示俄罗斯煤炭出口量将持续下滑，2025年预计降至1.94亿吨，2026年可能进一步降至1.9亿吨。\n(2) 主要制约因素包括全球市场需求疲软、卢布走强削弱价格竞争力、以及预计上调的铁路货运关税。\n(3) 运输成本是关键变量，远东港口因成本较低成为重要通道，但2026年库兹巴斯地区向东出口配额是否延续存不确定性。\n(4) 实际出口表现远低于俄罗斯能源部2022年的乐观预测（目标情景2.2亿吨），行业正沿更悲观路径发展。\n(5) 未来出口前景取决于全球能源市场、国内政策调整及运输基础设施等多重因素，短期内难以实现超过2亿吨的目标。", "raw_content": "根据CCA Analysis最新预测与分析，未来几年俄罗斯煤炭出口预计难以实现显著增长，行业正面临结构性挑战与外部压力。数据显示，到2025年，俄罗斯煤炭出口量预计降至1.94亿吨，较此前下降100万吨。这一趋势背后，是多重制约因素共同作用的结果。 首先，全球煤炭市场行情持续疲软，抑制了出口需求。与此同时，俄罗斯国内政策环境也在发生变化：前期卢布的走强，以及预计2025年底铁路货运关税将上调，这都进一步削弱了俄煤在国际市场上的价格竞争力。这些因素共同挤压了煤炭供应商的利润空间，限制了其出口能力。 值得注意的是，运输成本成为影响俄煤出口的关键变量。以远东港口为例，由于距离亚太市场较近、运输成本较低，已成为俄煤出口的重要通道。2025年，库兹巴斯地区向东出口煤炭的配额设定为5410万吨，成为支撑产区企业运营的重要保障。然而，2026年该配额是否延续仍存变数，俄罗斯铁路公司与克麦罗沃州尚未达成协议，为未来出口前景增添了不确定性。 基于当前形势，预测显示2026年俄罗斯煤炭出口量将进一步下滑至1.9亿吨。在乐观情景下，若外部因素改善，出口量或可达到2.1亿吨;而在负面情景下，可能跌至1.8亿吨或更低。无论哪种情景，出口规模均难以回到2019-2022年的水平。   这一现实与俄罗斯能源部在2022年7月的预测形成鲜明对比。当时，能源部设想到2026年，在目标情景下出口量可达2.2亿吨，即使在负面情景下也能维持在1.95亿吨。然而，实际出口表现表明，行业正沿着更为悲观的路径发展，此前设定的超过2亿吨的出口目标短期内难以实现。 综合来看，俄罗斯煤炭出口正面临内外双重压力：外部市场需求疲软，内部政策与成本制约加剧。出口增长作为行业可持续发展的关键条件，其前景不容乐观。未来俄罗斯煤炭行业能否突破困局，将取决于全球能源市场走势、国内政策调整以及运输基础设施的发展等多重因素的共同作用。", "release_time": "2025-10-13", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194773-1.html"}
{"category": "政策计划", "title": "洪都拉斯与IAEA签署2025-2031年国家合作框架", "short_summary": "洪都拉斯与IAEA签署七年合作框架，确定核技术五大优先发展领域。", "detailed_summary": "洪都拉斯与IAEA签署七年合作框架，确定核技术五大优先发展领域。\n（1）洪都拉斯副外长与IAEA副总干事于2025年10月10日签署2025-2031年国家计划框架；\n（2）该框架是成员国与IAEA中期技术合作的规划依据；\n（3）洪都拉斯自2003年起成为IAEA成员国；\n（4）CPF确定了五个优先合作领域：核与辐射安全、粮食安全与农业、人类健康与营养、水与环境、能源与工业。", "raw_content": "Ms Cindy Larissa Rodríguez, Vice Minister of Foreign Affairs and International Cooperation of Honduras, and Mr Hua Liu, IAEA Deputy Director General and Head of the Department of Technical Cooperation, signed Honduras’ Country Programme Framework (CPF) for the period of 2025-2031 on 10 October 2025. A CPF is the frame of reference for the medium-term planning of technical cooperation between a Member State and the IAEA and identifies priority areas where the transfer of nuclear technology and technical cooperation resources will be directed to support national development goals. Honduras has been an IAEA Member State since 2003. Its 2025-2031 CPF identifies 5 priority areas:   Nuclear and radiation safety   Food security and agriculture   Human health and nutrition   Water and the environment   Energy and industry", "release_time": "2025-10-14", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/honduras-signs-its-country-programme-framework-cpf-for-2025-2031"}
{"category": "产业应用", "title": "美陆军为灰鹰无人机增配新型电子战系统", "short_summary": "通用原子公司获合同，为灰鹰无人机集成开放式架构电子战能力，提升生存与杀伤力。", "detailed_summary": "通用原子公司获合同，为灰鹰无人机集成开放式架构电子战能力，提升生存与杀伤力。\n(1) 美国陆军授予通用原子公司新合同，为MQ-1C灰鹰无人机集成符合CMOSS标准的开放式架构电子战能力。\n(2) 这是集成到CMOSS底盘上的第三种电子战能力，展示了该平台快速集成新功能的模块化优势。\n(3) 新能力基于此前演示经验，适用于灰鹰增程型和短距起降型，将增强在印太地区的纵深侦察能力。\n(4) 该电子战系统可提升灰鹰无人机在印太责任区的生存能力和杀伤力，使指挥官能灵活选择时机与地点压制威胁。\n(5) 通用原子公司将与AeroVironment公司合作，将其SharkCage远征C5ISR底盘集成到灰鹰平台上。", "raw_content": "SAN DIEGO – 13 October 2025 – The U.S. Army has awarded General Atomics Aeronautical Systems, Inc. (GA-ASI) a new contract to add a C5ISR Modular Open Suite of Standards (CMOSS)-compliant open architecture Electronic Warfare (EW) capability onto the MQ-1C Gray Eagle® Unmanned Aircraft System (UAS). This will be the third EW capability that has been integrated into the CMOSS chassis, showing how quickly and easily new plug-and-play capabilities can be integrated into the Gray Eagle platform. Other recent additions include Electronic Attack, Communications Relay, Counter-UAS, and Signals Intelligence. Gray Eagle’s Modular Open Systems Architecture (MOSA) streamlines the integration of the new EW capability, which leverages previous operational demonstrations and exercises applicable to Gray Eagle Extended Range and Gray Eagle Short Takeoff and Landing (STOL) variants. This capability signals a major step forward in the ability to conduct deep sensing in the Pacific while increasing the survivability and lethality of the Gray Eagle at distances relevant in the INDOPACOM Area of Responsibility. “Persistent, long-endurance, long-range UAS combined with EW means that the U.S. Army division commanders can apply the powerful EW effects of the Gray Eagle to neutralize threats to the maneuver force at a time and location of their choosing,” said GA-ASI President David R. Alexander. GA-ASI will collaborate with AeroVironment, Inc. (“AV”) (NASDAQ: AVAV) to integrate the company's SharkCage Expeditionary C5ISR Chassis (ECCv3) onto the platform. Since 2024, GA-ASI and AV have jointly demonstrated a range of capabilities on the Gray Eagle open architecture chassis. About GA-ASI General Atomics Aeronautical Systems, Inc., is the world’s foremost builder of Unmanned Aircraft Systems (UAS). Logging more than 9 million flight hours, the Predator® line of UAS has flown for over 30 years and includes MQ-9A Reaper®, MQ-1C Gray Eagle®, MQ-20 Avenger®, and MQ-9B SkyGuardian®/SeaGuardian®. The company is dedicated to providing long-endurance, multi-mission solutions that deliver persistent situational awareness and rapid strike. For more information, visit www.ga-asi.com      Avenger, EagleEye, Gray Eagle, Lynx, Predator, Reaper, SeaGuardian, and SkyGuardian are trademarks of General Atomics Aeronautical Systems, Inc., registered in the United States and/or other countries.", "release_time": "2025-10-14", "source_institution": "通用原子能公司", "url": "http://www.ga.com/us-army-taps-ga-asi-to-add-mosa-ew-capability-onto-gray-eagle-uas"}
{"category": "研究前沿", "title": "CRAFT偏滤器原型部件研制成功 热负荷能力达国际领先", "short_summary": "我国聚变堆关键部件偏滤器原型研制成功，热负荷能力达20兆瓦/平方米。", "detailed_summary": "我国聚变堆关键部件偏滤器原型研制成功，热负荷能力达20兆瓦/平方米。\n（1）聚变堆主机关键系统综合研究设施（CRAFT）偏滤器原型部件通过测试验收。\n（2）部件稳态热负荷能力达到20兆瓦/平方米，靶板面向等离子体表面邻接误差小于1毫米。\n（3）设计上创新提出混合偏滤器包层集成方案，可提升氚增殖率超3%。\n（4）研制过程形成了热等静压与钎焊加爆炸焊等稳定工艺路线，推动了国产先进聚变材料发展。\n（5）该成果标志着我国偏滤器研发能力自主可控，为未来聚变堆工程应用奠定技术基础。", "raw_content": "CRAFT偏滤器原型部件研制成功  2025-10-13 | 作者：文/许铁军 图/蔡其敏 |【大 中 小】【打印】【关闭】   10月13日，聚变堆主机关键系统综合研究设施（CRAFT）取得重要进展——偏滤器原型部件顺利通过专家组测试与验收。测试结果显示，该部件稳态热负荷能力达到20兆瓦/平方米，靶板面向等离子体表面邻接误差小于1毫米，标志着中国自主设计、国际尺寸最大热负荷最高的偏滤器原型部件研制成功。偏滤器作为聚变堆堆芯稳态运行的关键部件，承担排出聚变产物和热量，控制杂质等重要功能，服役环境极为复杂和严苛。CRAFT偏滤器原型部件在设计上创新性地提出混合偏滤器包层集成设计方案，理论上可将氚增殖率提升超过3%，为实现氚自持提供了一种有效辅助途径；设计了三种结构可靠、可正面拆装的独特靶板，验证了可靠快速更换的可行性。通过采用平板结构，部件有效将钨表面温度控制在再结晶温度以下，成功实现了稳态20兆瓦/平方米的超高热负荷，相当于打造了一面“神话级的盾牌”。在研制过程中，形成了热等静压与钎焊加爆炸焊两条质量稳定的工艺路线，全面推动了包括钾钨、弥散强化铜和低活化钢等国产先进聚变堆材料的发展应用。偏滤器原型部件系统是“十三五”国家重大科技基础设施“聚变堆主机关键系统综合研究设施”项目19项系统中的关键1项。该部件的成功研制标志着我国偏滤器研发能力已实现自主可控，为未来中国聚变堆偏滤器的工程应用奠定了坚实的技术基础。相关技术不仅能为其他聚变装置面对等离子体部件部件提供技术支撑，还可拓展应用到航空航天、工业电子产品和新能源汽车等领域。CRAFT偏滤器原型部件", "release_time": "2025-10-13", "source_institution": "等离子体物理研究所", "url": "http://www.ipp.ac.cn/xwdt/ttxw/202510/t20251013_782113.html"}
{"category": "政策计划", "title": "G20核能会议召开 推动全球核能合作与发展", "short_summary": "G20首开核能高会，IAEA助力非洲能源转型，全球核能容量预计翻番。", "detailed_summary": "G20首开核能高会，IAEA助力非洲能源转型，全球核能容量预计翻番。\n（1）G20首次核能高级别会议在南非德班举行，由南非电力能源部与IAEA联合组织；\n（2）会议共识认为核能是可靠、安全、可负担的能源，IAEA承诺支持非洲及G20国家发展核能；\n（3）埃及即将成为非洲第二个核电运营国，孟加拉国和土耳其计划近年投运首堆；\n（4）IAEA发布《非洲核能展望》和《煤转核》报告，为能源转型提供路径支持；\n（5）IAEA预测全球核能容量2050年前翻番，小型模块化堆将发挥关键作用。", "raw_content": "Energy leaders from around the world convened in Durban last week for the first ever high level G20 meeting on nuclear energy, held amid rising projections for nuclear power expansion. Jointly organized by South Africa’s Department of Electricity & Energy and the IAEA, the conference brought together energy ministers and high level representatives from G20 countries, invited guest countries and the International Energy Agency (IEA).   “In Africa, as in the rest of the world, nuclear power is increasingly recognized as a source of reliable, safe and affordable energy,” said IAEA Director General Rafael Mariano Grossi during his keynote address. “The IAEA is and will always be ready to support Africa and the G20 in turning this potential into lasting progress.”  The global consensus on the need to bolster nuclear power capacity has been backed by efforts to increase access to financing, including by the World Bank, and efforts to streamline deployment.  Many of the 31 nuclear operating countries, including South Africa, are looking to build new capacity and extend the lifetime of existing reactors, and around three dozen newcomer countries are either considering the introduction of nuclear power or actively preparing infrastructure. Egypt is poised to become Africa’s second operating country as the construction of its inaugural El Dabaa nuclear power plant nears completion, while Bangladesh and Türkiye plan to commission their first units within the next few years.  The IAEA is participating in the G20 for the second year in a row, building on the cooperation that started under the G20’s Brazilian presidency last year. According to the International Energy Agency, around half a billion Africans lack electricity access, and by 2030 the continent will be home to about 20% of the world’s population — highlighting the need to scale up clean, reliable power, including nuclear.  In August 2025, the IAEA released the Outlook for Nuclear Energy in Africa as part of its collaboration with the South African G20 presidency. The report outlines nuclear power prospects on the continent and what is needed for it   to meet Africa’s growing energy demand.  After a press conference with Mr Grossi and South Africa’s Deputy Minister of Electricity and Energy Samantha Graham-Maré, Henri Paillere, Head of the IAEA’s Planning and Economic Studies Section, presented a new publication Coal to Nuclear: Supporting a Clean Energy Transition, the IAEA’s latest contribution to G20 work on nuclear power. The publication explores the benefits of repurposing former coal power plant sites to support reactor deployments, such as job creation and improved air quality. It also reviews technical considerations, including site selection and the feasibility of using existing infrastructure, and financing requirements. “This IAEA publication on coal-to-nuclear transitions is both timely and necessary,” Graham-Maré said. “It offers a practical pathway for countries, particularly those with established coal infrastructure, to accelerate their energy transitions while retaining grid stability, enabling industrialization and safeguarding jobs.” The conference closed with a panel discussion on the role that nuclear power could play in Africa’s energy future, with a forward-looking focus on technologies, strategies and implementation. According to the latest IAEA projections, nuclear generating capacity on the continent will triple by 2030 in the high case scenario compared with 2024 capacity. That same scenario has capacity growing sixteenfold by mid-century.  Speakers from nuclear power-related organizations in South Africa as well as the IAEA and the Electric Power Research Institute discussed enabling conditions for deployment, financing models, international cooperation and the importance of proactive stakeholder engagement for long-term success. “Nuclear offers a huge opportunity to industrialize Africa and enable the achievement of its goal of providing a better life for its citizens,” said Loyiso Tyabashe, CEO of the South African Nuclear Energy Corporation.    Globally, at the end of 2024, 417 nuclear power reactors were operational, with a global capacity of 377 gigawatts electric (GW(e).  In the high case projection, the IAEA estimates that global nuclear operational capacity will more than double by 2050 – with small modular reactors (SMRs) expected to play a pivotal role in this expansion.", "release_time": "2025-10-16", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/nuclear-energy-in-focus-at-the-g20-in-south-africa"}
{"category": "研究前沿", "title": "MIT开发可编辑设定点的基因表达控制系统", "short_summary": "MIT工程师设计DIAL系统，通过调整DNA间隔区精确控制蛋白质表达水平。", "detailed_summary": "MIT工程师设计DIAL系统，通过调整DNA间隔区精确控制蛋白质表达水平。\n（1）MIT工程师开发新型基因电路控制机制DIAL，可设定并事后编辑目标蛋白质的表达水平；\n（2）技术原理基于调整基因与启动子之间的DNA间隔区长度，长度增加降低表达，利用Cre重组酶切除部分间隔区可提高表达；\n（3）系统实现“高、中、低、关”多级设定，在细胞群体中实现均匀稳定的蛋白质表达；\n（4）实验演示成功将小鼠胚胎成纤维细胞转化为运动神经元，高基因剂量提升转化效率；\n（5）该工具有望推动细胞重编程系统研究并实现个性化基因治疗。", "raw_content": "For decades, synthetic biologists have been developing gene circuits that can be transferred into cells for applications such as reprogramming a stem cell into a neuron or generating a protein that could help treat a disease such as fragile X syndrome.These gene circuits are typically delivered into cells by carriers such as nonpathogenic viruses. However, it has been difficult to ensure that these cells end up producing the correct amount of the protein encoded by the synthetic gene.To overcome that obstacle, MIT engineers have designed a new control mechanism that allows them to establish a desired protein level, or set point, for any gene circuit. This approach also allows them to edit the set point after the circuit is delivered.“This is a really stable and multifunctional tool. The tool is very modular, so there are a lot of transgenes you could control with this system,” says Katie Galloway, an assistant professor in Chemical Engineering at MIT and the senior author of the new study.Using this strategy, the researchers showed that they could induce cells to generate consistent levels of target proteins. In one application that they demonstrated, they converted mouse embryonic fibroblasts to motor neurons by delivering high levels of a gene that promotes that conversion.MIT graduate student Sneha Kabaria is the lead author of the paper, which appears today in Nature Biotechnology. Other authors include Yunbeen Bae ’24; MIT graduate students Mary Ehmann, Brittany Lende-Dorn, Emma Peterman, and Kasey Love; Adam Beitz PhD ’25; and former MIT postdoc Deon Ploessl.Dialing up gene expressionSynthetic gene circuits are engineered to include not only the gene of interest, but also a promoter region. At this site, transcription factors and other regulators can bind, turning on the expression of the synthetic gene.However, it’s not always possible to get all of the cells in a population to express the desired gene at a uniform level. One reason for that is that some cells may take up just one copy of the circuit, while others receive many more. Additionally, cells have natural variation in how much protein they produce.That has made reprogramming cells challenging because it’s difficult to ensure that every cell in a population of skin cells, for example, will produce enough of the necessary transcription factors to successfully transition into a new cell identity, such as a neuron or induced pluripotent stem cell.In the new paper, the researchers devised a way to control gene expression levels by changing the distance between the synthetic gene and its promoter. They found that when there was a longer DNA “spacer” between the promoter region and the gene, the gene would be expressed at a lower level. That extra distance, they showed, makes it less likely that transcription factors bound to the promoter will effectively turn on gene transcription.Then, to create set points that could be edited, the researchers incorporated sites within the spacer that can be excised by an enzyme called Cre recombinase. As parts of the spacer are cut out, it helps bring the transcription factors closer to the gene of interest, which turns up gene expression.The researchers showed they could create spacers with multiple excision points, each targeted by different recombinases. This allowed them to create a system called DIAL, that they could use to establish “high,” “med,” “low” and “off” set points for gene expression.After the DNA segment carrying the gene and its promoter is delivered into cells, recombinases can be added to the cells, allowing the set point to be edited at any time.The researchers demonstrated their system in mouse and human cells by delivering the gene for different fluorescent proteins and functional genes, and showed that they could get uniform expression across the a population of cells at the target level.“We achieved uniform and stable control. This is very exciting for us because lack of uniform, stable control has been one of the things that's been limiting our ability to build reliable systems in synthetic biology. When there are too many variables that affect your system, and then you add in normal biological variation, it’s very hard to build stable systems,” Galloway says.Reprogramming cellsTo demonstrate potential applications of the DIAL system, the researchers then used it to deliver different levels of the gene HRasG12V to mouse embryonic fibroblasts. This HRas variant has previously been shown to increase the rate of conversion of fibroblasts to neurons. The MIT team found that in cells that received a higher dose of the gene, a larger percentage of them were able to successfully transform into neurons.Using this system, researchers now hope to perform more systematic studies of different transcription factors that can induce cells to transition to different cell types. Such studies could reveal how different levels of those factors affect the success rate, and whether changing the transcription factors levels might alter the cell type that is generated.In ongoing work, the researchers have shown that DIAL can be combined with a system they previously developed, known as ComMAND, that uses a feedforward loop to help prevent cells from overexpressing a therapeutic gene.Using these systems together, it could be possible to tailor gene therapies to produce specific, consistent protein levels in the target cells of individual patients, the researchers say.“This is something we’re excited about because both DIAL and ComMAND are highly modular, so you could not only have a well-controlled gene therapy that’s somewhat general for a population, but you could, in theory, tailor it for any given person or any given cell type,” Galloway says.The research was funded, in part, by the National Institute of General Medical Sciences, the National Science Foundation, and the Institute for Collaborative Biotechnologies.", "release_time": "2025-10-13", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/new-system-can-dial-expression-synthetic-genes-up-down-1013"}
{"category": "政策计划", "title": "信息缺失", "short_summary": "原文内容缺失，无法生成有效摘要。", "detailed_summary": "原文内容缺失，无法生成有效摘要。\n(1)提供的文本仅为网站版权声明，不包含新闻正文。\n(2)无法获取关于\"2015-2016年度农业扶持资金申报会\"的具体信息。\n(3)因此无法生成符合要求的详细概要。", "raw_content": "2015-2016年度农业扶持资金申报会文件 文章来源： | 发布日期：2015-03-04 | 作者： | 点击次数：         中国新能源网版权及免责声明： 1、凡本网注明\"来源：中国新能源网\" 的所有作品，版权均属于中国新能源网，未经本网授权，任何单位及个人不得转载、摘编或以其它方式使用上述作品。已经本网授权使用作品的，应在授权范围内使用，并注明\"来源：中国新能 源网\"。违反上述声明者，本网将追究其相关法律责任。 2、凡本网注明 \"来源：XXX（非中国新能源网）\" 的作品，均转载自其它媒体，转载目的在于传递更多信息，并不代表本网赞同其观点和对其真实性负责。", "release_time": "2025-10-12", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/xnyjz/yjdt/201503/t20150304_732563.html"}
{"category": "研究前沿", "title": "量子计算新突破：TWA方法实现普通电脑高效模拟", "short_summary": "布法罗大学扩展TWA方法，使普通电脑能高效模拟复杂量子系统。", "detailed_summary": "布法罗大学扩展TWA方法，使普通电脑能高效模拟复杂量子系统。\n（1）布法罗大学研究人员成功扩展了截断维格纳近似（TWA）方法的应用范围；\n（2）新方法能够处理包含能量耗散的真实世界量子系统，突破了传统TWA仅适用于理想孤立系统的限制；\n（3）研究团队将复杂的数学推导简化为易用的转换表，使物理学家能在几天内掌握该方法；\n（4）该方法显著降低计算成本，有望成为在消费级计算机上探索量子动力学的主要工具；\n（5）研究成果发表于美国物理学会期刊PRX Quantum，获得美国国家科学基金会等多方资助支持。", "raw_content": "Picture diving deep into the quantum realm, where unimaginably small particles can exist and interact in more than a trillion possible ways at the same time.  It's as complex as it sounds. To understand these mind-bending systems and their countless configurations, physicists usually turn to powerful supercomputers or artificial intelligence for help. But what if many of those same problems could be handled by a regular laptop? Scientists have long believed this was theoretically possible, yet actually achieving it has proven far more difficult. Researchers at the University at Buffalo have now taken a major step forward. They have expanded a cost-effective computational technique known as the truncated Wigner approximation (TWA), a kind of physics shortcut that simplifies quantum mathematics, so it can handle systems once thought to demand enormous computing power. Just as significant, their approach -- outlined in a study published in September in PRX Quantum, a journal of the American Physical Society -- offers a practical, easy-to-use TWA framework that lets researchers input their data and obtain meaningful results within hours. \"Our approach offers a significantly lower computational cost and a much simpler formulation of the dynamical equations,\" says the study's corresponding author, Jamir Marino, PhD, assistant professor of physics in the UB College of Arts and Sciences. \"We think this method could, in the near future, become the primary tool for exploring these kinds of quantum dynamics on consumer-grade computers.\" Marino, who joined UB this fall, began this work while at Johannes Gutenberg University Mainz in Germany. His co-authors include two of his former students there, Hossein Hosseinabadi and Oksana Chelpanova, the latter now a postdoctoral researcher in Marino's lab at UB.  The research received support from the National Science Foundation, the German Research Foundation, and the European Union. Taking a semiclassical approach Not every quantum system can be solved exactly. Doing so would be impractical, as the required computing power grows exponentially as the system becomes more complex. Instead, physicists often turn to what's known as semiclassical physics -- a middle-ground approach that keeps just enough quantum behavior to stay accurate, while discarding details that have little effect on the outcome. TWA is one such semiclassical approach that dates back to the 1970s, but is limited to isolated, idealized quantum systems where no energy is gained or lost. So Marino's team expanded TWA to the messier systems found in the real world, where particles are constantly pushed and pulled by outside forces and leak energy into their surroundings, otherwise known as dissipative spin dynamics.  \"Plenty of groups have tried to do this before us. It's known that certain complicated quantum systems could be solved efficiently with a semiclassical approach,\" Marino says. \"However, the real challenge has been to make it accessible and easy to do.\" Making quantum dynamics easy In the past, researchers looking to use TWA faced a wall of complexity. They had to re-derive the math from scratch each time they applied the method to a new quantum problem. So, Marino's team turned what used to be pages of dense, nearly impenetrable math into a straightforward conversion table that translates a quantum problem into solvable equations. \"Physicists can essentially learn this method in one day, and by about the third day, they are running some of the most complex problems we present in the study,\" Chelpanova says. Saving supercomputers for the big problems The hope is that the new method will save supercomputing clusters and AI models for the truly complicated quantum systems. These are systems that can't be solved with a semiclassical approach. Systems with not just a trillion possible states, but more states than there are atoms in the universe. \"A lot of what appears complicated isn't actually complicated,\" Marino says. \"Physicists can use supercomputing resources on the systems that need a full-fledged quantum approach and solve the rest quickly with our approach.\"", "release_time": "2025-10-12", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251011105515.htm"}
{"category": "研究前沿", "title": "研究证实液态地核可产生地球磁场", "short_summary": "新模型揭示地球早期液态核心即可形成磁场，助力理解生命演化与预测未来变化。", "detailed_summary": "新模型揭示地球早期液态核心即可形成磁场，助力理解生命演化与预测未来变化。\n(1) 苏黎世联邦理工学院与南科大团队在《自然》发表研究，通过超级计算机模拟地球内部动力学。\n(2) 首次在模型中证实即使地核完全液态且粘度极低时，仍能通过发电机效应产生稳定磁场。\n(3) 该发现表明地球磁场早在10亿年前固体内核形成前就已存在，形成机制与现今相似。\n(4) 研究有助于重新解读地质历史数据，理解磁场对生命起源的屏蔽保护作用。\n(5) 成果对预测磁场未来变化（如磁极移动）及研究太阳等天体磁场具有重要价值。", "raw_content": "Earth is lucky to have a magnetic field that shields the planet -- and everything living on it -- from dangerous cosmic radiation. Without this invisible barrier, Earth would be exposed to the same constant stream of charged particles that bombards other planets in our solar system, such as Mars, making life there far more difficult.  Scientists have long explained the source of this protective force through the dynamo theory, which describes how motion within Earth's liquid metal core creates magnetism. As the molten iron and nickel slowly cool, they form swirling convection currents in the outer core. The planet's rotation then twists these flows into a spiraling, screw-like pattern. These moving, electrically conductive materials generate electric currents that produce magnetic fields -- together forming most of Earth's overall magnetic field. Yet the theory raises a problem. Before Earth's solid inner core began to crystallize (about 1 billion years ago), the entire core was liquid. Could the planet's magnetic field have existed even then? A group of three geophysicists from ETH Zurich and SUSTech, China, set out to answer this question in a study published in Nature. New model offers fresh insight Because scientists cannot directly observe the processes deep inside Earth, they rely on computer simulations to model its internal dynamics. In this new work, the team built a detailed digital model of the planet to test whether a fully liquid core could still maintain a stable magnetic field. The calculations, some performed on the Piz Daint supercomputer at the CSCS in Lugano, revealed that magnetism can indeed arise even when viscosity -- the internal friction of the liquid metal -- has no measurable effect on the process. This finding suggests that Earth's magnetic field likely formed early in its history through mechanisms very similar to those still operating today.  Remarkably, the researchers were the first to show that viscosity could be reduced to an almost negligible level in such models. \"Until now, no one has ever managed to perform such calculations under these correct physical conditions,\" says the study's lead author, Yufeng Lin. Understanding the history of the Earth's magnetic field \"This finding helps us to better understand the history of the Earth's magnetic field and is useful in interpreting data from the geological past,\" says co-author Andy Jackson, Professor of Geophysics at ETH Zurich. This also places the emergence of life in a different light. Billions of years ago, life apparently benefited from the magnetic shield, which blocked harmful radiation from space, making its development possible in the first place. The researchers can also use the new findings to study the magnetic fields of other celestial bodies such as the Sun or the planets Jupiter and Saturn. Indispensable for modern civilizations The Earth's magnetic field not only protects life, however; it plays a crucial role in making satellite communications and many other aspects of modern civilisation possible. \"It is therefore important to understand how the magnetic field is generated, how it changes over time, and what mechanisms maintain it,\" says Jackson. \"If we understand how the magnetic field is generated, we can predict its future development.\" The magnetic field has changed its polarity thousands of times throughout the history of the Earth. In recent decades, researchers have also observed a rapid shift of the magnetic north pole toward the geographic north pole. It is essential for our civilization to understand how magnetism is changing on Earth. In brief: Geophysicists from ETH Zurich and SUSTech, China, have demonstrated the dynamo effect of the Earth's core in a model in which viscosity has no influence, as is the correct physical regime for the Earth. The magnetic field was created in the Earth's early history when its core was completely liquid in a similar way to today. This finding helps us to better understand the history of the Earth's magnetic field and make more precise predictions of its future development.", "release_time": "2025-10-13", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251011105527.htm"}
{"category": "政策计划", "title": "四部门发文促地热能开发 目标5000万吨标煤", "short_summary": "国家出台地热能开发指导意见，设定2020年利用量达5000万吨标煤目标。", "detailed_summary": "国家出台地热能开发指导意见，设定2020年利用量达5000万吨标煤目标。\n(1) 国家四部门发布《促进地热能开发利用的指导意见》，旨在推动地热能这一清洁可再生能源的发展。\n(2) 地热能分为浅层、深层和干热岩三种类型，我国资源潜力巨大，开发对能源结构调整和减排意义重大。\n(3) 设定明确目标：到2015年地热年利用量达2000万吨标煤，2020年达5000万吨标煤。\n(4) 政策提出完善财税价格扶持，对发电项目给予电价补贴，并鼓励关键技术攻关和设备研发。\n(5) 地热能开发将带动关键设备（如热泵压缩机、螺杆膨胀机）市场需求，预计相关投资规模可达千亿元。", "raw_content": "日前，国家四部门发布了《促进地热能开发利用的指导意见》（下称《意见》），旨在促进我国地热能的开发利用。《意见》的出台，将为地热能的开发利用打开市场空间。 地热能有浅层地热、深层地热、干热岩三种，是清洁环保的新型可再生能源，积极开发利用地热能对缓解我国能源资源压力、实现非化石能源目标、推进能源生产和消费革命、促进生态文明建设具有重要的现实意义和长远的战略意义。 据了解，中国是以中低温为主的地热资源大国，全国地热资源潜力接近全球的8%；中国从20世纪70年代初期开展现代意义上的地热资源开发利用，随着地源热泵技术的发展，浅层地热能利用目前是中国地热能开发应用的主要方式。此前有业内人士推测，到2015年，浅层地温能开发投资额将达1500亿元以上。 以宁夏银川为例。地埋管地源热泵是银川市浅层地热能开发利用的最适宜方式，银川市每年浅层地热能资源可利用量折合标准煤883万吨，对推动银川市乃至全区能源结构调整和节能减排具有重要意义。 有业内人士算过一笔账：在100米深度内，若采用地埋管地源热泵方式，冬季浅层地热能资源可利用量折合标准煤291万吨，最低可供暖面积为1.3亿平方米；夏季浅层地热能资源可利用量折合标准煤592万吨，最低可制冷面积为2.8亿平方米。若折合标准煤883万吨的浅层地热能都能得到开发，每年可减少二氧化碳排放量2106万吨，减少二氧化硫排放量15万吨，每年总计可节省环境治理费24.47亿元。 浅层地热能由于运行成本低、投资回收周期较短等优点，开发利用已经开始起步。但我国地热资源开发利用还存在资源勘察评价程度低、关键技术有待突破、地热开发利用缺乏统一规划、开发利用管理分散等问题。 因此，业内人士建议，对新建或改建公共建筑、居民住宅楼采用浅层地热能供暖制冷的项目给予财政补贴；对涉及浅层地热能开发利用技术研究的科研机构及企业给予政策及资金支持；设立专项资金对节能减排效果突出的浅层地热能利用项目予以奖励。 实际上，地热能的开发利用早就引起了我国相关部门的关注。早在2012年9月底，国家曾召开全国地热能勘查评价与开发利用工作座谈会，当时就对《意见》进行了讨论，此后又多次召集部分业内专家就此征求意见。 国家2010年发出《关于做好“应对全球气候变化地质响应与对策”有关工作的通知》提出，要利用三年时间，查明全国地热资源量，划分地热资源开发利用适宜区，制定地热资源开发利用规划，建立地热资源监测网，推动地热资源开发利用。通知还称，将通过财政部门安排专项，支持地热资源调查评价工作。 根据四部委发布的《促进地热能开发利用的指导意见》，地热能利用的主要目标为，到2015年，基本查清全国地热能资源情况和分布特点，建立国家地热能资源数据和信息服务体系。全国地热供暖面积达到5亿平方米，地热发电装机容量达到10万千瓦，地热能年利用量达到2000万吨标准煤，形成地热能资源评价、开发利用技术、关键设备制造、产业服务等比较完整的产业体系。到2020年，地热能开发利用量达到5000万吨标准煤，形成完善的地热能开发利用技术和产业体系。 《意见》提出，未来国家有关部门会编制地热能开发利用总体规划。同时，要完善价格财税扶持政策。按照可再生能源有关政策，中央财政重点支持地热能资源勘查与评估、地热能供热制冷项目、发电和综合利用示范项目。按照可再生能源电价附加政策要求，对地热发电商业化运行项目给予电价补贴政策。最后，还要建立市场保障机制。 目前，北京、浙江以及乌鲁木齐和临沂等地，都有针对辖区内地热资源利用的专门性文件，但全国范围内尚未有针对地热能开发的专门性文件。 本次文件提出，鼓励有条件的企业重点对地热能资源评价技术、地热发电技术、高效率换热（制冷）工质、中高温热泵压缩机、高性能管网材料、尾水回灌和水处理、矿物质提取等关键技术进行联合攻关；依托地热能利用示范项目，加快地热能利用关键技术产业化进程，形成对我国地热能开发利用强有力的产业支撑。 中投顾问能源行业研究认为，地热资源的开发利用不但能改变我国未来的能源消费结构，更能带动相关设备制造企业，还能为相关服务行业、上游勘探企业带来不小的发展机遇。 目前，中国地源热泵技术的建筑应用面积已超过1.4亿平方米，在十二五期间，中国预计将完成地源热泵供暖（制冷）面积3.5亿平方米左右，按每平米200~300元的投资强度，总投资金额可达700~1050亿元。 因此，有券商分析师表示，热泵压缩机和螺杆膨胀机等地热能开发利用的关键设备将会出现需求大增。在关键设备市场容量估算方面，地热发电螺杆膨胀机组按每千瓦1.2万元的单价计算，则7.5万千瓦装机容量对应的螺杆膨胀机需求金额可达9亿元，热泵压缩机组方面按每万平方米50万元的单价计算，则3.5亿平方米供暖面积对应热泵压缩机组需求金额可达175亿元。 此外，中国利用地热发电始于20世纪70年代初期，曾一度建有10余座地热发电站，总装机容量达2.8万千瓦，但由于设备老化等原因，目前缩减为约2.4万千瓦，位于世界地热发电第18位。业内人士表示，无论是更换旧有设备，还是上马新设备，都将引发地热能关键设备市场的需求。", "release_time": "2025-10-12", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/xnyjz/yjdt/201504/t20150422_732853.html"}
{"category": "研究前沿", "title": "MIT开发CODA算法革新野生动物AI监测", "short_summary": "新型AI模型选择方法CODA大幅提升生态数据分析效率，助力生物多样性保护。", "detailed_summary": "新型AI模型选择方法CODA大幅提升生态数据分析效率，助力生物多样性保护。\n（1）MIT团队提出共识驱动主动模型选择方法CODA，解决海量预训练模型筛选难题；\n（2）该方法通过智能标注关键数据点，仅需25个样本即可精准选择最优AI模型；\n（3）成功应用于野生动物图像分类，显著提升物种监测效率；\n（4）技术突破为珊瑚礁无人机监测、大象个体追踪等生态项目提供支持；\n（5）推动AI在生物多样性保护和气候变化应对中的实际应用。", "raw_content": "A recent study from Oregon State University estimated that more than 3,500 animal species are at risk of extinction because of factors including habitat alterations, natural resources being overexploited, and climate change.To better understand these changes and protect vulnerable wildlife, conservationists like MIT PhD student and Computer Science and Artificial Intelligence Laboratory (CSAIL) researcher Justin Kay are developing computer vision algorithms that carefully monitor animal populations. He’s working on tracking salmon in the Pacific Northwest, where they provide crucial nutrients to predators like birds and bears, while managing the population of prey like bugs.With all that wildlife data, though, researchers have lots of information to sort through and many AI models to choose from to analyze it all. Kay and his colleagues at CSAIL and the University of Massachusetts Amherst are developing AI methods that make this data-crunching process much more efficient, including a new approach called “consensus-driven active model selection” (or “CODA”) that helps conservationists choose which AI model to use. Their work was named a Highlight Paper at the International Conference on Computer Vision (ICCV) this month.That research was supported, in part, by the National Science Foundation (NSF), Natural Sciences and Engineering Research Council of Canada (NSERC), and Abdul Latif Jameel Water and Food Systems Lab. Here, Kay discusses this project, among other conservation efforts.Q: In your paper, you pose the question of which AI models will perform the best on a particular dataset. With as many as 1.9 million pre-trained models available in the HuggingFace Models repository alone, how does CODA help us address that challenge? A: Until recently, using AI for data analysis has typically meant training your own model. This requires significant effort to collect and annotate a representative training dataset, as well as iteratively train and validate models. You also need a certain technical skillset to run and modify AI training code. The way people interact with AI is changing, though — in particular, there are now millions of publicly available pre-trained models that can perform a variety of predictive tasks very well. This potentially enables people to use AI to analyze their data without developing their own model, simply by downloading an existing model with the capabilities they need. But this poses a new challenge: which model, of the millions available, should they use to analyze their data? Typically, answering this model selection question also requires you to spend a lot of time collecting and annotating a large dataset, albeit for testing models rather than training them. This is especially true for real applications where user needs are specific, data distributions are imbalanced and constantly changing, and model performance may be inconsistent across samples. Our goal with CODA was to substantially reduce this effort. We do this by making the data annotation process “active.” Instead of requiring users to bulk-annotate a large test dataset all at once, in active model selection, we make the process interactive, guiding users to annotate the most informative data points in their raw data. This is remarkably effective, often requiring users to annotate as few as 25 examples to identify the best model from their set of candidates. We’re very excited about CODA offering a new perspective on how to best utilize human effort in the development and deployment of machine-learning (ML) systems. As AI models become more commonplace, our work emphasizes the value of focusing effort on robust evaluation pipelines rather than solely on training.Q: You applied the CODA method to classifying wildlife in images. Why did it perform so well, and what role can systems like this have in monitoring ecosystems in the future?A: One key insight was that when considering a collection of candidate AI models, the consensus of all of their predictions is more informative than any individual model’s predictions. This can be seen as a sort of “wisdom of the crowd”: On average, pooling the votes of all models gives you a decent prior over what the labels of individual data points in your raw dataset should be. Our approach with CODA is based on estimating a “confusion matrix” for each AI model — given the true label for some data point is class X, what is the probability that an individual model predicts class X, Y, or Z? This creates informative dependencies between all of the candidate models, the categories you want to label, and the unlabeled points in your dataset.Consider an example application where you are a wildlife ecologist who has just collected a dataset containing potentially hundreds of thousands of images from cameras deployed in the wild. You want to know what species are in these images, a time-consuming task that computer vision classifiers can help automate. You are trying to decide which species classification model to run on your data. If you have labeled 50 images of tigers so far, and some model has performed well on those 50 images, you can be pretty confident it will perform well on the remainder of the (currently unlabeled) images of tigers in your raw dataset as well. You also know that when that model predicts some image contains a tiger, it is likely to be correct, and therefore that any model that predicts a different label for that image is more likely to be wrong. You can use all these interdependencies to construct probabilistic estimates of each model’s confusion matrix as well as a probability distribution over which model has the highest accuracy on the overall dataset. These design choices allow us to make more informed choices over which data points to label and ultimately are the reason why CODA performs model selection much more efficiently than past work.There are also a lot of exciting possibilities for building on top of our work. We think there may be even better ways of constructing informative priors for model selection based on domain expertise — for instance, if it is already known that one model performs exceptionally well on some subset of classes or poorly on others. There are also opportunities to extend the framework to support more complex machine learning tasks and more sophisticated probabilistic models of performance. We hope our work can provide inspiration and a starting point for other researchers to keep pushing the state of the art.Q: You work in the Beerylab, led by Sara Beery, MIT Department of Electrical Engineering and Computer Science (EECS) Assistant Professor and CSAIL principal investigator, where researchers are combining the pattern recognition capabilities of machine-learning algorithms with computer vision technology to monitor wildlife. What are some other ways your team is tracking and analyzing the natural world, beyond CODA?A: The lab is a really exciting place to work, and new projects are emerging all the time. We have ongoing projects monitoring coral reefs with drones, re-identifying individual elephants over time, and fusing multi-modal earth observation data from satellites and in-situ cameras, just to name a few. Broadly, we look at emerging technologies for biodiversity monitoring and try to understand where the data analysis bottlenecks are, and develop new computer vision and machine-learning approaches that address those problems in a widely applicable way. It’s an exciting way of approaching problems that sort of targets the “meta-questions” underlying particular data challenges we face. The computer vision algorithms I’ve worked on that count migrating salmon in underwater sonar video are examples of that work. We often deal with shifting data distributions, even as we try to construct the most diverse training datasets we can. We always encounter something new when we deploy a new camera, and this tends to degrade the performance of computer vision algorithms. This is one instance of a general problem in machine learning called domain adaptation, but when we tried to apply existing domain adaptation algorithms to our fisheries data we realized there were serious limitations in how existing algorithms were trained and evaluated. We were able to develop a new domain adaptation framework, published earlier this year in Transactions on Machine Learning Research, that addressed these limitations and led to advancements in fish counting, and even self-driving and spacecraft analysis.One line of work that I’m particularly excited about is understanding how to better develop and analyze the performance of predictive ML algorithms in the context of what they are actually used for. Usually, the outputs from some computer vision algorithm – say, bounding boxes around animals in images — are not actually the thing that people care about, but rather a means to an end to answer a larger problem – say, what species live here, and how is that changing over time? We have been working on methods to analyze predictive performance in this context and reconsider the ways that we input human expertise into ML systems with this in mind. CODA was one example of this, where we showed that we could actually consider the ML models themselves as fixed and build a statistical framework to understand their performance very efficiently. We have been working recently on similar integrated analyses combining ML predictions with multi-stage prediction pipelines as well as ecological statistical models. The natural world is changing at unprecedented rates and scales, and being able to quickly move from scientific hypotheses or management questions to data-driven answers is more important than ever for protecting ecosystems and the communities that depend on them. Advancements in AI can play an important role, but we need to think critically about the ways that we design, train, and evaluate algorithms in the context of these very real challenges.", "release_time": "2025-10-22", "source_institution": "麻省理工学院能源计划", "url": "https://www.csail.mit.edu/news/3-questions-how-ai-helping-us-monitor-and-support-vulnerable-ecosystems"}
{"category": "政策计划", "title": "四部门发文促地热能开发 目标2015年供暖5亿平米", "short_summary": "国家四部门联合发文，设定地热能发展目标并提供财税支持，推动清洁能源规模化应用。", "detailed_summary": "国家四部门联合发文，设定地热能发展目标并提供财税支持，推动清洁能源规模化应用。\n(1) 国家四部门联合发布《促进地热能开发利用的指导意见》，设定2015年地热供暖面积达5亿平方米、发电装机10万千瓦的目标。\n(2) 中央财政将重点支持资源勘查、供热制冷及发电示范项目，并对地热发电项目给予电价补贴。\n(3) 鼓励规模化应用浅层地热能，特别是在资源丰富、需求旺盛的地区，预计相关投资将超1500亿元。\n(4) 要求电网企业全额保障性收购地热发电量，并鼓励专业化公司从事地热利用服务。\n(5) 相关上市公司如海鸥卫浴、汉钟精机等有望从地热能产业发展中受益。", "raw_content": "国家能源局、财政部、国土部、住建部四部门在发布的《促进地热能开发利用的指导意见》中称，到2015年，全国地热供暖面积达到5亿平方米，地热发电装机容量达到10万千瓦，形成地热能资源评价、开发利用技术、关键设备制造、产业服务等比较完整的产业体系。 地热能是清洁环保的新型可再生能源，资源储量大、分布广，发展前景广阔，市场潜力巨大。 《意见》强调，中央财政将重点支持地热能资源勘查与评估、地热能供热制冷项目、发电和综合利用示范项目。同时，按照可再生能源电价附加政策要求，对地热发电商业化运行项目给予电价补贴政策。 通过合同能源管理实施的地热能利用项目，可按有关规定享受相关税收优惠政策。利用地热能供暖制冷的项目运行电价参照居民用电价格执行。采用地热能供暖(制冷)的企业可参照清洁能源锅炉采暖价格收取采暖费。 《意见》提出，在做好环境保护的前提下，促进浅层地热能的规模化应用。重点在地热能资源丰富、建筑利用条件优越、建筑用能需求旺盛的地区，规模化推广利用浅层地温能。此前，有业内人士预测，到2015年，浅层地温能开发投资额将达1500亿元以上。 另外，《意见》指出，我国鼓励专业化服务公司从事地热利用建设运营服务。电网企业要按照国家关于可再生能源电力保障性收购的要求，落实全额保障性收购地热发电量义务。 上市公司中，海鸥卫浴、汉钟精机、烟台冰轮等涉足地热能的开发和利用，有望从未来地热能产业的大发展中受益。", "release_time": "2025-10-12", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/xnyjz/yjdt/201504/t20150417_732805.html"}
{"category": "产业应用", "title": "EuroChem十年内将建五座跨国化肥厂", "short_summary": "EuroChem联合意大利企业，计划在俄美哈三国建设五座大型化肥厂。", "detailed_summary": "EuroChem联合意大利企业，计划在俄美哈三国建设五座大型化肥厂。\n（1）俄罗斯欧洲化学公司(EuroChem)与意大利Maire Tecnimont公司、SACE签署谅解备忘录；\n（2）计划未来十年在俄罗斯、美国和哈萨克斯坦三国建设5座化肥厂；\n（3）具体包括在俄罗斯建设1座合成氨厂和2座尿素厂，在美哈各建合成氨尿素综合设施；\n（4）五家工厂合成氨总产能达500万吨，尿素总产能为750万吨；\n（5）意大利方提供工程服务与信用保险支持这一跨国产业投资。", "raw_content": "EuroChem计划在俄美等国建设5座化肥厂 文章来源：hnsp1@163.com | 发布日期：2015-04-25 | 作者： | 点击次数：   近日，俄罗斯欧洲化学公司(EuroChem Group)和意大利Maire Tecnimont公司、SACE 签署谅解备忘录(MOU)。EuroChem计划未来十年在俄罗斯、美国和哈萨克斯坦EuroChem计划未来十年在俄罗斯、美国和哈萨克斯坦三国建设5座化肥厂。 根据谅解备忘录，意大利Maire Tecnimont为其提供工程、采购和施工服务，SACE提供信用保险。 EuroChem 计划在俄罗斯建设1座合成氨厂和2座尿素厂，在美国路易斯安那州和哈舍克斯坦各建设合成氨尿素综合设施。上述5家工厂的合成氨产能达500万吨，尿素产能合计为750万吨。     中国新能源网版权及免责声明： 1、凡本网注明\"来源：中国新能源网\" 的所有作品，版权均属于中国新能源网，未经本网授权，任何单位及个人不得转载、摘编或以其它方式使用上述作品。已经本网授权使用作品的，应在授权范围内使用，并注明\"来源：中国新能 源网\"。违反上述声明者，本网将追究其相关法律责任。 2、凡本网注明 \"来源：XXX（非中国新能源网）\" 的作品，均转载自其它媒体，转载目的在于传递更多信息，并不代表本网赞同其观点和对其真实性负责。", "release_time": "2025-10-12", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/xnyjz/yjdt/201504/t20150427_732875.html"}
{"category": "研究前沿", "title": "《中国能源报告2014：能源贫困研究》发布", "short_summary": "报告构建中国能源贫困评估体系，分析其与健康、经济及气候关联。", "detailed_summary": "报告构建中国能源贫困评估体系，分析其与健康、经济及气候关联。\n（1）北京理工大学能源与环境政策研究中心完成并出版《中国能源报告2014：能源贫困研究》。\n（2）报告系《中国能源报告》系列的第五卷，总结了国际能源贫困评估方法。\n（3）构建了中国本土化的能源贫困度量和综合评价指标体系。\n（4）从时间和空间维度系统评估了中国能源贫困状况。\n（5）针对固体燃料健康影响、能源贫困与经济发展、清洁能源发展、气候变化等关键问题开展了深入研究。", "raw_content": "《中国能源报告2014：能源贫困研究》出版 文章来源：中国科学报 | 发布日期：2014-09-09 | 作者： | 点击次数：   近日，由北京理工大学能源与环境政策研究中心完成的《中国能源报告2014：能源贫困研究》由科学出版社出版发行。该报告是在长期研究基础上形成的《中国能源报告》系列的第五卷。 报告总结并提炼了国际能源贫困评估方法，构建了中国能源贫困度量和综合评价指标，从时间和空间维度评估了中国能源贫困，并针对固体燃料利用对城乡居民健康影响、能源贫困与经济发展水平、清洁能源发展与能源贫困、气候变化与能源可获得性、消除能源贫困的政策与行动等重要问题开展了系统研究。     中国新能源网版权及免责声明： 1、凡本网注明\"来源：中国新能源网\" 的所有作品，版权均属于中国新能源网，未经本网授权，任何单位及个人不得转载、摘编或以其它方式使用上述作品。已经本网授权使用作品的，应在授权范围内使用，并注明\"来源：中国新能 源网\"。违反上述声明者，本网将追究其相关法律责任。 2、凡本网注明 \"来源：XXX（非中国新能源网）\" 的作品，均转载自其它媒体，转载目的在于传递更多信息，并不代表本网赞同其观点和对其真实性负责。", "release_time": "2025-10-12", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/xnyjz/yjdt/201501/t20150109_732443.html"}
{"category": "产业应用", "title": "福州钻获高温地热井，南区资源探采获突破", "short_summary": "福州南区钻出76℃高温地热井，日出水量超千吨，实现地热资源重大突破。", "detailed_summary": "福州南区钻出76℃高温地热井，日出水量超千吨，实现地热资源重大突破。\n（1）省地勘局在福州市仓山区螺洲镇成功钻探一口优质高温地热井。\n（2）钻井深度702米，孔口自流，水温高达76℃，日出水量达1655吨。\n（3）此举标志着福州南区地热田资源探采取得重大突破。\n（4）项目采用先进钻探工艺，历时108天，克服了当地复杂的水文地质条件。", "raw_content": "26日，省地勘局第四地质大队在福州市仓山区螺洲镇螺洲大桥东侧，钻出一口优质的高温地热井。钻井深度702米，孔口自流，返水温度76℃，日出水量1655吨。这意味着福州温泉资源版图再度扩大。 位于福州南区的螺洲镇，水文地质条件复杂，地层变化大，此前仅发现30℃-40℃的低温地热资源，一直未取得明显突破。此次勘查该地质大队采用更先进的钻探工艺和适用技术，历时108天，成功钻探出这口高温地热井，使福州南区地热田资源探采有了重大突破。", "release_time": "2025-10-12", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/xnyjz/yjdt/201504/t20150422_732851.html"}
{"category": "产业应用", "title": "甘肃前8月绿电成交量超73亿千瓦时", "short_summary": "甘肃绿电交易量增长显著，交易效率提升助力新能源消纳。", "detailed_summary": "甘肃绿电交易量增长显著，交易效率提升助力新能源消纳。\n（1）今年1至8月，甘肃绿电成交量达到73.13亿千瓦时。\n（2）甘肃电力交易中心通过政策宣传和培训，引导省内513家企业参与绿电交易。\n（3）与天津、四川、重庆、陕西达成多年期绿电中长期外送交易。\n（4）自主研发绿电意向撮合平台，将交易洽谈及协议签署平均时长从4天缩短至1天以内。\n（5）交易效率提升进一步促进了绿电消费和新能源消纳。", "raw_content": "记者近日从甘肃电力交易中心有限公司获悉，今年1—8月，甘肃绿电成交量73.13亿千瓦时。今年以来，甘肃电力交易中心依托甘肃绿电富集优势，引导省内企业积极扩大绿电绿证应用场景和规模，组建市场化专业团队开展绿电绿证消费政策宣传和交易流程培训，开设绿电绿证服务窗口，助力绿电消费。目前，省内参与绿电交易用户达到513家。同时，甘肃电力交易中心利用省内能源大通道，与天津、四川、重庆、陕西4个省市达成多年期绿电中长期外送交易，自主研发绿电意向撮合平台供经营主体开展意向申报，绿电交易洽谈及协议签署平均时长由4天缩短到1天以内，绿电交易成交效率进一步提升。", "release_time": "2025-11-11", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/zhdt/202510/t20251028_792208.html"}
{"category": "研究前沿", "title": "光子学突破：首款光学热力学自路由设备问世", "short_summary": "南加州大学研制出基于热力学原理的光学自路由设备，无需外部控制即可引导光信号。", "detailed_summary": "南加州大学研制出基于热力学原理的光学自路由设备，无需外部控制即可引导光信号。\n（1）南加州大学研究团队在《自然-光子学》发表突破性成果，首次实现基于光学热力学概念的光学设备；\n（2）该设备利用非线性系统中光的热力学行为，使光信号能够自我路由，无需开关网络或电子控制系统；\n（3）原理类比气体达到热平衡的过程，光通过光学扩张和热平衡两阶段自然流向指定输出通道；\n（4）此项技术有望为芯片通信、电信和高性能计算等领域提供更高效、节能的光学解决方案；\n（5）研究将非线性系统的混沌特性转化为可预测行为，开辟了光子设备设计的新途径。", "raw_content": "A research group from the Ming Hsieh Department of Electrical and Computer Engineering has achieved a major advance in photonics with the creation of the first optical device built on the emerging concept of optical thermodynamics. Their findings, published in Nature Photonics, reveal an entirely new way to control and direct light in nonlinear systems (systems that operate without switches, external controls, or digital commands). In this setup, light is not forced through specific routes; instead, it moves naturally through the device, guided by basic thermodynamic behavior.  From Valves to Routers to Light The idea of routing is common across engineering disciplines. In mechanics, a manifold valve controls where fluids flow. In electronics, a Wi-Fi router or Ethernet switch sends digital information from multiple input sources to the correct output port, ensuring every signal reaches its destination. Achieving a similar kind of routing with light, however, has long been much more complex. Traditional optical routers rely on intricate switch networks and electrical control systems to change light’s path, which adds layers of complexity and limits both speed and performance. Researchers at the USC Viterbi School of Engineering have now demonstrated a completely different approach. The concept can be imagined as a marble maze that organizes itself. Normally, a person would need to lift barriers and adjust the path to guide a marble to the right hole. In the USC team’s device, the maze is structured so that no matter where you drop the marble, it will roll toward its correct destination automatically. Light behaves in the same way within this system—it finds the appropriate path on its own by following the rules of thermodynamics. Potential Industry Impact The potential applications of this discovery reach well beyond academic research. As modern computing and data transfer continue to stretch the limits of conventional electronics, leading companies (including chip designers such as NVIDIA and others) are investigating optical technologies as faster and more energy-efficient alternatives. By offering a natural, self-organizing method for directing light signals, optical thermodynamics could speed up progress in these efforts. In addition to chip-level communication, this principle may also influence fields such as telecommunications, high-performance computing, and secure information transfer, paving the way for simpler yet more powerful optical systems. How it Works: Chaos Tamed by Thermodynamics Nonlinear multimode optical systems have often been viewed as chaotic and difficult to control. Their many overlapping light patterns make them extremely challenging to model or design for practical purposes. Yet this very complexity hides rich physical behavior that has remained largely untapped.The USC researchers realized that light in these nonlinear environments behaves much like a gas moving toward thermal equilibrium, where random collisions eventually create a stable distribution of energy. Based on this insight, they developed the theoretical framework of \"optical thermodynamics,\" describing how light in nonlinear lattices can undergo processes analogous to expansion, compression, and even phase transitions. This model provides a unified way to understand and harness the natural self-organization of light.   A Device that Routes Light by Itself The team's demonstration in Nature Photonics marks the first device designed with this new theory. Rather than actively steering the signal, the system is engineered so that the light routes itself. The principle is directly inspired by thermodynamics. Just as a gas undergoing what's known as a Joule-Thomson expansion redistributes its pressure and temperature before naturally reaching thermal equilibrium, light in the USC device experiences a two-step process: first an optical analogue of expansion, then thermal equilibrium. The result is a self-organized flow of photons into the designated output channel -- without any need for external switches.  Opening a New Frontier By effectively turning chaos into predictability, optical thermodynamics opens the door to the creation of a new class of photonic devices that harness, rather than fight against, the complexity of nonlinear systems. \"Beyond routing, this framework could also enable entirely new approaches to light management, with implications for information processing, communications, and the exploration of fundamental physics,\" said the study's lead author, Hediyeh M. Dinani, a PhD student in the Optics and Photonics Group lab at USC Viterbi. The Steven and Kathryn Sample Chair in Engineering, and Professor of Electrical and Computer Engineering at USC Viterbi Demetrios Christodoulides added, \"What was once viewed as an intractable challenge in optics has been reframed as a natural physical process -- one that may redefine how engineers approach the control of light and other electromagnetic signals.\"", "release_time": "2025-10-12", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251010091551.htm"}
{"category": "研究前沿", "title": "磁控可重构“灯笼”结构实现多稳态快速形变", "short_summary": "新型聚合物灯笼结构可通过磁控实现十余种三维形态快速切换，具备软体抓取与流体控制应用潜力。", "detailed_summary": "新型聚合物灯笼结构可通过磁控实现十余种三维形态快速切换，具备软体抓取与流体控制应用潜力。\n（1）研究团队开发出菱形聚合物薄片切割成的“中国灯笼”状可重构结构；\n（2）该结构具有多稳态特性，可通过压缩、扭转等操作实现十余种三维形态切换；\n（3）底部附加磁膜实现磁控远程操作，演示了无损抓取活鱼、水下流量控制等应用；\n（4）建立数学模型精准预测结构形变行为与弹性储能特性；\n（5）该技术为软体机器人与形变超材料提供了新的单元设计范式。", "raw_content": "Researchers have developed a polymer structure shaped like a \"Chinese lantern\" that can quickly change into more than a dozen curved, three-dimensional forms when it is compressed or twisted. This transformation can be triggered and controlled remotely with a magnetic field, opening possibilities for a wide range of practical uses.To build the lantern, the team began with a thin polymer sheet cut into a diamond-shaped parallelogram. They then sliced a series of evenly spaced lines through the center of the sheet, forming parallel ribbons connected by solid strips of material at the top and bottom. When the ends of these top and bottom strips are joined, the sheet naturally folds into a round, lantern-like shape.  \"This basic shape is, by itself, bistable,\" says Jie Yin, corresponding author of a paper on the work and a professor of mechanical and aerospace engineering at North Carolina State University. \"In other words, it has two stable forms. It is stable in its lantern shape, of course. But if you compress the structure, pushing down from the top, it will slowly begin to deform until it reaches a critical point, at which point it snaps into a second stable shape that resembles a spinning top. In the spinning-top shape, the structure has stored all of the energy you used to compress it. So, once you begin to pull up on the structure, you will reach a point where all of that energy is released at once, causing it to snap back into the lantern shape very quickly.\" \"We found that we could create many additional shapes by applying a twist to the shape, by folding the solid strips at the top or bottom of the lantern in or out, or any combination of those things,\" says Yaoye Hong, first author of the paper and a former Ph.D. student at NC State who is now a postdoctoral researcher at the University of Pennsylvania. \"Each of these variations is also multistable. Some can snap back and forth between two stable states. One has four stable states, depending on whether you're compressing the structure, twisting the structure, or compressing and twisting the structure simultaneously.\" The researchers also gave the lanterns magnetic control by attaching a thin magnetic film to the bottom strip. This allowed them to remotely twist or compress the structures using a magnetic field. They demonstrated several possible uses for the design, including a gentle magnetic gripper that can catch and release fish without harm, a flow-control filter that opens and closes underwater, and a compact shape that suddenly extends upward to reopen a collapsed tube. A video of the experiment is available below the article.To better understand and predict the lantern’s behavior, the team also created a mathematical model showing how the geometry of each angle affects both the final shape and how much elastic energy is stored in each stable configuration. \"This model allows us to program the shape we want to create, how stable it is, and how powerful it can be when stored potential energy is allowed to snap into kinetic energy,\" says Hong. \"And all of those things are critical for creating shapes that can perform desired applications.\" \"Moving forward, these lantern units can be assembled into 2D and 3D architectures for broad applications in shape-morphing mechanical metamaterials and robotics,\" says Yin. \"We will be exploring that.\" The paper, \"Reprogrammable snapping morphogenesis in freestanding ribbon-cluster meta-units via stored elastic energy,\" was published on Oct. 10 in the journal Nature Materials. The paper was co-authored by Caizhi Zhou and Haitao Qing, both Ph.D. students at NC State; and by Yinding Chi, a former Ph.D. student at NC State who is now a postdoctoral researcher at Penn. This work was done with support from the National Science Foundation under grants 2005374, 2369274 and 2445551.", "release_time": "2025-10-12", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251010091546.htm"}
{"category": "研究前沿", "title": "科学家研发出类太阳光谱超薄量子点LED", "short_summary": "新型超薄QLED模拟太阳光谱，光线柔和护眼，有望用于下一代显示屏与照明。", "detailed_summary": "新型超薄QLED模拟太阳光谱，光线柔和护眼，有望用于下一代显示屏与照明。\n(1) 研究人员成功设计出一种整体厚度如壁纸般的超薄白色量子点LED。\n(2) 通过合成红、黄绿、蓝色量子点并精确配比，使发光光谱高度匹配自然阳光。\n(3) 该QLED在较低电压下工作，光线红波长更强、蓝波长更弱，有益睡眠与眼部健康。\n(4) 器件显色指数超过92%，能真实还原物体颜色，亮度满足显示器要求。\n(5) 这项技术为下一代护眼显示屏、自适应室内照明及园艺应用开辟了新途径。", "raw_content": "Light bulbs come in all sorts of forms—globes, spirals, candle-like tips, and long tubes—but few are truly thin. Now, scientists reporting in ACS Applied Materials & Interfaces have designed an LED so slender it’s nearly as thin as paper, yet it emits a cozy, sunlike glow. This new design could illuminate the future of phone and computer screens as well as other lighting applications, all while minimizing sleep disruption caused by harsh artificial light.  \"This work demonstrates the feasibility of ultra-thin, large-area quantum dot LEDs that closely match the solar spectrum,\" says Xianghua Wang, a corresponding author of the study. \"These devices could enable next-generation eye-friendly displays, adaptive indoor lighting, and even wavelength-tunable sources for horticulture or well-being applications.\" Many people prefer indoor lighting that feels natural and soothing. Earlier approaches achieved this effect with flexible LEDs that used red and yellow phosphorescent dyes to create a candle-like warmth. A newer alternative relies on quantum dots—tiny semiconductor particles that transform electrical energy into colored light. Some research teams have already used quantum dots to make white LEDs, but replicating the complete spectrum of sunlight has remained difficult, particularly in the yellow and green regions where sunlight is strongest. To address this challenge, Lei Chen and colleagues developed quantum dots that could recreate that balanced, sunlike glow in a thin, white quantum dot LED (QLED). Meanwhile, Wang’s group proposed an efficient conductive material design that could operate effectively at relatively low voltages.The team began by synthesizing red, yellow-green, and blue quantum dots coated with zinc-sulfur shells. They determined the precise color ratio needed to match the spectrum of natural sunlight as closely as possible. Next, they assembled the QLED on an indium tin oxide glass substrate, layering conductive polymers, the quantum dot blend, metal oxide particles, and finally a top coating of aluminum or silver. The quantum dot layer measured only a few dozen nanometers in thickness—much thinner than standard color conversion layers—resulting in a white QLED with an overall profile comparable to wallpaper. In initial tests, the thin QLED performed best under a 11.5-volt (V) power supply, giving off the maxmium bright, warm white light. The emitted light had more intensity in red wavelengths and less intensity in blue wavelengths, which is better for sleep and eye health, according to the researchers. Objects illuminated by the QLED should appear close to their true colors, scoring over 92% on the color rendering index. In further experiments, the researchers made 26 white QLED devices, using the same quantum dots but different electrically conductive materials to optimize the operating voltage. These light sources required only 8 V to reach maximum light output, and about 80% exceeded the target brightness for computer monitors. The authors acknowledge funding from the National Natural Science Foundation of China, the Natural Science Foundation of Anhui Province, and the Major Science and Technology Special Project of Zhongshan City.", "release_time": "2025-10-12", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251010091543.htm"}
{"category": "研究前沿", "title": "AI驱动数字化克隆平台实现微生物多维表型高通量筛选", "short_summary": "AI平台DCP实现单细胞多表型筛选，助力发现乳酸耐受性提升的超级菌株。", "detailed_summary": "AI平台DCP实现单细胞多表型筛选，助力发现乳酸耐受性提升的超级菌株。\n（1）青岛能源所单细胞中心联合湖北大学等研发AI驱动数字化克隆挑选平台（DCP），突破传统微生物筛选通量低、精度不足的瓶颈；  \n（2）DCP通过微腔室分隔培养、AI图像识别和无接触激光挑取三大技术，实现单细胞生长、代谢及形态的多维表型动态追踪；  \n（3）在应用验证中，成功筛选出运动发酵单胞菌的“超级菌株”，其乳酸产量提升19.6%，生长速率提高75.9%；  \n（4）研究发现该菌株优异表型与ZMOp39x027基因突变相关，揭示了新的乳酸耐受机制；  \n（5）DCP与拉曼流式细胞分选仪FlowRACS形成功能互补，为合成生物学和绿色生物制造提供全流程技术支撑。", "raw_content": "如何在庞大的微生物群体中，高效、精准地筛选出代谢产量高、环境耐受性强的优异菌株，是制约菌种选育与产业化应用的关键环节。近日，青岛能源所单细胞中心联合湖北大学和青岛星赛生物科技有限公司，研发出一套AI驱动的数字化克隆挑选平台（Digital Colony Picker, DCP），实现了多表型高通量单细胞筛选。微生物细胞工厂在可持续燃料、材料和医药等领域具有重要支撑作用。然而，在“设计-构建-测试-学习”（DBTL）这一合成生物学核心循环中，细胞表型筛选一直是效率最低的“限速”环节。传统平板培养依赖宏观指标，通量有限，难以捕捉到“万分之一”概率的稀有优质突变体；液滴微流控虽可实现单细胞分析，但流程复杂、易交叉污染，且难以动态追踪细胞状态。因此，亟需一种既具高通量，又可精准捕捉多维表型的新一代筛选平台。针对这一挑战，单细胞中心刁志钿博士带领的研究团队研发了DCP系统，通过“微腔室分隔培养—AI辅助图像识别—无接触激光单克隆挑取”三大技术创新，实现了精准的微生物多维表型高通量筛选。该系统基于包含上万个微腔室的微流控芯片，实现了单个微生物细胞的独立培养；结合人工智能图像识别技术，可实时监测细胞的生长动态、代谢活性及形态特征；并通过激光诱导气泡技术将目标菌株无接触导出，能够高效筛选出数万个单克隆的多模态表型。与传统方法相比，DCP系统同时具备“高通量”和“高精准性”，尤其擅长筛选出具有潜在价值的稀有优良菌株。图1 AI驱动的多表型、高通量细胞筛选平台——DCP在应用验证中，湖北大学彭祺群博士等利用DCP对工业重要底盘菌—运动发酵单胞菌（Zymomonas mobilis）的突变体文库进行筛选。在30 g/L乳酸胁迫条件下，研究人员成功分离获得了一株“超级菌株”：其乳酸产量提升了19.6%，生长速率提高75.9%。进一步的基因组学与功能研究发现，该菌株的优异表型与外膜自转运蛋白基因ZMOp39x027的突变和过表达密切相关。该基因可增强乳酸跨膜转运能力，从而支撑细胞在高乳酸环境下的增殖，揭示了此前未知的乳酸耐受机制。DCP平台能够在单细胞水平实现多维度表型的并行筛选，大幅加快了优良菌株的发现进程，为代谢工程、环境微生物资源挖掘和工业菌株优化提供了有力的技术支撑。未来，该技术有望广泛应用于酶功能验证、定向进化和耐逆菌株选育等方向，助推绿色生物制造与合成生物学的快速发展。DCP平台与单细胞中心此前联合青岛星赛生物科技有限公司推出的拉曼流式细胞分选仪FlowRACS形成“功能协同搭档”：FlowRACS擅长“瞬时快照/分选”，以每分钟数百个细菌单细胞的通量，通过拉曼光谱“指纹”信号实现即时、非破坏性的代谢表型筛选与目标细胞分选；DCP平台侧重于“动态追踪/回收”，基于微腔室培养可在时间维度上追踪细胞的生长过程、代谢变化和形态演化。两者的结合形成了一套系统化的解决方案，前端可快速筛选目标群体，后端能深度解析单克隆性能，覆盖功能菌株发现的全流程。上述研究成果近日发表于Nature Communications。青岛能源所刁志钿与湖北大学彭祺群为论文共同第一作者，青岛能源所马波研究员、湖北大学杨世辉教授和青岛能源所徐健研究员为共同通讯作者。该研究得到国家重点研发计划、国家自然科学基金、湖北省国际科技合作基地等的支持。（文/刁志钿 图/刘阳）原文链接：https://doi.org/10.1038/s41467-025-63929-7Zhidian Diao#, Qiqun Peng#, Sijun Luo, Lingyan Kan, Anle Ge, Wei Gao, Runxia Li, Weiwei Bao, Xixian Wang, Yuetong Ji, Jian Xu*, Shihui Yang*, Bo Ma*. AI-powered high-throughput digital colony picker platform for sorting microbial strains by multi-modal phenotypes. Nature Communications, 2025, 16: 8769.", "release_time": "2025-10-29", "source_institution": "青岛生物能源与过程研究所", "url": "https://qibebt.cas.cn/news/kyjz/202510/t20251011_7986711.html"}
{"category": "研究前沿", "title": "IEA预测2030年全球可再生能源发电量将翻番", "short_summary": "IEA报告称太阳能光伏将主导未来五年可再生能源80%的增长，推动全球发电量翻倍。", "detailed_summary": "IEA报告称太阳能光伏将主导未来五年可再生能源80%的增长，推动全球发电量翻倍。\n(1) 国际能源署(IEA)预测，到2030年全球可再生能源发电容量将增加4,600吉瓦，大致翻一番。\n(2) 增长主要由太阳能光伏推动，预计占未来五年可再生能源增长的80%，得益于成本下降和许可加速。\n(3) 风能、水电、生物能源、地热能和抽水蓄能等其他可再生能源也将贡献增长，其中新兴经济体增长更快。\n(4) 报告指出面临供应链集中（如中国主导关键部件生产）、电网整合挑战及美中政策变化等风险。\n(5) 可再生能源在交通和供暖领域的作用也将逐步扩大，但份额增长相对有限。", "raw_content": "根据国际能源署(IEA)的最新中期预测，可再生能源发电量在全球范围内继续强劲增长，预计到2030年全球发电量将翻一番以上。这一增长主要是由太阳能光伏 (PV) 技术的快速崛起推动的，尽管该行业面临供应链限制、电网并网问题、财务压力和不断变化的政策等挑战。国际能源署的年度报告《可再生能源 2025》预计，到 2030 年，全球可再生能源发电容量将增加 4,600 吉瓦 (GW)，大致相当于中国、欧盟和日本的发电容量总和。 由于太阳能光伏的成本下降和许可时间的加快，预计未来五年太阳能光伏将占这一增长的80%左右。其他可再生能源，包括风能、水力发电、生物能源和地热能，也将有助于扩张。预计美国、日本、印度尼西亚和几个新兴经济体等市场的地热产能将达到历史新高。将可再生能源并入电网的复杂性日益增加，重新燃起了人们对抽水蓄能发电的兴趣，预计未来五年抽水蓄能发电的增长速度将比上一时期快近 80%。 亚洲、中东和非洲的新兴经济体正在经历更快的可再生能源增长，这要归功于成本竞争力的提高和更强有力的政策支持，包括新的拍卖计划和更高的国家目标。印度有望成为仅次于中国的全球第二大可再生能源增长市场，并有望实现其雄心勃勃的 2030 年目标。在企业层面，对可再生能源的信心仍然很高。与去年相比，大多数主要开发商维持或提高了 2030 年的部署目标，反映出该行业的韧性和乐观情绪。然而，由于关键市场的政策转变、供应链瓶颈和成本上升，海上风电的增长前景疲软，比去年低约 25%。 国际能源署执行董事法提赫·比罗尔(Fatih Birol)指出：“未来几年全球可再生能源装机容量的增长将由太阳能光伏主导，但风能、水力发电、生物能和地热也将做出贡献。预计未来五年，太阳能光伏将占全球可再生能源装机容量增长的80%左右。除了成熟市场的增长外，太阳能还将在沙特阿拉伯、巴基斯坦和几个东南亚国家等经济体激增。随着可再生能源在电力系统中的作用不断增强，政策制定者需要应对供应链安全和电网整合挑战。 报告较去年略微下调了全球增长前景，主要是由于美国和中国的政策变化。在美国，联邦税收优惠措施的提前取消和其他监管变化使可再生能源的预期增长比去年减少了近 50%。在中国，从固定电价到拍卖的转变影响了项目经济，降低了中国市场的增长预期。 这些下调被印度、欧洲和大多数新兴经济体强劲的增长前景部分抵消，这些经济体的拍卖量扩大、许可速度加快以及屋顶太阳能部署增加改善了前景。企业购电协议、公用事业合同和商业电厂也是增长的主要驱动力，占到 2030 年全球可再生能源装机容量扩张的 30%，是去年预测的两倍。 预计太阳能光伏仍将是新发电成本最低的选择，并在 2030 年之前主导可再生能源的增长。尽管面临短期挑战，但随着供应瓶颈的缓解，风力发电预计将大幅扩张，特别是在中国、欧洲和印度。水电和其他可再生能源技术将继续在支持电力系统和提高灵活性方面发挥重要作用。太阳能光伏和风力涡轮机稀土元素的全球供应链仍然严重集中在中国，给供应链安全带来了持续的风险。 虽然全球供应链多元化的投资正在增加，但预计到 2030 年，中国将继续生产 90% 以上的关键零部件。可变可再生能源的快速崛起也给电力系统带来了越来越大的压力，一些市场已经发生了限电和负面价格事件。为了应对这些挑战，需要在电网、存储和灵活发电方面进行紧急投资。虽然一些国家已经开始引入新的容量和存储拍卖，但要以具有成本效益和安全的方式整合可变可再生能源，还需要做更多的工作。 预计可再生能源在交通和供暖方面的作用也将越来越大，尽管仍然有限。在交通运输领域，预计其能源使用份额将从目前的 4% 增加到 2030 年的 6%，这主要得益于中国和欧洲电动汽车的可再生电力，以及巴西、印度尼西亚、印度和其他市场的生物燃料。在供暖方面，可再生能源在建筑和工业能源中使用的份额预计将在同一时期从 14% 上升到 18%。", "release_time": "2025-10-11", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194721-1.html"}
{"category": "产业应用", "title": "麦格理：炼焦煤价或长期站上200美元", "short_summary": "成本支撑与供应压力推动炼焦煤价进入可持续高位区间。", "detailed_summary": "成本支撑与供应压力推动炼焦煤价进入可持续高位区间。\n（1）麦格理投行预测炼焦煤价格可能攀升并长期维持在每吨200美元以上，受成本上升支撑。\n（2）当前市场供需保持小幅盈余，但印度需求加速增长将很快缩减过剩供应。\n（3）持续低价正迫使全球煤矿削减成本、关闭边缘矿山，对焦煤供应造成压力。\n（4）中国2025年焦煤产量增长预测从3%下调至1%，主因安全生产检查加强。\n（5）下游焦炭价格经历七轮上调，扭转负利润局面，但中国产量高位存过剩风险。\n（6）印度钢厂季风后或恢复焦煤累库，其进口强度受明年焦炭质量限制政策影响。", "raw_content": "据Kallanish Energy 10月3日发布的资讯报告表示，澳大利亚金融服务公司麦格理投行(Macquarie)预计，受成本不断上升的支撑，炼焦煤价格可能将攀升并长期位于每吨200美元以上，进入更具可持续性的区间。 在该投行最近的研究报告中，仍维持这样的观点，认为目前市场供需确实还将保持小幅盈余，但指出随着印度需求的加速增长，这一供应过剩数量预计将会很快缩减。 至关重要的是，当前长时间的持续低价，正开始迫使煤矿大面积的削减成本，以及处于盈亏边缘的采矿作业的停止或矿山关闭，直接对全球的焦煤供应造成压力。 麦格理银行还将对中国2025年焦煤产量的预测从增长3%下调至仅增长1%，主要原因是中国近期加强了安全生产检查。 尽管预计这些检查对煤矿实际产量的减少是有限的，但相关的新闻传播可能会继续对期货价格产生放大的影响。 下游的焦炭市场，自今年7月中旬以来，焦煤价格的强势已推动焦炭价格经历了七轮上调。这成功扭转了此前焦炭利润大多为负的局面。鉴于当前利润状况良好，麦格理银行警告称，中国焦炭产量可能仍将保持高位，且面临供过于求的风险。 至于印度的钢厂，看起来准备在季风期惯常的去库存之后，将恢复港口焦煤库存的累库。麦格理银行估计，印度当前的库存水平为550万吨，相当于约22天的使用量，接近于三年平均水平。然而，印度炼焦煤进口的强度，可能还要取决于明年是否延续“焦炭质量限制”(Quality Restriction -QR)政策。", "release_time": "2025-10-11", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194735-1.html"}
{"category": "研究前沿", "title": "新型扩散渗透机制实现抗缺陷盐差发电", "short_summary": "青岛能源所与山大合作开发磺酸COF膜盐差发电新机制，突破传统技术局限。", "detailed_summary": "青岛能源所与山大合作开发磺酸COF膜盐差发电新机制，突破传统技术局限。\n(1) 研究针对传统盐差能收集技术受膜材料“通量-选择性”博弈和浓差极化限制的问题；\n(2) 提出基于扩散-渗透机制的新方法，利用磺酸COF膜致密磺酸基团和垂直孔道结构；\n(3) 该机制不依赖离子选择性，在0.03mm²面积实现101.2W/m²高功率密度；\n(4) 膜面积放大至20mm²时功率密度仍达7W/m²，展现良好可规模化性；\n(5) 具备优异抗缺陷能力，10%针孔缺陷下仍稳定工作，显著提高工程应用可行性。", "raw_content": "盐差能作为一种清洁、稳定的可再生能源，近年来受到广泛关注。传统盐差能的收集方式主要基于反向电渗析（RED）技术，其核心在于通过高离子选择性的膜材料以产生净离子流，因此，性能一直受“通量—选择性”博弈的制约。高选择性通常要求膜材料具有亚纳米级的孔径，这不仅增加了膜的制备难度和成本，还使得能量转换效率容易受到结构缺陷的影响。此外，高选择性膜还能导致严重的浓差极化，从而使大面积测试下的功率密度急剧下降，进一步限制了盐差能的规模化应用。现实中，许多高功率密度材料通常仅在极小测试面积中得到验证（1 μm2到0.03 mm2），距离实际的大规模应用仍存在显著差距。针对上述问题，青岛能源所高军研究员与山东大学刘鹏教授合作，提出了一种利用扩散—渗透（diffusio-osmosis）机制来收集盐差能的新方法，不同于选择性机制的RED技术，该机制产生的电流源于双电层内界面渗透压梯度驱动的扩散—渗透流携带的净电荷，不依赖膜材料的离子选择性。此前，利用单孔氮化硼纳米管、石墨纳米通道的研究已表明该机制有望实现超高功率密度的盐差能转换，但在膜尺度上仍缺乏相关研究。研究团队针对难以找到合适的膜材料匹配该机制开展研究，发现利用磺酸共价有机框架（COF）膜致密分布的磺酸基团、垂直排列的孔道结构，可以实现基于扩散-渗透机制的可规模化盐差发电。图1 基于磺酸COF膜在不同盐度梯度下的盐差能转换机制在5 M/0.5 M NaCl浓度梯度下，由于COF通道内的德拜长度（λD）不重合，因此该膜不具备电荷选择性，Na+和Cl-的渗透测试进一步验证了这一结论。此外，扩散—渗透电流与活度比的对数呈线性关系，表明扩散—渗透机制主导了盐差能转换过程。此过程中，COF致密分布的磺酸基团提供了高电荷密度，增强了电双层内界面渗透压梯度从而能有效产生扩散—渗透流，结合其垂直排列的一维孔道，能高效驱动离子输运。避免了传统RED对选择性的依赖，克服了“通量—选择性”博弈和浓差极化等问题。在0.03 mm2测试面积下，实现了101.2 W m-2的最大功率密度，显著高于多数已报道材料。当膜面积放大两个数量级（~20 mm2），功率密度仍能维持在~7 W m-2。这一新机制的优势在于不依赖膜材料的离子选择性，使得体系表现出前所未有的抗缺陷能力，即便在膜上引入超过测试面积10%的针孔缺陷，仍能维持稳定的输出电压与输出功率，而传统RED膜在类似条件下几乎完全失效。这一发现显著提高了膜材料的制备容错度，有望降低膜材料的制造成本并提高其工程化应用的可行性。图2 磺酸COF膜的制备与表征   图3 扩散-渗透机制盐差发电该研究展示了一种抗缺陷、可规模化的扩渗盐差发电新机制，克服了传统RED技术的局限性，为实现规模化的盐差发电提供了新思路。相关成果近期发表在Angewandte Chemie International Edition上，文章的第一作者是山东大学与青岛能源所联合培养的博士研究生潘尚发。（文/图 潘尚发、高军）图4 高功率密度且可规模化的盐差发电图5 抗缺陷性能    原文链接：https://doi.org/10.1002/anie.202514637Defect-Tolerant and Scalable Diffusio-Osmotic Power Generation with Sulfonated Covalent Organic Framework Membrane. Shangfa Pan, Qi Li, Qianqian Fu, Jingting Zeng, Peng Liu,* Lei Jiang and Jun Gao*. Angew. Chem. Int. Ed., 2025, DOI: 10.1002/anie.202514637", "release_time": "2025-10-29", "source_institution": "青岛生物能源与过程研究所", "url": "https://qibebt.cas.cn/news/kyjz/202510/t20251010_7985819.html"}
{"category": "研究前沿", "title": "EPFL研发后注入金属盐3D打印技术，强度提升20倍", "short_summary": "新型3D打印通过水凝胶模板后注入金属盐，制造高密度金属陶瓷，强度显著提升。", "detailed_summary": "新型3D打印通过水凝胶模板后注入金属盐，制造高密度金属陶瓷，强度显著提升。\n(1) EPFL团队开发新型3D打印技术，先用水凝胶打印框架，后注入金属盐生成纳米颗粒；\n(2) 经过5-10次生长循环和加热去除凝胶，获得高密度金属或陶瓷物体，形状精确；\n(3) 材料强度比传统方法高20倍，收缩率仅20%（传统为60-90%）；\n(4) 同一水凝胶模板可制造多种金属、陶瓷或复合材料，实现打印后材料选择；\n(5) 技术适用于制造传感器、生物医疗设备、能源转换存储等复杂强韧结构。", "raw_content": "Vat photopolymerization is a type of 3D printing that involves pouring a light-reactive liquid resin into a container and then solidifying specific areas with a laser or ultraviolet light to create a shape. However, because this method only works with light-sensitive polymers, its practical uses are limited.  Some researchers have developed techniques to turn these printed polymers into stronger materials like metals and ceramics, but Daryl Yee, who leads the Laboratory for the Chemistry of Materials and Manufacturing at EPFL’s School of Engineering, says these approaches have major flaws. \"These materials tend to be porous, which significantly reduces their strength, and the parts suffer from excessive shrinkage, which causes warping,\" he says. To address these issues, Yee and his team have introduced a new approach described in their paper published in Advanced Materials. Instead of hardening a resin already mixed with metal compounds, the researchers first 3D print a framework using a simple water-based gel known as a hydrogel. They then soak this “blank” structure in metal salts, which are chemically converted into tiny metal-containing nanoparticles that spread throughout the gel. Repeating this process multiple times allows them to create composites with very high metal content. After 5–10 of these “growth cycles,” the remaining hydrogel is removed through heating, leaving behind a dense metal or ceramic object that precisely matches the shape of the original printed gel. Because the metal salts are added only after printing, the same hydrogel template can be used to make a variety of different metals, ceramics, or composite materials. \"Our work not only enables the fabrication of high-quality metals and ceramics with an accessible, low-cost 3D printing process; it also highlights a new paradigm in additive manufacturing where material selection occurs after 3D printing, rather than before,\" Yee summarizes. Targeting advanced 3D architectures For their study, the team fabricated intricate mathematical lattice shapes called gyroids out of iron, silver, and copper, demonstrating their technique's ability to produce strong yet complex structures. To test the strength of their materials, they used a device called a universal testing machine to apply increasing pressure to the gyroids. \"Our materials could withstand 20 times more pressure compared to those produced with previous methods, while exhibiting only 20% shrinkage versus 60-90%,\" says PhD student and first author Yiming Ji. The scientists say their technique is especially interesting for the fabrication of advanced 3D architectures that must be simultaneously strong, lightweight, and complex, like sensors, biomedical devices, or devices for energy conversion and storage. For example, metal catalysts are essential for enabling reactions that convert chemical energy into electricity. Other applications could include high-surface area metals with advanced cooling properties for energy technologies. Looking ahead, the team is working on improving their process to facilitate uptake by industry, notably by further increasing the density of their materials. Another goal is speed: the repeated infusion steps, while essential for producing stronger materials, make the method more time-consuming compared to other 3D printing techniques for converting polymers to metals. \"We are already working on bringing the total processing time down by using a robot to automate these steps,\" Yee says.", "release_time": "2025-10-11", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251009033209.htm"}
{"category": "研究前沿", "title": "青岛能源所改造β-葡萄糖苷酶提升纤维素糖化效率", "short_summary": "研究通过酶工程获得高性能β-葡萄糖苷酶突变体，显著提升纤维素糖化速率。", "detailed_summary": "研究通过酶工程获得高性能β-葡萄糖苷酶突变体，显著提升纤维素糖化速率。\n(1) 针对木质纤维素高效降解挑战，研究聚焦关键酶β-葡萄糖苷酶CaBGL的性能提升；\n(2) 采用定向进化与半理性设计相结合策略，构建高通量筛选平台并获得最优突变体M418T；\n(3) 突变体在葡萄糖存在下催化活性提高两倍以上，体外糖化实验速率系数提升43%；\n(4) 机制分析表明突变减少了底物通道空间位阻，提升了催化效率；\n(5) 研究成果发表于Bioresource Technology，已获发明专利，为生物质转化提供新催化剂。", "raw_content": "木质纤维素作为地球上最丰富的可再生生物质资源，是生产可持续生物燃料和化学品的关键原料。然而，由于其结构复杂顽固，高效降解一直以来面临诸多挑战。在生物法降解纤维素的过程中，β-葡萄糖苷酶（BGL）负责将中间产物纤维寡糖分解为葡萄糖，并能解除寡糖对上游纤维素酶的抑制，作用至关重要。来源于Caldicellulosiruptor sp. F32的β-葡萄糖苷酶CaBGL因其出色的活性和稳定性，以及与热纤梭菌良好的适配性，已被应用于整合生物糖化这一新兴工艺中。由于野生型CaBGL的最佳工作条件与整合生物糖化工艺所需的条件存在显著差异，进一步提升CaBGL在整合生物糖化工艺操作条件下的性能具有重要的价值。针对这一问题，青岛能源所先进生物炼制与合成研究组通过酶工程技术，成功改造CaBGL，获得了性能大幅提升的突变体。研究团队设计了一种定向进化与半理性设计相结合的策略（图1）：首先构建了一套基于热稳定绿色荧光蛋白（TGP）的高通量筛选平台，对CaBGL进行定向进化筛选；随后结合结构生物学和分子对接分析，对获得的CaBGL突变体进行进一步的半理性设计和筛选，最终获得高性能的突变体。图1 CaBGL的酶工程改造策略：基于TGP融合的高通量筛选和基于结构的半理性设计相结合使用该策略，研究团队构建了包含6000个转化子的突变体库，经过初筛和复筛，成功获得了3个具有活性显著提升的突变体。对突变体上的活性位点进行饱和突变和组合突变，最终筛选到一个性能最优的突变体M418T。研究表明，在不同浓度（0-675 mM）葡萄糖存在的情况下，M418T的催化活性均比野生型酶提高两倍以上。在体外与天然纤维小体复配进行纤维素糖化实验中，M418T将糖化速率系数显著提升了43%。此外，通过结构分析与分子对接，研究团队还揭示了M418T性能提升的分子机制：M418T位点的突变有效减少了底物通道入口的空间位阻，使得底物更易进入，产物更易排出，从而大幅提升了催化效率（图2）。该研究不仅为工业木质纤维素转化提供了一种极具应用潜力的高性能生物催化剂，也为其他工业酶的定向改造和性能提升提供了可借鉴的有效策略。图2 CaBGL的酶工程改造优化结果及其性能提升的机制分析相关研究成果以“Engineering of β-glucosidase CaBGL with improved performance in cellulose hydrolysis”为题发表于Bioresource Technology，先进生物炼制与合成研究组冯银刚研究员和崔球研究员为论文的通讯作者，助理研究员游偲和硕士生郑欣为论文的共同第一作者。该论文所报道的高性能突变体酶已申请发明专利一项并获得授权（专利号202211087492.3）。相关研究得到了国家自然科学基金、青岛能源所强基计划等项目的支持。（文/图 游偲）原文链接：https://doi.org/10.1016/j.biortech.2025.133424You C#, Zheng X#, Qi K, Dong S, Liu YJ, Chen C, Cui Q*, Feng Y*. Engineering of β-glucosidase CaBGL with improved performance in cellulose hydrolysis. Bioresour. Technol. 2026, 440:133424. doi: 10.1016/j.biortech.2025.133424.发明专利：具备高酶活和高葡萄糖耐受性的β-葡萄糖苷酶突变体及应用；专利号：202211087492.3，发明人：崔球、游偲、郑欣、陈超、冯银刚；授权日：2024.07.02。", "release_time": "2025-10-29", "source_institution": "青岛生物能源与过程研究所", "url": "https://qibebt.cas.cn/news/kyjz/202510/t20251010_7985834.html"}
{"category": "政策计划", "title": "英国加入《核损害补充赔偿公约》推动全球核责任制度", "short_summary": "CSC公约旨在建立全球核责任制度，英国加入连接巴黎与维也纳体系。", "detailed_summary": "CSC公约旨在建立全球核责任制度，英国加入连接巴黎与维也纳体系。\n(1)《核损害补充赔偿公约》（CSC）是1997年通过、2015年生效的关键多边条约，旨在建立全球核责任制度，确保核事故损害的及时充分赔偿。\n(2)该公约作为“伞式”文书，向所有国家开放，并旨在通过缔约国提供的补充资金增加核事件赔偿金额。\n(3)英国加入CSC是首个巴黎公约缔约国的加入，首次建立了基于CSC的跨巴黎和维也纳体系的条约关系，是迈向全球核责任制度的重要一步。\n(4)CSC是目前覆盖全球最多在运核电机组的国际公约，英国加入后预计将覆盖约190台（约45%）在运机组。\n(5)目前CSC有11个缔约国和11个签署国，相关方定期举行年度会议。", "raw_content": "For over a decade, the General Conference of the IAEA has called upon Member States to consider joining the international nuclear liability instruments and to work towards establishing a global nuclear liability regime, to ensure prompt, adequate and non-discriminatory compensation for damage to people, property and the environment due to a nuclear accident or incident.  Adopted under the auspices of the IAEA on 12 September 1997 and entering into force on 15 April 2015, the CSC is a key multilateral treaty in the field of nuclear liability. It serves as an ‘umbrella’ instrument open to all States — including Parties to the 1963 and 1997 Vienna Conventions on Civil Liability for Nuclear Damage, the Paris Convention on Third Party Liability in the Field of Nuclear Energy, and States that are not party to any of these conventions but whose national legislation conforms to the provisions of the Annex to the CSC. The CSC also aims at increasing the amount of compensation available in the event of a nuclear incident through supplementary funds to be provided by its Contracting Parties.  “As the first Party to the Paris Convention to join the CSC, the UK’s accession establishes – for the first time - treaty relations based on the CSC across both the Paris and Vienna regimes and States belonging to neither,” said IAEA Director General Rafael Mariano Grossi, noting this represented “an important step towards achieving a truly global nuclear liability regime.”  The CSC is the single existing international nuclear liability convention covering the greatest number of nuclear power reactors in operation worldwide. When the UK becomes a Contracting Party, the CSC will cover approximately 190, or around 45 per cent, of such operational reactors.  The CSC currently has 11 Parties (Argentina, Benin, Canada, Ghana, India, Japan, Montenegro, Morocco, Romania, United Arab Emirates and United States of America) and 11 Signatories (Australia, Czech Republic, Indonesia, Italy, Lebanon, Lithuania, Mauritius, Peru, Philippines, Senegal and Ukraine). The IAEA’s online CSC calculator enables countries to run scenarios of potential contributions to the CSC’s contingent supplementary international fund. The CSC Parties and Signatories hold annual meetings, with the Fifth Meeting being held on 23-26 June 2025.", "release_time": "2025-10-11", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/an-important-step-for-the-global-nuclear-liability-regime-uk-accedes-to-the-csc"}
{"category": "产业应用", "title": "日立与谷歌云合作开发AI代理提升运营效率", "short_summary": "日立携手谷歌云利用AI代理技术优化能源、铁路等社会基础设施运营。", "detailed_summary": "日立携手谷歌云利用AI代理技术优化能源、铁路等社会基础设施运营。\n(1) 日立公司与谷歌云扩大战略合作，将AI应用扩展至运营技术领域，旨在解决劳动力短缺和技术传承问题；\n(2) 利用谷歌云的多模态AI Gemini Enterprise，开发无代码AI代理，帮助前线员工处理文本、图像等数据，提升任务效率；\n(3) 设立“Agent Factory”作为开发环境，结合日立领域知识和谷歌云技术，安全处理复杂流程和机密数据；\n(4) 具体应用案例包括在日立电力解决方案公司进行真空断路器检查的验证，通过图像比对减少人为错误；\n(5) 未来计划推广AI代理民主化，内部先行实施，并将成果通过HMAX提供给客户，促进社会基础设施可持续性。", "raw_content": "Tokyo, October 10th, 2025, Hitachi, Ltd. (TSE:6501, \"Hitachi\") has been working to improve productivity through AI utilization, software modernization, and enhanced customer service under its strategic alliance with Google Cloud*1. Now expanding into the OT (Operational Technology) domain, Hitachi will develop and utilize AI agents to accelerate operational transformation for frontline workers in social infrastructure sectors such as energy, railways, and manufacturing lines. Gemini, a multimodal AI, is designed to simultaneously understand and process various formats–text, images, audio, and video–making it highly compatible with frontline tasks that require accurate handling of physical information such as products and equipment. By utilizing Gemini Enterprise, even users without specialized knowledge can create AI agents to execute specific tasks via no-code interfaces, streamlining workflows. Hitachi has established the \"Agent Factory\" as its AI agent development environment. By leveraging Google Cloud technology, Hitachi will enhance this environment to enable simpler and faster development of AI agents tailored to specific on-site tasks and applications. This can be achieved by leveraging Google Cloud's advanced AI technologies together with Hitachi's deep domain knowledge and data governance expertise cultivated over many years. Even complex on-site processes and highly confidential data can be safely utilized, making it easier to apply AI to frontline workers' tasks–an area where AI adoption has traditionally been challenging. Notably, applying Gemini Enterprise  to frontline operations represents a highly advanced initiative and a key driver in realizing the vision of Hitachi's Lumada 3.0. Going forward, Hitachi will adopt a “Customer Zero” approach, focusing first on internal implementation. The company will work to create a variety of use cases within the Hitachi Group using Google Cloud, while also promoting the democratization of AI agents–empowering employees to develop solutions themselves using no-code tools, based on the expertise gained through these efforts. In particular, Hitachi's subsidiary, GlobalLogic Inc. (“GlobalLogic”), is a key global partner of Google Cloud and a launch partner for Gemini Enterprise, actively driving the deployment and adoption of Gemini Enterprise both internally and externally. Hitachi will accelerate value creation by integrating GlobalLogic's technology and expertise. Through the democratization of AI agents, Hitachi aims to foster an environment where new ideas for technology and operational improvements can emerge from the ground up. Hitachi will then offer these proven outcomes and field-driven innovations as part of HMAX to customers facing similar challenges, contributing to the enhanced sustainability and safety of social infrastructure.  *1 Hitachi and Google Cloud Announce Strategic Partnership to Accelerate Innovation and Productivity with Generative AI : May 28, 2024  Background In recent years, field operations such as maintenance and manufacturing that support social infrastructure have faced urgent challenges including worsening labor shortages and the aging of skilled technicians, making technology succession critical. Based on the strategic alliance announced in May 2024, Hitachi is driving corporate innovation and productivity by combining its deep domain knowledge in the social infrastructure business with Google Cloud's world-class AI and tools. Jun Abe, Executive Vice President of Hitachi, Ltd., General Manager of the Digital Systems & Services Division, stated: \"Hitachi views AI not merely as a tool, but as a partner that extends human capabilities. We are very pleased that our strategic alliance with Google Cloud has steadily advanced employee productivity and accelerated innovation. Looking ahead, we aim to extend these achievements into the OT domain, creating frontline environments where workers can collaborate with AI, stay energized, and focus on creative, high-value tasks. Under our Inspire 2027 vision, Hitachi has positioned the evolution of Lumada to version 3.0–driven by the fusion of domain knowledge and AI–as a key enabler of a 'Harmonized Society.' This initiative, leveraging advanced AI technologies from Google Cloud such as Gemini Enterprise alongside Hitachi's deep domain expertise, is a symbolic step toward that goal. As One Hitachi, we will continue working together across the group to fully harness the power of AI and build a better future.” Additionally, Hiroyuki Koike, Managing Director, Customer Engineering, Google Cloud Japan states: \"To solve complex business challenges with generative AI, companies need advanced technology and the expertise to successfully implement it across the organization. Through our strategic partnership with Hitachi, we will provide customers with the necessary technologies and resources to optimally build, implement, and manage every phase of their generative AI projects.\" Use cases As part of its initial rollout, Hitachi has begun a technical proof-of-concept at Hitachi Power Solutions Co., Ltd., a group company specializing in maintenance services for the energy and industrial sectors. One focus area is the inspection of vacuum circuit breakers (VCBs), critical components housed within power distribution panels. These inspections typically involve multiple technicians and carry a risk of human error–such as incorrect bolt alignment, misconnected capacitor wiring, or missed removal of discharge clips. To address these challenges, Hitachi is exploring the use of AI agents powered by Gemini Enterprise at its maintenance training center. The goal is to digitize and enhance restoration checks that were previously conducted using paper-based checklists, improving both reliability and operational efficiency. In this proof-of-concept, Hitachi is testing whether AI agents can compare images taken before and after maintenance work to verify proper restoration. Maintenance staff simply upload the images, and the AI agent provides alerts if any issues are detected. This approach is being considered for inspections across thousands of units annually, which currently require multiple technicians and final checks by experienced inspectors. By introducing AI agents, Hitachi aims to improve the accuracy of double-checks, reduce oversight, and enhance both the quality and efficiency of maintenance operations. The AI agent for this verification was designed by inputting essential inspection points, past failure causes, and important notes as natural language prompts, and then feeding it several examples of correct and incorrect post-work images. While initial setup may require support from an AI expert, the specifications are simple enough for on-site staff to handle subsequent adjustments and trials. Hitachi believes this low barrier to entry is essential for the democratization of AI agents. Going forward, Hitachi will also explore AI agents that use video data to check in real time if work procedures are being followed correctly, providing timely warnings about deviations or dangers. Hitachi will also take on the challenge of automatically generating reports from video footage, aiming to facilitate the transfer of on-site skills and knowledge and further reduce workloads. AI Agent Utilization: Work Process Concept    Image Comparison for Preventing Omissions in Restoring Conditions    (Left: Before Work(Correct State),Right: After work(Error Example))   About Hitachi, Ltd.  Through its Social Innovation Business (SIB) that brings together IT, OT(Operational Technology) and products, Hitachi contributes to a harmonized society where the environment, wellbeing, and economic growth are in balance. Hitachi operates globally in four sectors – Digital Systems & Services, Energy, Mobility, and Connective Industries – and the Strategic SIB Business Unit for new growth businesses. With Lumada at its core, Hitachi generates value from integrating data, technology and domain knowledge to solve customer and social challenges. Revenues for FY2024 (ended March 31, 2025) totaled 9,783.3 billion yen, with 618 consolidated subsidiaries and approximately 280,000 employees worldwide. Visit us at www.hitachi.com.  Information contained in this news release is current as of the date of the press announcement, but may be subject to change without prior notice.", "release_time": "2025-10-29", "source_institution": "日本日立", "url": "http://www.hitachi.com/New/cnews/month/2025/10/251010a.html"}
{"category": "产业应用", "title": "江苏建成规模化多形态储能调峰体系", "short_summary": "江苏整合多形态储能技术建成调峰体系，有效平抑电网负荷波动。", "detailed_summary": "江苏整合多形态储能技术建成调峰体系，有效平抑电网负荷波动。\n（1）江苏建成我国储能种类最全、资源最丰富的区域储能调峰体系；\n（2）体系整合新型储能集中调用、抽水蓄能科学调配、新能源汽车接网备用等技术；\n（3）可平抑电网负荷波动，应对新能源发电并网带来的调峰压力；\n（4）依托智能调度平台实现各类储能资源协同调度和集群控制；\n（5）迎峰度夏期间累计调用储能资源超1.4万次，最大调峰规模超1000万千瓦。", "raw_content": "近日，从国网江苏省电力有限公司获悉，江苏已建成规模化区域储能调峰体系。该体系整合了新型储能集中调用、抽水蓄能科学调配、新能源汽车接网备用等多形态储能调峰技术，能够有效平抑电网负荷波动。这是目前我国储能种类最全、资源最丰富的区域储能调峰体系，为新型电力系统建设提供了样板。作为经济大省和用能大省，江苏电网最大用电负荷已超1.56亿千瓦。同时，新能源发电并网规模超1亿千瓦，白天光伏发电量大时电网调峰压力小，傍晚光伏发电骤降时电网调峰压力急剧增大。”这种陡升陡降的负荷特性，对电网安全运行带来挑战。“国网江苏电力调控中心调度运行处处长仇晨光说，建设规模化、多形态的储能调峰体系，平抑电网负荷波动，对于江苏来说意义重大。这个区域储能调峰体系能够实现全省超760万千瓦新型储能集中调用，以及373万千瓦抽水蓄能科学调配。国网江苏电力还将新能源汽车作为移动储能资源纳入该体系，根据居住区、办公区等长时间停放新能源汽车的特点，引导新能源汽车在闲暇时间接受电网调控或根据激励信号自主充放电，实现削峰填谷。该体系能把分散在全省各地的储能资源聚合起来，形成了一个可以柔性控制的“超级充电宝”。依托国网江苏电力创新研发的智能调度平台，该体系可通过实时研判电网波动情况，智能生成各类储能资源的充放电控制策略，实现各类储能资源的协同调度和集群控制，发挥储能资源在区域电网中的协同互济作用。今年迎峰度夏期间，通过区域储能调峰体系，国网江苏电力累计集中调用各类储能资源超1.4万次，总充放电量超25亿千瓦时，最大调峰规模超1000万千瓦。这组数字充分说明了区域储能调峰体系支撑电力保供的作用。", "release_time": "2025-11-11", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/zhdt/202510/t20251028_792204.html"}
{"category": "研究前沿", "title": "LIGO新观测验证爱因斯坦与霍金黑洞理论", "short_summary": "最新引力波数据证实黑洞仅由质量与自旋定义，并验证霍金面积定理。", "detailed_summary": "最新引力波数据证实黑洞仅由质量与自旋定义，并验证霍金面积定理。\n（1）LIGO-Virgo-KAGRA合作组观测到形成63倍太阳质量黑洞的合并事件；\n（2）通过改进的探测技术首次清晰捕捉合并后黑洞的毫秒级\"铃声\"；\n（3）验证黑洞符合克尔解描述，仅由质量和自旋两个参数定义；\n（4）以四倍精度证实霍金面积定理，揭示事件视界面积与熵的关联；\n（5）该发现为统一广义相对论与量子物理提供新实验依据。", "raw_content": "A decade ago, scientists first detected ripples in the fabric of space-time, called gravitational waves, from the collision of two black holes. Now, thanks to improved technology and a bit of luck, a newly detected black hole merger is providing the clearest evidence yet of how black holes work -- and, in the process, offering long-sought confirmation of fundamental predictions by Albert Einstein and Stephen Hawking.  The new measurements were made by the Laser Interferometer Gravitational-Wave Observatory (LIGO), with analyses led by astrophysicists Maximiliano Isi and Will Farr of the Flatiron Institute's Center for Computational Astrophysics in New York City. The results reveal insights into the properties of black holes and the fundamental nature of space-time, hinting at how quantum physics and Einstein's general relativity fit together. \"This is the clearest view yet of the nature of black holes,\" says Isi, who is also an assistant professor at Columbia University. \"We've found some of the strongest evidence yet that astrophysical black holes are the black holes predicted from Albert Einstein's theory of general relativity.\" The results were reported in a paper published September 10 in Physical Review Letters by the LIGO-Virgo-KAGRA Collaboration. For massive stars, black holes are the final stage in their evolution. Black holes are so dense that even light cannot escape their gravity. When two black holes collide, the event distorts space itself, creating ripples in space-time that fan out across the universe, like sound waves ringing out from a struck bell. Those space-deforming ripples, called gravitational waves, can tell scientists a great deal about the objects that created them. Just as a large iron bell makes different sounds than a smaller aluminum bell, the \"sound\" a black hole merger makes is specific to the properties of the black holes involved. Scientists can detect gravitational waves with special instruments at observatories such as LIGO in the United States, Virgo in Italy and KAGRA in Japan. These instruments carefully measure how long it takes a laser to travel a given path. As gravitational waves stretch and compress space-time, the length of the instrument, and thus the light's travel time, changes minutely. By measuring those tiny changes with great precision, scientists can use them to determine the black holes' characteristics.  The newly reported gravitational waves were found to be created by a merger that formed a black hole with the mass of 63 suns and spinning at 100 revolutions per second. The findings come 10 years after LIGO made the first black hole merger detection. Since that landmark discovery, improvements in equipment and techniques have enabled scientists to get a much clearer look at these space-shaking events. \"The new pair of black holes are almost twins to the historic first detection in 2015,\" Isi says. \"But the instruments are much better, so we're able to analyze the signal in ways that just weren't possible 10 years ago.\" With these new signals, Isi and his colleagues got a complete look at the collision from the moment the black holes first careened into each other until the final reverberations as the merged black hole settled into its new state, which happened only milliseconds after first contact. Previously, the final reverberations were difficult to capture, as by that point, the ringing of the black hole would be very faint. As a result, scientists couldn't separate the ringing of the collision from that of the final black hole itself. In 2021, Isi led a study showcasing a cutting-edge method that he, Farr and others developed to isolate certain frequencies -- or 'tones' -- using data from the 2015 black hole merger. This method proved powerful, but the 2015 measurements weren't clear enough to confirm key predictions about black holes. With the new, more precise measurements, though, Isi and his colleagues were more confident they had successfully isolated the milliseconds-long signal of the final, settled black hole. This enabled more unambiguous tests of the nature of black holes. \"Ten milliseconds sounds really short, but our instruments are so much better now that this is enough time for us to really analyze the ringing of the final black hole,\" Isi says. \"With this new detection, we have an exquisitely detailed view of the signal both before and after the black hole merger.\" The new observations allowed scientists to test a key conjecture dating back decades that black holes are fundamentally simple objects. In 1963, physicist Roy Kerr used Einstein's general relativity to mathematically describe black holes with one equation. The equation showed that astrophysical black holes can be described by just two characteristics: spin and mass. With the new, higher-quality data, the scientists were able to measure the frequency and duration of the ringing of the merged black hole more precisely than ever before. This allowed them to see that, indeed, the merged black hole is a simple object, described by just its mass and spin.  The observations were also used to test a foundational idea proposed by Stephen Hawking called Hawking's area theorem. It states that the size of a black hole's event horizon -- the line past which nothing, not even light, can return -- can only ever grow. Testing whether this theorem applies requires exceptional measurements of black holes before and after their merger. Following the first black hole merger detection in 2015, Hawking wondered if the merger signature could be used to confirm his theorem. At the time, no one thought it was possible. By 2019, a year after Hawking's death, methods had improved enough that a first tentative confirmation came using techniques developed by Isi, Farr, and colleagues. With four times better resolution, the new data gives scientists much more confidence that Hawking's theorem is correct. In confirming Hawking's theorem, the results also hint at connections to the second law of thermodynamics. This law states that a property that measures a system's disorder, known as entropy, must increase, or at least remain constant, over time. Understanding the thermodynamics of black holes could lead to advances in other areas of physics, including quantum gravity, which aims to merge general relativity with quantum physics. \"It's really profound that the size of a black hole's event horizon behaves like entropy,\" Isi says. \"It has very deep theoretical implications and means that some aspects of black holes can be used to mathematically probe the true nature of space and time.\" Many suspect that future black hole merger detections will only reveal more about the nature of these objects. In the next decade, detectors are expected to become 10 times more sensitive than today, allowing for more rigorous tests of black hole characteristics. \"Listening to the tones emitted by these black holes is our best hope for learning about the properties of the extreme space-times they produce,\" says Farr, who is also a professor at Stony Brook University. \"And as we build more and better gravitational wave detectors, the precision will continue to improve.\" \"For so long this field has been pure mathematical and theoretical speculation,\" Isi says. \"But now we're in a position of actually seeing these amazing processes in action, which highlights how much progress there's been -- and will continue to be -- in this field.\"", "release_time": "2025-10-10", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250928095645.htm"}
{"category": "产业应用", "title": "国际原子能机构助力刚果建设首个放疗中心", "short_summary": "IAEA与欧佩克基金合作在刚果建立首个公共医院放疗中心，预计年治疗2000名癌症患者。", "detailed_summary": "IAEA与欧佩克基金合作在刚果建立首个公共医院放疗中心，预计年治疗2000名癌症患者。\n（1）国际原子能机构与欧佩克基金完成刚果民主共和国技术考察，评估首个公共医院放疗中心投资计划；\n（2）该项目属于2024年双方合作协议的一部分，旨在通过\"希望之光\"倡议扩大放疗可及性；\n（3）中心建成后预计每年可治疗至少2000名癌症患者，填补该国放疗服务空白；\n（4）考察团队包括辐射医学专家、卫生投资分析师及环境社会治理顾问；\n（5）IAEA总干事2023年访刚果时已为项目奠基，强调这是提升可持续癌症护理能力的关键一步。", "raw_content": "The IAEA and the OPEC Fund for International Development completed a joint technical mission in the Democratic Republic of the Congo (DRC) last week to review an investment plan to support the establishment of the country’s first radiotherapy centre in a public hospital, expected to treat at least 2000 cancer patients per year.  The visit follows an agreement between the two organizations in 2024 to join efforts to tackle growing global challenges in health, food and energy, among others, including through the IAEA’s Rays of Hope initiative to expand radiotherapy in countries with limited or no access to this life-saving treatment.  IAEA Director General Rafael Mariano Grossi met with DRC President Félix Antoine Tshisekedi Tshilombo during his visit to the country in November 2023 and laid a symbolic foundation stone for the new radiotherapy centre.  “The Democratic Republic of the Congo is taking a historic step to bring radiotherapy to its people,” the IAEA Director General said. “Our strategic partnership with the OPEC Fund under the Rays of Hope initiative exemplifies how combining our strengths can unlock critical financing that will enable the country not only to establish a radiotherapy centre but also to build the national expertise and infrastructure needed to deliver sustainable cancer care for years to come.” The mission’s objective was to visit the proposed site for the National Cancer Centre in Kinshasa, review capacities and needs and provide technical review for funding proposals. The mission team comprised radiation medicine experts from the IAEA, health sector investment and infrastructure analysts, and procurement and environmental, social and governance (ESG) advisors from the OPEC Fund.", "release_time": "2025-10-11", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/iaea-and-opec-fund-conduct-technical-visit-to-expand-cancer-services-in-the-drc"}
{"category": "产业应用", "title": "国际原子能机构颁发核能创新奖 五团队获奖", "short_summary": "IAEA表彰五支团队核能创新成果，涵盖人工智能、机器人等技术应用。", "detailed_summary": "IAEA表彰五支团队核能创新成果，涵盖人工智能、机器人等技术应用。\n（1）第二届国际核电站运行支持创新网络（ISOP）颁奖典礼在维也纳举行，五支团队从10国32项提交中获奖；\n（2）中国核电工程公司凭借反应堆安全壳结构光纤实时监测技术获先进仪表与控制奖；\n（3）西屋公司通过3D打印技术开发沸水堆燃料组件碎片过滤器，获先进制造奖；\n（4）阿联酋核能公司应用巴拉卡核电站数字孪生技术提升人员培训和运营效率；\n（5）布里斯托大学团队研发石墨堆芯检测机器人，降低人工风险并提高数据准确性；\n（6）Blue Wave AI实验室的人工智能模型实现热限值精准预测，优化反应堆运行安全。", "raw_content": "Five teams from around the world were honoured for advancing nuclear power sustainability at the second International Network on Innovation to Support Operating Nuclear Power Plants Innovation Awards. The winners were selected from 32 submissions across 10 countries and were awarded at a ceremony on the margins of the 69th IAEA General Conference in Vienna.  “Today’s award recipients exemplify the spirit of innovation,” said Deputy Director General and Head of the IAEA Department of Nuclear Energy Mikhail Chudakov in his opening remarks at the awards ceremony. “They have demonstrated creativity, technical excellence and a commitment to improving nuclear safety and performance.” The International Network on Innovation to Support Operating Nuclear Power Plants (ISOP) was established in 2023 to promote cross-border collaboration and continuous improvement in nuclear power. The network supports the long-term sustainability of operating nuclear power plants. ISOP’s scope includes any deployed innovation that helps sustain nuclear power reactors as a key component of current and future energy systems. Network activities include workshops, technical reports and collaborative initiatives, including use case sharing and coordinated research projects.  Award categories included artificial intelligence, advanced instrumentation and control, advanced manufacturing, robotics and drones, and other significant innovations. All entries had to have been deployed at an operational nuclear power plant. The winning teams presented their innovations in a webcast following the awards ceremony. Advanced Instrumentation and Control A team from China Nuclear Power Engineering (CNPE) led the field in the advanced instrumentation and control. Their reactor containment structure monitoring technology uses fibre optic cables to provide intelligent real-time monitoring of the steel strands embedded in containment structures, one of the most vital safety features of a nuclear reactor. “We are deeply honoured by this recognition and remain committed to advancing intelligent monitoring technology for an even safer and more sustainable future in nuclear containment,” said Di Yao, Director of CNPE’s Innovation Centre. Advanced Manufacturing  The Westinghouse Nuclear Fuel team won in the advanced manufacturing category. They developed a debris filter for boiling water reactor fuel assemblies using additive manufacturing also known as 3D printing. This technique enabled them to produce a highly effective filter with a geometrical complexity not possible with conventional manufacturing processes. \"The additive manufacturing process opened a whole new world of design options and inspired creative thinking in my team,” said Uffe Bergmann, Chief Engineer at Westinghouse Nuclear Fuel. “The StrongHold AM fuel debris filter improves operating efficiency of boiling water reactors in the nuclear fleet.\" Other Significant Innovations The Emirates Nuclear Energy Company (ENEC) based in the United Arab Emirates stood out with its digital twin technology — an interactive virtual model — of the Barakah Nuclear Power Plant designed to enable advanced training scenarios and enhance operational efficiency. This technology enables the plant to strengthen personnel training and improve reactor outage planning. “ENEC leverages digital twin and simulator technology to modernize nuclear training, aligning with tech-savvy learners’ expectations for immersive, visual and self-guided learning experiences,” said Abdulrahman Al Jailani, Director of Strategy and Digitization at ENEC Operations. Robotics and Drones A University of Bristol-based team won for its wheeled robot equipped with a Raman spectroscopy probe for in-core measurements of graphite reactor cores. This technology enables the collection of highly accurate, real-time characterization data while reducing human risk and saving time and cost. “To keep nuclear energy competitive on cost, there is a huge opportunity to better harness robotics and advanced sensor systems to enhance operational efficiency, tackle difficult tasks and at the same time improve safety. It's great to have our robotics work recognized by the IAEA,” said Professor Tom Scott, Head of the Hot Robotics Facility at the University of Bristol’s Interface Analysis Centre. “It is one step along the road of achieving our grand ambition of making robotic systems commonplace in the day to day running of nuclear power sites.” Artificial Intelligence In the artificial intelligence (AI) category, Blue Wave AI Labs won for its AI model for thermal limit predictions which was informed by a vast trove of operating data that enables it to accurately predict thermal limit parameters during reactor operation. Thermal limits are designed to, for example, prevent fuel cladding damage and radiological release during plant operations. The tool more accurately predicts margins to thermal limits, enabling operators to optimize reactor operation, fuel performance and cost. “We are proud that Nuclear-Grade AI™ from Blue Wave AI Labs was selected to receive the 2025 AI Award for our work with our partners at Constellation and Southern Nuclear,\" said Jonathan Nistory, Chief Operating Officer at Blue Wave Labs. Earlier this year, the IAEA conducted a webinar series highlighting some of the innovations submitted to the 2024 ISOP Awards. The recordings are available here.", "release_time": "2025-10-16", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/winning-teams-honoured-at-2nd-isop-innovation-awards"}
{"category": "研究前沿", "title": "世界最大环向场磁体线圈盒交付 助力聚变能源研究", "short_summary": "CRAFT项目世界最大TF磁体线圈盒交付，攻克多项关键技术，推动聚变能源商业化。", "detailed_summary": "CRAFT项目世界最大TF磁体线圈盒交付，攻克多项关键技术，推动聚变能源商业化。\n（1）聚变堆主机关键系统综合研究设施（CRAFT）环向场磁体线圈盒正式交付，外形尺寸达21米*12米，重400吨，为世界最大。\n（2）线圈盒采用超低温奥氏体不锈钢，最大焊接厚度超360毫米，尺寸与重量均超越国际热核聚变实验堆（ITER）同类部件。\n（3）项目历时5年多，攻克了低温不锈钢材料国产化、大厚度组合焊接、精密成形等多项关键技术难题。\n（4）此次交付为我国聚变装置高端装备制造积累了技术经验，培养了全流程产业供应链体系。\n（5）相关技术成果可应用于航空航天、能源装备等多个领域，是聚变能源商业化的重要一步。", "raw_content": "CRAFT环向场磁体线圈盒顺利交付 2025-10-09 | 作者：文/方超 图/蔡其敏 |【 大 中 小 】 【打印】 【关闭】 近日，聚变堆主机关键系统综合研究设施（CRAFT）项目取得重要进展，环向场（TF）磁体线圈盒抵达园区正式交付。 线圈盒是环向场磁体的主体承力结构部件，也是整个磁体系统的重要组成部分，主要用于保护TF线圈绕组并支撑与固定着极向场磁体等其他超导磁体。TF线圈盒由超低温奥氏体不锈钢316LN和316LMn材料构成，其外形尺寸达21米*12米，重量达400吨，最大焊接厚度超360毫米，是目前世界上最大的环向场磁体线圈盒，整体尺寸是国际热核聚变实验堆（ITER）同类部件的1.2倍以上，重量约为其两倍。 从研发到制造完成，项目团队历时5年多时间，攻克了多项关键技术难题。在原材料研制方面，完成了低温不锈钢316LMn材料的国产化、完成了百吨级316LN超大锻件和128毫米316LN超厚钢板的研制。在制造技术方面，面对最大厚度达360毫米的焊接挑战，研发了大厚度激光焊接和超深窄间隙钨极氩弧焊的组合焊接技术、相控阵无损检测技术，实现了线圈盒焊接的控形控性；开发了30米长空间弯管的精密成形、低温树脂与钎焊的冷却管固定技术，实现了冷却管的高精密安装。 线圈盒的顺利交付，不仅为我国聚变装置高端装备制造积累了相关技术经验，还培养了全流程全周期的产业供应链体系，是聚变能源商业化迈出的重要一步。相关技术还可应用于航空航天、能源装备、船舶海工等领域。 环向场（TF）磁体线圈盒正式交付 附件：", "release_time": "2025-10-09", "source_institution": "等离子体物理研究所", "url": "http://www.ipp.ac.cn/xwdt/ttxw/202510/t20251009_780702.html"}
{"category": "研究前沿", "title": "科学家揭示甲脒碘化铅低温相结构 助力高效太阳能电池研发", "short_summary": "研究结合机器学习模拟揭示卤化物钙钛矿低温结构，解决材料不稳定难题。", "detailed_summary": "研究结合机器学习模拟揭示卤化物钙钛矿低温结构，解决材料不稳定难题。\n(1) 全球电力需求持续增长，亟需开发如高效太阳能电池等环保能源转换技术；\n(2) 卤化物钙钛矿是极具前景的太阳能电池材料，但甲脒碘化铅的不稳定性制约其应用；\n(3) 查尔默斯理工大学团队通过机器学习辅助模拟，首次精确揭示了该材料低温相结构；\n(4) 研究发现分子在冷却过程中会陷入半稳定状态，这一发现通过与伯明翰大学实验对比验证；\n(5) 该突破为优化钙钛矿材料混合物设计提供了关键理论基础，推动下一代光电器件发展。", "raw_content": "Electricity use is constantly increasing globally and, according to the International Energy Agency, its proportion of the world's total energy consumption is expected to exceed 50 percent in 25 years, compared to the current 20 percent. \"To meet the demand, there is a significant and growing need for new, environmentally friendly and efficient energy conversion methods, such as more efficient solar cells. Our findings are essential to engineer and control one of the most promising solar cell materials for optimal utilization. It's very exciting that we now have simulation methods that can answer questions that were unresolved just a few years ago,\" says Julia Wiktor, the study's principal investigator and an associate professor at Chalmers. Promising materials for efficient solar cells Materials lying within a group called halide perovskites are considered the most promising for producing cost-effective, flexible and lightweight solar cells and optoelectronic devices such as LED bulbs, as they absorb and emit light extremely efficiently. However, perovskite materials can degrade quickly and knowing how best to utilize them requires a deeper understanding of why this happens and how the materials work. Scientists have long struggled to understand one particular material within the group, a crystalline compound called formamidinium lead iodide. It has outstanding optoelectronic properties. Greater use of the material has been hampered by its instability but this can be solved by mixing two types of halide perovskites. However, more knowledge is needed about the two types so that researchers can best control the mixture. The key to material design and control A research group at Chalmers can now provide a detailed account of an important phase of the material that has previously been difficult to explain by experiments alone. Understanding this phase is key to being able to design and control both this material and mixtures based on it. The study was recently published in Journal of the American Chemical Society. \"The low-temperature phase of this material has long been a missing piece of the research puzzle and we've now settled a fundamental question about the structure of this phase,\" says Chalmers researcher Sangita Dutta. Machine learning contributed to the breakthrough The researchers' expertise lies in building accurate models of different materials in computer simulations. This allows them to test the materials by exposing them to different scenarios and these are confirmed experimentally. Nevertheless, modelling materials in the halide perovskite family is tricky, as capturing and decoding their properties requires powerful supercomputers and long simulation times. \"By combining our standard methods with machine learning, we're now able to run simulations that are thousands of times longer than before. And our models can now contain millions of atoms instead of hundreds, which brings them closer to the real world,\" says Dutta. Lab observations match the simulations The researchers identified the structure of formamidinium lead iodide at low temperatures. They could also see that the formamidinium molecules get stuck in a semi-stable state while the material cools. To ensure that their study models reflect reality, they collaborated with experimental researchers at the University of Birmingham. They cooled the material to -- 200°C to ensure their experiments matched the simulations. \"We hope the insights we've gained from the simulations can contribute to how to model and analyse complex halide perovskite materials in the future,\" says Erik Fransson, at the Department of Physics at Chalmers. More about the research: The article \"Revealing the Low Temperature Phase of FAPbI 3 using A Machine-Learned Potential\" was published in Journal of the American Chemical Society on 14 th August 2025 and was written by Sangita Dutta, Erik Fransson, Tobias Hainer, Benjamin M. Gallant, Dominik J. Kubicki, Paul Erhart and Julia Wiktor. The researchers are all members of the Department of Physics at Chalmers University of Technology, except for Gallant and Kubicki, who are from the School of Chemistry, University of Birmingham. The research was supported by the Swedish Foundation for Strategic Research, the Swedish Energy Agency, the Swedish Research Council, the European Research Council, the Knut and Alice Wallenberg Foundation and the Nano Area of Advance at Chalmers University of Technology. The calculations were facilitated by resources from the National Academic Infrastructure for Supercomputing in Sweden (NAISS) at C3SE.", "release_time": "2025-10-10", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251001092218.htm"}
{"category": "研究前沿", "title": "MIT首次发现金属制造中非平衡态化学模式", "short_summary": "MIT研究揭示金属制造中原子非完全混合现象，为材料性能调控开辟新途径。", "detailed_summary": "MIT研究揭示金属制造中原子非完全混合现象，为材料性能调控开辟新途径。\n（1）MIT团队发现传统制造金属中存在此前未知的化学模式，这些\"远非平衡态\"模式会影响材料性能；\n（2）通过机器学习模拟追踪数百万原子运动，首次观察到制造过程中形成的特殊原子排列模式；\n（3）研究揭示了位错缺陷对原子交换的选择性偏好是形成这些模式的关键物理机制；\n（4）团队开发了可预测金属化学模式的简单模型，为材料设计提供新工具；\n（5）该发现有望在航空航天、核反应堆、半导体等领域实现材料性能的精准调控。", "raw_content": "For decades, it’s been known that subtle chemical patterns exist in metal alloys, but researchers thought they were too minor to matter — or that they got erased during manufacturing. However, recent studies have shown that in laboratory settings, these patterns can change a metal’s properties, including its mechanical strength, durability, heat capacity, radiation tolerance, and more. Now, researchers at MIT have found that these chemical patterns also exist in conventionally manufactured metals. The surprising finding revealed a new physical phenomenon that explains the persistent patterns. In a paper published in Nature Communications today, the researchers describe how they tracked the patterns and discovered the physics that explains them. The authors also developed a simple model to predict chemical patterns in metals, and they show how engineers could use the model to tune the effect of such patterns on metallic properties, for use in aerospace, semiconductors, nuclear reactors, and more. “The conclusion is: You can never completely randomize the atoms in a metal. It doesn’t matter how you process it,” Freitas says. “This is the first paper showing these non-equilibrium states that are retained in the metal. Right now, this chemical order is not something we’re controlling for or paying attention to when we manufacture metals.” For Freitas, an early-career researcher, the findings offer vindication for exploring a crowded field that he says few believed would lead to unique or broadly impactful results. He credits the U.S. Air Force Office of Scientific Research, which supported the work through their Young Investigator Program. He also credits the collaborative effort that enabled the paper, which features three MIT PhD students as co-first authors: Mahmudul Islam, Yifan Cao, and Killian Sheriff. “There was the question of whether I should even be tackling this specific problem because people have been working on it for a long time,” Freitas says. “But the more I learned about it, the more I saw researchers were thinking about this in idealized laboratory scenarios. We wanted to perform simulations that were as realistic as possible to reproduce these manufacturing processes with high fidelity. My favorite part of this project is how non-intuitive the findings are. The fact that you cannot completely mix something together, people didn’t see that coming.” From surprises to theories Freitas’ research team began with a practical question: How fast do chemical elements mix during metal processing? Conventional wisdom held that there’s a point where the chemical composition of metals becomes completely uniform from mixing during manufacturing. By finding that point, the researchers thought they could develop a simple way to design alloys with different levels of atomic order, also known as short-range order. The researchers used machine-learning techniques to track millions of atoms as they moved and rearranged themselves under conditions that mimicked metal processing. “The first thing we did was to deform a piece of metal,” Freitas explains. “That’s a common step during manufacturing: You roll the metal and deform it and heat it up again and deform it a little more, so it develops the structure you want. We did that and we tracked chemical order. The thought was as you deform the material, its chemical bonds are broken and that randomizes the system. These violent manufacturing processes essentially shuffle the atoms.” The researchers hit a snag during the mixing process: The alloys never reached a fully random state. That was a surprise, because no known physical mechanism could explain the result. “It pointed to a new piece of physics in metals,” the researchers write in the paper. “It was one of those cases where applied research led to a fundamental discovery.” To uncover the new physics, the researchers developed computational tools, including high-fidelity machine-learning models, to capture atomic interactions, along with new statistical methods that quantify how chemical order changes over time. They then applied these tools in large-scale molecular dynamics simulations to track how atoms rearrange during processing. The researchers found some standard chemical arrangements in their processed metals, but at higher temperatures than would normally be expected. Even more surprisingly, they found completely new chemical patterns never seen outside of manufacturing processes. This was the first time such patterns were observed. The researchers referred to the patterns as “far-from-equilibrium states.” The researchers also built a simple model that reproduced key features of the simulations. The model explains how the chemical patterns arise from defects known as dislocations, which are like three-dimensional scribbles within a metal. As the metal is deformed, those scribbles warp, shuffling nearby atoms along the way. Previously, researchers believed that shuffling completely erased order in the metals, but they found that dislocations favor some atomic swaps over others, resulting not in randomness but in subtle patterns that explain their findings. “These defects have chemical preferences that guide how they move,” Freitas says. “They look for low energy pathways, so given a choice between breaking chemical bonds, they tend to break the weakest bonds, and it’s not completely random. This is very exciting because it’s a non-equilibrium state: It’s not something you’d see naturally occurring in materials. It’s the same way our bodies live in non-equilibrium. The temperature outside is always hotter or colder than our bodies, and we’re maintaining that steady state equilibrium to stay alive. That’s why these states exist in metal: the balance between an internal push toward disorder plus this ordering tendency of breaking certain bonds that are always weaker than others.” Applying a new theory The researchers are now exploring how these chemical patterns develop across a wide range of manufacturing conditions. The result is a map that links various metal processing steps to different chemical patterns in metal. To date, this chemical order and the properties they tune have been largely considered an academic subject. With this map, the researchers hope engineers can begin thinking of these patterns as levers in design that can be pulled during production to get new properties. “Researchers have been looking at the ways these atomic arrangements change metallic properties — a big one is catalysis,” Freitas says of the process that drives chemical reactions. “Electrochemistry happens at the surface of the metal, and it’s very sensitive to local atomic arrangements. And there have been other properties that you wouldn't think would be influenced by these factors. Radiation damage is another big one. That affects these materials’ performance in nuclear reactors.” Researchers have already told Freitas the paper could help explain other surprise findings about metallic properties, and he’s excited for the field to move from fundamental research into chemical order to more applied work. “You can think of areas where you need very optimized alloys like aerospace,” Freitas says. “They care about very specific compositions. Advanced manufacturing now makes it possible to combine metals that normally wouldn’t mix through deformation. Understanding how atoms actually shuffle and mix in those processes is crucial, because it’s the key to gaining strength while still keeping the low density. So, this could be a huge deal for them.” This work was supported, in part, by the U.S. Air Force Office of Scientific Research, MathWorks, and the MIT-Portugal Program.", "release_time": "2025-10-08", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/uncovering-new-physics-metals-manufacturing-1008"}
{"category": "研究前沿", "title": "新型CAR-NK细胞实现免疫隐身，抗癌更安全高效", "short_summary": "MIT哈佛开发可逃避免疫排斥的CAR-NK细胞，为现货抗癌疗法铺平道路。", "detailed_summary": "MIT哈佛开发可逃避免疫排斥的CAR-NK细胞，为现货抗癌疗法铺平道路。\n（1）MIT与哈佛团队通过siRNA技术敲除NK细胞表面HLA蛋白，使其能逃逸宿主免疫系统攻击；\n（2）新型CAR-NK细胞在人类化免疫系统小鼠实验中近乎完全清除淋巴瘤，且存活时间超3周；\n（3）相比传统疗法，该技术显著降低细胞因子风暴风险，安全性更高；\n（4）单次基因工程即可实现\"现货\"供应，将治疗准备时间从数周缩短至即刻使用；\n（5）技术可拓展至CAR-T替代及自身免疫疾病治疗，已启动临床试验筹备。", "raw_content": "One of the newest weapons that scientists have developed against cancer is a type of engineered immune cell known as CAR-NK (natural killer) cells. Similar to CAR-T cells, these cells can be programmed to attack cancer cells. MIT and Harvard Medical School researchers have now come up with a new way to engineer CAR-NK cells that makes them much less likely to be rejected by the patient’s immune system, which is a common drawback of this type of treatment. The new advance may also make it easier to develop “off-the-shelf” CAR-NK cells that could be given to patients as soon as they are diagnosed. Traditional approaches to engineering CAR-NK or CAR-T cells usually take several weeks. “This enables us to do one-step engineering of CAR-NK cells that can avoid rejection by host T cells and other immune cells. And, they kill cancer cells better and they’re safer,” says Jianzhu Chen, an MIT professor of biology, a member of the Koch Institute for Integrative Cancer Research,and one of the senior authors of the study. In a study of mice with humanized immune systems, the researchers showed that these CAR-NK cells could destroy most cancer cells while evading the host immune system. Rizwan Romee, an associate professor of medicine at Harvard Medical School and Dana-Farber Cancer Institute, is also a senior author of the paper, which appears today in Nature Communications . The paper’s lead author is Fuguo Liu, a postdoc at the Koch Institute and a research fellow at Dana-Farber. Evading the immune system NK cells are a critical part of the body’s natural immune defenses, and their primary responsibility is to locate and kill cancer cells and virus-infected cells. One of their cell-killing strategies, also used by T cells, is a process called degranulation. Through this process, immune cells release a protein called perforin, which can poke holes in another cell to induce cell death. To create CAR-NK cells to treat cancer patients, doctors first take a blood sample from the patient. NK cells are isolated from the sample and engineered to express a protein called a chimeric antigen receptor (CAR), which can be designed to target specific proteins found on cancer cells. Then, the cells spend several weeks proliferating until there are enough to transfuse back into the patient. A similar approach is also used to create CAR-T cells. Several CAR-T cell therapies have been approved to treat blood cancers such as lymphoma and leukemia, but CAR-NK treatments are still in clinical trials. Because it takes so long to grow a population of engineered cells that can be infused into the patient, and those cells may not be as viable as cells that came from a healthy person, researchers are exploring an alternative approach: using NK cells from a healthy donor. Such cells could be grown in large quantities and would be ready whenever they were needed. However, the drawback to these cells is that the recipient’s immune system may see them as foreign and attack them before they can start killing cancer cells. In the new study, the MIT team set out to find a way to help NK cells “hide” from a patient’s immune system. Through studies of immune cell interactions, they showed that NK cells could evade a host T-cell response if they did not carry surface proteins called HLA class 1 proteins. These proteins, usually expressed on NK cell surfaces, can trigger T cells to attack if the immune system doesn’t recognize them as “self.” To take advantage of this, the researchers engineered the cells to express a sequence of siRNA (short interfering RNA) that interferes with the genes for HLA class 1. They also delivered the CAR gene, as well as the gene for either PD-L1 or single-chain HLA-E (SCE). PD-L1 and SCE are proteins that make NK cells more effective by turning up genes that are involved in killing cancer cells. All of these genes can be carried on a single piece of DNA, known as a construct, making it simple to transform donor NK cells into immune-evasive CAR-NK cells. The researchers used this construct to create CAR-NK cells targeting a protein called CD-19, which is often found on cancerous B cells in lymphoma patients. NK cells unleashed The researchers tested these CAR-NK cells in mice with a human-like immune system. These mice were also injected with lymphoma cells. Mice that received CAR-NK cells with the new construct maintained the NK cell population for at least three weeks, and the NK cells were able to nearly eliminate cancer in those mice. In mice that received either NK cells with no genetic modifications or NK cells with only the CAR gene, the host immune cells attacked the donor NK cells. In these mice, the NK cells died out within two weeks, and the cancer spread unchecked. The researchers also found that these engineered CAR-NK cells were much less likely to induce cytokine release syndrome — a common side effect of immunotherapy treatments, which can cause life-threatening complications. Because of CAR-NK cells’ potentially better safety profile, Chen anticipates that they could eventually be used in place of CAR-T cells. For any CAR-NK cells that are now in development to target lymphoma or other types of cancer, it should be possible to adapt them by adding the construct developed in this study, he says. The researchers now hope to run a clinical trial of this approach, working with colleagues at Dana-Farber. They are also working with a local biotech company to test CAR-NK cells to treat lupus, an autoimmune disorder that causes the immune system to attack healthy tissues and organs. The research was funded, in part, by Skyline Therapeutics, the Koch Institute Frontier Research Program through the Kathy and Curt Marble Cancer Research Fund and the Elisa Rah Memorial Fund, the Claudia Adams Barr Foundation, and the Koch Institute Support (core) Grant from the National Cancer Institute.", "release_time": "2025-10-08", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/engineered-natural-killer-cells-could-help-fight-cancer-1008"}
{"category": "研究前沿", "title": "MIT研发混合制氨法减排63%", "short_summary": "MIT提出蓝绿氨混合生产新工艺，可大幅降低温室气体排放并节约成本。", "detailed_summary": "MIT提出蓝绿氨混合生产新工艺，可大幅降低温室气体排放并节约成本。\n(1) 氨生产是化工行业主要碳排放源之一，占该行业温室气体排放的20%。\n(2) MIT研究人员提出将\"蓝氨\"（碳捕获）与\"绿氨\"（电解水制氢）生产设施结合的新方法。\n(3) 该方法利用绿氨厂产生的副产品纯氧供给蓝氨厂，实现协同效应，预计可比现有低碳方法减排63%。\n(4) 混合工艺能提高效率、降低总体成本，是向未来纯绿氨生产过渡的重要桥梁。\n(5) 该技术对满足全球日益增长的化肥需求及氨作为航运替代燃料的前景具有重要意义。", "raw_content": "Ammonia is one of the most widely produced chemicals in the world, used mostly as fertilizer, but also for the production of some plastics, textiles, and other applications. Its production, through processes that require high heat and pressure, accounts for up to 20 percent of all the greenhouse gases from the entire chemical industry, so efforts have been underway worldwide to find ways to reduce those emissions. Now, researchers at MIT have come up with a clever way of combining two different methods of producing the compound that minimizes waste products, that, when combined with some other simple upgrades, could reduce the greenhouse emissions from production by as much as 63 percent, compared to the leading “low-emissions” approach being used today. The new approach is described in the journal Energy & Fuels , in a paper by MIT Energy Initiative (MITEI) Director William H. Green, graduate student Sayandeep Biswas, MITEI Director of Research Randall Field, and two others. “Ammonia has the most carbon dioxide emissions of any kind of chemical,” says Green, who is the Hoyt C. Hottel Professor in Chemical Engineering. “It’s a very important chemical,” he says, because its use as a fertilizer is crucial to being able to feed the world’s population. Until late in the 19th century, the most widely used source of nitrogen fertilizer was mined deposits of bat or bird guano, mostly from Chile, but that source was beginning to run out, and there were predictions that the world would soon be running short of food to sustain the population. But then a new chemical process, called the Haber-Bosch process after its inventors, made it possible to make ammonia out of nitrogen from the air and hydrogen, which was mostly derived from methane. But both the burning of fossil fuels to provide the needed heat and the use of methane to make the hydrogen led to massive climate-warming emissions from the process. To address this, two newer variations of ammonia production have been developed: so-called “blue ammonia,” where the greenhouse gases are captured right at the factory and then sequestered deep underground, and “green ammonia,” produced by a different chemical pathway, using electricity instead of fossil fuels to hydrolyze water to make hydrogen. Blue ammonia is already beginning to be used, with a few plants operating now in Louisiana, Green says, and the ammonia mostly being shipped to Japan, “so that’s already kind of commercial.” Other parts of the world are starting to use green ammonia, especially in places that have lots of hydropower, solar, or wind to provide inexpensive electricity, including a giant plant now under construction in Saudi Arabia. But in most places, both blue and green ammonia are still more expensive than the traditional fossil-fuel-based version, so many teams around the world have been working on ways to cut these costs as much as possible so that the difference is small enough to be made up through tax subsidies or other incentives. The problem is growing, because as the population grows, and as wealth increases, there will be ever-increasing demands for nitrogen fertilizer. At the same time, ammonia is a promising substitute fuel to power hard-to-decarbonize transportation such as cargo ships and heavy trucks, which could lead to even greater needs for the chemical. “It definitely works” as a transportation fuel, by powering fuel cells that have been demonstrated for use by everything from drones to barges and tugboats and trucks, Green says. “People think that the most likely market of that type would be for shipping,” he says, “because the downside of ammonia is it’s toxic and it’s smelly, and that makes it slightly dangerous to handle and to ship around.” So its best uses may be where it’s used in high volume and in relatively remote locations, like the high seas. In fact, the International Maritime Organization will soon be voting on new rules that might give a strong boost to the ammonia alternative for shipping. The key to the new proposed system is to combine the two existing approaches in one facility, with a blue ammonia factory next to a green ammonia factory. The process of generating hydrogen for the green ammonia plant leaves a lot of leftover oxygen that just gets vented to the air. Blue ammonia, on the other hand, uses a process called autothermal reforming that requires a source of pure oxygen, so if there’s a green ammonia plant next door, it can use that excess oxygen. “Putting them next to each other turns out to have significant economic value,” Green says. This synergy could help hybrid “blue-green ammonia” facilities serve as an important bridge toward a future where eventually green ammonia, the cleanest version, could finally dominate. But that future is likely decades away, Green says, so having the combined plants could be an important step along the way. “It might be a really long time before [green ammonia] is actually attractive” economically, he says. “Right now, it’s nowhere close, except in very special situations.” But the combined plants “could be a really appealing concept, and maybe a good way to start the industry,” because so far only small, standalone demonstration plants of the green process are being built. “If green or blue ammonia is going to become the new way of making ammonia, you need to find ways to make it relatively affordable in a lot of countries, with whatever resources they’ve got,” he says. This new proposed combination, he says, “looks like a really good idea that can help push things along. Ultimately, there’s got to be a lot of green ammonia plants in a lot of places,” and starting out with the combined plants, which could be more affordable now, could help to make that happen. The team has filed for a patent on the process. Although the team did a detailed study of both the technology and the economics that show the system has great promise, Green points out that “no one has ever built one. We did the analysis, it looks good, but surely when people build the first one, they’ll find funny little things that need some attention,” such as details of how to start up or shut down the process. “I would say there’s plenty of additional work to do to make it a real industry.” But the results of this study, which shows the costs to be much more affordable than existing blue or green plants in isolation, “definitely encourages the possibility of people making the big investments that would be needed to really make this industry feasible.” This proposed integration of the two methods “improves efficiency, reduces greenhouse gas emissions, and lowers overall cost,” says Kevin van Geem, a professor in the Center for Sustainable Chemistry at Ghent University, who was not associated with this research. “The analysis is rigorous, with validated process models, transparent assumptions, and comparisons to literature benchmarks. By combining techno-economic analysis with emissions accounting, the work provides a credible and balanced view of the trade-offs.” He adds that, “given the scale of global ammonia production, such a reduction could have a highly impactful effect on decarbonizing one of the most emissions-intensive chemical industries.” The research team also included MIT postdoc Angiras Menon and MITEI research lead Guiyan Zang. The work was supported by IHI Japan through the MIT Energy Initiative and the Martin Family Society of Fellows for Sustainability.", "release_time": "2025-10-09", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/how-reduce-greenhouse-gas-emissions-ammonia-production-1008"}
{"category": "产业应用", "title": "美国电力需求激增下的供应与价格挑战研讨会", "short_summary": "研讨会探讨AI、电动汽车等因素导致美国电力需求激增后的供电稳价策略。", "detailed_summary": "研讨会探讨AI、电动汽车等因素导致美国电力需求激增后的供电稳价策略。\n（1）卡内基国际和平基金会等机构将于11月4日举办专题小组讨论会。\n（2）核心议题为美国电力需求因AI数据中心、电动汽车、制造业复兴及高温天气而快速增长的应对之策。\n（3）讨论重点包括如何保障电力供应稳定、控制电价，以及可再生能源与储能的角色定位。\n（4）会议将探讨如何在天然气供应链受阻背景下建立本土安全、有韧性的能源解决方案供应链。", "raw_content": "Join the Carnegie Endowment for International Peace, C2ES, and the Georgia Tech Strategic Energy Initiative on November 4th for panel discussions and a subsequent reception. On November 4th, join the Carnegie Endowment for International Peace, the Center for Climate and Energy Solutions, and the Georgia Tech Strategic Energy Institute for a panel discussion on Power and Production: Keeping Electricity Prices Down and the U.S. Economy Running . This panel discussion will be followed by audience Q&A and a reception. For two decades, power demand in the United States was essentially flat. It is now growing quickly again, as the country builds AI data centers, switches to EVs and electric heaters, seeks to revive domestic manufacturing, and turns up the AC to keep cool as temperatures rise. How can the United States keep the AC running, the lights on, and the prices down? What is the proper role for renewables and storage–the fastest growing energy sources in the country–at a time when the supply chain for gas power is snarled and blocked? And finally, how can we ensure a domestic, secure, resilient supply chain to produce all of these energy solutions here in the United States?", "release_time": "2025-10-10", "source_institution": "气候和能源解决方案中心（C2ES）", "url": "https://www.c2es.org/event/keeping-electricity-prices-down-and-the-u-s-economy-running/"}
{"category": "研究前沿", "title": "MIT突破量子噪声限制实现光学原子钟精度翻倍", "short_summary": "MIT团队开发全球相位光谱法，通过量子放大技术将光学原子钟测量精度提升一倍。", "detailed_summary": "MIT团队开发全球相位光谱法，通过量子放大技术将光学原子钟测量精度提升一倍。\n（1）MIT物理学家发现通过减少量子噪声可提高光学原子钟稳定性；\n（2）利用激光诱导的\"全局相位\"效应，结合量子放大技术开发全球相位光谱法；\n（3）新方法使光学原子钟辨别能力翻倍，能检测每秒100万亿次的原子振荡；\n（4）研究团队通过量子纠缠和时间反转技术突破传统微波频率限制；\n（5）该技术有望实现便携式光学原子钟，应用于暗物质探测和地震预测等领域。", "raw_content": "Every time you check the time on your phone, make an online transaction, or use a navigation app, you are depending on the precision of atomic clocks. An atomic clock keeps time by relying on the “ticks” of atoms as they naturally oscillate at rock-steady frequencies. Today’s atomic clocks operate by tracking cesium atoms, which tick over 10 billion times per second. Each of those ticks is precisely tracked using lasers that oscillate in sync, at microwave frequencies. Scientists are developing next-generation atomic clocks that rely on even faster-ticking atoms such as ytterbium, which can be tracked with lasers at higher, optical frequencies. If they can be kept stable, optical atomic clocks could track even finer intervals of time, up to 100 trillion times per second. Now, MIT physicists have found a way to improve the stability of optical atomic clocks, by reducing “quantum noise” — a fundamental measurement limitation due to the effects of quantum mechanics, which obscures the atoms’ pure oscillations. In addition, the team discovered that an effect of a clock’s laser on the atoms, previously considered irrelevant, can be used to further stabilize the laser. The researchers developed a method to harness a laser-induced “global phase” in ytterbium atoms, and have boosted this effect with a quantum-amplification technique. The new approach doubles the precision of an optical atomic clock, enabling it to discern twice as many ticks per second compared to the same setup without the new method. What’s more, they anticipate that the precision of the method should increase steadily with the number of atoms in an atomic clock. The researchers detail the method, which they call global phase spectroscopy, in a study appearing today in the journal Nature . They envision that the clock-stabilizing technique could one day enable portable optical atomic clocks that can be transported to various locations to measure all manner of phenomena. “With these clocks, people are trying to detect dark matter and dark energy, and test whether there really are just four fundamental forces , and even to see if these clocks can predict earthquakes,” says study author Vladan Vuletić, the Lester Wolfe Professor of Physics at MIT. “We think our method can help make these clocks transportable and deployable to where they’re needed.” The paper’s co-authors are Leon Zaporski, Qi Liu, Gustavo Velez, Matthew Radzihovsky, Zeyang Li, Simone Colombo, and Edwin Pedrozo-Peñafiel, who are members of the MIT-Harvard Center for Ultracold Atoms and the MIT Research Laboratory of Electronics. Ticking time In 2020, Vuletić and his colleagues demonstrated that an atomic clock could be made more precise by quantumly entangling the clock’s atoms. Quantum entanglement is a phenomenon by which particles can be made to behave in a collective, highly correlated manner. When atoms are quantumly entangled, they redistribute any noise, or uncertainty in measuring the atoms’ oscillations, in a way that reveals a clearer, more measurable “tick.” In their previous work, the team induced quantum entanglement among several hundred ytterbium atoms that they first cooled and trapped in a cavity formed by two curved mirrors. They sent a laser into the cavity, which bounced thousands of times between the mirrors, interacting with the atoms and causing the ensemble to entangle. They were able to show that quantum entanglement could improve the precision of existing atomic clocks by essentially reducing the noise, or uncertainty between the laser’s and atoms’ tick rates. At the time, however, they were limited by the ticking instability of the clock’s laser. In 2022, the same team derived a way to further amplify the difference in laser versus atom tick rates with “time reversal” — a trick that relies on entangling and de-entangling the atoms to boost the signal acquired in between. However, in that work the team was still using traditional microwaves, which oscillate at much lower frequencies than the optical frequency standards ytterbium atoms can provide. It was as if they had painstakingly lifted a film of dust off a painting, only to then photograph it with a low-resolution camera. “When you have atoms that tick 100 trillion times per second, that’s 10,000 times faster than the frequency of microwaves,” Vuletić says. “We didn’t know at the time how to apply these methods to higher-frequency optical clocks that are much harder to keep stable.” About phase In their new study, the team has found a way to apply their previously developed approach of time reversal to optical atomic clocks. They then sent in a laser that oscillates near the optical frequency of the entangled atoms. “The laser ultimately inherits the ticking of the atoms,” says first author Zaporski. “But in order for this inheritance to hold for a long time, the laser has to be quite stable.” The researchers found they were able to improve the stability of an optical atomic clock by taking advantage of a phenomenon that scientists had assumed was inconsequential to the operation. They realized that when light is sent through entangled atoms, the interaction can cause the atoms to jump up in energy, then settle back down into their original energy state and still carry the memory about their round trip. “One might think we’ve done nothing,” Vuletić says. “You get this global phase of the atoms, which is usually considered irrelevant. But this global phase contains information about the laser frequency.” In other words, they realized that the laser was inducing a measurable change in the atoms, despite bringing them back to the original energy state, and that the magnitude of this change depends on the laser’s frequency. “Ultimately, we are looking for the difference of laser frequency and the atomic transition frequency,” explains co-author Liu. “When that difference is small, it gets drowned by quantum noise. Our method amplifies this difference above this quantum noise.” In their experiments, the team applied this new approach and found that through entanglement they were able to double the precision of their optical atomic clock. “We saw that we can now resolve nearly twice as small a difference in the optical frequency or, the clock ticking frequency, without running into the quantum noise limit,” Zaporski says. “Although it’s a hard problem in general to run atomic clocks, the technical benefits of our method it will make it easier, and we think this can enable stable, transportable atomic clocks.” This research was supported, in part, by the U.S. Office of Naval Research, the National Science Foundation, the U.S. Defense Advanced Research Projects Agency, the U.S. Department of Energy, the U.S. Office of Science, the National Quantum Information Science Research Centers, and the Quantum Systems Accelerator.", "release_time": "2025-10-09", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/mit-physicists-improve-atomic-clocks-precision-1008"}
{"category": "政策计划", "title": "IAEA区域合作协定年会推动核技术应用", "short_summary": "IAEA四大区域协定年会协调优先事项，通过南南合作强化核技术应用。", "detailed_summary": "IAEA四大区域协定年会协调优先事项，通过南南合作强化核技术应用。\n（1）IAEA第69届大会期间举行四大区域合作协定年会，超过200名代表参会；\n（2）区域合作协定包括非洲的AFRA、亚洲阿拉伯国家的ARASIA、拉美加勒比的ARCAL和亚太地区的RCA；\n（3）会议结论将指导新项目设计、新倡议制定和明年区域优先事项确认；\n（4）技术合作计划通过南南合作帮助各国加强医疗、能源安全等优先领域；\n（5）国家联络官和助理作为IAEA与成员国沟通关键渠道，协调项目执行。", "raw_content": "Over 200 delegates attended four annual regional meetings on the margins of the IAEA’s 69th General Conference to coordinate the activities of the AFRA, ARASIA, ARCAL and RCA regional cooperative agreements. The conclusions emerging from these meetings will inform the design of new projects, the development of new initiatives and the identification of regional priorities for the next year.  Regional and South-South cooperation are key pillars of the IAEA’s technical cooperation (TC) programme. The TC programme helps countries sustainably address their most urgent priorities, such as strengthening healthcare or energy security, through the application of nuclear science and technology. One element of this support is through South-South Cooperation at a regional level, such as sharing resources, transferring knowledge and participating in training. These activities are coordinated by the four regional cooperative agreements: AFRA for IAEA Member States in Africa, ARASIA for Arab States in Asia, ARCAL for Latin America and the Caribbean, and RCA for countries in Asia and the Pacific. Each year during the IAEA’s General Conference, parties to all four Regional Cooperative Agreements hold their annual meeting to advance shared regional priorities and exchange knowledge and best practices. Europe and Central Asia’s National Liaison Officers and Assistants also meet in during the General Conference to review the implementation of TC projects, share best practices and challenges, and discuss ways to improve project design and monitoring.  What are Regional Cooperative Agreements? Regional Cooperative Agreements are formal inter-governmental agreements that serve as a framework for IAEA Member States to intensify their collaboration through programmes and projects focused on the shared needs of specific regions, and to promote the application of nuclear science and technology at the regional level. The TC Division for Europe also has a regional strategy and profile in place to promote collaboration and knowledge exchange in Europe and Central Asia. What are NLOs and NLAs? Designated by the relevant government authority, National Liaison Officers (NLOs) and Assistants (NLAs) play an important role in the delivery of the IAEA’s technical cooperation programme: “As the IAEA does not have country teams on the ground, NLOs and NLAs play a crucial role representing their countries, conveying national priorities, and acting as the primary channel of communication between the IAEA and Member States,” said Hua Liu, Deputy Director General and Head of the IAEA’s Technical Cooperation Department, during this year’s meeting of NLOs and NLAs from Europe and Central Asia.", "release_time": "2025-10-16", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/regional-cooperation-high-on-the-agenda-at-the-iaeas-69th-general-conference"}
{"category": "研究前沿", "title": "MIT与MBZUAI启动AI联合研究计划", "short_summary": "两校合作推进AI基础研究，聚焦科学、人类与地球三大领域应用。", "detailed_summary": "两校合作推进AI基础研究，聚焦科学、人类与地球三大领域应用。\n（1）MIT与MBZUAI启动五年期联合研究计划，加强AI基础技术并加速解决科学与社会挑战；\n（2）合作聚焦三大核心领域：科学发现、人类福祉和地球健康；\n（3）双方将联合开展基础研究项目，由MIT的Philip Isola和MBZUAI的Le Song分别担任学术总监；\n（4）研究成果将公开出版，每年资助多个联合项目，由双方代表组成的指导委员会遴选；\n（5）合作旨在负责任地推进AI创新，改善人类健康、智能机器人和可持续AI应用。", "raw_content": "The MIT Schwarzman College of Computing and the Mohamed bin Zayed University of Artificial Intelligence (MBZUAI) recently celebrated the launch of the MIT–MBZUAI Collaborative Research Program, a new effort to strengthen the building blocks of artificial intelligence and accelerate its use in pressing scientific and societal challenges.Under the five-year agreement, faculty, students, and research staff from both institutions will collaborate on fundamental research projects to advance the technological foundations of AI and its applications in three core areas: scientific discovery, human thriving, and the health of the planet.“Artificial intelligence is transforming nearly every aspect of human endeavor. MIT’s leadership in AI is greatly enriched through collaborations with leading academic institutions in the U.S. and around the world,” says Dan Huttenlocher, dean of the MIT Schwarzman College of Computing and the Henry Ellis Warren Professor of Electrical Engineering and Computer Science. “Our collaboration with MBZUAI reflects a shared commitment to advancing AI in ways that are responsible, inclusive, and globally impactful. Together, we can explore new horizons in AI and bring broad benefits to society.”“This agreement will unite the efforts of researchers at two world-class institutions to advance frontier AI research across scientific discovery, human thriving, and the health of the planet. By combining MBZUAI’s focus on foundational models and real-world deployment with MIT’s depth in computing and interdisciplinary innovation, we are creating a transcontinental bridge for discovery. Together, we will not only expand the boundaries of AI science, but also ensure that these breakthroughs are pursued responsibly and applied where they matter most — improving human health, enabling intelligent robotics, and driving sustainable AI at scale,” says Eric Xing, president and university professor at MBZUAI.Each institution has appointed an academic director to oversee the program on its campus. At MIT, Philip Isola , the Class of 1948 Career Development Professor in the Department of Electrical Engineering and Computer Science, will serve as program lead. At MBZUAI, Le Song , professor of machine learning, will take on the role.Supported by MBZUAI — the first university dedicated entirely to advancing science through AI, and based in Abu Dhabi, U.A.E. — the collaboration will fund a number of joint research projects per year. The findings will be openly publishable, and each project will be led by a principal investigator from MIT and one from MBZUAI, with project selections made by a steering committee composed of representatives from both institutions.", "release_time": "2025-10-09", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/mit-schwarzman-college-computing-mbzuai-launch-collaboration-shape-future-ai-1008"}
{"category": "研究前沿", "title": "金刚石单光子高效收集技术突破量子应用瓶颈", "short_summary": "研究人员利用混合纳米天线实现金刚石缺陷单光子80%收集率，推动量子技术实用化。", "detailed_summary": "研究人员利用混合纳米天线实现金刚石缺陷单光子80%收集率，推动量子技术实用化。\n（1）以色列希伯来大学与柏林洪堡大学合作开发新型混合纳米天线系统；  \n（2）将含氮空位中心的纳米金刚石精准嵌入金属-电介质牛眼结构天线中心；  \n（3）该系统在室温下实现80%的单光子定向收集效率，远超以往技术；  \n（4）突破解决了量子信息载体（光子）散射损失的关键难题；  \n（5）技术为量子计算机、安全通信和超灵敏传感器提供实用化芯片基础。", "raw_content": "Diamonds have long been prized for their sparkle, but researchers at the Hebrew University of Jerusalem in collaboration with colleagues from the Humboldt University in Berlin are showing they achieve an almost optimal \"sparkling,\" a key requirement for using diamonds also for quantum technology. The team has approached an almost perfect collection of the faintest light signals, single photons, from tiny diamond defects, known as nitrogen-vacancy (NV) centers, which are vital for developing next-generation quantum computers, sensors, and communication networks. NV centers are microscopic imperfections in the diamond structure that can act like quantum \"light switches.\" They emit single particles of light (photons) that carry quantum information. The problem, until now, has been that much of this light is lost in all directions, making it hard to capture and use. The Hebrew University team, together with their research partners from Berlin, solved this challenge by embedding nanodiamonds containing NV centers into specially designed hybrid nanoantennas. These antennas, built from layers of metal and dielectric materials in a precise bullseye pattern, guide the light in a well-defined direction instead of letting it scatter. Using ultra-precise positioning, the researchers placed the nanodiamonds exactly at the antenna center -- within a few billionths of a meter. Featured in APL Quantum , the results are significant: the new system can collect up to 80% of the emitted photons at room temperature. This is a dramatic improvement compared to previous attempts, where only a small fraction of the light was usable. Prof. Rapaport explained, \"Our approach brings us much closer to practical quantum devices. By making photon collection more efficient, we're opening the door to technologies such as secure quantum communication and ultra-sensitive sensors.\" Dr. Lubotzky added, \"What excites us is that this works in a simple, chip-based design and at room temperature. That means it can be integrated into real-world systems much more easily than before.\" The research demonstrates not just clever engineering, but also the potential of diamonds beyond jewelry. With quantum technologies racing toward real-world applications, this advance could help pave the way for faster, more reliable quantum networks.", "release_time": "2025-10-08", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251007081833.htm"}
{"category": "研究前沿", "title": "MIT开发可控场景生成技术革新机器人训练", "short_summary": "MIT团队利用扩散模型生成物理精确的3D场景，大幅提升机器人模拟训练效果。", "detailed_summary": "MIT团队利用扩散模型生成物理精确的3D场景，大幅提升机器人模拟训练效果。\n（1）MIT与丰田研究院合作开发\"可控场景生成\"技术，通过扩散模型生成逼真的3D场景；\n（2）采用蒙特卡洛树搜索等策略优化场景生成，确保物理准确性并支持复杂场景构建；\n（3）实验显示该技术能生成包含34个物体的餐厅场景，提示遵循准确率最高达98%；\n（4）该系统可为机器人提供多样化训练环境，支持物品摆放等精细操作模拟；\n（5）未来计划整合互联网图像数据，进一步扩展场景多样性和真实性。", "raw_content": "Chatbots like ChatGPT and Claude have experienced a meteoric rise in usage over the past three years because they can help you with a wide range of tasks. Whether you’re writing Shakespearean sonnets, debugging code, or need an answer to an obscure trivia question, artificial intelligence systems seem to have you covered. The source of this versatility? Billions, or even trillions, of textual data points across the internet. Those data aren’t enough to teach a robot to be a helpful household or factory assistant, though. To understand how to handle, stack, and place various arrangements of objects across diverse environments, robots need demonstrations. You can think of robot training data as a collection of how-to videos that walk the systems through each motion of a task. Collecting these demonstrations on real robots is time-consuming and not perfectly repeatable, so engineers have created training data by generating simulations with AI (which don’t often reflect real-world physics), or tediously handcrafting each digital environment from scratch. Researchers at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) and the Toyota Research Institute may have found a way to create the diverse, realistic training grounds robots need. Their “ steerable scene generation ” approach creates digital scenes of things like kitchens, living rooms, and restaurants that engineers can use to simulate lots of real-world interactions and scenarios. Trained on over 44 million 3D rooms filled with models of objects such as tables and plates, the tool places existing assets in new scenes, then refines each one into a physically accurate, lifelike environment. Steerable scene generation creates these 3D worlds by “steering” a diffusion model — an AI system that generates a visual from random noise — toward a scene you’d find in everyday life. The researchers used this generative system to “in-paint” an environment, filling in particular elements throughout the scene. You can imagine a blank canvas suddenly turning into a kitchen scattered with 3D objects, which are gradually rearranged into a scene that imitates real-world physics. For example, the system ensures that a fork doesn’t pass through a bowl on a table — a common glitch in 3D graphics known as “clipping,” where models overlap or intersect.How exactly steerable scene generation guides its creation toward realism, however, depends on the strategy you choose. Its main strategy is “Monte Carlo tree search” (MCTS), where the model creates a series of alternative scenes, filling them out in different ways toward a particular objective (like making a scene more physically realistic, or including as many edible items as possible). It’s used by the AI program AlphaGo to beat human opponents in Go (a game similar to chess), as the system considers potential sequences of moves before choosing the most advantageous one.“We are the first to apply MCTS to scene generation by framing the scene generation task as a sequential decision-making process,” says MIT Department of Electrical Engineering and Computer Science (EECS) PhD student Nicholas Pfaff, who is a CSAIL researcher and a lead author on a paper presenting the work. “We keep building on top of partial scenes to produce better or more desired scenes over time. As a result, MCTS creates scenes that are more complex than what the diffusion model was trained on.” In one particularly telling experiment, MCTS added the maximum number of objects to a simple restaurant scene. It featured as many as 34 items on a table, including massive stacks of dim sum dishes, after training on scenes with only 17 objects on average. Steerable scene generation also allows you to generate diverse training scenarios via reinforcement learning — essentially, teaching a diffusion model to fulfill an objective by trial-and-error. After you train on the initial data, your system undergoes a second training stage, where you outline a reward (basically, a desired outcome with a score indicating how close you are to that goal). The model automatically learns to create scenes with higher scores, often producing scenarios that are quite different from those it was trained on.Users can also prompt the system directly by typing in specific visual descriptions (like “a kitchen with four apples and a bowl on the table”). Then, steerable scene generation can bring your requests to life with precision. For example, the tool accurately followed users’ prompts at rates of 98 percent when building scenes of pantry shelves, and 86 percent for messy breakfast tables. Both marks are at least a 10 percent improvement over comparable methods like “ MiDiffusion ” and “ DiffuScene .”The system can also complete specific scenes via prompting or light directions (like “come up with a different scene arrangement using the same objects”). You could ask it to place apples on several plates on a kitchen table, for instance, or put board games and books on a shelf. It’s essentially “filling in the blank” by slotting items in empty spaces, but preserving the rest of a scene. According to the researchers, the strength of their project lies in its ability to create many scenes that roboticists can actually use. “A key insight from our findings is that it’s OK for the scenes we pre-trained on to not exactly resemble the scenes that we actually want,” says Pfaff. “Using our steering methods, we can move beyond that broad distribution and sample from a ‘better’ one. In other words, generating the diverse, realistic, and task-aligned scenes that we actually want to train our robots in.” Such vast scenes became the testing grounds where they could record a virtual robot interacting with different items. The machine carefully placed forks and knives into a cutlery holder, for instance, and rearranged bread onto plates in various 3D settings. Each simulation appeared fluid and realistic, resembling the real-world, adaptable robots steerable scene generation could help train, one day. While the system could be an encouraging path forward in generating lots of diverse training data for robots, the researchers say their work is more of a proof of concept. In the future, they’d like to use generative AI to create entirely new objects and scenes, instead of using a fixed library of assets. They also plan to incorporate articulated objects that the robot could open or twist (like cabinets or jars filled with food) to make the scenes even more interactive. To make their virtual environments even more realistic, Pfaff and his colleagues may incorporate real-world objects by using a library of objects and scenes pulled from images on the internet and using their previous work on “ Scalable Real2Sim .” By expanding how diverse and lifelike AI-constructed robot testing grounds can be, the team hopes to build a community of users that’ll create lots of data, which could then be used as a massive dataset to teach dexterous robots different skills.“Today, creating realistic scenes for simulation can be quite a challenging endeavor; procedural generation can readily produce a large number of scenes, but they likely won’t be representative of the environments the robot would encounter in the real world. Manually creating bespoke scenes is both time-consuming and expensive,” says Jeremy Binagia, an applied scientist at Amazon Robotics who wasn’t involved in the paper. “Steerable scene generation offers a better approach: train a generative model on a large collection of pre-existing scenes and adapt it (using a strategy such as reinforcement learning) to specific downstream applications. Compared to previous works that leverage an off-the-shelf vision-language model or focus just on arranging objects in a 2D grid, this approach guarantees physical feasibility and considers full 3D translation and rotation, enabling the generation of much more interesting scenes.” “Steerable scene generation with post training and inference-time search provides a novel and efficient framework for automating scene generation at scale,” says Toyota Research Institute roboticist Rick Cory SM ’08, PhD ’10, who also wasn’t involved in the paper. “Moreover, it can generate ‘never-before-seen’ scenes that are deemed important for downstream tasks. In the future, combining this framework with vast internet data could unlock an important milestone towards efficient training of robots for deployment in the real world.”Pfaff wrote the paper with senior author Russ Tedrake, the Toyota Professor of Electrical Engineering and Computer Science, Aeronautics and Astronautics, and Mechanical Engineering at MIT; a senior vice president of large behavior models at the Toyota Research Institute; and CSAIL principal investigator. Other authors were Toyota Research Institute robotics researcher Hongkai Dai SM ’12, PhD ’16; team lead and Senior Research Scientist Sergey Zakharov; and Carnegie Mellon University PhD student Shun Iwase. Their work was supported, in part, by Amazon and the Toyota Research Institute. The researchers presented their work at the Conference on Robot Learning (CoRL) in September.", "release_time": "2025-10-09", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/using-generative-ai-diversify-virtual-training-grounds-robots-1008"}
{"category": "研究前沿", "title": "日本研究揭示kagome金属磁控电流反转机制", "short_summary": "量子几何效应将kagome金属磁控电流反转放大百倍，为新型量子器件奠定理论基础。", "detailed_summary": "量子几何效应将kagome金属磁控电流反转放大百倍，为新型量子器件奠定理论基础。\n（1）日本团队首次理论解释kagome金属中弱磁场反转微观环状电流的量子机制；  \n（2）研究发现量子几何效应将电流方向切换（二极管效应）放大约100倍；  \n（3）机制源于晶格几何 frustration 与电荷密度波共同打破电子结构对称性；  \n（4）实验在-190°C极低温下观测环状电流与磁控反转现象；  \n（5）理论突破为磁控量子存储器、超灵敏传感器等新型器件开发提供基础。", "raw_content": "Researchers in Japan have explained how electricity behaves in a special group of quantum metals called kagome metals. The study is the first to show how weak magnetic fields reverse tiny loop electrical currents inside these metals. This switching changes the material's macroscopic electrical properties and reverses which direction has easier electrical flow, a property known as the diode effect, where current flows more easily in one direction than the other. Notably, the research team found that quantum geometric effects amplify this switching by about 100 times. The study, published in Proceedings of the National Academy of Sciences , provides the theoretical foundation that could eventually lead to new electronic devices controlled by simple magnets. Scientists had observed this strange magnetic switching behavior in experiments since around 2020 but could not explain why it happened and why the effect was so strong. This study provides the first theoretical framework explaining both. When frustrated electrons cannot settle The name \"kagome metal\" comes from the Japanese word \"kagome,\" meaning \"basket eyes\" or \"basket pattern,\" which refers to a traditional bamboo weaving technique that creates interlocking triangular designs. These metals are special because their atoms are arranged in this unique basket-weave pattern that creates what scientists call \"geometric frustration\" -- electrons cannot settle into simple, organized patterns and are forced into more complex quantum states that include the loop currents. When the loop currents inside these metals change direction, the electrical behavior of the metal changes. The research team showed that loop currents and wave-like electron patterns (charge density waves) work together to break fundamental symmetries in the electronic structure. They also discovered that quantum geometric effects -- unique behaviors that only occur at the smallest scales of matter -- significantly enhance the switching effect. \"Every time we saw the magnetic switching, we knew something extraordinary was happening, but we couldn't explain why,\" Hiroshi Kontani, senior author and professor from the Graduate School of Science at Nagoya University, recalled. \"Kagome metals have built-in amplifiers that make the quantum effects much stronger than they would be in ordinary metals. The combination of their crystal structure and electronic behavior allows them to break certain core rules of physics simultaneously, a phenomenon known as spontaneous symmetry breaking. This is extremely rare in nature and explains why the effect is so powerful.\" The research method involved cooling the metals to extremely low temperatures of about -190°C. At this temperature, the kagome metal naturally develops quantum states where electrons form circulating currents and create wave-like patterns throughout the material. When scientists apply weak magnetic fields, they reverse the direction these currents spin, and as a result, the preferred direction of current flow in the metal changes. New materials meet new theory This breakthrough in quantum physics was not possible until recently because kagome metals were only discovered around 2020. While scientists quickly observed the mysterious electrical switching effect in experiments, they could not explain how it worked. The quantum interactions involved are very complex and require advanced understanding of how loop currents, quantum geometry, and magnetic fields work together -- knowledge that has only developed in recent years. These effects are also very sensitive to impurities, strain, and external conditions, which makes them difficult to study. \"This discovery happened because three things came together at just the right time: we finally had the new materials, the advanced theories to understand them, and the high-tech equipment to study them properly. None of these existed together until very recently, which is why no one could solve this puzzle before now,\" Professor Kontani added. \"The magnetic control of electrical properties in these metals could potentially enable new types of magnetic memory devices or ultra-sensitive sensors. Our study provides the fundamental understanding needed to begin developing the next generation of quantum-controlled technology,\" he said.", "release_time": "2025-10-08", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251007081829.htm"}
{"category": "研究前沿", "title": "肠道菌群与大脑边界免疫研究揭示神经疾病新机制", "short_summary": "研究揭示肠道菌群驱动帕金森病，迷走神经调控免疫，大脑边界巨噬细胞节律清障。", "detailed_summary": "研究揭示肠道菌群驱动帕金森病，迷走神经调控免疫，大脑边界巨噬细胞节律清障。\n(1) Sarkis Mazmanian教授团队发现肠道微生物组可通过细菌淀粉样蛋白促进α-突触核蛋白病理，并开发高纤维饮食和药物干预缓解帕金森病小鼠症状。\n(2) Kevin Tracey教授阐述迷走神经刺激调控免疫细胞因子，FDA批准颈部植入设备治疗类风湿关节炎而不抑制整体免疫系统。\n(3) Beth Stevens和Marco Colonna等团队研究发现大脑边界相关巨噬细胞具有昼夜节律，其清障功能受时钟基因调控，节律紊乱可能加剧阿尔茨海默病蛋白堆积。", "raw_content": "In his talk, Caltech Professor Sarkis Mazmanian focused on work in his lab linking the gut microbiome to Parkinson’s disease (PD), for instance by promoting alpha-synuclein protein pathology and motor problems in mouse models. His lab hypothesizes that the microbiome can nucleate alpha-synuclein in the gut via a bacterial amyloid protein that may subsequently promote pathology in the brain, potentially via the vagus nerve. Based on its studies, the lab has developed two interventions. One is giving alpha-synuclein overexpressing mice a high-fiber diet to increase short-chain fatty acids in their gut, which actually modulates the activity of microglia in the brain. The high-fiber diet helps relieve motor dysfunction, corrects microglia activity, and reduces protein pathology, he showed. Another is a drug to disrupt the bacterial amyloid in the gut. It prevents alpha synuclein formation in the mouse brain and ameliorates PD-like symptoms. These results are pending publication. Meanwhile, Kevin Tracey, professor at Hofstra University and Northwell Health, took listeners on a journey up and down the vagus nerve to the spleen, describing how impulses in the nerve regulate immune system emissions of signaling molecules, or “cytokines.” Too great a surge can become harmful, for instance causing the autoimmune disorder rheumatoid arthritis. Tracey described how a newly U.S. Food and Drug Administration-approved pill-sized neck implant to stimulate the vagus nerve helps patients with severe forms of the disease without suppressing their immune system. The brain’s border Other speakers discussed opportunities for understanding neuro-immune interactions in aging and disease at the “borders” where the brain’s and body’s immune system meet. These areas include the meninges that surround the brain, the choroid plexus (proximate to the ventricles, or open spaces, within the brain), and the interface between brain cells and the circulatory system. For instance, taking a cue from studies showing that circadian disruptions are a risk factor for Alzheimer’s disease, Harvard Medical School Professor Beth Stevens of Boston Children’s Hospital described new research in her lab that examined how brain immune cells may function differently around the day-night cycle. The project, led by newly minted PhD Helena Barr, found that “border-associated macrophages” — long-lived immune cells residing in the brain’s borders — exhibited circadian rhythms in gene expression and function. Stevens described how these cells are tuned by the circadian clock to “eat” more during the rest phase, a process that may help remove material draining from the brain, including Alzheimer’s disease-associated peptides such as amyloid-beta. So, Stevens hypothesizes, circadian disruptions, for example due to aging or night-shift work, may contribute to disease onset by disrupting the delicate balance in immune-mediated “clean-up” of the brain and its borders. Following Stevens at the podium, Washington University Professor Marco Colonna traced how various kinds of macrophages, including border macrophages and microglia, develop from the embryonic stage. He described the different gene-expression programs that guide their differentiation into one type or another. One gene he highlighted, for instance, is necessary for border macrophages along the brain’s vasculature to help regulate the waste-clearing cerebrospinal fluid (CSF) flow that Stevens also discussed. Knocking out the gene also impairs blood flow. Importantly, his lab has found that versions of the gene may be somewhat protective against Alzheimer’s, and that regulating expression of the gene could be a therapeutic strategy. Colonna’s WashU colleague Jonathan Kipnis (a former student of Schwartz) also discussed macrophages that are associated with the particular border between brain tissue and the plumbing alongside the vasculature that carries CSF. The macrophages, his lab showed in 2022, actively govern the flow of CSF. He showed that removing the macrophages let Alzheimer’s proteins accumulate in mice. His lab is continuing to investigate ways in which these specific border macrophages may play roles in disease. He’s also looking in separate studies of how the skull’s brain marrow contributes to the population of immune cells in the brain and may play a role in neurodegeneration.", "release_time": "2025-10-09", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/immune-informed-brain-aging-research-offers-new-treatment-possibilities-1008"}
{"category": "研究前沿", "title": "MIT教授获摩尔基金资助研发新型磁电材料", "short_summary": "MIT教授获百万美元资助，研究二维三维材料界面磁电耦合，推动自旋电子学发展。", "detailed_summary": "MIT教授获百万美元资助，研究二维三维材料界面磁电耦合，推动自旋电子学发展。\n(1) MIT物理学副教授Riccardo Comin及其两位校友荣获戈登与贝蒂·摩尔基金会2025年实验物理学研究者奖，获得130万美元资助。\n(2) Comin的研究项目I-MAGinE旨在通过堆叠二维范德华材料与三维氧化物薄膜，创造新型人工磁电多铁性界面。\n(3) 该研究突破传统外延生长限制，探索不受晶格匹配约束的界面磁电耦合效应。\n(4) 研究成果有望为自旋电子学、数据存储和传感技术等领域开发创新、高能效的设备奠定基础。", "raw_content": "MIT associate professor of physics Riccardo Comin has been selected as 2025 Experimental Physics Investigator by the Gordon and Betty Moore Foundation . Two MIT physics alumni — Gyu-Boong Jo PhD ’10 of Rice University, and Ben Jones PhD ’15 of the University of Texas at Arlington — were also among this year’s cohort of 22 honorees. The prestigious Experimental Physics Investigators (EPI) Initiative recognizes mid-career scientists advancing the frontiers of experimental physics. Each award provides $1.3 million over five years to accelerate breakthroughs and strengthen the experimental physics community. At MIT, Comin investigates magnetoelectric multiferroics by engineering interfaces between two-dimensional materials and three-dimensional oxide thin films. His research aims to overcome long-standing limitations in spin-charge coupling by moving beyond epitaxial constraints, enabling new interfacial phases and coupling mechanisms. In these systems, Comin’s team explores the coexistence and proximity of magnetic and ferroelectric order, with a focus on achieving strong magnetoelectric coupling. This approach opens new pathways for designing tunable multiferroic systems unconstrained by traditional synthesis methods. Comin’s research expands the frontier of multiferroics by demonstrating stacking-controlled magnetoelectric coupling at 2D–3D interfaces. This approach enables exploration of fundamental physics in a versatile materials platform and opens new possibilities for spintronics, sensing, and data storage. By removing constraints of epitaxial growth, Comin’s work lays the foundation for microelectronic and spintronic devices with novel functionalities driven by interfacial control of spin and polarization. Comin’s project, Interfacial MAGnetoElectrics (I-MAGinE), aims to study a new class of artificial magnetoelectric multiferroics at the interfaces between ferroic materials from 2D van der Waals systems and 3D oxide thin films. The team aims to identify and understand novel magnetoelectric effects to demonstrate the viability of stacking-controlled interfacial magnetoelectric coupling. This research could lead to significant contributions in multiferroics, and could pave the way for innovative, energy-efficient storage devices. “This research has the potential to make significant contributions to the field of multiferroics by demonstrating the viability of stacking-controlled interfacial magnetoelectric coupling,” according to Comin’s proposal. “The findings could pave the way for future applications in spintronics, data storage, and sensing. It offers a significant opportunity to explore fundamental physics questions in a novel materials platform, while laying the ground for future technological applications, including microelectronic and spintronic devices with new functionalities.” Comin’s group has extensive experience in researching 2D and 3D ferroic materials and electronically ordered oxide thin films, as well as ultrathin van der Waals magnets, ferroelectrics, and multiferroics. Their lab is equipped with state-of-the-art tools for material synthesis, including bulk crystal growth of van der Waals materials and pulsed laser deposition targets, along with comprehensive fabrication and characterization capabilities. Their expertise in magneto-optical probes and advanced magnetic X-ray techniques promises to enable in-depth studies of electronic and magnetic structures, specifically spin-charge coupling, in order to contribute significantly to understanding spin-charge coupling in magnetochiral materials. The coexistence of ferroelectricity and ferromagnetism in a single material, known as multiferroicity, is rare, and strong spin-charge coupling is even rarer due to fundamental chemical and electronic structure incompatibilities. The few known bulk multiferroics with strong magnetoelectric coupling generally rely on inversion symmetry-breaking spin arrangements, which only emerge at low temperatures, limiting practical applications. While interfacial magnetoelectric multiferroics offer an alternative, achieving efficient spin-charge coupling often requires stringent conditions like epitaxial growth and lattice matching, which limit material combinations. This research proposes to overcome these limitations by using non-epitaxial interfaces of 2D van der Waals materials and 3D oxide thin films. Unique features of this approach include leveraging the versatility of 2D ferroics for seamless transfer onto any substrate, eliminating lattice matching requirements, and exploring new classes of interfacial magnetoelectric effects unconstrained by traditional thin-film synthesis limitations. Launched in 2018, the Moore Foundation’s EPI Initiative cultivates collaborative research environments and provides research support to promote the discovery of new ideas and emphasize community building. “We have seen numerous new connections form and new research directions pursued by both individuals and groups based on conversations at these gatherings,” says Catherine Mader, program officer for the initiative. The Gordon and Betty Moore Foundation was established to create positive outcomes for future generations. In pursuit of that vision, it advances scientific discovery, environmental conservation, and the special character of the San Francisco Bay Area.", "release_time": "2025-10-09", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/riccardo-comin-mit-alumni-named-moore-experimental-physics-investigators-1008"}
{"category": "研究前沿", "title": "研究：太阳能光伏成全球清洁能源转型关键驱动力", "short_summary": "萨里大学研究指出太阳能光伏已成为全球能源转型核心，成本优势显著且装机迅猛增长。", "detailed_summary": "萨里大学研究指出太阳能光伏已成为全球能源转型核心，成本优势显著且装机迅猛增长。\n(1) 萨里大学研究发表于《能源与环境材料》期刊，指出太阳能光伏技术是全球向清洁可再生能源转型的关键驱动力。\n(2) 全球太阳能装机容量在2024年已超过1.5太瓦，是2020年的两倍，足以为数亿家庭供电。\n(3) 锂离子电池价格自2010年下降89%，使太阳能加储能系统成本与天然气电厂相当，成为可靠的可调度电源。\n(4) 研究指出主要挑战是大量太阳能接入现有电网，导致部分地区电网拥堵和能源浪费。\n(5) 未来需依靠智能电网、人工智能预测和区域互联保持电网稳定，并需长期政策支持驱动创新。", "raw_content": "In a study published in Energy and Environment Materials , researchers from Surrey's Advanced Technology Institute (ATI) argue that solar photovoltaic (PV) technology is now the key driver of the world's transition to clean, renewable power. Professor Ravi Silva, co-author of the study and Director of the ATI at the University of Surrey, said: \"Even here in the UK, a country that sits 50 degrees north of the equator, solar is the cheapest option for large-scale energy generation. Globally, the total amount of solar power installed passed 1.5 terawatts in 2024 - twice as much as in 2020 and enough to power hundreds of millions of homes. Simply put, this technology is no longer a moonshot prospect but a foundational part of the resilient, low-carbon energy future that we all want to bring to reality.\" The research team also found that the price of lithium-ion batteries has fallen by 89% since 2010, making solar-plus-storage systems as cost-effective as gas power plants. These hybrid setups, which combine solar panels with batteries, are now standard in many regions and allow solar energy to be stored and released when needed, turning it into a more reliable, dispatchable source of power that helps balance grid demand. Despite many reasons to be optimistic, the ATI research team points to several challenges - particularly connecting large amounts of solar power to existing electricity networks. In some regions, such as California and China, high solar generation has led to grid congestion and wasted energy when supply exceeds demand. Dr Ehsan Rezaee, co-author of the study from the University of Surrey, comments: \"Connecting growing levels of solar power to electricity networks is now one of the biggest challenges. Smart grids, artificial intelligence forecasting and stronger links between regions will be vital to keep power systems stable as renewable energy use rises.\" Professor Silva added: \"With the integration of energy storage and smart grid technologies, solar is now capable of delivering reliable, affordable and clean power at scale. Innovations in materials such as perovskite solar cells could boost energy output by up to 50% without increasing land use. \"However, progress will depend on consistent, long-term policy support. Initiatives such as the Inflation Reduction Act in the US, the EU's REPowerEU plan and India's Production Linked Incentive scheme show how clear direction can drive investment and innovation. Sustained commitment and international collaboration will be essential if we are to accelerate the world's transition to a clean and reliable energy system.\"", "release_time": "2025-10-07", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251007081814.htm"}
{"category": "研究前沿", "title": "芯片集成高功率光频梳技术获突破", "short_summary": "研究人员成功在单一芯片上生成高功率光频梳，可大幅提升数据中心能效与传输速度。", "detailed_summary": "研究人员成功在单一芯片上生成高功率光频梳，可大幅提升数据中心能效与传输速度。\n(1) 研究团队利用硅光子技术将大功率多模激光二极管集成于芯片，并通过锁定机制纯化其输出的\"杂乱\"光束，获得高相干性的稳定光源。\n(2) 该芯片的非线性光学特性可将单一光束分裂为数十个等间距的彩色频率，形成光频梳，取代了以往需要大型昂贵激光器和放大器的系统。\n(3) 此项突破的核心应用在于数据中心，光频梳可实现波分复用技术，使单根光纤能并行传输数十个数据流，极大提升信息传输速度和系统能效。\n(4) 该技术除数据中心外，还有望应用于便携式光谱仪、光学时钟、量子设备及先进激光雷达系统等多个前沿领域。", "raw_content": "They were working on a project to improve LiDAR, a technology that uses lightwaves to measure distance. The lab was designing high-power chips that could produce brighter beams of light. \"As we sent more and more power through the chip, we noticed that it was creating what we call a frequency comb,\" says Andres Gil-Molina, a former postdoctoral researcher in Lipson's lab. A frequency comb is a special type of light that contains many colors lined up next to each other in an orderly pattern, kind of like a rainbow. Dozens of colors -- or frequencies of light -- shine brightly, while the gaps between them remain dark. When you look at a frequency comb on a spectrogram, these bright frequencies appear as spikes, or teeth on a comb. This offers the tremendous opportunity of sending dozens of streams of data simultaneously. Because the different colors of light don't interfere with each other, each tooth acts as its own channel. Today, creating a powerful frequency comb requires large and expensive lasers and amplifiers. In their new paper in Nature Photonics , Lipson, Eugene Higgins Professor of Electrical Engineering and professor of Applied Physics, and her collaborators show how to do the same thing on a single chip. \"Data centers have created tremendous demand for powerful and efficient sources of light that contain many wavelengths,\" says Gil-Molina, who is now a principal engineer at Xscape Photonics. \"The technology we've developed takes a very powerful laser and turns it into dozens of clean, high-power channels on a chip. That means you can replace racks of individual lasers with one compact device, cutting cost, saving space, and opening the door to much faster, more energy-efficient systems.\" \"This research marks another milestone in our mission to advance silicon photonics,\" Lipson said. \"As this technology becomes increasingly central to critical infrastructure and our daily lives, this type of progress is essential to ensuring that data centers are as efficient as possible.\" Cleaning up messy light The breakthrough started with a simple question: What's the most powerful laser we can put on a chip? The team chose a type called a multimode laser diode, which is used widely in applications like medical devices and laser cutting tools. These lasers can produce enormous amounts of light, but the beam is \"messy,\" which makes it hard to use for precise applications. Integrating such a laser into a silicon photonics chip, where the light pathways are just a few microns -- even hundreds of nanometers -- wide, required careful engineering. \"We used something called a locking mechanism to purify this powerful but very noisy source of light,\" Gil-Molina says. The method relies on silicon photonics to reshape and clean up the laser's output, producing a much cleaner, more stable beam, a property scientists call high coherence. Once the light is purified, the chip's nonlinear optical properties take over, splitting that single powerful beam into dozens of evenly spaced colors, a defining feature of a frequency comb. The result is a compact, high-efficiency light source that combines the raw power of an industrial laser with the precision and stability needed for advanced communications and sensing. Why it matters now The timing for this breakthrough is no accident. With the explosive growth of artificial intelligence, the infrastructure inside data centers is straining to move information fast enough, for example, between processors and memory. State-of-the-art data centers are already using fiber optic links to transport data, but most of these still rely on single-wavelength lasers. Frequency combs change that. Instead of one beam carrying one data stream, dozens of beams can run in parallel through the same fiber. That's the principle behind wavelength-division multiplexing (WDM), the technology that turned the internet into a global high-speed network in the late 1990s. By making high-power, multi-wavelength combs small enough to fit directly on a chip, Lipson's team has made it possible to bring this capability into the most compact, cost-sensitive parts of modern computing systems. Beyond data centers, the same chips could enable portable spectrometers, ultra-precise optical clocks, compact quantum devices, and even advanced LiDAR systems. \"This is about bringing lab-grade light sources into real-world devices,\" says Gil-Molina. \"If you can make them powerful, efficient, and small enough, you can put them almost anywhere.\"", "release_time": "2025-10-07", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251007081823.htm"}
{"category": "研究前沿", "title": "普里亚·东蒂利用AI优化电网应对气候变化", "short_summary": "MIT教授东蒂研究AI算法提升可再生能源电网效率，致力解决气候不公问题。", "detailed_summary": "MIT教授东蒂研究AI算法提升可再生能源电网效率，致力解决气候不公问题。\n(1) 普里亚·东蒂现任MIT电子工程与计算机科学系教授，童年经历激发其解决全球不平等与气候变化的使命感。\n(2) 她将计算机科学和公共政策结合，研究利用深度学习和机器学习优化高比例可再生能源电网的预测与控制。\n(3) 其突破性算法考虑电网物理约束，优化成本速度提升10倍，成本显著降低，已引起电网运营商关注。\n(4) 她共同创立非营利组织“Climate Change AI”，促进跨学科合作，并开发合成数据基准以推动电力系统效率研究。\n(5) 东蒂获得多项荣誉，包括入选《麻省理工科技评论》“35岁以下创新者”，并将于MIT联合开设“AI for Climate Action”课程。", "raw_content": "For Priya Donti, childhood trips to India were more than an opportunity to visit extended family. The biennial journeys activated in her a motivation that continues to shape her research and her teaching. Contrasting her family home in Massachusetts, Donti — now the Silverman Family Career Development Professor in the Department of Electrical Engineering and Computer Science (EECS), a shared position between the MIT Schwarzman College of Computing and EECS, and a principal investigator at the MIT Laboratory for Information and Decision Systems (LIDS) — was struck by the disparities in how people live. “It was very clear to me the extent to which inequity is a rampant issue around the world,” Donti says. “From a young age, I knew that I definitely wanted to address that issue.” That motivation was further stoked by a high school biology teacher, who focused his class on climate and sustainability. “We learned that climate change, this huge, important issue, would exacerbate inequity,” Donti says. “That really stuck with me and put a fire in my belly.” So, when Donti enrolled at Harvey Mudd College, she thought she would direct her energy toward the study of chemistry or materials science to create next-generation solar panels. Those plans, however, were jilted. Donti “fell in love” with computer science, and then discovered work by researchers in the United Kingdom who were arguing that artificial intelligence and machine learning would be essential to help integrate renewables into power grids. “It was the first time I’d seen those two interests brought together,” she says. “I got hooked and have been working on that topic ever since.” Pursuing a PhD at Carnegie Mellon University, Donti was able to design her degree to include computer science and public policy. In her research, she explored the need for fundamental algorithms and tools that could manage, at scale, power grids relying heavily on renewables. “I wanted to have a hand in developing those algorithms and tool kits by creating new machine learning techniques grounded in computer science,” she says. “But I wanted to make sure that the way I was doing the work was grounded both in the actual energy systems domain and working with people in that domain” to provide what was actually needed. While Donti was working on her PhD, she co-founded a nonprofit called Climate Change AI. Her objective, she says, was to help the community of people involved in climate and sustainability — “be they computer scientists, academics, practitioners, or policymakers” — to come together and access resources, connection, and education “to help them along that journey.” “In the climate space,” she says, “you need experts in particular climate change-related sectors, experts in different technical and social science tool kits, problem owners, affected users, policymakers who know the regulations — all of those — to have on-the-ground scalable impact.” When Donti came to MIT in September 2023, it was not surprising that she was drawn by its initiatives directing the application of computer science toward society’s biggest problems, especially the current threat to the health of the planet. “We’re really thinking about where technology has a much longer-horizon impact and how technology, society, and policy all have to work together,” Donti says. “Technology is not just one-and-done and monetizable in the context of a year.” Her work uses deep learning models to incorporate the physics and hard constraints of electric power systems that employ renewables for better forecasting, optimization, and control. “Machine learning is already really widely used for things like solar power forecasting, which is a prerequisite to managing and balancing power grids,” she says. “My focus is, how do you improve the algorithms for actually balancing power grids in the face of a range of time-varying renewables?” Among Donti’s breakthroughs is a promising solution for power grid operators to be able to optimize for cost, taking into account the actual physical realities of the grid, rather than relying on approximations. While the solution is not yet deployed, it appears to work 10 times faster, and far more cheaply, than previous technologies, and has attracted the attention of grid operators. Another technology she is developing works to provide data that can be used in training machine learning systems for power system optimization. In general, much data related to the systems is private, either because it is proprietary or because of security concerns. Donti and her research group are working to create synthetic data and benchmarks that, Donti says, “can help to expose some of the underlying problems” in making power systems more efficient. “The question is,” Donti says, “can we bring our datasets to a point such that they are just hard enough to drive progress?” For her efforts, Donti has been awarded the U.S. Department of Energy Computational Science Graduate Fellowship and the NSF Graduate Research Fellowship. She was recognized as part of MIT Technology Review ’s 2021 list of “35 Innovators Under 35” and Vox’s 2023 “Future Perfect 50.” Next spring, Donti will co-teach a class called AI for Climate Action with Sara Beery, EECS assistant professor, whose focus is AI for biodiversity and ecosystems, and Abigail Bodner, assistant professor in the departments of EECS and Earth, Atmospheric and Planetary Sciences, whose focus is AI for climate and Earth science. “We’re all super-excited about it,” Donti says. Coming to MIT, Donti says, “I knew that there would be an ecosystem of people who really cared, not just about success metrics like publications and citation counts, but about the impact of our work on society.”", "release_time": "2025-10-08", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/fighting-health-planet-ai-priya-donti-1007"}
{"category": "研究前沿", "title": "MIT研发高强度可3D打印铝合金", "short_summary": "MIT利用机器学习设计出高强度耐高温铝合金，兼容3D打印技术。", "detailed_summary": "MIT利用机器学习设计出高强度耐高温铝合金，兼容3D打印技术。\n(1) MIT工程师结合机器学习与模拟技术，从40种配方中高效筛选出最优铝合金成分。\n(2) 新材料强度为传统铸造铝合金的五倍，且能耐400摄氏度高温。\n(3) 该合金专为激光粉末床熔融3D打印工艺设计，利用快速冷却获得优异微观结构。\n(4) 潜在应用包括航空发动机风扇叶片、真空泵及数据中心冷却设备等轻量化部件。", "raw_content": "MIT engineers have developed a printable aluminum alloy that can withstand high temperatures and is five times stronger than traditionally manufactured aluminum. The new printable metal is made from a mix of aluminum and other elements that the team identified using a combination of simulations and machine learning, which significantly pruned the number of possible combinations of materials to search through. While traditional methods would require simulating over 1 million possible combinations of materials, the team’s new machine learning-based approach needed only to evaluate 40 possible compositions before identifying an ideal mix for a high-strength, printable aluminum alloy. When they printed the alloy and tested the resulting material, the team confirmed that, as predicted, the aluminum alloy was as strong as the strongest aluminum alloys that are manufactured today using traditional casting methods. The researchers envision that the new printable aluminum could be made into stronger, more lightweight and temperature-resistant products, such as fan blades in jet engines. Fan blades are traditionally cast from titanium — a material that is more than 50 percent heavier and up to 10 times costlier than aluminum — or made from advanced composites. “If we can use lighter, high-strength material, this would save a considerable amount of energy for the transportation industry,” says Mohadeseh Taheri-Mousavi, who led the work as a postdoc at MIT and is now an assistant professor at Carnegie Mellon University. “Because 3D printing can produce complex geometries, save material, and enable unique designs, we see this printable alloy as something that could also be used in advanced vacuum pumps, high-end automobiles, and cooling devices for data centers,” adds John Hart, the Class of 1922 Professor and head of the Department of Mechanical Engineering at MIT. Hart and Taheri-Mousavi provide details on the new printable aluminum design in a paper published in the journal Advanced Materials . The paper’s MIT co-authors include Michael Xu, Clay Houser, Shaolou Wei, James LeBeau, and Greg Olson, along with Florian Hengsbach and Mirko Schaper of Paderborn University in Germany, and Zhaoxuan Ge and Benjamin Glaser of Carnegie Mellon University. Micro-sizing The new work grew out of an MIT class that Taheri-Mousavi took in 2020, which was taught by Greg Olson, professor of the practice in the Department of Materials Science and Engineering. As part of the class, students learned to use computational simulations to design high-performance alloys. Alloys are materials that are made from a mix of different elements, the combination of which imparts exceptional strength and other unique properties to the material as a whole. Olson challenged the class to design an aluminum alloy that would be stronger than the strongest printable aluminum alloy designed to date. As with most materials, the strength of aluminum depends in large part on its microstructure: The smaller and more densely packed its microscopic constituents, or “precipitates,” the stronger the alloy would be. With this in mind, the class used computer simulations to methodically combine aluminum with various types and concentrations of elements, to simulate and predict the resulting alloy’s strength. However, the exercise failed to produce a stronger result. At the end of the class, Taheri-Mousavi wondered: Could machine learning do better? “At some point, there are a lot of things that contribute nonlinearly to a material’s properties, and you are lost,” Taheri-Mousavi says. “With machine-learning tools, they can point you to where you need to focus, and tell you for example, these two elements are controlling this feature. It lets you explore the design space more efficiently.” Layer by layer In the new study, Taheri-Mousavi continued where Olson’s class left off, this time looking to identify a stronger recipe for aluminum alloy. This time, she used machine-learning techniques designed to efficiently comb through data such as the properties of elements, to identify key connections and correlations that should lead to a more desirable outcome or product. She found that, using just 40 compositions mixing aluminum with different elements, their machine-learning approach quickly homed in on a recipe for an aluminum alloy with higher volume fraction of small precipitates, and therefore higher strength, than what the previous studies identified. The alloy’s strength was even higher than what they could identify after simulating over 1 million possibilities without using machine learning. To physically produce this new strong, small-precipitate alloy, the team realized 3D printing would be the way to go instead of traditional metal casting, in which molten liquid aluminum is poured into a mold and is left to cool and harden. The longer this cooling time is, the more likely the individual precipitate is to grow. The researchers showed that 3D printing, broadly also known as additive manufacturing, can be a faster way to cool and solidify the aluminum alloy. Specifically, they considered laser bed powder fusion (LBPF) — a technique by which a powder is deposited, layer by layer, on a surface in a desired pattern and then quickly melted by a laser that traces over the pattern. The melted pattern is thin enough that it solidfies quickly before another layer is deposited and similarly “printed.” The team found that LBPF’s inherently rapid cooling and solidification enabled the small-precipitate, high-strength aluminum alloy that their machine learning method predicted. “Sometimes we have to think about how to get a material to be compatible with 3D printing,” says study co-author John Hart. “Here, 3D printing opens a new door because of the unique characteristics of the process — particularly, the fast cooling rate. Very rapid freezing of the alloy after it’s melted by the laser creates this special set of properties.” Putting their idea into practice, the researchers ordered a formulation of printable powder, based on their new aluminum alloy recipe. They sent the powder — a mix of aluminum and five other elements — to collaborators in Germany, who printed small samples of the alloy using their in-house LPBF system. The samples were then sent to MIT where the team ran multiple tests to measure the alloy’s strength and image the samples’ microstructure. Their results confirmed the predictions made by their initial machine learning search: The printed alloy was five times stronger than a casted counterpart and 50 percent stronger than alloys designed using conventional simulations without machine learning. The new alloy’s microstructure also consisted of a higher volume fraction of small precipitates, and was stable at high temperatures of up to 400 degrees Celsius — a very high temperature for aluminum alloys. The researchers are applying similar machine-learning techniques to further optimize other properties of the alloy. “Our methodology opens new doors for anyone who wants to do 3D printing alloy design,” Taheri-Mousavi says. “My dream is that one day, passengers looking out their airplane window will see fan blades of engines made from our aluminum alloys.”", "release_time": "2025-10-07", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/printable-aluminum-alloy-sets-strength-records-may-enable-lighter-aircraft-parts-1007"}
{"category": "研究前沿", "title": "73量子比特系统通过贝尔测试验证量子性", "short_summary": "国际团队实现73量子比特贝尔关联认证，突破量子计算机真量子性验证尺度。", "detailed_summary": "国际团队实现73量子比特贝尔关联认证，突破量子计算机真量子性验证尺度。\n（1）研究团队来自莱顿大学、清华大学和浙江大学，通过优化策略验证量子计算机真量子性；\n（2）创新采用能量最小化方法，在超导量子处理器中制备73量子比特特殊态；\n（3）测得能量值较经典系统低48个标准差，显著证明量子效应真实性；\n（4）首次实现24量子比特真多体贝尔关联认证，要求所有量子比特协同参与；\n（5）该突破为量子通信、密码安全和算法开发提供重要技术支撑。", "raw_content": "You could call it a 'quantum lie detector': Bell's test designed by famous physicist John Bell. This test shows whether a machine, like a quantum computer, is truly using quantum effects or just mimics them. As quantum technologies become more mature, ever more stringent tests of quantumness become necessary. In this new study, the researchers took things to the next level, testing Bell correlations in systems with up to 73 qubits -- the basic building blocks of a quantum computer. The study involved a global team: theoretical physicists Jordi Tura, Patrick Emonts, PhD candidate Mengyao Hu from Leiden University, together with colleagues from Tsinghua University (Beijing) and experimental physicists from Zhejiang University (Hangzhou). Clever experimenting It was an extremely ambitious plan, but the team's well-optimized strategy made all the difference. Instead of trying to directly measure the complex Bell correlations, they focused on something quantum devices are already good at: minimizing energy. And it paid off. The team created a special quantum state using 73 qubits in a superconducting quantum processor and measured energies far below what would be possible in a classical system. The difference was striking -- 48 standard deviations -- making it almost impossible that the result was due to chance. But the team didn't stop there. They went on to certify a rare and more demanding type of nonlocality - known as genuine multipartite Bell correlations. In this kind of quantum correlation, all qubits in the system must be involved, making it much harder to generate -- and even harder to verify. Remarkably, the researchers succeeded in preparing a whole series of low-energy states that passed this test up to 24 qubits, confirming these special correlations efficiently. This result shows that quantum computers are not just getting bigger -- they are also becoming better at displaying and proving truly quantum behaviour. Why this matters This study proves that it's possible to certify deep quantum behaviour in large, complex systems -- something never done at this scale before. It's a big step toward making sure quantum computers are truly quantum. These insights are more than just theoretical. Understanding and controlling Bell correlations could improve quantum communication, make cryptography more secure, and help develop new quantum algorithms.", "release_time": "2025-10-07", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251007081840.htm"}
{"category": "研究前沿", "title": "MIT开发托卡马克等离子体安全关闭预测模型", "short_summary": "MIT团队结合机器学习与物理模型，实现托卡马克等离子体安全关闭精准预测。", "detailed_summary": "MIT团队结合机器学习与物理模型，实现托卡马克等离子体安全关闭精准预测。\n（1）MIT团队开发新型预测模型，结合机器学习与等离子体物理模拟；\n（2）模型使用瑞士托卡马克实验数据训练，能以少量数据实现高精度预测；\n（3）重点解决等离子体高速关闭时的不稳定性问题，防止设备内部损伤；\n（4）实验显示该方法可生成安全关闭轨迹，部分案例实现无中断快速关闭；\n（5）技术有望提升未来聚变电站可靠性，获Commonwealth Fusion Systems支持。", "raw_content": "Tokamaks are machines that are meant to hold and harness the power of the sun. These fusion machines use powerful magnets to contain a plasma hotter than the sun’s core and push the plasma’s atoms to fuse and release energy. If tokamaks can operate safely and efficiently, the machines could one day provide clean and limitless fusion energy. Today, there are a number of experimental tokamaks in operation around the world, with more underway. Most are small-scale research machines built to investigate how the devices can spin up plasma and harness its energy. One of the challenges that tokamaks face is how to safely and reliably turn off a plasma current that is circulating at speeds of up to 100 kilometers per second, at temperatures of over 100 million degrees Celsius. Such “rampdowns” are necessary when a plasma becomes unstable. To prevent the plasma from further disrupting and potentially damaging the device’s interior, operators ramp down the plasma current. But occasionally the rampdown itself can destabilize the plasma. In some machines, rampdowns have caused scrapes and scarring to the tokamak’s interior — minor damage that still requires considerable time and resources to repair. Now, scientists at MIT have developed a method to predict how plasma in a tokamak will behave during a rampdown. The team combined machine-learning tools with a physics-based model of plasma dynamics to simulate a plasma’s behavior and any instabilities that may arise as the plasma is ramped down and turned off. The researchers trained and tested the new model on plasma data from an experimental tokamak in Switzerland. They found the method quickly learned how plasma would evolve as it was tuned down in different ways. What’s more, the method achieved a high level of accuracy using a relatively small amount of data. This training efficiency is promising, given that each experimental run of a tokamak is expensive and quality data is limited as a result. The new model, which the team highlights this week in an open-access Nature Communications paper , could improve the safety and reliability of future fusion power plants. “For fusion to be a useful energy source it’s going to have to be reliable,” says lead author Allen Wang, a graduate student in aeronautics and astronautics and a member of the Disruption Group at MIT’s Plasma Science and Fusion Center (PSFC). “To be reliable, we need to get good at managing our plasmas.” The study’s MIT co-authors include PSFC Principal Research Scientist and Disruptions Group leader Cristina Rea, and members of the Laboratory for Information and Decision Systems (LIDS) Oswin So, Charles Dawson, and Professor Chuchu Fan, along with Mark (Dan) Boyer of Commonwealth Fusion Systems and collaborators from the Swiss Plasma Center in Switzerland. “A delicate balance” Tokamaks are experimental fusion devices that were first built in the Soviet Union in the 1950s. The device gets its name from a Russian acronym that translates to a “toroidal chamber with magnetic coils.” Just as its name describes, a tokamak is toroidal, or donut-shaped, and uses powerful magnets to contain and spin up a gas to temperatures and energies high enough that atoms in the resulting plasma can fuse and release energy. Today, tokamak experiments are relatively low-energy in scale, with few approaching the size and output needed to generate safe, reliable, usable energy. Disruptions in experimental, low-energy tokamaks are generally not an issue. But as fusion machines scale up to grid-scale dimensions, controlling much higher-energy plasmas at all phases will be paramount to maintaining a machine’s safe and efficient operation. “Uncontrolled plasma terminations, even during rampdown, can generate intense heat fluxes damaging the internal walls,” Wang notes. “Quite often, especially with the high-performance plasmas, rampdowns actually can push the plasma closer to some instability limits. So, it’s a delicate balance. And there’s a lot of focus now on how to manage instabilities so that we can routinely and reliably take these plasmas and safely power them down. And there are relatively few studies done on how to do that well.” Bringing down the pulse Wang and his colleagues developed a model to predict how a plasma will behave during tokamak rampdown. While they could have simply applied machine-learning tools such as a neural network to learn signs of instabilities in plasma data, “you would need an ungodly amount of data” for such tools to discern the very subtle and ephemeral changes in extremely high-temperature, high-energy plasmas, Wang says. Instead, the researchers paired a neural network with an existing model that simulates plasma dynamics according to the fundamental rules of physics. With this combination of machine learning and a physics-based plasma simulation, the team found that only a couple hundred pulses at low performance, and a small handful of pulses at high performance, were sufficient to train and validate the new model. The data they used for the new study came from the TCV, the Swiss “variable configuration tokamak” operated by the Swiss Plasma Center at EPFL (the Swiss Federal Institute of Technology Lausanne). The TCV is a small experimental fusion experimental device that is used for research purposes, often as test bed for next-generation device solutions. Wang used the data from several hundred TCV plasma pulses that included properties of the plasma such as its temperature and energies during each pulse’s ramp-up, run, and ramp-down. He trained the new model on this data, then tested it and found it was able to accurately predict the plasma’s evolution given the initial conditions of a particular tokamak run. The researchers also developed an algorithm to translate the model’s predictions into practical “trajectories,” or plasma-managing instructions that a tokamak controller can automatically carry out to for instance adjust the magnets or temperature maintain the plasma’s stability. They implemented the algorithm on several TCV runs and found that it produced trajectories that safely ramped down a plasma pulse, in some cases faster and without disruptions compared to runs without the new method. “At some point the plasma will always go away, but we call it a disruption when the plasma goes away at high energy. Here, we ramped the energy down to nothing,” Wang notes. “We did it a number of times. And we did things much better across the board. So, we had statistical confidence that we made things better.” The work was supported in part by Commonwealth Fusion Systems (CFS), an MIT spinout that intends to build the world’s first compact, grid-scale fusion power plant. The company is developing a demo tokamak, SPARC, designed to produce net-energy plasma, meaning that it should generate more energy than it takes to heat up the plasma. Wang and his colleagues are working with CFS on ways that the new prediction model and tools like it can better predict plasma behavior and prevent costly disruptions to enable safe and reliable fusion power. “We’re trying to tackle the science questions to make fusion routinely useful,” Wang says. “What we’ve done here is the start of what is still a long journey. But I think we’ve made some nice progress.” Additional support for the research came from the framework of the EUROfusion Consortium, via the Euratom Research and Training Program and funded by the Swiss State Secretariat for Education, Research, and Innovation.", "release_time": "2025-10-07", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/new-prediction-model-could-improve-reliability-fusion-power-plants-1007"}
{"category": "研究前沿", "title": "MIT研发新型近红外荧光染料，有望用于肿瘤成像", "short_summary": "MIT化学家设计出稳定的近红外硼烯离子染料，亮度高，可穿透组织用于清晰成像。", "detailed_summary": "MIT化学家设计出稳定的近红外硼烯离子染料，亮度高，可穿透组织用于清晰成像。\n(1) MIT化学家成功设计并稳定了一种基于带正电硼烯离子的新型荧光分子。\n(2) 通过配体附着技术克服了硼烯离子 historically 不稳定的难题，使其可在空气中处理。\n(3) 该染料发射红光至近红外光，量子产率高达约30%，亮度远超传统近红外染料（约1%）。\n(4) 近红外光能更深穿透组织，有望生成更清晰的体内肿瘤等结构图像。\n(5) 潜在应用还包括药物运输温度传感器、柔性屏幕有机发光二极管（OLED）等。", "raw_content": "MIT chemists have designed a new type of fluorescent molecule that they hope could be used for applications such as generating clearer images of tumors. The new dye is based on a borenium ion — a positively charged form of boron that can emit light in the red to near-infrared range. Until recently, these ions have been too unstable to be used for imaging or other biomedical applications. In a study appearing today in Nature Chemistry , the researchers showed that they could stabilize borenium ions by attaching them to a ligand. This approach allowed them to create borenium-containing films, powders, and crystals, all of which emit and absorb light in the red and near-infrared range. That is important because near-IR light is easier to see when imaging structures deep within tissues, which could allow for clearer images of tumors and other structures in the body. “One of the reasons why we focus on red to near-IR is because those types of dyes penetrate the body and tissue much better than light in the UV and visible range. Stability and brightness of those red dyes are the challenges that we tried to overcome in this study,” says Robert Gilliard, the Novartis Professor of Chemistry at MIT and the senior author of the study. MIT research scientist Chun-Lin Deng is the lead author of the paper. Other authors include Bi Youan (Eric) Tra PhD ’25, former visiting graduate student Xibao Zhang, and graduate student Chonghe Zhang. Stabilized borenium Most fluorescent imaging relies on dyes that emit blue or green light. Those imaging agents work well in cells, but they are not as useful in tissue because low levels of blue and green fluorescence produced by the body interfere with the signal. Blue and green light also scatters in tissue, limiting how deeply it can penetrate. Imaging agents that emit red fluorescence can produce clearer images, but most red dyes are inherently unstable and don’t produce a bright signal, because of their low quantum yields (the ratio of fluorescent photons emitted per photon of light is absorbed). For many red dyes, the quantum yield is only about 1 percent. Among the molecules that can emit near-infrared light are borenium cations —positively charged ions containing an atom of boron attached to three other atoms. When these molecules were first discovered in the mid-1980s, they were considered “laboratory curiosities,” Gilliard says. These molecules were so unstable that they had to be handled in a sealed container called a glovebox to protect them from exposure to air, which can lead them to break down. Later, chemists realized they could make these ions more stable by attaching them to molecules called ligands. Working with these more stable ions, Gillliard’s lab discovered in 2019 that they had some unusual properties: Namely, they could respond to changes in temperature by emitting different colors of light. However, at that point, “there was a substantial problem in that they were still too reactive to be handled in open air,” Gilliard says. His lab began working on new ways to further stabilize them using ligands known as carbodicarbenes (CDCs), which they reported in a 2022 study . Due to this stabilization, the compounds can now be studied and handled without using a glovebox. They are also resistant to being broken down by light, unlike many previous borenium-based compounds. In the new study, Gilliard began experimenting with the anions (negatively charged ions) that are a part of the CDC-borenium compounds. Interactions between these anions and the borenium cation generate a phenomenon known as exciton coupling, the researchers discovered. This coupling, they found, shifted the molecules’ emission and absorption properties toward the infrared end of the color spectrum. These molecules also generated a high quantum yield, allowing them to shine more brightly. “Not only are we in the correct region, but the efficiency of the molecules is also very suitable,” Gilliard says. “We’re up to percentages in the thirties for the quantum yields in the red region, which is considered to be high for that region of the electromagnetic spectrum.” Potential applications The researchers also showed that they could convert their borenium-containing compounds into several different states, including solid crystals, films, powders, and colloidal suspensions. For biomedical imaging, Gilliard envisions that these borenium-containing materials could be encapsulated in polymers, allowing them to be injected into the body to use as an imaging dye. As a first step, his lab plans to work with researchers in the chemistry department at MIT and at the Broad Institute of MIT and Harvard to explore the potential of imaging these materials within cells. Because of their temperature responsiveness, these materials could also be deployed as temperature sensors, for example, to monitor whether drugs or vaccines have been exposed to temperatures that are too high or low during shipping. “For any type of application where temperature tracking is important, these types of ‘molecular thermometers’ can be very useful,” Gilliard says. If incorporated into thin films, these molecules could also be useful as organic light-emitting diodes (OLEDs), particularly in new types of materials such as flexible screens, Gilliard says. “The very high quantum yields achieved in the near-IR, combined with the excellent environmental stability, make this class of compounds extremely interesting for biological applications,” says Frieder Jaekle, a professor of chemistry at Rutgers University, who was not involved in the study. “Besides the obvious utility in bioimaging, the strong and tunable near-IR emission also makes these new fluorophores very appealing as smart materials for anticounterfeiting, sensors, switches, and advanced optoelectronic devices.” In addition to exploring possible applications for these dyes, the researchers are now working on extending their color emission further into the near-infrared region, which they hope to achieve by incorporating additional boron atoms. Those extra boron atoms could make the molecules less stable, so the researchers are also working on new types of carbodicarbenes to help stabilize them. The research was funded by the Arnold and Mabel Beckman Foundation and the National Institutes of Health.", "release_time": "2025-10-06", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/chemists-create-red-fluorescent-dyes-may-enable-clearer-biomedical-imaging-1006"}
{"category": "研究前沿", "title": "FAO/IAEA食品实验室负责人谈国际合作与研究前沿", "short_summary": "Vlachou领导实验室利用核技术保障食品安全，推动国际合作应对全球挑战。", "detailed_summary": "Vlachou领导实验室利用核技术保障食品安全，推动国际合作应对全球挑战。\n（1）Vlachou担任FAO/IAEA食品安全与控制实验室负责人，负责利用核技术进行食品安全与真实性分析研究；\n（2）实验室工作涵盖咖啡豆、橄榄油认证及果汁铅、开心果毒素检测等领域；\n（3）团队与FAO等机构合作应对食品安全、微塑料污染及抗菌素耐药性等全球性挑战；\n（4）Vlachou强调跨学科学习与国际合作的重要性，并建议年轻人广泛学习、夯实技能。", "raw_content": "Leadership in the Lab and Beyond Today, in her role as Head of the Joint FAO/IAEA Food Safety and Control Laboratory in Seibersdorf, Austria, Vlachou oversees research and method development for food safety, traceability and authenticity analysis using nuclear and complementary techniques. After working at the national and EU levels, she now applies her skills to the international level. From authenticating coffee beans and olive oil to detecting lead in fruit juice and toxins in pistachios, Vlachou and her team develop tools and guidance to help countries protect both their economies and consumers,” she said. The food safety lab also collaborates with other IAEA laboratories and the Food and Agriculture Organization of the United Nations (FAO) to tackle big challenges - food security, microplastic contamination, antimicrobial resistance risks in food and agriculture. “My team is amazing, and it has been truly rewarding to collaborate with the FAO on joint projects and interdisciplinary research.” Vlachou says. Her career path exemplifies the power of interdisciplinary learning, and how international cooperation helps integrating science into real-world applications. For young people in STEM, her advice is: “Learn broadly, build technical skills—and remember, practice makes perfect.”", "release_time": "2025-10-09", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/iaea-profile-championing-food-safety-through-nuclear-science-using-chemistry-to-combat-food-poisoning"}
{"category": "研究前沿", "title": "MIT研究揭示音乐训练如何重塑大脑听觉注意力", "short_summary": "MIT科学家发现音乐训练能锐化大脑神经机制，增强对目标声音的专注并抑制干扰。", "detailed_summary": "MIT科学家发现音乐训练能锐化大脑神经机制，增强对目标声音的专注并抑制干扰。\n（1）MIT麦戈文脑研究所科学家通过脑成像技术研究听觉注意力机制；\n（2）研究采用频率标记和脑磁图方法，区分大脑对目标旋律与干扰旋律的反应；\n（3）音乐训练背景者更擅长利用自上而下注意力聚焦目标，抑制自下而上干扰；\n（4）该发现发表于《科学进展》，为经验如何塑造听觉处理提供新见解；\n（5）研究模型有助于理解专业训练对认知能力的普遍提升作用。", "raw_content": "In a world full of competing sounds, we often have to filter out a lot of noise to hear what’s most important. This critical skill may come more easily for people with musical training, according to scientists at MIT’s McGovern Institute for Brain Research, who used brain imaging to follow what happens when people try to focus their attention on certain sounds. When Cassia Low Manting, a recent MIT postdoc working in the labs of MIT Professor and McGovern Institute PI John Gabrieli and former McGovern Institute PI Dimitrios Pantazis, asked people to focus on a particular melody while another melody played at the same time, individuals with musical backgrounds were, unsurprisingly, better able to follow the target tune. An analysis of study participants’ brain activity suggests this advantage arises because musical training sharpens neural mechanisms that amplify the sounds they want to listen to while turning down distractions. “People can hear, understand, and prioritize multiple sounds around them that flow on a moment-to-moment basis,” explains Gabrieli, who is the Grover Hermann Professor of Health Sciences and Technology at MIT. “This study reveals the specific brain mechanisms that successfully process simultaneous sounds on a moment-to-moment basis and promote attention to the most important sounds. It also shows how musical training alters that processing in the mind and brain, offering insight into how experience shapes the way we listen and pay attention.” The research team, which also included senior author Daniel Lundqvist at the Karolinska Institute in Sweden, reported their open-access findings Sept. 17 in the journal Science Advances. Manting, who is now at the Karolinska Institute, notes that the research is part of an ongoing collaboration between the two institutions. Overcoming challenges Participants in the study had vastly difference backgrounds when it came to music. Some were professional musicians with deep training and experience, while others struggled to differentiate between the two tunes they were played, despite each one’s distinct pitch. This disparity allowed the researchers to explore how the brain’s capacity for attention might change with experience. “Musicians are very fun to study because their brains have been morphed in ways based on their training,” Manting says. “It’s a nice model to study these training effects.” Still, the researchers had significant challenges to overcome. It has been hard to study how the brain manages auditory attention, because when researchers use neuroimaging to monitor brain activity, they see the brain’s response to all sounds: those that the listener cares most about, as well as those the listener is trying to ignore. It is usually difficult to figure out which brain signals were triggered by which sounds. Manting and her colleagues overcame this challenge with a method called frequency tagging. Rather than playing the melodies in their experiments at a constant volume, the volume of each melody oscillated, rising and falling with a particular frequency. Each melody had its own frequency, creating detectable patterns in the brain signals that responded to it. “When you play these two sounds simultaneously to the subject and you record the brain signal, you can say, this 39-Hertz activity corresponds to the lower-pitch sound and the 43-Hertz activity corresponds specifically to the higher-pitch sound,” Manting explains. “It is very clean and very clear.” When they paired frequency tagging with magnetoencephalography, a noninvasive method of monitoring brain activity, the team was able to track how their study participants’ brains responded to each of two melodies during their experiments. While the two tunes played, subjects were instructed to follow either the higher-pitched or the lower-pitched melody. When the music stopped, they were asked about the final notes of the target tune: did they rise or did they fall? The researchers could make this task harder by making the two tunes closer together in pitch, as well as by altering the timing of the notes. Manting used a survey that asked about musical experience to score each participant’s musicality, and this measure had an obvious effect on task performance: The more musical a person was, the more successful they were at following the tune they had been asked to track. To look for differences in brain activity that might explain this, the research team developed a new machine-learning approach to analyze their data. They used it to tease apart what was happening in the brain as participants focused on the target tune — even, in some cases, when the notes of the distracting tune played at the exact same time. Top-down versus bottom-up attention What they found was a clear separation of brain activity associated with two kinds of attention, known as top-down and bottom-up attention. Manting explains that top-down attention is goal-oriented, involving a conscious focus — the kind of attention listeners called on as they followed the target tune. Bottom-up attention, on the other hand, is triggered by the nature of the sound itself. A fire alarm would be expected to trigger this kind of attention, both with its volume and its suddenness. The distracting tune in the team’s experiments triggered activity associated with bottom-up attention — but more so in some people than in others. “The more musical someone is, the better they are at focusing their top-down selective attention, and the less the effect of bottom-up attention is,” Manting explains. Manting expects that musicians use their heightened capacity for top-down attention in other situations, as well. For example, they might be better than others at following a conversation in a room filled with background chatter. “I would put my bet on it that there is a high chance that they will be great at zooming into sounds,” she says. She wonders, however, if one kind of distraction might actually be harder for a musician to filter out: the sound of their own instrument. Manting herself plays both the piano and the Chinese harp, and she says hearing those instruments is “like someone calling my name.” It’s one of many questions about how musical training affects cognition that she plans to explore in her future work.", "release_time": "2025-10-07", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/study-sheds-light-musicians-enhanced-attention-1006"}
{"category": "研究前沿", "title": "CRISPR与计算模型共推微生物燃料化研究", "short_summary": "学者运用基因编辑与计算机模型解析微生物代谢，助力生物燃料与塑料化学品绿色制造。", "detailed_summary": "学者运用基因编辑与计算机模型解析微生物代谢，助力生物燃料与塑料化学品绿色制造。\n(1) 研究人员以心理疗法作类比，使用CRISPR技术逐一关闭关键基因，探究Z. mobilis细菌如何应对植物毒素及生物燃料等压力。\n(2) 识别Z. mobilis的耐受基因是培育新菌株的第一步，新菌株能更高效地将生物质转化为燃料及制造塑料、粘合剂等的化学品。\n(3) 另一项研究利用计算机模型解析如Novosphingobium aromaticivorans等微生物的代谢网络，该微生物可将植物生物质中的芳香化学品转化为塑料原料。\n(4) 威斯康星大学麦迪逊分校的科学传播计划支持研究人员（如博士后Blaise Manga Enuh）向公众清晰阐述其前沿工作，促进科学普及。", "raw_content": "Using psychotherapy as an analogy, she explains how she uses CRISPR to turn off key genes one at a time to figure out how the bug responds to various stresses, from toxins that plants produce to ward off bacteria to the biofuels themselves.  Identifying the genes behind Z. mobilis’ coping mechanisms is the first step to growing new strains that are better at converting biomass into fuel and chemicals used to make plastics, adhesives, and other products.    Launched in 2010 by UW–Madison chemistry Professor Bassam Shakhashiri, the initiative aims to promote literacy in science, mathematics, and technology and to attract future generations to careers in research, teaching, and public service. As Shakhashiri wrote, \"Science literacy enlightens and enables people to make informed choices, allowing us to be skeptical, to reject shams, quackery, unproven conjecture, and to avoid being bamboozled into making foolish decisions where matters of science and technology are concerned.\" The program pairs PhD candidates with editors to help them write a chapter of their thesis specifically for a non-science audience. Those who complete the program receive a cash prize. There is a parallel program for postdocs.  In 2024, Blaise Manga Enuh, a postdoc in Dan Noguera’s lab, wrote about his work using computer modeling to understand metabolic networks in microbes like Novosphingobium aromaticivorans, a bug that can convert aromatic chemicals in plant biomass into chemicals used to make plastic.   Other past award recipients include GLBRC members Christine Hustmyer, Jennifer Tran, and Shannon Goes.", "release_time": "2025-11-13", "source_institution": "美国能源部大湖生物能源研究中心", "url": "https://www.glbrc.org/news/using-gene-editing-advance-renewable-energy"}
{"category": "研究前沿", "title": "路灯变身充电桩，美研究测试低成本电动汽车充电方案", "short_summary": "美研究团队开发路灯充电框架，测试证明其成本低、充电快且更公平便捷。", "detailed_summary": "美研究团队开发路灯充电框架，测试证明其成本低、充电快且更公平便捷。\n（1）研究动机为解决城市公寓居民缺乏家用充电桩的问题，利用现有路灯基础设施。\n（2）在堪萨斯城改装23个路灯为充电站，建立需求、可行性和效益三维评估框架。\n（3）测试发现路灯充电站比传统站安装成本更低、充电速度更快、环境负面影响更少。\n（4）框架注重公平性，确保不同社区能公平受益，并利用AI模型预测需求。\n（5）研究成果支持可持续电气化，未来将纳入社会经济和天气数据以优化模型。", "raw_content": "To address this issue, a team of researchers at Penn State created a scalable framework to develop, analyze and evaluate using streetlights as a low-cost, equitable EV charging option. They then installed 23 streetlight charging units in Kansas City, Missouri, and tested their framework. The researchers found that streetlight charging stations, compared to traditional EV charging stations, were more cost- and time-effective, had fewer negative environmental impacts, and were more convenient and accessible. Their results were published in the Journal of Urban Planning and Development, which is overseen by the American Society of Civil Engineers. \"The motivation for this work comes from the fact that many apartment and multi-unit dwelling residents, particularly in urban and downtown areas, lack access to dedicated home EV chargers, since they don't have the privilege of owning a garage,\" said Xianbiao \"XB\" Hu, associate professor of civil and environmental engineering. \"Fortunately, streetlight poles are already powered and typically owned by municipalities, making them relatively easy to work with. Their placement -- often near on-street parking and in high-traffic areas -- makes them well-positioned to serve both local residents and visitors.\" Funded by the U.S. Department of Energy, the researchers partnered with the Kansas City, the non-profit organization Metro Energy Center, local utilities companies and the National Renewable Energy Lab to retrofit existing streetlights to function as EV chargers. They then established a three-pronged framework -- focused on demand, feasibility and benefits -- for other communities to use to develop streetlight EV chargers. \"The scalability was a huge part of what makes this framework important,\" said corresponding author Yang \"Chris\" Song, who was a doctoral student at Penn State at the time of the research and is now a data scientist at ElectroTempo. \"Creating something that works not just in one specific city but that can be adopted by many communities easily is critical for increasing EV use across the country.\" To determine demand, the researchers looked at factors including land use, station density, points of interest nearby, and traffic volume and then used the data to train artificial intelligence models to make demand predictions based on these factors. \"We also took into account equity, which here means the proactive engagement with the community to ensure fair and inclusive distribution of the streetlight charging benefits across diverse neighborhoods,\" Song said. The researchers used the demand and equity analyses to select 23 streetlights and installed EV charging stations. They collected data from the stations for one year. Compared to traditional EV charging ports, they found that these stations were much cheaper to install, since the infrastructure already existed. They also found that the streetlight chargers offered significantly faster charging speeds, likely because they draw power from dedicated municipal electrical lines and face less competition from multiple vehicles charging simultaneously, unlike clustered commercial stations, according to Yuyan \"Annie\" Pan, a postdoctoral researcher working with Hu. The streetlight charging stations also benefited the environment, since there were gasoline savings and greenhouse gas reductions by using locations where cars were already parking. \"We found that using streetlights for EV charging offers an innovative and equitable approach to expanding charging infrastructure and promoting sustainable electrification,\" Pan said. For next steps, the researchers said they would like to build on their models to incorporate more detailed socio-economic data and weather information. Incorporating socio-economic factors will help identify communities with limited EV access or adoption potential, ensuring more equitable infrastructure deployment. Weather data is also critical, as extreme temperatures can affect battery performance, travel frequency and overall energy demand. Tianjia Yang, a postdoctoral researcher, and Yuxin Ding, a doctoral candidate, both of whom are affiliated with the Department of Civil and Environmental Engineering, are co-authors on the paper. The U.S. Department of Energy supported this work.", "release_time": "2025-10-06", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251005085620.htm"}
{"category": "研究前沿", "title": "MIT报告：企业供应链可持续性实践持续加强", "short_summary": "MIT研究显示，85%企业维持或加强供应链可持续性努力，但数据测量方法亟待改进。", "detailed_summary": "MIT研究显示，85%企业维持或加强供应链可持续性努力，但数据测量方法亟待改进。\n(1) MIT最新报告显示，85%的公司在全球政策和经济不确定性下，维持或增加了供应链可持续性实践。\n(2) 行动驱动因素存在地区差异：欧洲企业主要受政府法规驱动，而北美企业更受投资者和竞争对手压力影响。\n(3) 企业在追踪“范围3”排放（供应链间接排放）方面面临重大挑战，约70%的公司缺乏来自供应商的足够数据进行准确计算。\n(4) 报告指出许多公司，尤其是北美企业（50%），仍使用简单的电子表格而非专业的生命周期评估软件来测算排放，导致数据质量不佳。\n(5) 在减少运输排放方面，企业正在探索生物燃料、电动汽车和氢动力等多种方案，同时优化现有物流基础设施也是实现可持续性和降低成本的关键途径。", "raw_content": "Corporations are actively seeking sustainability advances in their supply chains — but many need to improve the business metrics they use in this area to realize more progress, according to a new report by MIT researchers. During a time of shifting policies globally and continued economic uncertainty, the survey-based report finds 85 percent of companies say they are continuing supply chain sustainability practices at the same level as in recent years, or are increasing those efforts. “What we found is strong evidence that sustainability still matters,” says Josué Velázquez Martínez, a research scientist and director of the MIT Sustainable Supply Chain Lab, which helped produce the report. “There are many things that remain to be done to accomplish those goals, but there’s a strong willingness from companies in all parts of the world to do something about sustainability.” The new analysis, titled “ Sustainability Still Matters ,” was released today. It is the sixth annual report on the subject prepared by the MIT Sustainable Supply Chain Lab, which is part of MIT’s Center for Transportation and Logistics. The Council of Supply Chain Management Professionals collaborated on the project as well. The report is based on a global survey, with responses from 1,203 professionals in 97 countries. This year, the report analyzes three issues in depth, including regulations and the role they play in corporate approaches to supply chain management. A second core topic is management and mitigation of what industry professionals call “Scope 3” emissions, which are those not from a firm itself, but from a firm’s supply chain. And a third issue of focus is the future of freight transportation, which by itself accounts for a substantial portion of supply chain emissions. Broadly, the survey finds that for European-based firms, the principal driver of action in this area remains government mandates, such as the Corporate Sustainability Reporting Directive, which requires companies to publish regular reports on their environmental impact and the risks to society involved. In North America, firm leadership and investor priorities are more likely to be decisive factors in shaping a company’s efforts. “In Europe the pressure primarily comes more from regulation, but in the U.S. it comes more from investors, or from competitors,” Velázquez Martínez says. The survey responses on Scope 3 emissions reveal a number of opportunities for improvement. In business and sustainability terms, Scope 1 greenhouse gas emissions are those a firm produces directly. Scope 2 emissions are the energy it has purchased. And Scope 3 emissions are those produced across a firm’s value chain, including the supply chain activities involved in producing, transporting, using, and disposing of its products. The report reveals that about 40 percent of firms keep close track of Scope 1 and 2 emissions, but far fewer tabulate Scope 3 on equivalent terms. And yet Scope 3 may account for roughly 75 percent of total firm emissions, on aggregate. About 70 percent of firms in the survey say they do not have enough data from suppliers to accurately tabulate the total greenhouse gas and climate impact of their supply chains. Certainly it can be hard to calculate the total emissions when a supply chain has many layers, including smaller suppliers lacking data capacity. But firms can upgrade their analytics in this area, too. For instance, 50 percent of North American firms are still using spreadsheets to tabulate emissions data, often making rough estimates that correlate emissions to simple economic activity. An alternative is life cycle assessment software that provides more sophisticated estimates of a product’s emissions, from the extraction of its materials to its post-use disposal. By contrast, only 32 percent of European firms are still using spreadsheets rather than life cycle assessment tools. “You get what you measure,” Velázquez Martínez says. “If you measure poorly, you’re going to get poor decisions that most likely won’t drive the reductions you’re expecting. So we pay a lot of attention to that particular issue, which is decisive to defining an action plan. Firms pay a lot of attention to metrics in their financials, but in sustainability they’re often using simplistic measurements.” When it comes to transportation, meanwhile, the report shows that firms are still grappling with the best ways to reduce emissions. Some see biofuels as the best short-term alternative to fossil fuels; others are investing in electric vehicles; some are waiting for hydrogen-powered vehicles to gain traction. Supply chains, after all, frequently involve long-haul trips. For firms, as for individual consumers, electric vehicles are more practical with a larger infrastructure of charging stations. There are advances on that front but more work to do as well. That said, “Transportation has made a lot of progress in general,” Velázquez Martínez says, noting the increased acceptance of new modes of vehicle power in general. Even as new technologies loom on the horizon, though, supply chain sustainability is not wholly depend on their introduction. One factor continuing to propel sustainability in supply chains is the incentives companies have to lower costs. In a competitive business environment, spending less on fossil fuels usually means savings. And firms can often find ways to alter their logistics to consume and spend less. “Along with new technologies, there is another side of supply chain sustainability that is related to better use of the current infrastructure,” Velázquez Martínez observes. “There is always a need to revise traditional ways of operating to find opportunities for more efficiency.”", "release_time": "2025-10-07", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/report-sustainability-supply-chains-still-firm-level-priority-1006"}
{"category": "研究前沿", "title": "MIT化学系新任主任Matthew Shoulders的前沿研究", "short_summary": "Matthew Shoulders将执掌MIT化学系，其蛋白质折叠与农业安全研究引领生物技术前沿。", "detailed_summary": "Matthew Shoulders将执掌MIT化学系，其蛋白质折叠与农业安全研究引领生物技术前沿。\n（1）Matthew D. Shoulders被任命为MIT化学系主任，自2026年1月16日生效；\n（2）研究方向聚焦细胞蛋白质折叠机制，开发新型蛋白质工程技术，应用于生物技术和疾病治疗；\n（3）发现病毒病原体劫持人类分子伴侣实现快速进化，为癌症和病毒感染治疗提供新策略；\n（4）领导J-WAFS粮食安全项目，通过工程化改造RuBisCO酶提升农作物光合作用效率，应对气候变化；\n（5）作为杰出教育者，开发MIT化学课程创新教学工具，并创立高中实习生项目培养科研人才。", "raw_content": "Matthew D. Shoulders, the Class of 1942 Professor of Chemistry, a MacVicar Faculty Fellow, and an associate member of the Broad Institute of MIT and Harvard, has been named head of the MIT Department of Chemistry, effective Jan. 16, 2026. “Matt has made pioneering contributions to the chemistry research community through his research on mechanisms of proteostasis and his development of next-generation techniques to address challenges in biomedicine and agriculture,” says Nergis Mavalvala, dean of the MIT School of Science and the Curtis and Kathleen Marble Professor of Astrophysics. “He is also a dedicated educator, beloved by undergraduates and graduates alike. I know the department will be in good hands as we double down on our commitment to world-leading research and education in the face of financial headwinds.” Shoulders succeeds Troy Van Voorhis, the Robert T. Haslam and Bradley Dewey Professor of Chemistry, who has been at the helm since October 2019. “I am tremendously grateful to Troy for his leadership the past six years, building a fantastic community here in our department. We face challenges, but also many exciting opportunities, as a department in the years to come,” says Shoulders. “One thing is certain: Chemistry innovations are critical to solving pressing global challenges. Through the research that we do and the scientists we train, our department has a huge role to play in shaping the future.” Shoulders studies how cells fold proteins, and he develops ​and applies novel protein engineering techniques to challenges in biotechnology. His work across chemistry and biochemistry fields including proteostasis, extracellular matrix biology, virology, evolution, and synthetic biology is yielding not just important insights into topics like how cells build healthy tissues and how proteins evolve, but also influencing approaches to disease therapy and biotechnology development. “Matt is an outstanding researcher whose work touches on fundamental questions about how the cell machinery directs the synthesis and folding of proteins. His discoveries about how that machinery breaks down as a result of mutations or in response to stress has a fundamental impact on how we think about and treat human diseases,” says Van Voorhis. In one part of Matt's current research program, he is studying how protein folding systems in cells — known as chaperones — shape the evolution of their clients. Amongst other discoveries, his lab has shown that viral pathogens hijack human chaperones to enable their rapid evolution and escape from host immunity. In related recent work, they have discovered that these same chaperones can promote access to malignancy-driving mutations in tumors. Beyond fundamental insights into evolutionary biology, these findings hold potential to open new therapeutic strategies to target cancer and viral infections. “Matt’s ability to see both the details and the big picture makes him an outstanding researcher and a natural leader for the department,” says Timothy Swager, the John D. MacArthur Professor of Chemistry. “MIT Chemistry can only benefit from his dedication to understanding and addressing the parts and the whole.” Shoulders also leads a food security project through the Abdul Latif Jameel Water and Food Systems Lab (J-WAFS). Shoulders, along with MIT Research Scientist Robbie Wilson, assembled an interdisciplinary team based at MIT to enhance climate resilience in agriculture by improving one of the most inefficient aspects of photosynthesis, the carbon dioxide-fixing plant enzyme RuBisCO. J-WAFS funded this high-risk, high-reward MIT Grand Challenge project in 2023, and it has received further support from federal research agencies and the Grantham Foundation for the Protection of the Environment. “Our collaborative team of biochemists and synthetic biologists, computational biologists, and chemists is deeply integrated with plant biologists, creating a robust feedback loop for enzyme engineering,” Shoulders says. “Together, this team is making a concerted effort using state-of-the-art techniques to engineer crop RuBisCO with an eye to helping make meaningful gains in securing a stable crop supply, hopefully with accompanying improvements in both food and water security.” In addition to his research contributions, Shoulders has taught multiple classes for Course V, including 5.54 (Advances in Chemical Biology) and 5.111 (Principles of Chemical Science), along with a number of other key chemistry classes. His contributions to a 5.111 “bootcamp” through the MITx platform served to address gaps in the classroom curriculum by providing online tools to help undergraduate students better grasp the material in the chemistry General Institute Requirement (GIR). His development of Guided Learning Demonstrations to support first-year chemistry courses at MIT has helped bring the lab to the GIR, and also contributed to the popularity of 5.111 courses offered regularly via MITx . “I have had the pleasure of teaching with Matt on several occasions, and he is a fantastic educator. He is an innovator both inside and outside the classroom and has an unwavering commitment to his students’ success,” says Van Voorhis of Shoulders, who was named a 2022 MacVicar Faculty Fellow, and who received a Committed to Caring award through the Office of Graduate Education. Shoulders also founded the MIT Homeschool Internship Program for Science and Technology, which brings high school students to campus for paid summer research experiences in labs across the Institute. He is a founding member of the Department of Chemistry’s Quality of Life Committee and chair for the last six years, helping to improve all aspects of opportunity, professional development, and experience in the department: “countless changes that have helped make MIT a better place for all,” as Van Voorhis notes, including creating a peer mentoring program for graduate students and establishing universal graduate student exit interviews to collect data for department-wide assessment and improvement. At the Institute level, Shoulders has served on the Committee on Graduate Programs, Committee on Sexual Misconduct Prevention and Response (in which he co-chaired the provost's working group on the Faculty and Staff Sexual Misconduct Survey), and the Committee on Assessment of Biohazards and Embryonic Stem Cell Research Oversight, among other roles. Shoulders graduated summa cum laude from Virginia Tech in 2004, earning a BS in chemistry with a minor in biochemistry. He earned a PhD in chemistry at the University of Wisconsin at Madison in 2009 under Professor Ronald Raines. Following an American Cancer Society Postdoctoral Fellowship at Scripps Research Institute, working with professors Jeffery Kelly and Luke Wiseman, Shoulders joined the MIT Department of Chemistry faculty as an assistant professor in 2012. Shoulders also serves as an associate member of the Broad Institute and an investigator at the Center for Musculoskeletal Research at Massachusetts General Hospital. Among his many awards, Shoulders has received a NIH Director's New Innovator Award under the NIH High-Risk, High-Reward Research Program; an NSF CAREER Award; an American Cancer Society Research Scholar Award; the Camille Dreyfus Teacher-Scholar Award; and most recently the Ono Pharma Foundation Breakthrough Science Award.", "release_time": "2025-10-07", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/matthew-shoulders-named-head-department-chemistry-1006"}
{"category": "研究前沿", "title": "超大质量黑洞风或是超高能宇宙射线源头", "short_summary": "挪威研究提出新假说，认为超大质量黑洞产生的风可能加速形成超高能宇宙射线。", "detailed_summary": "挪威研究提出新假说，认为超大质量黑洞产生的风可能加速形成超高能宇宙射线。\n(1) 超高能宇宙射线是物理学长期未解之谜，其能量极高，来源未知。\n(2) 挪威科技大学研究团队提出新假说，认为活跃超大质量黑洞产生的超高速风可能是粒子加速器。\n(3) 该模型能较好解释特定能量范围内宇宙射线的化学组成，这是其他模型难以实现的。\n(4) 研究人员持谨慎态度，表示目前仅为\"可能\"答案，尚未能最终证实。\n(5) 未来计划通过与中微子天文学家合作进行实验，以进一步检验这一假说。", "raw_content": "Curiously, \"cosmic rays\" are not actually rays - this name has historical reasons - but small particles, mostly atomic nuclei, which are accelerated to enormous energies somewhere in the universe. Although their sources are not yet fully understood, they are most likely associated with some of the most extreme environments in the universe, such as black holes, supernovae, or rotating neutron stars (a type of dead star). But occasionally cosmic rays have much higher energy than usual. We've known about this since 1962, but we still have no idea why. We also don't know where this ultra-high-energy cosmic radiation comes from. Now, research from the Norwegian University of Science and Technology (NTNU) may have found the answer to this big unanswered question in physics. Supermassive black holes may be the cause Foteini Oikonomou, an associate professor at NTNU's Department of Physics, is working on the case. In a recent article, she and her colleagues present a completely new and plausible explanation for this ultra-high-energy radiation. The lead author is PhD research fellow Domenik Ehlert from the same department. The team also includes postdoctoral fellow Enrico Peretti from the Université Paris Cité. Their work focuses on astroparticle physics, which studies the relationship between the smallest particles in the universe and the universe's largest phenomena. \"We suspect that this high-energy radiation is created by winds from supermassive black holes,\" said Oikonomou. But what on earth does that mean? Active black holes create winds The Milky Way is the neighborhood in the universe where you and I live. Our Sun and solar system are part of this galaxy, along with at least 100 billion other stars. \"There is a black hole called Sagittarius-A* located right in the centre of the Milky Way. This black hole is currently in a quiet phase where it isn't consuming any stars, as there is not enough matter in the vicinity,\" Peretti said. This contrasts with growing, supermassive, active black holes that consume up to several times the mass of our own Sun each year. \"A tiny portion of the material can be pushed away by the force of the black hole before it is pulled in. As a result, around half of these supermassive black holes create winds that move through the universe at up to half the speed of light,\" Peretti said. We have known about these gigantic winds for approximately ten years. The winds from these black holes can affect galaxies. By blowing away gases, they can prevent new stars from forming, for example. This is dramatic enough in itself, but Oikonomou and her colleagues looked at something else, much smaller, that these winds could be the cause of.\" It is possible that these powerful winds accelerate the particles that create the ultra-high-energy radiation,\" said Ehlert. To understand this, we also need to explain a little bit about atoms. Atoms and enormous amounts of energy Atoms consist of a nucleus, which is made up of protons and neutrons. These particles are made up of quarks, but we don't need to go into that right now. One or more electrons can be found around this nucleus in the so-called cloud. \"The ultra-high-energy radiation consists of protons or atomic nuclei with energy up to 1020 electron volts,\" explained Oikonomou. If that number doesn't mean anything to you, you should know that in this context, it is an absolutely enormous amount of energy. \"A particle like this, which is smaller than an atom, contains about as much energy as a tennis ball when Serena Williams serves it at 200 kilometers per hour,\" said Oikonomou. It corresponds to approximately a billion times more energy than the particles created by researchers in the Large Hadron Collider in Switzerland and France. Fortunately, these cosmic rays are destroyed by the Earth's atmosphere. When they reach ground level, they are as harmless as all the other cosmic radiation that reaches us at the Earth's surface. \"But for astronauts, cosmic radiation is a very serious problem,\" Oikonomou said. Airline crews don't need to worry about this because they don't fly high enough. \"The main concern for astronauts is cosmic low-energy radiation produced by our own Sun, because it is much more common. The rays we study are infrequent enough that it is extremely unlikely they would pass through an astronaut,\" she said. Other suspects Previously, researchers have looked into whether these high-energy particles come from gamma-ray bursts, from galaxies that are creating new stars at an extremely high rate, or from plasma outflows from supermassive black holes. However, Oikonomou and her colleagues have another hypothesis. \"All the other hypotheses are very good guesses - they are all sources that contain a lot of energy. But no one has provided evidence that any of them are the source. That is why we decided to investigate the winds from the supermassive black holes,\" said Ehlert. Guilty? Maybe So what do we actually know? Is it the winds that create the high-energy particles in the cosmic radiation? \"Our answer is more of a cautious 'maybe',\" said Oikonomou. That doesn't sound particularly dramatic. However, when researchers ask questions like this, they often feel a sense of excitement and think \"YES, that might just be the case!,\" but that doesn't mean it is the case in this instance. \"We find that the conditions related to these winds align particularly well with particle acceleration. But we are still unable to prove that it is specifically these winds that accelerate the particles behind the high-energy cosmic radiation,\" Oikonomou said. However, the model the researchers are using can explain one specific aspect of these particles that we still don't understand. Within a certain energy range, the particles have a chemical composition that other models cannot explain in any meaningful way. \"We can also test the model using neutrino experiments,\" said Oikonomou. That, however, is something for a completely different article. \"In the years to come, we hope to collaborate with neutrino astronomers to test our hypothesis,\" Oikonomou said. Perhaps they will then find more evidence, one way or the other.", "release_time": "2025-10-06", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251005085639.htm"}
{"category": "研究前沿", "title": "新型桌面引力波探测器填补中频探测空白", "short_summary": "英高校提出光学谐振腔探测器方案，实现毫赫兹引力波地面探测。", "detailed_summary": "英高校提出光学谐振腔探测器方案，实现毫赫兹引力波地面探测。\n（1）英国伯明翰大学和萨塞克斯大学团队提出新型引力波探测器概念，利用光学原子钟技术探测毫赫兹频段（10⁻⁵–1 Hz）引力波；\n（2）该桌面级探测器基于光学谐振腔技术，通过测量激光相位变化探测引力波，具有抗地震噪声、结构紧凑等优势；\n（3）可探测白矮星双星、黑洞合并等天体物理信号，为2030年代发射的LISA等空间任务提供前期数据支持；\n（4）未来可组建全球探测网络，与现有高频探测器（LIGO）形成互补，拓展引力波探测频率覆盖范围。", "raw_content": "Gravitational waves—ripples in spacetime predicted by Einstein—have been observed at high frequencies by ground-based interferometers such as LIGO and Virgo, and at ultra-low frequencies by pulsar timing arrays. However, the mid-band range has remained a scientific blind spot. Developed by researchers at the Universities of Birmingham and Sussex, the new detector concept uses cutting-edge optical cavity and atomic clock technologies to sense gravitational waves in the elusive milli-Hertz frequency band (10⁻⁵ – 1 Hz). Publishing their proposal today (Oct. 3) in Classical and Quantum Gravity , the scientist reveal a detector that uses advances in optical resonator technology, originally developed for optical atomic clocks, to measure tiny phase shifts in laser light caused by passing gravitational waves. Unlike large-scale interferometers, these detectors are compact, relatively immune to seismic and Newtonian noise. Co-author Dr Vera Guarrera, from the University of Birmingham, commented: “By using technology matured in the context of optical atomic clocks, we can extend the reach of gravitational wave detection into a completely new frequency range with instruments that fit on a laboratory table. This opens the exciting possibility of building a global network of such detectors and searching for signals that would otherwise remain hidden for at least another decade.” The milli-Hertz frequency band - sometimes called the ‘mid-band’ - is expected to host signals from a variety of astrophysical and cosmological sources, including compact binaries of white dwarfs and black hole mergers. Ambitious space missions such as LISA also target this frequency band, but they are scheduled for launch in the 2030s. The proposed optical resonator detectors could begin exploring this territory now. Co-author Professor Xavier Calmet, from the University of Sussex, commented: “This detector allows us to test astrophysical models of binary systems in our galaxy, explore the mergers of massive black holes, and even search for stochastic backgrounds from the early universe. With this method, we have the tools to start probing these signals from the ground, opening the path for future space missions.” While future space-based missions like LISA will offer superior sensitivity, their operation is over a decade away. The proposed optical cavity detectors provide an immediate, cost-effective means to explore the milli-Hz band. The study also suggests that integrating these detectors with existing clock networks could extend gravitational wave detection to even lower frequencies, complementing high-frequency observatories like LIGO. Each unit consists of two orthogonal ultrastable optical cavities and an atomic frequency reference, enabling multi-channel detection of gravitational wave signals. This configuration not only enhances sensitivity but also allows for the identification of wave polarisation and source direction.", "release_time": "2025-10-04", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251003033920.htm"}
{"category": "研究前沿", "title": "科学家突破性追踪暗激子，奠定暗谷电子学基础", "short_summary": "研究团队首次实现暗激子全特性追踪，揭示其长寿命谷信息保存能力，为量子技术开辟新路径。", "detailed_summary": "研究团队首次实现暗激子全特性追踪，揭示其长寿命谷信息保存能力，为量子技术开辟新路径。\n(1) 研究背景：谷电子学旨在利用电子在晶体动量空间中的不同能谷（valley）来编码信息，暗激子因其对环境干扰抵抗力强而成为量子技术的潜在候选者。\n(2) 研究方法：团队使用世界领先的时间-角分辨光电子能谱（TR-ARPES）装置，首次同时量化了电子和空穴的动量、自旋和布居数，追踪了TMD材料中激子的演变。\n(3) 关键发现：亮激子在皮秒内通过声子散射变为动量暗激子，随后自旋暗激子主导并在纳秒尺度上持续存在，这两种暗激子都能长时间保存谷信息。\n(4) 科学意义：该研究克服了探测和追踪暗激子的根本性挑战，直接绘制了暗激子保存谷信息的过程，为“暗谷电子学”领域的建立奠定了基础。\n(5) 潜在应用：未来通过读取暗激子的谷特性，有望在信息技术系统中实现广泛的暗谷电子学应用，可能降低量子比特对极端冷却的要求。", "raw_content": "\"In the general field of electronics, one manipulates electron charge to process information,\" explains Xing Zhu, co-first author and PhD student in the unit. \"In the field of spintronics, we exploit the spin of electrons to carry information. Going further, in valleytronics, the crystal structure of unique materials enables us to encode information into distinct momentum states of the electrons, known as valleys.\" The ability to use the valley dimension of dark excitons to carry information positions them as promising candidates for quantum technologies. Dark excitons are by nature more resistant to environmental factors like thermal background than the current generation of qubits, potentially requiring less extreme cooling and making them less prone to decoherence, where the unique quantum state breaks down. Defining landscapes of energy with bright and dark excitons Over the past decade, progress has been made in the development of a class of atomically thin semiconducting materials known as TMDs (transition metal dichalcogenides). As with all semiconductors, atoms in TMDs are aligned in a crystal lattice, which confines electrons to a specific level (or band) of energy, such as the valence band. When exposed to light, the negatively charged electrons are excited to a higher energy state - the conduction band - leaving behind a positively charged hole in the valence band. The electrons and holes are bound together by electrostatic attraction, forming hydrogen-like quasiparticles called excitons. If certain quantum properties of the electron and hole match, i.e. they have the same spin configuration and they inhabit the same 'valley' in momentum space (the energy minima that electrons and holes can occupy in the atomic crystal structure) the two recombine within a picosecond (1ps = 10 −12 second), emitting light in the process. These are 'bright' excitons. However, if the quantum properties of the electron and hole do not match up, the electron and hole are forbidden from recombining on their own and do not emit light. These are characterized as 'dark' excitons. \"There are two 'species' of dark excitons,\" explains Dr. David Bacon, co-first author who is now at University College London, \"momentum-dark and spin-dark, depending on where the properties of electron and hole are in conflict. The mismatch in properties not only prevents immediate recombination, allowing them to exist up to several nanoseconds (1ns = 10 −9 second - a much more useful timescale), but also makes dark excitons more isolated from environmental interactions.\" \"The unique atomic symmetry of TMDs means that when exposed to a state of light with a circular polarization, one can selectively create bright excitons only in a specific valley. This is the fundamental principle of valleytronics. However, bright excitons rapidly turn into numerous dark excitons that can potentially preserve the valley information. Which species of dark excitons are involved and to what degree they can sustain the valley information is unclear, but this is a key step in the pursuit of valleytronic applications,\" explains Dr. Vivek Pareek, co-first author and OIST graduate who is now a Presidential Postdoctoral Fellow at the California Institute of Technology. Observing electrons at the femtosecond scale Using the world-leading TR-ARPES (time- and angle resolved photoemission spectroscopy) setup at OIST, which includes a proprietary, table-top XUV (extreme ultraviolet) source, the team has managed to track the characteristics of all excitons after the creation of bright excitons in a specific valley in a TMD semiconductor over time by simultaneously quantifying momentum, spin state, and population levels of electrons and holes - these properties have never been simultaneously quantified before. Their findings show that within a picosecond, some bright excitons are scattered by phonons (quantized crystal lattice vibrations) into different momentum valleys, rendering them momentum-dark. Later, spin-dark excitons dominate, where electrons have flipped spin within the same valley, persisting on nanosecond scales. With this, the team has overcome the fundamental challenge of how to access and track dark excitons, laying the foundation for dark valleytronics as a field. Dr. Julien Madéo of the unit summarizes: \"Thanks to the sophisticated TR-ARPES setup at OIST, we have directly accessed and mapped how and what dark excitons keep long-lived valley information. Future developments to read out the dark excitons valley properties will unlock broad dark valleytronic applications across information systems.\"", "release_time": "2025-10-04", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251003033928.htm"}
{"category": "政策计划", "title": "国际原子能机构在阿根廷举办小型模块堆区域学校", "short_summary": "IAEA在阿根廷举办小型模块堆区域研讨会，推动拉美核能政策与规划发展。", "detailed_summary": "IAEA在阿根廷举办小型模块堆区域研讨会，推动拉美核能政策与规划发展。\n(1) 国际原子能机构在阿根廷举办小型模块堆区域学校，汇集拉美及加勒比地区监管机构、政策制定者参与。\n(2) 为期五天的培训涵盖SMR技术、战略能源规划、核基础设施、安全及法律框架等关键议题。\n(3) 活动促进区域对话，支持多米尼加共和国等新兴核能国家制定实施路线图。\n(4) 与会者参观阿根廷阿图查核电站及CAREM小型堆原型机建设现场，结合实践学习。\n(5) IAEA通过此学校及更广泛支持计划，助力区域国家为SMR部署构建必要政策与基础设施。", "raw_content": "The IAEA’s school on small modular reactors concluded its first year with a regional workshop in Argentina that brought together regulators, policy makers and international organization representatives from across Latin America and the Caribbean to discuss key aspects of small modular reactor (SMR) development and deployment. The five-day training formed part of the IAEA’s SMR School initiative, which launched in May with the inaugural workshop held in Kenya . In July, participants from across Asia convened in Thailand for the second edition of the school. Argentina hosted the workshop in September through the Argentine Nuclear Council, which was recently established to implement the country’s plans for nuclear power expansion. While only three Latin American countries currently operate nuclear power plants – Argentina, Brazil and Mexico – interest in nuclear power is growing in the region, with seven of the world’s newcomer countries located in Central or South America. “This extremely important meeting brings together no less than ten countries in our region, as well as the Inter-American Development Bank, the Latin American and Caribbean Development Bank, CAF, and the Latin American Energy Organization, or OLADE, important institutions with which we have been working to support this new and exciting development we are seeing in the world and, of course, in our region, around nuclear energy,” IAEA Director General Rafael Mariano Grossi said to the participants. “We hope this school enables you to have a more complete, informed, and systematic view of what is happening in the international market.” Education to bolster preparedness The school gathered over 50 participants from 10 countries and regional organizations in Latin America and the Caribbean. IAEA staff delivered  lectures  on  SMR technologies, strategic energy planning, nuclear infrastructure, safety, radioactive waste management and legal frameworks. Participants also presented updates on the status of their national nuclear power programmes. “This activity represents an important milestone for the Dominican Republic in our roadmap toward the implement of nuclear power in our generation mix,” said Gaddis Enrique Corporan Segura, Vice Minister of Nuclear Energy in the Dominican Republic. “It allowed us to learn about the main perspectives and advances of Latin American countries in nuclear power generation. It also helped us narrow the learning curve on the technical, economic and social aspects of SMRs as well as technology development.” SMRs for a clean energy future There are currently about 70 SMR designs in active development, though for now only China and Russia have SMRs in commercial operation. The latest IAEA projections have global nuclear capacity increasing by 2.6 times the 2024 level by 2050 in the high case scenario, with SMRs comprising about a quarter of this new capacity. “The SMR School in Argentina offered Brazil a valuable opportunity to share its perspectives on SMR and microreactor technologies, while engaging with high-level specialists and Member States,” said Nelbia da Silva Lapa of Brazil’s National Nuclear Energy Commission. “Discussions highlighted Brazil’s alignment with the IAEA on regulatory framework updates and raised key issues such as emergency planning zones as well as the potential role of Brazil and Argentina in supporting newcomer countries.” Participants also visited Argentina’s Atucha Nuclear Power Plant, which entered commercial operation more than 50 years ago, and the construction site for the CAREM, an SMR prototype. “Nuclear energy, and particularly SMRs, is increasingly recognized as a valid and beneficial alternative for the energy transition in Latin America and the Caribbean,” said Guido Maiulini, Head of Strategic Advisory at OLADE. ““It is very important to take advantage of opportunities such as this workshop to build a regional dialogue on the expectations, challenges and opportunities that this technology represents for our region.” IAEA Support on SMRs This school was implemented through the IAEA technical cooperation project ‘Supporting the Development of Comprehensive Energy Plans Considering the Climate, Land, Energy and Water in Latin America and the Caribbean’, an initiative to introduce and implement sustainable energy planning that integrates climate, land use, energy and water considerations in the region. The SMR School is part of a wider package of IAEA support, including the SMR Platform and the Nuclear Harmonization and Standardization Initiative (NHSI), which assist countries in building the infrastructure needed for SMR development, deployment and oversight. Additional SMR Schools are planned for 2026.", "release_time": "2025-10-05", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/iaea-smr-school-concludes-its-first-year-with-workshop-in-argentina"}
{"category": "政策计划", "title": "美能源部长访MIT 共议能源创新与政策支持", "short_summary": "美能源部长赖特访问MIT，探讨AI、核聚变等前沿能源技术发展与合作前景。", "detailed_summary": "美能源部长赖特访问MIT，探讨AI、核聚变等前沿能源技术发展与合作前景。\n(1) 美国能源部长克里斯·赖特访问麻省理工学院，与校长科恩布鲁斯及前能源部长莫尼兹等举行论坛对话；\n(2) 访问期间参观了MIT.nano实验室及能源研究设施，观摩研究生能源技术演示；\n(3) 赖特强调能源是“世界最重要产业”，需加强基础研究及国家实验室支持；\n(4) 论坛重点讨论人工智能、核聚变能源、量子计算等前沿技术发展前景；\n(5) MIT与GE Vernova新成立能源气候联盟，强化产学研合作推动能源创新。", "raw_content": "U.S. Secretary of Energy Chris Wright ’85 visited MIT on Monday, meeting Institute leaders, discussing energy innovation at a campus forum, viewing poster presentations from researchers supported through the MIT-GE Vernova Energy and Climate Alliance, and watching energy research demos in the lab where he used to work as a student. “I’ve always been in energy because I think it’s just far and away the world’s most important industry,” Wright said at the forum, which included a panel discussion with business leaders and a fireside chat with MIT Professor Ernest Moniz, who was the U.S. secretary of energy from 2013 to 2017. Wright added: “Not only is it by far the world’s most important industry, because it enables all the others, but it’s also a booming time right now. … It is an awesomely exciting time to be in energy.” Wright was greeted on campus by MIT President Sally Kornbluth, who also gave introductory remarks at the forum, held in MIT’s Samberg Center. While the Institute has added many research facilities and buildings since Wright was a student, Kornbluth observed, the core MIT ethos remains the same. “MIT is still MIT,” Kornbluth said. “It’s a community that rewards merit, boldness, and scientific rigor. And it’s a magnet for people with a drive to solve hard problems that matter in the real world, an enthusiasm for working with industry, and an ethic of national service.” When it comes to energy research, Kornbluth added, “MIT is developing transformational approaches to make American energy more secure, reliable, affordable, and clean — which in turn will strengthen both U.S. competitiveness and national security.” At the event, Wright, the 17th U.S. secretary of energy, engaged in a fireside chat with Moniz, the 13th U.S. secretary of energy, the Cecil and Ida Green Professor of Physics and Engineering Systems Post-Tenure, a special advisor to the MIT president, and the founding director of the MIT Energy Initiative (MITEI). Wright began his remarks by reflecting on Kornbluth’s description of the Institute. “Merit, boldness, and scientific rigor,” Wright said. “That is MIT … to me. That hit me hard when I got here, and frankly, it’s a good part of the reason my life has gone the way it’s gone.” On energy topics, Wright emphasized the need for continued innovation in energy across a range of technologies, including fusion, geothermal, and more, while advocating for the benefits of vigorous market-based progress. Before becoming secretary of energy, Wright most recently served as founder and CEO of Liberty Energy. He also was the founder of Pinnacle Technologies, among other enterprises. Wright was confirmed as secretary by the U.S. Senate in February. Asked to name promising areas of technological development, Wright focused on three particular areas of interest. Citing artificial intelligence, he noted that the interest in it was “overwhelming,” with many possible applications. Regarding fusion energy, Wright said, “We are going to see meaningful breakthroughs.” And quantum computing, he added, was going to be a “game-changer” as well. Wright also emphasized the value of federal support for fundamental research, including projects in the national laboratories the Department of Energy oversees. “The 17 national labs we have in this country are absolute jewels. They are gems of this country,” Wright said. He later noted, “There are things, like this foundational research, that are just an essential part of our country and an essential part of our future.” Moniz asked Wright a range of questions in the fireside chat, while adding his own perspective at times about the many issues connected to energy abundance globally. “Climate, energy, security, equity, affordability, have to be recognized as one conversation, and not separate conversations,” Moniz said. “That’s what’s at stake in my view.” Wright’s appearance was part of the Energy Freedom Tour developed by the American Conservation Coalition (ACC), in coordination with the Hamm Institute for American Energy at Oklahoma State University. Later stops are planned for Stanford University and Texas A&M University. Ann Bluntzer Pullin, executive director of the Hamm Institute, gave remarks at the forum as well, noting the importance of making students aware of the energy industry and helping to “get them excited about the impact this career can make.” She also praised MIT’s advances in the field, adding, “This is where so many ideas were born and executed that have allowed America to really thrive in this energy abundance in our country that we have [had] for so long.” The forum also featured remarks from Roger Martella, chief corporate officer, chief sustainability officer, and head of government affairs at GE Vernova. In March, MIT and GE Vernova announced a new five-year joint program, the MIT-GE Vernova Energy and Climate Alliance, featuring research projects, education programs, and career opportunities for MIT students. “That’s what we’re about, electrification as the lifeblood of prosperity,” Martella said, describing GE Vernova’s work. “When we’re here at MIT we feel like we’re living history every moment when we’re walking down the halls, because no institution has [contributed] to innovation and technology more, doing it every single day to advance prosperity for all people around the world.” A panel discussion at the forum featured Wright speaking along with three MIT alumni who are active in the energy business: Carlos Araque ’01, SM ’02, CEO of Quaise Energy , a leading-edge firm in geothermal energy solutions; Bob Mumgaard SM ’15, PhD ’15, CEO of Commonwealth Fusion Systems , a leading fusion energy firm and an MIT spinout; and Milo Werner SM ’07, MBA ’07, a general partner at DCVC and expert in energy and climate investments. The panel was moderated by Chris Barnard, president of the ACC. Mumgaard noted that Commonwealth Fusion Systems launched in 2018 with “an explicit mission, working with MIT still today, of putting fusion onto an industrial trajectory,” although there is “plenty left to do, still, at that intersection of science, technology, innovation, and business.” Araque said he believes geothermal is “metric-by-metric” more powerful and profitable than many other forms of energy. “This is not a stop-gap,” he added. Quaise is currently developing its first power-plant-scale facility in the U.S. Werner noted that the process of useful innovation only begins in the lab; making an advance commercially viable is the critical next step. The biggest impact “is not in the breakthrough,” she said. “It’s not in the discovery that you make in the lab. It’s actually once you’ve built a billion of them. That’s when you actually change the world.” After the forum, Wright took a tour of multiple research centers on the MIT campus, including the MIT.nano facility, guided by Vladimir Bulović, faculty director of MIT.nano and the Fariborz Maseeh Chair in Emerging Technology. At MIT.nano, Bulović showed Wright the Titan Krios G3i, a nearly room-size electron microscope that enables researchers to take a high-resolution look at the structure of tiny particles, with a variety of research applications. The tour also viewed one of MIT.nano’s cleanrooms, a shared fabrication facility used by both MIT researchers and users outside of MIT, including many in industry. On a different note, in an MIT.nano hallway, Bulović showed Wright the One.MIT mosaics , which contain the names of all MIT students and employees past and present — well over 300,000 in all. First etched on a 6-inch wafer, the mosaics are a visual demonstration of the power of nanotechnology — and a searchable display, so Bulović located Wright’s name, which is printed near the chin of one of the figures on the MIT seal. The tour ended in the basement of Building 10, in what is now the refurbished Grainger Energy Machine Facility, where Wright used to conduct research. After earning his undergraduate degree in mechanical engineering, Wright entered into graduate studies at MIT before leaving, as he recounted at the forum, to pursue business opportunities. At the lab, Wright met with David Perreault, the Ford Foundation Professor of Engineering; and Steven Leeb, the Emanuel Landsman Professor, a specialist in power systems. A half-dozen MIT graduate students gave Wright demos of their research projects, all involving energy-generation innovations. Wright readily engaged with all the graduate students about the technologies and the parameters of the devices, and asked the students about their own careers. Wright was accompanied on the lab tour by MIT Provost Anantha Chandrakasan, himself an expert in developing energy-efficient systems. Chandrakasan delivered closing remarks at the forum in the Samberg Center, noting MIT’s “strong partnership with the Department of Energy” and its “long and proud history of engaging industry.” As such, Chandrakasan said, MIT has a “role as a resource in service of the nation, so please don’t hesitate to call on us.”", "release_time": "2025-10-03", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/secretary-energy-chris-wright-visits-mit-1003"}
{"category": "研究前沿", "title": "AI助力发现克罗恩病靶向抗生素新机制", "short_summary": "AI模型加速发现靶向抗生素enterololin，精准抑制致病菌且保护肠道菌群。", "detailed_summary": "AI模型加速发现靶向抗生素enterololin，精准抑制致病菌且保护肠道菌群。\n(1) 研究团队发现新型化合物enterololin，可精准抑制与克罗恩病发作相关的大肠杆菌；\n(2) 利用生成式AI模型DiffDock快速预测化合物作用机制，将传统需数年的研究缩短至数月；\n(3) 实验证实enterololin靶向细菌LolCDE蛋白复合体，有效运输脂蛋白；\n(4) 小鼠模型显示该药物比万古霉素更有效，恢复更快且保护肠道微生物组；\n(5) 该研究为开发窄谱抗生素提供新范式，有望改善炎症性肠病患者生活质量。", "raw_content": "For patients with inflammatory bowel disease, antibiotics can be a double-edged sword. The broad-spectrum drugs often prescribed for gut flare-ups can kill helpful microbes alongside harmful ones, sometimes worsening symptoms over time. When fighting gut inflammation, you don’t always want to bring a sledgehammer to a knife fight. Researchers at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) and McMaster University have identified a new compound that takes a more targeted approach. The molecule, called enterololin, suppresses a group of bacteria linked to Crohn’s disease flare-ups while leaving the rest of the microbiome largely intact. Using a generative AI model, the team mapped how the compound works, a process that usually takes years but was accelerated here to just months. “This discovery speaks to a central challenge in antibiotic development,” says Jon Stokes, senior author of a new paper on the work , assistant professor of biochemistry and biomedical sciences at McMaster, and research affiliate at MIT’s Abdul Latif Jameel Clinic for Machine Learning in Health. “The problem isn’t finding molecules that kill bacteria in a dish — we’ve been able to do that for a long time. A major hurdle is figuring out what those molecules actually do inside bacteria. Without that detailed understanding, you can’t develop these early-stage antibiotics into safe and effective therapies for patients.” Enterololin is a stride toward precision antibiotics: treatments designed to knock out only the bacteria causing trouble. In mouse models of Crohn’s-like inflammation, the drug zeroed in on Escherichia coli , a gut-dwelling bacterium that can worsen flares, while leaving most other microbial residents untouched. Mice given enterololin recovered faster and maintained a healthier microbiome than those treated with vancomycin, a common antibiotic. Pinning down a drug’s mechanism of action, the molecular target it binds inside bacterial cells, normally requires years of painstaking experiments. Stokes’ lab discovered enterololin using a high-throughput screening approach, but determining its target would have been the bottleneck. Here, the team turned to DiffDock , a generative AI model developed at CSAIL by MIT PhD student Gabriele Corso and MIT Professor Regina Barzilay. DiffDock was designed to predict how small molecules fit into the binding pockets of proteins, a notoriously difficult problem in structural biology. Traditional docking algorithms search through possible orientations using scoring rules, often producing noisy results. DiffDock instead frames docking as a probabilistic reasoning problem: a diffusion model iteratively refines guesses until it converges on the most likely binding mode. “In just a couple of minutes, the model predicted that enterololin binds to a protein complex called LolCDE, which is essential for transporting lipoproteins in certain bacteria,” says Barzilay, who also co-leads the Jameel Clinic. “That was a very concrete lead — one that could guide experiments, rather than replace them.” Stokes’ group then put that prediction to the test. Using DiffDock predictions as an experimental GPS, they first evolved enterololin-resistant mutants of E. coli in the lab, which revealed that changes in the mutant’s DNA mapped to lolCDE, precisely where DiffDock had predicted enterololin to bind. They also performed RNA sequencing to see which bacterial genes switched on or off when exposed to the drug, as well as used CRISPR to selectively knock down expression of the expected target. These laboratory experiments all revealed disruptions in pathways tied to lipoprotein transport, exactly what DiffDock had predicted. “When you see the computational model and the wet-lab data pointing to the same mechanism, that’s when you start to believe you’ve figured something out,” says Stokes. For Barzilay, the project highlights a shift in how AI is used in the life sciences. “A lot of AI use in drug discovery has been about searching chemical space, identifying new molecules that might be active,” she says. “What we’re showing here is that AI can also provide mechanistic explanations, which are critical for moving a molecule through the development pipeline.” That distinction matters because mechanism-of-action studies are often a major rate-limiting step in drug development. Traditional approaches can take 18 months to two years, or more, and cost millions of dollars. In this case, the MIT–McMaster team cut the timeline to about six months, at a fraction of the cost. Enterololin is still in the early stages of development, but translation is already underway. Stokes’ spinout company, Stoked Bio, has licensed the compound and is optimizing its properties for potential human use. Early work is also exploring derivatives of the molecule against other resistant pathogens, such as Klebsiella pneumoniae . If all goes well, clinical trials could begin within the next few years. The researchers also see broader implications. Narrow-spectrum antibiotics have long been sought as a way to treat infections without collateral damage to the microbiome, but they have been difficult to discover and validate. AI tools like DiffDock could make that process more practical, rapidly enabling a new generation of targeted antimicrobials. For patients with Crohn’s and other inflammatory bowel conditions, the prospect of a drug that reduces symptoms without destabilizing the microbiome could mean a meaningful improvement in quality of life. And in the bigger picture, precision antibiotics may help tackle the growing threat of antimicrobial resistance. “What excites me is not just this compound, but the idea that we can start thinking about the mechanism of action elucidation as something we can do more quickly, with the right combination of AI, human intuition, and laboratory experiments,” says Stokes. “That has the potential to change how we approach drug discovery for many diseases, not just Crohn’s.” “One of the greatest challenges to our health is the increase of antimicrobial-resistant bacteria that evade even our best antibiotics,” adds Yves Brun, professor at the University of Montreal and distinguished professor emeritus at Indiana University Bloomington, who wasn’t involved in the paper. “AI is becoming an important tool in our fight against these bacteria. This study uses a powerful and elegant combination of AI methods to determine the mechanism of action of a new antibiotic candidate, an important step in its potential development as a therapeutic.”Corso, Barzilay, and Stokes wrote the paper with McMaster researchers Denise B. Catacutan, Vian Tran, Jeremie Alexander, Yeganeh Yousefi, Megan Tu, Stewart McLellan, and Dominique Tertigas, and professors ​​Jakob Magolan, Michael Surette, Eric Brown, and Brian Coombes. Their research was supported, in part, by the Weston Family Foundation; the David Braley Centre for Antibiotic Discovery; the Canadian Institutes of Health Research; the Natural Sciences and Engineering Research Council of Canada; M. and M. Heersink; Canadian Institutes for Health Research; Ontario Graduate Scholarship Award; the Jameel Clinic; and the U.S. Defense Threat Reduction Agency Discovery of Medical Countermeasures Against New and Emerging Threats program. The researchers posted sequencing data in public repositories and released the DiffDock-L code openly on GitHub.", "release_time": "2025-10-04", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/ai-maps-how-new-antibiotic-targets-gut-bacteria-1003"}
{"category": "研究前沿", "title": "MIT研发应对不确定性的复杂系统设计新框架", "short_summary": "MIT新框架助工程师设计无人机等复杂系统时量化组件性能不确定性。", "detailed_summary": "MIT新框架助工程师设计无人机等复杂系统时量化组件性能不确定性。\n(1) MIT研究人员开发了一种新设计框架，专门处理复杂系统中各组件的性能不确定性；\n(2) 该框架基于范畴论，可将互连部件的多种不确定行为结果进行建模和概率化分析；\n(3) 相比仅能模拟最佳和最差情况的现有方法，新方法能提供更详细的性能权衡信息；\n(4) 以无人机设计为例，框架能优化电池和感知系统选择，量化不同负载下的成本与可行性概率；\n(5) 此技术有望提升自动驾驶汽车、飞机等复杂系统在真实不可预测环境中的鲁棒性和可靠性。", "raw_content": "Designing a complex electronic device like a delivery drone involves juggling many choices, such as selecting motors and batteries that minimize cost while maximizing the payload the drone can carry or the distance it can travel. Unraveling that conundrum is no easy task, but what happens if the designers don’t know the exact specifications of each battery and motor? On top of that, the real-world performance of these components will likely be affected by unpredictable factors, like changing weather along the drone’s route. MIT researchers developed a new framework that helps engineers design complex systems in a way that explicitly accounts for such uncertainty. The framework allows them to model the performance tradeoffs of a device with many interconnected parts, each of which could behave in unpredictable ways. Their technique captures the likelihood of many outcomes and tradeoffs, giving designers more information than many existing approaches which, at most, can usually only model best-case and worst-case scenarios. Ultimately, this framework could help engineers develop complex systems like autonomous vehicles, commercial aircraft, or even regional transportation networks that are more robust and reliable in the face of real-world unpredictability. “In practice, the components in a device never behave exactly like you think they will. If someone has a sensor whose performance is uncertain, and an algorithm that is uncertain, and the design of a robot that is also uncertain, now they have a way to mix all these uncertainties together so they can come up with a better design,” says Gioele Zardini, the Rudge and Nancy Allen Assistant Professor of Civil and Environmental Engineering at MIT, a principal investigator in the Laboratory for Information and Decision Systems (LIDS), an affiliate faculty with the Institute for Data, Systems, and Society (IDSS), and senior author of a paper on this framework. Zardini is joined on the paper by lead author Yujun Huang, an MIT graduate student; and Marius Furter, a graduate student at the University of Zurich. The research will be presented at the IEEE Conference on Decision and Control. Considering uncertainty The Zardini Group studies co-design, a method for designing systems made of many interconnected components, from robots to regional transportation networks. The co-design language breaks a complex problem into a series of boxes, each representing one component, that can be combined in different ways to maximize outcomes or minimize costs. This allows engineers to solve complex problems in a feasible amount of time. In prior work, the researchers modeled each co-design component without considering uncertainty. For instance, the performance of each sensor the designers could choose for a drone was fixed. But engineers often don’t know the exact performance specifications of each sensor, and even if they do, it is unlikely the senor will perfectly follow its spec sheet. At the same time, they don’t know how each sensor will behave once integrated into a complex device, or how performance will be affected by unpredictable factors like weather. “With our method, even if you are unsure what the specifications of your sensor will be, you can still design the robot to maximize the outcome you care about,” says Furter. To accomplish this, the researchers incorporated this notion of uncertainty into an existing framework based on category theory. Using some mathematical tricks, they simplified the problem into a more general structure. This allows them to use the tools of category theory to solve co-design problems in a way that considers a range of uncertain outcomes. By reformulating the problem, the researchers can capture how multiple design choices affect one another even when their individual performance is uncertain. This approach is also simpler than many existing tools that typically require extensive domain expertise. With their plug-and-play system, one can rearrange the components in the system without violating any mathematical constraints. And because no specific domain expertise is required, the framework could be used by a multidisciplinary team where each member designs one component of a larger system. “Designing an entire UAV isn’t feasible for just one person, but designing a component of a UAV is. By providing the framework for how these components work together in a way that considers uncertainty, we’ve made it easier for people to evaluate the performance of the entire UAV system,” Huang says. More detailed information The researchers used this new approach to choose perception systems and batteries for a drone that would maximize its payload while minimizing its lifetime cost and weight. While each perception system may offer a different detection accuracy under varying weather conditions, the designer doesn’t know exactly how its performance will fluctuate. This new system allows the designer to take these uncertainties into consideration when thinking about the drone’s overall performance. And unlike other approaches, their framework reveals distinct advantages of each battery technology. For instance, their results show that at lower payloads, nickel-metal hydride batteries provide the lowest expected lifetime cost. This insight would be impossible to fully capture without accounting for uncertainty, Zardini says. While another method might only be able to show the best-case and worst-case performance scenarios of lithium polymer batteries, their framework gives the user more detailed information. For example, it shows that if the drone’s payload is 1,750 grams, there is a 12.8 percent chance the battery design would be infeasible. “Our system provides the tradeoffs, and then the user can reason about the design,” he adds. In the future, the researchers want to improve the computational efficiency of their problem-solving algorithms. They also want to extend this approach to situations where a system is designed by multiple parties that are collaborative and competitive, like a transportation network in which rail companies operate using the same infrastructure. “As the complexity of systems grow, and involves more disparate components, we need a formal framework in which to design these systems. This paper presents a way to compose large systems from modular components, understand design trade-offs, and importantly do so with a notion of uncertainty. This creates an opportunity to formalize the design of large-scale systems with learning-enabled components,” says Aaron Ames, the Bren Professor of Mechanical and Civil Engineering, Control and Dynamical Systems, and Aerospace at Caltech, who was not involved with this research.", "release_time": "2025-10-02", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/accounting-uncertainty-help-engineers-design-complex-systems-1002"}
{"category": "研究前沿", "title": "MIT部署全美高校最强AI超算TX-GAIN", "short_summary": "MIT林肯实验室启用顶尖AI超算，支持生成式AI与多领域前沿科学研究。", "detailed_summary": "MIT林肯实验室启用顶尖AI超算，支持生成式AI与多领域前沿科学研究。\n(1) MIT林肯实验室超级计算中心部署TX-GAIN系统，成为全美高校最强大的AI超级计算机，峰值性能达每秒200亿亿次AI运算。\n(2) 该系统配备600多个专用AI加速器，重点支持生成式AI、物理模拟和大数据分析等前沿研究。\n(3) 应用领域广泛，包括蛋白质相互作用建模、新药设计、雷达信号评估、天气数据补充和网络异常检测。\n(4) 系统以交互式操作为特色，研究人员无需并行处理专业知识即可便捷使用强大算力。\n(5) 该系统还支持MIT校内多个研究中心合作，并致力于通过软件工具将AI模型训练能耗降低高达80%。", "raw_content": "The new TX-Generative AI Next (TX-GAIN) computing system at the Lincoln Laboratory Supercomputing Center (LLSC) is the most powerful AI supercomputer at any U.S. university. With its recent ranking from TOP500 , which biannually publishes a list of the top supercomputers in various categories, TX-GAIN joins the ranks of other powerful systems at the LLSC, all supporting research and development at Lincoln Laboratory and across the MIT campus. \"TX-GAIN will enable our researchers to achieve scientific and engineering breakthroughs. The system will play a large role in supporting generative AI, physical simulation, and data analysis across all research areas,\" says Lincoln Laboratory Fellow Jeremy Kepner , who heads the LLSC. The LLSC is a key resource for accelerating innovation at Lincoln Laboratory. Thousands of researchers tap into the LLSC to analyze data, train models, and run simulations for federally funded research projects. The supercomputers have been used, for example, to simulate billions of aircraft encounters to develop collision-avoidance systems for the Federal Aviation Administration, and to train models in the complex tasks of autonomous navigation for the Department of Defense. Over the years, LLSC capabilities have been essential to numerous award-winning technologies , including those that have improved  airline safety,  prevented the spread of new diseases, and  aided in hurricane responses. As its name suggests, TX-GAIN is especially equipped for developing and applying generative AI. Whereas traditional AI focuses on categorization tasks, like identifying whether a photo depicts a dog or cat, generative AI produces entirely new outputs. Kepner describes it as a mathematical combination of interpolation (filling in the gaps between known data points) and extrapolation (extending data beyond known points). Today, generative AI is widely known for its use of large language models to create human-like responses to user prompts. At Lincoln Laboratory, teams are applying generative AI to various domains beyond large language models. They are using the technology, for instance, to evaluate radar signatures, supplement weather data where coverage is missing, root out anomalies in network traffic, and explore chemical interactions to design new medicines and materials. To enable such intense computations, TX-GAIN is powered by more than 600 NVIDIA graphics processing unit accelerators specially designed for AI operations, in addition to traditional high-performance computing hardware. With a peak performance of two AI exaflops (two quintillion floating-point operations per second), TX-GAIN is the top AI system at a university, and in the Northeast. Since TX-GAIN came online this summer, researchers have taken notice. \"TX-GAIN is allowing us to model not only significantly more protein interactions than ever before, but also much larger proteins with more atoms. This new computational capability is a game-changer for protein characterization efforts in biological defense,\" says Rafael Jaimes, a researcher in Lincoln Laboratory's Counter–Weapons of Mass Destruction Systems Group . The LLSC's focus on interactive supercomputing makes it especially useful to researchers. For years, the LLSC has pioneered software that lets users access its powerful systems without needing to be experts in configuring algorithms for parallel processing. \"The LLSC has always tried to make supercomputing feel like working on your laptop,\" Kepner says. \"The amount of data and the sophistication of analysis methods needed to be competitive today are well beyond what can be done on a laptop. But with our user-friendly approach, people can run their model and get answers quickly from their workspace.\" Beyond supporting programs solely at Lincoln Laboratory, TX-GAIN is enhancing research collaborations with MIT's campus. Such collaborations include the Haystack Observatory , Center for Quantum Engineering , Beaver Works , and Department of Air Force–MIT AI Accelerator. The latter initiative is rapidly prototyping, scaling, and applying AI technologies for the U.S. Air Force and Space Force, optimizing flight scheduling for global operations as one fielded example. The LLSC systems are housed in an energy-efficient data center and facility in Holyoke, Massachusetts. Research staff in the LLSC are also tackling the immense energy needs of AI and leading research into various power-reduction methods . One software tool they developed can reduce the energy of training an AI model by as much as 80 percent . \"The LLSC provides the capabilities needed to do leading-edge research, while in a cost-effective and energy-efficient manner,\" Kepner says. All of the supercomputers at the LLSC use the \"TX\" nomenclature in homage to Lincoln Laboratory's Transistorized Experimental Computer Zero (TX-0) of 1956. TX-0 was one of the world's first transistor-based machines, and its 1958 successor, TX-2 , is storied for its role in pioneering human-computer interaction and AI. With TX-GAIN, the LLSC continues this legacy.", "release_time": "2025-10-03", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/lincoln-lab-unveils-most-powerful-ai-supercomputer-at-any-us-university-1002"}
{"category": "研究前沿", "title": "MIT揭示锂电池快充新机制，提出耦合离子电子转移模型", "short_summary": "MIT研究提出锂电池充放电新理论，耦合离子电子转移模型有望指导快充电池设计。", "detailed_summary": "MIT研究提出锂电池充放电新理论，耦合离子电子转移模型有望指导快充电池设计。\n(1) MIT研究人员通过测量多种电池材料中的锂嵌入速率，对锂电池核心充放电反应机制提出新见解。\n(2) 研究推翻了传统的Butler-Volmer方程模型，提出新理论认为锂嵌入由\"耦合离子-电子转移\"过程控制。\n(3) 新模型表明，锂离子进入电极需伴随电子从电解质同步转移，此过程降低了反应能垒。\n(4) 实验验证了超过50种电解质和电极组合，数据与新CIET模型预测一致，与传统模型差异显著。\n(5) 该理论框架为理性设计更强大、充电更快的锂电池提供了指导，有望减少试错并优化电解质成分。", "raw_content": "At the heart of all lithium-ion batteries is a simple reaction: Lithium ions dissolved in an electrolyte solution “intercalate” or insert themselves into a solid electrode during battery discharge. When they de-intercalate and return to the electrolyte, the battery charges. This process happens thousands of times throughout the life of a battery. The amount of power that the battery can generate, and how quickly it can charge, depend on how fast this reaction happens. However, little is known about the exact mechanism of this reaction, or the factors that control its rate. In a new study, MIT researchers have measured lithium intercalation rates in a variety of different battery materials and used that data to develop a new model of how the reaction is controlled. Their model suggests that lithium intercalation is governed by a process known as coupled ion-electron transfer, in which an electron is transferred to the electrode along with a lithium ion. Insights gleaned from this model could guide the design of more powerful and faster charging lithium-ion batteries, the researchers say. “What we hope is enabled by this work is to get the reactions to be faster and more controlled, which can speed up charging and discharging,” says Martin Bazant, the Chevron Professor of Chemical Engineering and a professor of mathematics at MIT. The new model may also help scientists understand why tweaking electrodes and electrolytes in certain ways leads to increased energy, power, and battery life — a process that has mainly been done by trial and error. “This is one of these papers where now we began to unify the observations of reaction rates that we see with different materials and interfaces, in one theory of coupled electron and ion transfer for intercalation, building up previous work on reaction rates,” says Yang Shao-Horn, the J.R. East Professor of Engineering at MIT and a professor of mechanical engineering, materials science and engineering, and chemistry. Shao-Horn and Bazant are the senior authors of the paper , which appears today in Science . The paper’s lead authors are Yirui Zhang PhD ’22, who is now an assistant professor at Rice University; Dimitrios Fraggedakis PhD ’21, who is now an assistant professor at Princeton University; Tao Gao, a former MIT postdoc who is now an assistant professor at the University of Utah; and MIT graduate student Shakul Pathak. Modeling lithium flow For many decades, scientists have hypothesized that the rate of lithium intercalation at a lithium-ion battery electrode is determined by how quickly lithium ions can diffuse from the electrolyte into the electrode. This reaction, they believed, was governed by a model known as the Butler-Volmer equation, originally developed almost a century ago to describe the rate of charge transfer during an electrochemical reaction. However, when researchers have tried to measure lithium intercalation rates, the measurements they obtained were not always consistent with the rates predicted by the Butler-Volmer equation. Furthermore, obtaining consistent measurements across labs has been difficult, with different research teams reporting measurements for the same reaction that varied by a factor of up to 1 billion. In the new study, the MIT team measured lithium intercalation rates using an electrochemical technique that involves applying repeated, short bursts of voltage to an electrode. They generated these measurements for more than 50 combinations of electrolytes and electrodes, including lithium nickel manganese cobalt oxide, which is commonly used in electric vehicle batteries, and lithium cobalt oxide, which is found in the batteries that power most cell phones, laptops, and other portable electronics. For these materials, the measured rates are much lower than has previously been reported, and they do not correspond to what would be predicted by the traditional Butler-Volmer model. The researchers used the data to come up with an alternative theory of how lithium intercalation occurs at the surface of an electrode. This theory is based on the assumption that in order for a lithium ion to enter an electrode, an electron from the electrolyte solution must be transferred to the electrode at the same time. “The electrochemical step is not lithium insertion, which you might think is the main thing, but it’s actually electron transfer to reduce the solid material that is hosting the lithium,” Bazant says. “Lithium is intercalated at the same time that the electron is transferred, and they facilitate one another.” This coupled-electron ion transfer (CIET) lowers the energy barrier that must be overcome for the intercalation reaction to occur, making it more likely to happen. The mathematical framework of CIET allowed the researchers to make reaction rate predictions, which were validated by their experiments and substantially different from those made by the Butler-Volmer model. Faster charging In this study, the researchers also showed that they could tune intercalation rates by changing the composition of the electrolyte. For example, swapping in different anions can lower the amount of energy needed to transfer the lithium and electron, making the process more efficient. “Tuning the intercalation kinetics by changing electrolytes offers great opportunities to enhance the reaction rates, alter electrode designs, and therefore enhance the battery power and energy,” Shao-Horn says. Shao-Horn’s lab and their collaborators have been using automated experiments to make and test thousands of different electrolytes, which are used to develop machine-learning models to predict electrolytes with enhanced functions. The findings could also help researchers to design batteries that would charge faster, by speeding up the lithium intercalation reaction. Another goal is reducing the side reactions that can cause battery degradation when electrons are picked off the electrode and dissolve into the electrolyte. “If you want to do that rationally, not just by trial and error, you need some kind of theoretical framework to know what are the important material parameters that you can play with,” Bazant says. “That’s what this paper tries to provide.” The research was funded by Shell International Exploration and Production and the Toyota Research Institute through the D3BATT Center for Data-Driven Design of Rechargeable Batteries.", "release_time": "2025-10-03", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/simple-formula-could-guide-design-faster-charging-longer-lasting-batteries-1002"}
{"category": "政策计划", "title": "核安全国际公约二十周年成果与展望", "short_summary": "国际社会纪念两项核安全公约通过二十周年，强化核材料与设施保护及反核恐合作。", "detailed_summary": "国际社会纪念两项核安全公约通过二十周年，强化核材料与设施保护及反核恐合作。\n(1) 摩洛哥驻国际原子能机构大使在二十周年纪念活动上重申国际社会防止核恐怖主义和加强合作的承诺。\n(2) 《核材料实物保护公约》修正案扩大了原条约范围，涵盖国内和平用途核设施与材料的保护，并将相关犯罪活动刑事化。\n(3) 《制止核恐怖主义行为国际公约》要求缔约国将非法持有、使用放射性材料及破坏核设施的行为定为犯罪。\n(4) 两项公约共同为加强核安全领域的国际合作提供了关键法律框架。", "raw_content": "Opening the side event, Ambassador Azzeddine Farhane, Resident Representative of  Morocco to the IAEA, said: “The adoption of these key legal instruments in 2005 represented a decisive step forward in our collective efforts to prevent nuclear terrorism and strengthen international cooperation. Now, twenty years later, we reaffirm our commitment to these goals and reflect on the progress made—and the work that still lies ahead.” The Amendment to the Convention on the Physical Protection of Nuclear Material (CPPNM), adopted under IAEA auspices, significantly strengthens the original CPPNM in a number of important ways. It extends the scope of the original treaty to cover physical protection of nuclear facilities and nuclear material used for peaceful purposes in domestic use, storage and transport; it further criminalizes offences related to illicit trafficking and sabotage of nuclear material or nuclear facilities; and it provides for strengthened international cooperation. The International Convention for the Suppression of Acts of Nuclear Terrorism (ICSANT), adopted under the auspices of the United Nations, covers all radioactive material, including nuclear material, and requires States Parties to criminalize the unlawful and intentional possession and use of radioactive material or radioactive devices, as well as the unlawful use of or damage to nuclear facilities.", "release_time": "2025-10-05", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/celebrating-20-years-of-a-legal-milestone-in-nuclear-security"}
{"category": "研究前沿", "title": "MIT物理学家因发现分数量子反常霍尔效应获奖", "short_summary": "MIT青年科学家因发现分数量子反常霍尔效应获2025年麦克米伦奖，该发现有望推动量子计算发展。", "detailed_summary": "MIT青年科学家因发现分数量子反常霍尔效应获2025年麦克米伦奖，该发现有望推动量子计算发展。\n(1) MIT物理学家贾奇才和吕正东因发现分数量子反常霍尔效应（FQAHE）荣获2025年伊利诺伊大学麦克米伦奖。\n(2) FQAHE是一种电子可呈现分数状态的奇异现象，最初在石墨烯等二维摩尔材料中被观测到。\n(3) 该发现由两位科学家在不同实验室独立完成，被认为对开发更稳健的量子计算机具有重要潜力。\n(4) 麦克米伦奖是授予年轻凝聚态物理学家的最高荣誉之一，获奖者将获得奖金并在伊利诺伊大学进行学术报告。", "raw_content": "Last year, MIT physicists reported in the journal Nature that electrons can become fractions of themselves in graphene, an atomically thin form of carbon. This exotic electronic state, called the fractional quantum anomalous Hall effect (FQAHE), could enable more robust forms of quantum computing. Now two young MIT-affiliated physicists involved in the discovery of FQAHE have been named the 2025 recipients of the McMillan Award from the University of Illinois for their work. Jiaqi Cai and Zhengguang Lu won the award “for the discovery of fractional anomalous quantum hall physics in 2D moiré materials.” Cai is currently a Pappalardo Fellow at MIT working with Pablo Jarillo-Herrero, the Cecil and Ida Green Professor of Physics, and collaborating with several other labs at MIT including Long Ju, the Lawrence and Sarah W. Biedenharn Career Development Associate Professor in the MIT Department of Physics. He discovered FQAHE while working in the laboratory of Professor Xiaodong Xu at the University of Washington. Lu discovered FQAHE while working as a postdoc Ju's lab and has since become an assistant professor at Florida State University. The two independent discoveries were made in the same year. “The McMillan award is the highest honor that a young condensed matter physicist can receive,” says Ju. “My colleagues and I in the Condensed Matter Experiment and the Condensed Matter Theory Group are very proud of Zhengguang and Jiaqi.” Ju and Jarillo-Herrero are both also affiliated with the Materials Research Laboratory. In addition to a monetary prize and a plaque, Lu and Cai will give a colloquium on their work at the University of Illinois this fall.", "release_time": "2025-10-03", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/mit-affiliated-physicists-win-mcmillan-award-discovery-exotic-electronic-state-1002"}
{"category": "研究前沿", "title": "研究证实钢琴家可通过触键控制音色", "short_summary": "科学家首次通过实验证实钢琴家能通过触键技巧控制音色，为音乐教学与技能传递提供科学基础。", "detailed_summary": "科学家首次通过实验证实钢琴家能通过触键技巧控制音色，为音乐教学与技能传递提供科学基础。\n(1) 研究团队开发了高精度传感器系统，以1000帧/秒的速度测量专业钢琴家演奏时的琴键运动。\n(2) 心理物理实验表明，听众能准确识别钢琴家意图表达的不同音色（如明亮/暗淡），且与是否受过音乐训练无关。\n(3) 数据分析识别出导致音色差异的关键运动特征，如击弦加速度和双手同步性偏差，并实验证实了其因果关系。\n(4) 该发现解决了长达一个多世纪的争议，证明通过触键控制音色是科学可验证的技能，而非感官隐喻。\n(5) 研究成果对音乐教育、康复治疗、人机界面设计等多个领域具有应用潜力，相关论文发表于《美国国家科学院院刊》。", "raw_content": "Creativity in painting, music, and other arts is underpinned by the ability to create diverse perceptual experiences for audiences. However, whether timbre could actually be changed mid-instrumental performance, and what physical motor skills would be required to do so, remained unclear. The research group developed a unique sensor system that can measure piano key movements at a temporal resolution of 1,000 fps, and measured key movements when professional pianists expressed various timbres on the piano. The results revealed that listeners could distinguish the pianists' intended timbres, regardless of whether or not they had any piano performance training experience. The group further successfully identified the key movement features that produce these timbre differences. This discovery addresses the over century-old question, \"Can pianists alter timbre through touch?\" by demonstrating that timbre manipulation through touch cultivated by pianists is not a mere sensory metaphor but a scientifically backed skill. These findings open the possibility of visualizing and teaching specific movement features that produce timbre, which would lead to more efficient practice and prevention of mislearning. They also reveal that high-level body motor control shapes artistic perception, suggesting potential applications across various disciplines, including rehabilitation, skill transfer, and human interface design. These research findings were published in the international scientific journal Proceedings of the National Academy of Sciences (PNAS) on September 22, 2025. These results were obtained through the following program, research area, and research theme: JST Strategic Basic Research Program (CREST) Research Area: Core Technologies for Trusted Quality AI Systems (Research Supervisor: Akiko Aizawa, Professor, Digital Content and Media Sciences Research Division, National Institute of Informatic, Research Organization of Information and Systems) Research Theme: Building a Trusted Explorable Recommendation Foundation Technology Research Director: Masataka Goto (Prime Senior Researcher, AIST) Research Period: October 2020 -- March 2026 Moonshot Research & Development Program (MOONSHOT) Research Area: Realization of a society in which human beings can be free from limitations of body, brain, space, and time by 2050 (Research Supervisor: Norihiro Hagita, Chair and Professor, Art Science Department, Osaka University of Arts) Research Theme: Liberation from Biological Limitations via Physical, Cognitive and Perceptual Augmentation Research Director: Ryota Kanai (Director, Corporate Planning & Innovation Co-Creation Unit, Advanced Telecommunications Research Institute International (ATR)) Research Period: October 2020 -- March 2026 Background and History of the Research Musicians and other performing artists, surgeons, traditional craftsmen and others considered experts in various fields acquire their skills through years of extensive training. In particular, in the performing arts, it has long been thought that the mastering of physical motor skills that produce diverse perceptions is essential for embodying creativity. For instance, while pitch and volume in instrumental performance clearly depend on manipulation of the instrument, there had been no scientific evidence for cases where \"an instrument that should produce a certain sound produces a different timbre\" -- a phenomenon that was widely believed possible among performers and educators. This question was discussed regarding the piano in Nature magazine in the early 20th century, but systematic perceptual experiments and data analysis had not been carried out to date, leaving the question unanswered. Thus, the means for acquiring skills that produce diverse expressions remained unknown, and problems during this process -- such as misrecognition of personal limitations and risk of injury or disability arising during skill-acquisition training -- persisted. An evidence-based understanding of the mechanisms of technical skill is essential for humans and systems to be able to recommend appropriate training methods, and for the resulting recommendations to be trusted by learners and teachers. Background and History of the Research A research team from the NeuroPiano Institute and Sony Computer Science Laboratories (Sony CSL) revealed that the timbral qualities pianists intended to express were conveyed to listeners, and that the high-precision control of fingertip movement was involved. The research group used Hackkey, their proprietary high-precision non-contact sensor system, to measure the movements of all 88 keys at 1,000 fps (1 ms temporal precision) and 0.01 mm spatial resolution. This apparatus analyzed keyboard movements when 20 internationally renowned pianists performed with the intent to produce diverse timbral qualities, including bright/dark and light/heavy. Additionally, the team carried out a psychophysical experiment, with 40 participants -- including pianists and individuals with no musical experience -- who listened to the recorded performances. The results revealed that the pianists' intended timbres were consistently perceived by the listeners, regardless of their musical experience. The listeners who were pianists, in particular, were able to distinguish timbral differences with greater sensitivity. This timbral discernment was found to be possible even when controlling for volume and tempo, factors previously thought to influence timbral perception. Data analysis using a linear mixed-effects (LME) model revealed that contributions to timbral differences are concentrated in a limited set of movement features (e.g., acceleration during escapement, deviation in hand synchronization). It was further experimentally confirmed that notes played by varying only one of these features were perceived by listeners as having a different timbre, providing the first empirical evidence of a causal relationship between key movement and timbre. These findings have the following significance for musicians and educators: Building a technical foundation to support artistic creativity ：This research quantifies the \"tacit knowledge\" of how pianists produce timbre, paving the way for understanding an artist's expressive intent and developing new educational methods and technologies that will maximize it. Furthermore, proving that the manipulation of timbre through touch cultivated by artists is a scientifically grounded skill rather than a mere sensory metaphor makes it possible to efficiently learn and acquire the skills to create timbral expressions -- which had been difficult to verbalize in instruction to date -- by applying it to recommendation systems that present the appropriate movement features to learners. Illuminating the biological mechanisms that produce higher-order perception: The phenomenon in which the same sound can be perceived differently indicates advanced integration of human sensory and motor systems. This research clarifies how dexterous motor control produces higher-order perception and aesthetic experiences, opening new avenues for interdisciplinary research in neuroscience, psychology, and arts studies, and holds additional promise for applications across multiple fields, including skill transfer, rehabilitation, and human interface design. Future Developments This research has clarified the relationship between key movement features and piano timbre, suggesting the possibility for explicitly acquiring a repertoire of movements that can produce a diverse palette of perceptions. This is essential for recommending evidence-based body use and practice methods in physical education for the performing arts, and for empowering both teachers and learners to pursue learning with confidence. While perception research has until now focused mainly on lower-level perceptual information such as pitch, loudness, and rhythm, the advance of future research into timbre and other higher-level perceptual information is expected to lead to clarification of the underlying brain information processing mechanisms, as well as the development of training methods that skillfully utilize advanced technologies. Moreover, the thrill of using one's body to improve and achieve something that was once impossible is something that is shared across disciplines beyond music performance, including sports, cooking, painting, and even surgery. This research holds promise for generating ripple effects across multiple disciplines. The involvement of science and technology in music learning has lagged behind significantly, compared to that in fields such as sports and medicine. As a result, many artists all over the world have long been beset with the problem of embodying artistic expression and creativity while being constrained by physical and mental limitations. The knowledge regarding the foundational skills for producing diverse expressions provided by this research will contribute to the creation of a future society where artists are liberated from physical and mental constraints and can fully embody their creativity. This will be achieved through the establishment of a new evidence-based form of music education grounded in dynaformics, the science of music performance.", "release_time": "2025-10-02", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251002073956.htm"}
{"category": "研究前沿", "title": "MIT研究揭示独特含义句子更易被记忆", "short_summary": "MIT研究发现句子含义独特性是决定其记忆持久性的关键因素。", "detailed_summary": "MIT研究发现句子含义独特性是决定其记忆持久性的关键因素。\n(1) MIT认知科学家研究发现，具有独特含义的句子比含义相似的句子更容易被记住。\n(2) 研究通过对2500个六词句子的记忆测试，并利用Sentence BERT模型分析句子语义相似性。\n(3) 含义独特的句子在大脑记忆空间中编码位置不拥挤，减少了特征重叠带来的记忆干扰。\n(4) 该发现支持\"噪声表征假说\"，解释了大脑如何在不丢失旧记忆的情况下持续形成新记忆。\n(5) 研究由美国国立卫生研究院等机构资助，未来将探索生动语言等其他特征对记忆的影响。", "raw_content": "“You still had to prove yourself.” “Every cloud has a blue lining!” Which of those sentences are you most likely to remember a few minutes from now? If you guessed the second, you’re probably correct. According to a new study from MIT cognitive scientists, sentences that stick in your mind longer are those that have distinctive meanings, making them stand out from sentences you’ve previously seen. They found that meaning, not any other trait, is the most important feature when it comes to memorability. “One might have thought that when you remember sentences, maybe it’s all about the visual features of the sentence, but we found that that was not the case. A big contribution of this paper is pinning down that it is the meaning-related space that makes sentences memorable,” says Greta Tuckute PhD ’25, who is now a research fellow at Harvard University’s Kempner Institute. The findings support the hypothesis that sentences with distinctive meanings — like “Does olive oil work for tanning?” — are stored in brain space that is not cluttered with sentences that mean almost the same thing. Sentences with similar meanings end up densely packed together and are therefore more difficult to recognize confidently later on, the researchers believe. “When you encode sentences that have a similar meaning, there’s feature overlap in that space. Therefore, a particular sentence you’ve encoded is not linked to a unique set of features, but rather to a whole bunch of features that may overlap with other sentences,” says Evelina Fedorenko, an MIT associate professor of brain and cognitive sciences (BCS), a member of MIT’s McGovern Institute for Brain Research, and the senior author of the study. Tuckute and Thomas Clark, an MIT graduate student, are the lead authors of the paper , which appears in the Journal of Memory and Language . MIT graduate student Bryan Medina is also an author. Distinctive sentences What makes certain things more memorable than others is a longstanding question in cognitive science and neuroscience. In a 2011 study , Aude Oliva, now a senior research scientist at MIT and MIT director of the MIT-IBM Watson AI Lab, showed that not all items are created equal: Some types of images are much easier to remember than others, and people are remarkably consistent in what images they remember best. In that study, Oliva and her colleagues found that, in general, images with people in them are the most memorable, followed by images of human-scale space and close-ups of objects. Least memorable are natural landscapes. As a follow-up to that study, Fedorenko and Oliva, along with Ted Gibson, another faculty member in BCS, teamed up to determine if words also vary in their memorability. In a study published earlier this year, co-led by Tuckute and Kyle Mahowald, a former PhD student in BCS, the researchers found that the most memorable words are those that have the most distinctive meanings. Words are categorized as being more distinctive if they have a single meaning, and few or no synonyms — for example, words like “pineapple” or “avalanche” which were found to be very memorable. On the other hand, words that can have multiple meanings, such as “light,” or words that have many synonyms, like “happy,” were more difficult for people to recognize accurately. In the new study, the researchers expanded their scope to analyze the memorability of sentences. Just like words, some sentences have very distinctive meanings, while others communicate similar information in slightly different ways. To do the study, the researchers assembled a collection of 2,500 sentences drawn from publicly available databases that compile text from novels, news articles, movie dialogues, and other sources. Each sentence that they chose contained exactly six words. The researchers then presented a random selection of about 1,000 of these sentences to each study participant, including repeats of some sentences. Each of the 500 participants in the study was asked to press a button when they saw a sentence that they remembered seeing earlier. The most memorable sentences — the ones where participants accurately and quickly indicated that they had seen them before — included strings such as “Homer Simpson is hungry, very hungry,” and “These mosquitoes are — well, guinea pigs.” Those memorable sentences overlapped significantly with sentences that were determined as having distinctive meanings as estimated through the high-dimensional vector space of a large language model (LLM) known as Sentence BERT. That model is able to generate sentence-level representations of sentences, which can be used for tasks like judging meaning similarity between sentences. This model provided researchers with a distinctness score for each sentence based on its semantic similarity to other sentences. The researchers also evaluated the sentences using a model that predicts memorability based on the average memorability of the individual words in the sentence. This model performed fairly well at predicting overall sentence memorability, but not as well as Sentence BERT. This suggests that the meaning of a sentence as a whole — above and beyond the contributions from individual words — determines how memorable it will be, the researchers say. Noisy memories While cognitive scientists have long hypothesized that the brain’s memory banks have a limited capacity, the findings of the new study support an alternative hypothesis that would help to explain how the brain can continue forming new memories without losing old ones. This alternative, known as the noisy representation hypothesis, says that when the brain encodes a new memory, be it an image, a word, or a sentence, it is represented in a noisy way — that is, this representation is not identical to the stimulus, and some information is lost. For example, for an image, you may not encode the exact viewing angle at which an object is shown, and for a sentence, you may not remember the exact construction used. Under this theory, a new sentence would be encoded in a similar part of the memory space as sentences that carry a similar meanings, whether they were encountered recently or sometime across a lifetime of language experience. This jumbling of similar meanings together increases the amount of noise and can make it much harder, later on, to remember the exact sentence you have seen before. “The representation is gradually going to accumulate some noise. As a result, when you see an image or a sentence for a second time, your accuracy at judging whether you’ve seen it before will be affected, and it’ll be less than 100 percent in most cases,” Clark says. However, if a sentence has a unique meaning that is encoded in a less densely crowded space, it will be easier to pick out later on. “Your memory may still be noisy, but your ability to make judgments based on the representations is less affected by that noise because the representation is so distinctive to begin with,” Clark says. The researchers now plan to study whether other features of sentences, such as more vivid and descriptive language, might also contribute to making them more memorable, and how the language system may interact with the hippocampal memory structures during the encoding and retrieval of memories. The research was funded, in part, by the National Institutes of Health, the McGovern Institute, the Department of Brain and Cognitive Sciences, the Simons Center for the Social Brain, and the MIT Quest Initiative for Intelligence.", "release_time": "2025-10-01", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/mit-cognitive-scientists-reveal-why-some-sentences-stand-out-1001"}
{"category": "研究前沿", "title": "新型AI工具Diag2Diag提升核聚变等离子体诊断能力", "short_summary": "Diag2Diag AI通过生成合成传感器数据，提升聚变等离子体监测细节与系统可靠性。", "detailed_summary": "Diag2Diag AI通过生成合成传感器数据，提升聚变等离子体监测细节与系统可靠性。\n(1) 新型AI工具Diag2Diag可利用现有传感器数据生成其他类型传感器的合成数据，数据更详细且与真实数据一致。\n(2) 该AI特别增强了托卡马克装置中汤姆逊散射诊断的测量能力，提供了等离子体边缘 pedestal 区域更精细的温度和密度细节。\n(3) Diag2Diag生成的数据为抑制边缘局域模(ELMs)的磁岛理论提供了新证据，支持通过共振磁扰动(RMPs)提高等离子体稳定性。\n(4) 该技术有望减少未来商业聚变系统所需的诊断设备数量，从而降低复杂性、成本和维护需求，使系统更紧凑、可靠。\n(5) 此项研究由多国机构合作完成，除核聚变外，该AI在航天器、机器人手术等领域也有应用潜力，可恢复故障传感器数据。", "raw_content": "That's the general concept behind a new AI that fills in missing data about plasma, the fuel of fusion, according to Azarakhsh Jalalvand of Princeton University. Jalalvand is the lead author on a paper about the AI, known as Diag2Diag, that was recently published in Nature Communications. \"We have found a way to take the data from a bunch of sensors in a system and generate a synthetic version of the data for a different kind of sensor in that system,\" he said. The synthetic data aligns with real-world data and is more detailed than what an actual sensor could provide. This could increase the robustness of control while reducing the complexity and cost of future fusion systems. \"Diag2Diag could also have applications in other systems such as spacecraft and robotic surgery by enhancing detail and recovering data from failing or degraded sensors, ensuring reliability in critical environments.\" The research is the result of an international collaboration between scientists at Princeton University, the U.S. Department of Energy's (DOE) Princeton Plasma Physics Laboratory (PPPL), Chung-Ang University, Columbia University and Seoul National University. All of the sensor data used in the research to develop the AI was gathered from experiments at the DIII-D National Fusion Facility, a DOE user facility. The new AI enhances the way scientists can monitor and control the plasma inside a fusion system and could help keep future commercial fusion systems a reliable source of electricity. \"Fusion devices today are all experimental laboratory machines, so if something happens to a sensor, the worst thing that can happen is that we lose time before we can restart the experiment. But if we are thinking about fusion as a source of energy, it needs to work 24/7, without interruption,\" Jalalvand said. AI could lead to compact, economical fusion systems The name Diag2Diag originates from the word \"diagnostic,\" which refers to the technique used to analyze a plasma and includes sensors that measure the plasma. Diagnostics take measurements at regular intervals, often as fast as a fraction of a second apart. But some don't measure the plasma often enough to detect particularly fast-evolving plasma instabilities: sudden changes in the plasma that can make it hard to produce power reliably. There are many diagnostics in a fusion system that measure different characteristics of the plasma. Thomson scattering, for example, is a diagnostic technique used in doughnut-shaped fusion systems called tokamaks. The Thomson scattering diagnostic measures the temperature of negatively charged particles known as electrons, as well as the density: the number of electrons packed into a unit of space. It takes measurements quickly but not fast enough to provide details that plasma physicists need to keep the plasma stable and at peak performance. \"Diag2Diag is kind of giving your diagnostics a boost without spending hardware money,\" said Egemen Kolemen, principal investigator of the research who is jointly appointed at PPPL and Princeton University's Andlinger Center for Energy and the Environment and the Department of Mechanical and Aerospace Engineering. This is particularly important for Thomson scattering because the other diagnostics can't take measurements at the edge of the plasma, which is also known as the pedestal. It is the most important part of the plasma to monitor, but it's very hard to measure. Carefully monitoring the pedestal helps scientists enhance plasma performance so they can learn the best ways to get the most energy out of the fusion reaction efficiently. For fusion energy to be a major part of the U.S. power system, it must be both economical and reliable. PPPL Staff Research Scientist SangKyeun Kim, who was part of the Diag2Diag research team, said the AI moves the U.S. toward those goals. \"Today's experimental tokamaks have a lot of diagnostics, but future commercial systems will likely need to have far fewer,\" Kim said. \"This will help make fusion reactors more compact by minimizing components not directly involved in producing energy.\" Fewer diagnostics also frees up valuable space inside the machine, and simplifying the system also makes it more robust and reliable, with fewer chances for error. Plus, it lowers maintenance costs. PPPL: A leader in AI approaches to stabilizing fusion plasma The research team also found that the AI data supports a leading theory about how one method for stopping plasma disruptions works. Fusion scientists around the world are working on ways to control edge-localized modes (ELMs), which are powerful energy bursts in fusion reactors that can severely damage the reactor's inner walls. One promising method to stop ELMs involves applying resonant magnetic perturbations (RMPs): small changes made to the magnetic fields used to hold a plasma inside a tokamak. PPPL is a leader in ELM-suppression research, with recent papers on AI and traditional approaches to stopping these problematic disruptions. One theory suggests that RMPs create \"magnetic islands\" at the plasma's edge. These islands cause the plasma's temperature and density to flatten, meaning the measurements were more uniform across the edge of the plasma. \"Due to the limitation of the Thomson diagnostic, we cannot normally observe this flattening,\" said PPPL Principal Research Scientist Qiming Hu, who also worked on the project. \"Diag2Diag provided much more details on how this happens and how it evolves.\" While magnetic islands can lead to ELMs, a growing body of research suggests they can also be fine-tuned using RMPs to improve plasma stability. Diag2Diag generated data that provided new evidence of this simultaneous flattening of both temperature and density in the pedestal region of the plasma. This strongly supports the magnetic island theory for ELM suppression. Understanding this mechanism is crucial for the development of commercial fusion reactors. The scientists are already pursuing plans to expand the scope of Diag2Diag. Kolemen noted that several researchers have already expressed interest in trying the AI. \"Diag2Diag could be applied to other fusion diagnostics and is broadly applicable to other fields where diagnostic data is missing or limited,\" he said. This research was supported by DOE under awards DE-FC02-04ER54698, DE-SC0022270, DE-SC0022272, DE-SC0024527, DE-SC0020413, DE-SC0015480 and DE-SC0024626, as well as the National Research Foundation of Korea award RS-2024-00346024 funded by the Korean government (MSIT). The authors also received financial support from the Princeton Laboratory for Artificial Intelligence under award 2025-97.", "release_time": "2025-10-01", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/10/251001092204.htm"}
{"category": "研究前沿", "title": "MIT研发可储电碳混凝土，建筑变身巨型电池", "short_summary": "新型导电混凝土实现储能突破，未来建筑可兼具结构与供电功能。", "detailed_summary": "新型导电混凝土实现储能突破，未来建筑可兼具结构与供电功能。\n(1) MIT团队开发出电子导电碳混凝土（ec³），将水泥、碳黑与电解质结合，形成可储能的纳米导电网络。\n(2) 通过优化电解质和使用有机溶液，能量存储密度大幅提升，一立方米材料可储存约2千瓦时电能。\n(3) 该材料具多功能潜力，可作为建筑结构件、实现自监测（应力变化影响电信号输出），并已应用于日本融雪人行道。\n(4) 技术旨在支持可再生能源转型，为太阳能等间歇性能源提供长效储能方案，减少对传统电池依赖。\n(5) 未来应用前景广阔，包括可为电动汽车充电的道路、离网住宅等，将古老建筑材料赋予全新功能。", "raw_content": "Concrete already builds our world, and now it’s one step closer to powering it, too. Made by combining cement, water, ultra-fine carbon black (with nanoscale particles), and electrolytes, electron-conducting carbon concrete (ec 3 , pronounced “e-c-cubed”) creates a conductive “nanonetwork” inside concrete that could enable everyday structures like walls, sidewalks, and bridges to store and release electrical energy. In other words, the concrete around us could one day double as giant “batteries.” As MIT researchers report in a new PNAS paper , optimized electrolytes and manufacturing processes have increased the energy storage capacity of the latest ec 3 supercapacitors by an order of magnitude. In 2023, storing enough energy to meet the daily needs of the average home would have required about 45 cubic meters of ec 3 , roughly the amount of concrete used in a typical basement. Now, with the improved electrolyte, that same task can be achieved with about 5 cubic meters, the volume of a typical basement wall. “A key to the sustainability of concrete is the development of ‘multifunctional concrete,’ which integrates functionalities like this energy storage, self-healing , and carbon sequestration . Concrete is already the world’s most-used construction material, so why not take advantage of that scale to create other benefits?” asks Admir Masic, lead author of the new study, MIT Electron-Conducting Carbon-Cement-Based Materials Hub (EC³ Hub) co-director, and associate professor of civil and environmental engineering (CEE) at MIT. The improved energy density was made possible by a deeper understanding of how the nanocarbon black network inside ec 3 functions and interacts with electrolytes. Using focused ion beams for the sequential removal of thin layers of the ec 3 material, followed by high-resolution imaging of each slice with a scanning electron microscope (a technique called FIB-SEM tomography), the team across the EC³ Hub and MIT Concrete Sustainability Hub was able to reconstruct the conductive nanonetwork at the highest resolution yet. This approach allowed the team to discover that the network is essentially a fractal-like “web” that surrounds ec 3 pores, which is what allows the electrolyte to infiltrate and for current to flow through the system. “Understanding how these materials ‘assemble’ themselves at the nanoscale is key to achieving these new functionalities,” adds Masic. Equipped with their new understanding of the nanonetwork, the team experimented with different electrolytes and their concentrations to see how they impacted energy storage density. As Damian Stefaniuk, first author and EC³ Hub research scientist, highlights, “we found that there is a wide range of electrolytes that could be viable candidates for ec 3 . This even includes seawater, which could make this a good material for use in coastal and marine applications, perhaps as support structures for offshore wind farms.” At the same time, the team streamlined the way they added electrolytes to the mix. Rather than curing ec 3 electrodes and then soaking them in electrolyte, they added the electrolyte directly into the mixing water. Since electrolyte penetration was no longer a limitation, the team could cast thicker electrodes that stored more energy. The team achieved the greatest performance when they switched to organic electrolytes, especially those that combined quaternary ammonium salts — found in everyday products like disinfectants — with acetonitrile, a clear, conductive liquid often used in industry. A cubic meter of this version of ec 3 — about the size of a refrigerator — can store over 2 kilowatt-hours of energy. That’s about enough to power an actual refrigerator for a day. While batteries maintain a higher energy density, ec 3 can in principle be incorporated directly into a wide range of architectural elements — from slabs and walls to domes and vaults — and last as long as the structure itself. “The Ancient Romans made great advances in concrete construction. Massive structures like the Pantheon stand to this day without reinforcement. If we keep up their spirit of combining material science with architectural vision, we could be at the brink of a new architectural revolution with multifunctional concretes like ec 3 ,” proposes Masic. Taking inspiration from Roman architecture, the team built a miniature ec 3 arch to show how structural form and energy storage can work together. Operating at 9 volts, the arch supported its own weight and additional load while powering an LED light. However, something unique happened when the load on the arch increased: the light flickered. This is likely due to the way stress impacts electrical contacts or the distribution of charges. “There may be a kind of self-monitoring capacity here. If we think of an ec 3 arch at architectural scale, its output may fluctuate when it’s impacted by a stressor like high winds. We may be able to use this as a signal of when and to what extent a structure is stressed, or monitor its overall health in real time,” envisions Masic. The latest developments in ec³ technology bring it a step closer to real-world scalability. It’s already been used to heat sidewalk slabs in Sapporo, Japan, due to its thermally conductive properties, representing a potential alternative to salting. “With these higher energy densities and demonstrated value across a broader application space, we now have a powerful and flexible tool that can help us address a wide range of persistent energy challenges,” explains Stefaniuk. “One of our biggest motivations was to help enable the renewable energy transition. Solar power, for example, has come a long way in terms of efficiency. However, it can only generate power when there’s enough sunlight. So, the question becomes: How do you meet your energy needs at night, or on cloudy days?” Franz-Josef Ulm, EC³ Hub co-director and CEE professor, continues the thread: “The answer is that you need a way to store and release energy. This has usually meant a battery, which often relies on scarce or harmful materials. We believe that ec 3 is a viable substitute, letting our buildings and infrastructure meet our energy storage needs.” The team is working toward applications like parking spaces and roads that could charge electric vehicles, as well as homes that can operate fully off the grid. “What excites us most is that we’ve taken a material as ancient as concrete and shown that it can do something entirely new,” says James Weaver, a co-author on the paper who is an associate professor of design technology and materials science and engineering at Cornell University, as well as a former EC³ Hub researcher. “By combining modern nanoscience with an ancient building block of civilization, we’re opening a door to infrastructure that doesn’t just support our lives, it powers them.”", "release_time": "2025-10-02", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/concrete-battery-now-packs-ten-times-power-1001"}
{"category": "研究前沿", "title": "LZ实验发布最新结果，大幅缩小暗物质搜索范围", "short_summary": "LZ实验分析280天数据，对弱相互作用大质量粒子设定迄今最严格限制。", "detailed_summary": "LZ实验分析280天数据，对弱相互作用大质量粒子设定迄今最严格限制。\n(1) LUX-ZEPLIN实验发布最新分析结果，基于地下深处10吨液态氙探测器收集的280天数据。\n(2) 实验通过多层屏蔽、新型分析技术和\"加盐\"盲分析法，有效排除中子、氡等背景信号干扰。\n(3) 新结果探索了前所未有的弱相互作用范围，大幅缩小了WIMP暗物质粒子的可能属性范围。\n(4) 该成果为全球暗物质研究排除错误模型，使科学家能更精准地聚焦后续搜索方向。\n(5) 实验将持续运行至2028年，计划收集1000天数据，并已规划下一代XLZD探测器。", "raw_content": "\"While we always hope to discover a new particle, it is important for particle physics that we are able to set bounds on what the dark matter might actually be,\" said UC Santa Barbara experimental physicist Hugh Lippincott. Scientists have suspected the existence of dark matter for decades, but it remains a mysterious substance -- one that nevertheless plays a fundamental role in the structure of the universe. LZ hunts for dark matter from a cavern nearly one mile underground at the Sanford Underground Research Facility (SURF) in South Dakota. The experiment's new results explore weaker dark matter interactions than ever searched before and further limit what WIMPs could be. The results analyze 280 days' worth of data: a new set of 220 days (collected between March 2023 and April 2024) combined with 60 earlier days from LZ's first run. The experiment plans to collect 1,000 days' worth of data before it ends in 2028. The inner portion of the LZ detector consists of two nested titanium tanks filled with ten tonnes of transparent pure liquid xenon, which is so dense it creates a highly isolated environment, free from the \"noise\" of the outside world and perfect for capturing the faintest of faint signals that could be indicative of a WIMP. The hope is for a WIMP to knock into a xenon nucleus, causing it to move, much like a hit from a cue ball in a game of pool. By collecting the light and electrons emitted during interactions, LZ captures potential WIMP signals alongside other data. This liquid xenon core is surrounded by a much larger Outer Detector (OD) -- acrylic tanks filled with gadolinium-loaded liquid scintillator. LZ's sensitivity comes from the myriad ways the detector can reduce backgrounds, the false signals that can impersonate or hide a dark matter interaction. Deep underground, the detector is shielded from cosmic rays coming from space. To reduce natural radiation from everyday objects, LZ was built from thousands of ultraclean, low-radiation parts. The detector is built like an onion, with each layer either blocking outside radiation or tracking particle interactions to rule out dark matter mimics. And, sophisticated new analysis techniques help rule out background interactions. UCSB was one of the founding groups in LZ, led by UCSB physicist Harry Nelson, who hosted the first LZ meeting at UCSB in 2012. The team currently consists of faculty members Lippincott and Nelson, postdoctoral researchers Chami Amarasinghe and TJ Whitis, and graduate students Jeonghwa Kim, Makayla Trask, Lindsey Weeldreyer, and Jordan Thomas. Other contributors to the result include recent Ph.D. recipient Jack Bargemann, now a postdoctoral researcher at Pacific Northwest National Laboratory, and former undergraduate researcher; Tarun Advaith Kumar, now a graduate student at the Perimeter Institute. The physics coordinator for the result was Scott Haselschwardt, who received his Ph.D. from UCSB in 2018 and is now an assistant professor at the University of Michigan. Neutrons, subatomic particles that exist in every atom save hydrogen, are among the most common confounders of WIMP signals. Nelson and UCSB led the design, fabrication, and commissioning of the OD, the critical component that allows the collaboration to rule out these particles and enable a real discovery. \"The tricky thing about neutrons is that they also interact with the xenon nuclei, giving off a signal identical to what we expect from WIMPs,\" Trask said. \"The OD is excellent at detecting neutrons, and confirms a WIMP detection by not having any response.\" Presence of a pulse in the OD can veto an otherwise perfect candidate for a WIMP detection. Radon is also a WIMP mimic, for which the scientists must be vigilant. \"Radon undergoes a particular sequence of decays, some of which could be mistaken for WIMPs,\" Bargemann said. \"One of the things we were able to do in this run was look out for the whole set of decays in the detector to identify the radon and avoid confusing them for WIMPs.\" To enable a strong result and eliminate unconscious bias, the LZ collaboration applied a technique called \"salting,\" which adds fake WIMP signals during data collection. By camouflaging the real data until \"unsalting\" at the very end, researchers can avoid unconscious bias and keep from overly interpreting or changing their analysis. \"We're pushing the boundary into a regime where people have not looked for dark matter before,\" said Haselschwardt. \"There's a human tendency to want to see patterns in data, so it's really important when you enter this new regime that no bias wanders in. If you make a discovery, you want to get it right.\" With these results, the field of possibilities for what WIMPs may be has narrowed dramatically, allowing all scientists searching for dark matter to better focus their searches and reject incorrect models of how the universe operates. It's a long game, with more data collection in the future and one that will do more than accelerate the search for dark matter. \"Our experiment is also sensitive to rare events with roots in diverse areas of physics,\" Amarasinghe said. \"Some examples are solar neutrinos, the fascinating decays of certain xenon isotopes, and even other types of dark matter. With the intensity of this result behind us, I'm very excited to spend more time on these searches.\" \"The UCSB Physics Department has a long history of devising searches for dark matter, starting with one of the first published results of a search in 1988,\" Nelson said. Previous faculty members include David Caldwell (now deceased), and Michael Witherell, now director of the Lawrence Berkeley Laboratory. David Hale (now retired) pioneered many of the techniques for suppressing fake dark matter signals which are now employed throughout the field of dark matter searches. \"UCSB, through the Physics Department, the College of Letters and Science, the administration, and through private donations, has strongly supported the dark matter effort for decades, and made substantial contributions to LZ.\" LZ is a collaboration of roughly 250 scientists from 38 institutions in the United States, United Kingdom, Portugal, Switzerland, South Korea, and Australia; much of the work building, operating, and analyzing the record-setting experiment is done by early career researchers. The collaboration is already looking forward to analyzing the next data set and extending our data analysis techniques to seek signals from lower-mass dark matter. Scientists are also thinking through potential upgrades to further improve LZ, and planning for a next-generation dark matter detector called XLZD. LZ is supported by the U.S. Department of Energy, Office of Science, Office of High Energy Physics and the National Energy Research Scientific Computing Center, a DOE Office of Science user facility. LZ is also supported by the Science & Technology Facilities Council of the United Kingdom; the Portuguese Foundation for Science and Technology; the Swiss National Science Foundation, and the Institute for Basic Science, Korea. More than 38 institutions of higher education and advanced research provided support to LZ. The assistance of the Sanford Underground Research Facility has at all times been critical for UCSB efforts to LZ.", "release_time": "2025-10-01", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250930034209.htm"}
{"category": "研究前沿", "title": "半胱氨酸饮食可促进肠道干细胞再生", "short_summary": "MIT研究发现半胱氨酸能激活免疫通路促进肠道修复，或有助于减轻放化疗损伤。", "detailed_summary": "MIT研究发现半胱氨酸能激活免疫通路促进肠道修复，或有助于减轻放化疗损伤。\n（1）MIT研究发现富含半胱氨酸的饮食能显著促进小鼠小肠干细胞和祖细胞的再生；\n（2）机制上，肠道细胞吸收半胱氨酸后转化为CoA，激活CD8 T细胞产生IL-22细胞因子，进而驱动干细胞再生；\n（3）该再生效应有助于修复辐射和化疗药物（如5-氟尿嘧啶）对肠道造成的损伤；\n（4）研究首次明确单一营养素对肠道干细胞再生的促进作用，为利用天然膳食成分辅助癌症治疗提供了新策略；\n（5）未来将探索半胱氨酸对其他组织（如毛囊）再生的影响及其他氨基酸的类似作用机制。", "raw_content": "A diet rich in the amino acid cysteine may have rejuvenating effects in the small intestine, according to a new study from MIT. This amino acid, the researchers discovered, can turn on an immune signaling pathway that helps stem cells to regrow new intestinal tissue. This enhanced regeneration may help to heal injuries from radiation, which often occur in patients undergoing radiation therapy for cancer. The research was conducted in mice, but if future research shows similar results in humans, then delivering elevated quantities of cysteine, through diet or supplements, could offer a new strategy to help damaged tissue heal faster, the researchers say. “The study suggests that if we give these patients a cysteine-rich diet or cysteine supplementation, perhaps we can dampen some of the chemotherapy or radiation-induced injury,” says Omer Yilmaz, director of the MIT Stem Cell Initiative, an associate professor of biology at MIT, and a member of MIT’s Koch Institute for Integrative Cancer Research. “The beauty here is we’re not using a synthetic molecule; we’re exploiting a natural dietary compound.” While previous research has shown that certain types of diets, including low-calorie diets, can enhance intestinal stem cell activity, the new study is the first to identify a single nutrient that can help intestinal cells to regenerate. Yilmaz is the senior author of the study, which appears today in Nature . Koch Institute postdoc Fangtao Chi is the paper’s lead author. Boosting regeneration It is well-established that diet can affect overall health: High-fat diets can lead to obesity, diabetes, and other health problems, while low-calorie diets have been shown to extend lifespans in many species. In recent years, Yilmaz’s lab has investigated how different types of diets influence stem cell regeneration, and found that high-fat diets , as well as short periods of fasting , can enhance stem cell activity in different ways. “We know that macro diets such as high-sugar diets, high-fat diets, and low-calorie diets have a clear impact on health. But at the granular level, we know much less about how individual nutrients impact stem cell fate decisions, as well as tissue function and overall tissue health,” Yilmaz says. In their new study, the researchers began by feeding mice a diet high in one of 20 different amino acids, the building blocks of proteins. For each group, they measured how the diet affected intestinal stem cell regeneration. Among these amino acids, cysteine had the most dramatic effects on stem cells and progenitor cells (immature cells that differentiate into adult intestinal cells). Further studies revealed that cysteine initiates a chain of events leading to the activation of a population of immune cells called CD8 T cells. When cells in the lining of the intestine absorb cysteine from digested food, they convert it into CoA, a cofactor that is released into the mucosal lining of the intestine. There, CD8 T cells absorb CoA, which stimulates them to begin proliferating and producing a cytokine called IL-22. IL-22 is an important player in the regulation of intestinal stem cell regeneration, but until now, it wasn’t known that CD8 T cells can produce it to boost intestinal stem cells. Once activated, those IL-22-releasing T cells are primed to help combat any kind of injury that could occur within the intestinal lining. “What’s really exciting here is that feeding mice a cysteine-rich diet leads to the expansion of an immune cell population that we typically don’t associate with IL-22 production and the regulation of intestinal stemness,” Yilmaz says. “What happens in a cysteine-rich diet is that the pool of cells that make IL-22 increases, particularly the CD8 T-cell fraction.” These T cells tend to congregate within the lining of the intestine, so they are already in position when needed. The researchers found that the stimulation of CD8 T cells occurred primarily in the small intestine, not in any other part of the digestive tract, which they believe is because most of the protein that we consume is absorbed by the small intestine. Healing the intestine In this study, the researchers showed that regeneration stimulated by a cysteine-rich diet could help to repair radiation damage to the intestinal lining. Also, in work that has not been published yet, they showed that a high-cysteine diet had a regenerative effect following treatment with a chemotherapy drug called 5-fluorouracil. This drug, which is used to treat colon and pancreatic cancers, can also damage the intestinal lining. Cysteine is found in many high-protein foods, including meat, dairy products, legumes, and nuts. The body can also synthesize its own cysteine, by converting the amino acid methionine to cysteine — a process that takes place in the liver. However, cysteine produced in the liver is distributed through the entire body and doesn’t lead to a buildup in the small intestine the way that consuming cysteine in the diet does. “With our high-cysteine diet, the gut is the first place that sees a high amount of cysteine,” Chi says. Cysteine has been previously shown to have antioxidant effects, which are also beneficial, but this study is the first to demonstrate its effect on intestinal stem cell regeneration. The researchers now hope to study whether it may also help other types of stem cells regenerate new tissues. In one ongoing study, they are investigating whether cysteine might stimulate hair follicle regeneration. They also plan to further investigate some of the other amino acids that appear to influence stem cell regeneration. “I think we’re going to uncover multiple new mechanisms for how these amino acids regulate cell fate decisions and gut health in the small intestine and colon,” Yilmaz says. The research was funded, in part, by the National Institutes of Health, the V Foundation, the Kathy and Curt Marble Cancer Research Award, the Koch Institute-Dana-Farber/Harvard Cancer Center Bridge Project, the American Federation for Aging Research, the MIT Stem Cell Initiative, and the Koch Institute Support (core) Grant from the National Cancer Institute.", "release_time": "2025-10-02", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/cysteine-rich-diet-may-promote-intestinal-lining-regeneration-study-suggests-1001"}
{"category": "研究前沿", "title": "MIT研发耐高温钯膜，推动高效制氢技术", "short_summary": "MIT工程师开发出新型钯膜，可在1000开尔文高温下稳定运行，提升氢燃料生产效率。", "detailed_summary": "MIT工程师开发出新型钯膜，可在1000开尔文高温下稳定运行，提升氢燃料生产效率。\n(1) MIT工程师创新设计将钯以\"栓塞\"形式沉积于多孔二氧化硅基底中，而非传统连续薄膜。\n(2) 新型膜在高达1000开尔文温度下保持稳定超过100小时，耐热性比传统钯膜提升至少200开尔文。\n(3) 该设计解决了传统钯膜在800开尔文以上易降解的问题，保持了氢气的选择性分离能力。\n(4) 高温稳定性为紧凑型蒸汽甲烷重整和氨裂解等制氢技术提供了更高效、廉价的膜反应器方案。\n(5) 此项研究为未来实现零碳排放的氢燃料和电力生产提供了有前景的技术路径。", "raw_content": "Palladium is one of the keys to jump-starting a hydrogen-based energy economy. The silvery metal is a natural gatekeeper against every gas except hydrogen, which it readily lets through. For its exceptional selectivity, palladium is considered one of the most effective materials at filtering gas mixtures to produce pure hydrogen. Today, palladium-based membranes are used at commercial scale to provide pure hydrogen for semiconductor manufacturing, food processing, and fertilizer production, among other applications in which the membranes operate at modest temperatures. If palladium membranes get much hotter than around 800 kelvins, they can break down. Now, MIT engineers have developed a new palladium membrane that remains resilient at much higher temperatures. Rather than being made as a continuous film, as most membranes are, the new design is made from palladium that is deposited as “plugs” into the pores of an underlying supporting material. At high temperatures, the snug-fitting plugs remain stable and continue separating out hydrogen, rather than degrading as a surface film would. The thermally stable design opens opportunities for membranes to be used in hydrogen-fuel-generating technologies such as compact steam methane reforming and ammonia cracking — technologies that are designed to operate at much higher temperatures to produce hydrogen for zero-carbon-emitting fuel and electricity. “With further work on scaling and validating performance under realistic industrial feeds, the design could represent a promising route toward practical membranes for high-temperature hydrogen production,” says Lohyun Kim PhD ’24, a former graduate student in MIT’s Department of Mechanical Engineering. Kim and his colleagues report details of the new membrane in a study appearing today in the journal Advanced Functional Materials . The study’s co-authors are Randall Field, director of research at the MIT Energy Initiative (MITEI); former MIT chemical engineering graduate student Chun Man Chow PhD ’23; Rohit Karnik, the Jameel Professor in the Department of Mechanical Engineering at MIT and the director of the Abdul Latif Jameel Water and Food Systems Lab (J-WAFS); and Aaron Persad, a former MIT research scientist in mechanical engineering who is now an assistant professor at the University of Maryland Eastern Shore. Compact future The team’s new design came out of a MITEI project related to fusion energy. Future fusion power plants, such as the one MIT spinout Commonwealth Fusion Systems is designing , will involve circulating hydrogen isotopes of deuterium and tritium at extremely high temperatures to produce energy from the isotopes’ fusing. The reactions inevitably produce other gases that will have to be separated, and the hydrogen isotopes will be recirculated into the main reactor for further fusion. Similar issues arise in a number of other processes for producing hydrogen, where gases must be separated and recirculated back into a reactor. Concepts for such recirculating systems would require first cooling down the gas before it can pass through hydrogen-separating membranes — an expensive and energy-intensive step that would involve additional machinery and hardware. “One of the questions we were thinking about is: Can we develop membranes which could be as close to the reactor as possible, and operate at higher temperatures, so we don’t have to pull out the gas and cool it down first?” Karnik says. “It would enable more energy-efficient, and therefore cheaper and compact, fusion systems.” The researchers looked for ways to improve the temperature resistance of palladium membranes. Palladium is the most effective metal used today to separate hydrogen from a variety of gas mixtures. It naturally attracts hydrogen molecules (H 2 ) to its surface, where the metal’s electrons interact with and weaken the molecule’s bonds, causing H 2 to temporarily break apart into its respective atoms. The individual atoms then diffuse through the metal and join back up on the other side as pure hydrogen. Palladium is highly effective at permeating hydrogen, and only hydrogen, from streams of various gases. But conventional membranes typically can operate at temperatures of up to 800 kelvins before the film starts to form holes or clumps up into droplets, allowing other gases to flow through. Plugging in Karnik, Kim and their colleagues took a different design approach. They observed that at high temperatures, palladium will start to shrink up. In engineering terms, the material is acting to reduce surface energy. To do this, palladium, and most other materials and even water, will pull apart and form droplets with the smallest surface energy. The lower the surface energy, the more stable the material can be against further heating. This gave the team an idea: If a supporting material’s pores could be “plugged” with deposits of palladium — essentially already forming a droplet with the lowest surface energy — the tight quarters might substantially increase palladium’s heat tolerance while preserving the membrane’s selectivity for hydrogen. To test this idea, they fabricated small chip-sized samples of membrane using a porous silica supporting layer (each pore measuring about half a micron wide), onto which they deposited a very thin layer of palladium. They applied techniques to essentially grow the palladium into the pores, and polished down the surface to remove the palladium layer and leave palladium only inside the pores. They then placed samples in a custom-built apparatus in which they flowed hydrogen-containing gas of various mixtures and temperatures to test its separation performance. The membranes remained stable and continued to separate hydrogen from other gases even after experiencing temperatures of up to 1,000 kelvins for over 100 hours — a significant improvement over conventional film-based membranes. “The use of palladium film membranes are generally limited to below around 800 kelvins, at which point they degrade,” Kim says. “Our plug design therefore extends palladium’s effective heat resilience by roughly at least 200 kelvins and maintains integrity far longer under extreme conditions.” These conditions are within the range of hydrogen-generating technologies such as steam methane reforming and ammonia cracking. Steam methane reforming is an established process that has required complex, energy-intensive systems to preprocess methane to a form where pure hydrogen can be extracted. Such preprocessing steps could be replaced with a compact “membrane reactor,” through which a methane gas would directly flow, and the membrane inside would filter out pure hydrogen. Such reactors would significantly cut down the size, complexity, and cost of producing hydrogen from steam methane reforming, and Kim estimates a membrane would have to work reliably in temperatures of up to nearly 1,000 kelvins. The team’s new membrane could work well within such conditions. Ammonia cracking is another way to produce hydrogen, by “cracking” or breaking apart ammonia. As ammonia is very stable in liquid form, scientists envision that it could be used as a carrier for hydrogen and be safely transported to a hydrogen fuel station, where ammonia could be fed into a membrane reactor that again pulls out hydrogen and pumps it directly into a fuel cell vehicle. Ammonia cracking is still largely in pilot and demonstration stages, and Kim says any membrane in an ammonia cracking reactor would likely operate at temperatures of around 800 kelvins — within the range of the group’s new plug-based design. Karnik emphasizes that their results are just a start. Adopting the membrane into working reactors will require further development and testing to ensure it remains reliable over much longer periods of time. “We showed that instead of making a film, if you make discretized nanostructures you can get much more thermally stable membranes,” Karnik says. “It provides a pathway for designing membranes for extreme temperatures, with the added possibility of using smaller amounts of expensive palladium, toward making hydrogen production more efficient and affordable. There is potential there.” This work was supported by Eni S.p.A. via the MIT Energy Initiative.", "release_time": "2025-10-02", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/palladium-filters-could-enable-cheaper-more-efficient-generation-hydrogen-fuel-1001"}
{"category": "研究前沿", "title": "BEST聚变装置杜瓦底座成功安装", "short_summary": "BEST装置首个关键部件杜瓦底座精准落位，标志主体工程建设进入新阶段。", "detailed_summary": "BEST装置首个关键部件杜瓦底座精准落位，标志主体工程建设进入新阶段。\n（1）BEST紧凑型聚变能实验装置的首个关键部件杜瓦底座成功研制并精准安装；\n（2）该部件直径约18米，重400余吨，是国内聚变领域最大的真空部件；\n（3）项目团队攻克高精度成型焊接、毫米级形变控制等关键技术难题；\n（4）安装精度要求极高，落位位置偏差不得超过正负2毫米；\n（5）为后续核心部件安装奠定基础，标志项目建设进入新阶段。", "raw_content": "BEST装置首个关键部件杜瓦底座成功落位装配 2025-10-01 | 作者：BEST项目团队 |【 大 中 小 】 【打印】 【关闭】 近日，紧凑型聚变能实验装置BEST项目建设取得关键突破。BEST装置主机关键部件杜瓦底座研制成功并顺利完成交付，成功精准落位安装在BEST装置主机大厅内。作为首个进驻主机大厅的关键部件，杜瓦底座的落位安装标志着BEST项目主体工程建设步入新阶段，部件研制和工程安装开启“加速度”。 杜瓦底座是BEST装置主机的首个真空大部件，设计工况复杂，接口数百余个。结构尺寸大，直径约18米，高度约5米，总重量400余吨，是BEST主机系统中最重的部件，也是国内聚变领域最大的真空部件。该部件承载着BEST装置近七千吨重量支撑和绝热功能，其安装精度直接关系到整个工程的稳定性和安全性。项目团队精诚合作，相继攻克了高精度成型和焊接、毫米级形变控制、高真空密封等关键技术，成功研制出杜瓦底座部件。 杜瓦底座的吊装精度高，表面水平高差需控制在15毫米以内，落位位置偏差不得超过正负2毫米；作业空间极度狭小，底座外边缘与主机坑屏蔽墙的最小间隙不足100毫米。面对这些挑战，项目团队连续奋战、攻坚克难，全力保障工程进度。团队自主研发了专用吊具系统，通过均衡梁、吊梁、提升适配器及花篮螺丝等组件的协同作用，精细调节吊装水平度。同时，采用多站激光跟踪仪实时监测基准点，动态调整吊装姿态，最终实现杜瓦底座的毫米级精准落位安装。 杜瓦底座的制造交付和落位装配，为BEST装置后续核心部件的安装和调试奠定了坚实基础。接下来，BEST团队发扬全超导托卡马克大科学团队精神，全力以赴推进装置部件安装工作，确保BEST装置建设目标按期高质量完成。 杜瓦底座落位 杜瓦底座转运 附件：", "release_time": "2025-10-01", "source_institution": "等离子体物理研究所", "url": "http://www.ipp.ac.cn/xwdt/ttxw/202510/t20251001_780417.html"}
{"category": "研究前沿", "title": "MIT推出Graffiti框架：可互操作个性化社交应用新范式", "short_summary": "MIT研发Graffiti框架，支持个性化社交应用开发与跨平台互操作。", "detailed_summary": "MIT研发Graffiti框架，支持个性化社交应用开发与跨平台互操作。\n(1) MIT研究人员推出名为Graffiti的新框架，旨在降低个性化社交应用开发门槛；\n(2) 该框架采用去中心化基础设施，用户数据由个人控制而非平台持有；\n(3) 支持应用间完全互操作，内容可在不同设计应用间共享显示；\n(4) 通过\"完全具体化\"设计实现灵活的内容审核机制，用户可自定义规则；\n(5) 采用频道组织内容避免语境坍塌问题，保护用户社交边界。", "raw_content": "Say a local concert venue wants to engage its community by giving social media followers an easy way to share and comment on new music from emerging artists. Rather than working within the constraints of existing social platforms, the venue might want to create its own social app with the functionality that would be best for its community. But building a new social app from scratch involves many complicated programming steps, and even if the venue can create a customized app, the organization’s followers may be unwilling to join the new platform because it could mean leaving their connections and data behind. Now, researchers from MIT have launched a framework called Graffiti that makes building personalized social applications easier, while allowing users to migrate between multiple applications without losing their friends or data. “We want to empower people to have control over their own designs rather than having them dictated from the top down,” says electrical engineering and computer science graduate student Theia Henderson. Henderson and her colleagues designed Graffiti with a flexible structure so individuals have the freedom to create a variety of customized applications, from messenger apps like WhatsApp to microblogging platforms like X to location-based social networking sites like Nextdoor, all using only front-end development tools like HTML. The protocol ensures all applications can interoperate, so content posted on one application can appear on any other application, even those with disparate designs or functionality. Importantly, Graffiti users retain control of their data, which is stored on a decentralized infrastructure rather than being held by a specific application. While the pros and cons of implementing Graffiti at scale remain to be fully explored, the researchers hope this new approach can someday lead to healthier online interactions. “We’ve shown that you can have a rich social ecosystem where everyone owns their own data and can use whatever applications they want to interact with whoever they want in whatever way they want. And they can have their own experiences without losing connection with the people they want to stay connected with,” says David Karger, professor of EECS and a member of the Computer Science and Artificial Intelligence Laboratory (CSAIL). Henderson, the lead author, and Karger are joined by MIT Research Scientist David D. Clark on a paper about Graffiti , which will be presented at the ACM Symposium on User Interface Software and Technology. Personalized, integrated applications With Graffiti, the researchers had two main goals: to lower the barrier to creating personalized social applications and to enable those personalized applications to interoperate without requiring permission from developers. To make the design process easier, they built a collective back-end infrastructure that all applications access to store and share content. This means developers don’t need to write any complex server code. Instead, designing a Graffiti application is more like making a website using popular tools like Vue. Developers can also easily introduce new features and new types of content, giving them more freedom and fostering creativity. “Graffiti is so straightforward that we used it as the infrastructure for the intro to web design class I teach, and students were able to write the front-end very easily to come up with all sorts of applications,” Karger says. The open, interoperable nature of Graffiti means no one entity has the power to set a moderation policy for the entire platform. Instead, multiple competing and contradictory moderation services can operate, and people can choose the ones they like. Graffiti uses the idea of “total reification,” where every action taken in Graffiti, such as liking, sharing, or blocking a post, is represented and stored as its own piece of data. A user can configure their social application to interpret or ignore those data using its own rules. For instance, if an application is designed so a certain user is a moderator, posts blocked by that user won’t appear in the application. But for an application with different rules where that person isn’t considered a moderator, other users might just see a warning or no flag at all. “Theia’s system lets each person pick their own moderators, avoiding the one-sized-fits-all approach to moderation taken by the major social platforms,” Karger says. But at the same time, having no central moderator means there is no one to remove content from the platform that might be offensive or illegal. “We need to do more research to understand if that is going to provide real, damaging consequences or if the kind of personal moderation we created can provide the protections people need,” he adds. Empowering social media users The researchers also had to overcome a problem known as context collapse, which conflicts with their goal of interoperation. For instance, context collapse would occur if a person’s Tinder profile appeared on LinkedIn, or if a post intended for one group, like close friends, would create conflict with another group, such as family members. Context collapse can lead to anxiety and have social repercussions for the user and their different communities. “We realize that interoperability can sometimes be a bad thing. People have boundaries between different social contexts, and we didn’t want to violate those,” Henderson says. To avoid context collapse, the researchers designed Graffiti so all content is organized into distinct channels. Channels are flexible and can represent a variety of contexts, such as people, applications, locations, etc. If a user’s post appears in an application channel but not their personal channel, others using that application will see the post, but those who only follow this user will not. “Individuals should have the power to choose the audience for whatever they want to say,” Karger adds. The researchers created multiple Graffiti applications to showcase personalization and interoperability, including a community-specific application for a local concert venue, a text-centric microblogging platform patterned off X, a Wikipedia-like application that enables collective editing, and a real-time messaging app with multiple moderation schemes patterned off WhatsApp and Slack. “It also leaves room to create so many social applications people haven’t thought of yet. I’m really excited to see what people come up with when they are given full creative freedom,” Henderson says. In the future, she and her colleagues want to explore additional social applications they could build with Graffiti. They also intend to incorporate tools like graphical editors to simplify the design process. In addition, they want to strengthen Graffiti’s security and privacy. And while there is still a long way to go before Graffiti could be implemented at scale, the researchers are currently running a user study as they explore the potential positive and negative impacts the system could have on the social media landscape.", "release_time": "2025-10-02", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/system-lets-people-personalize-online-social-spaces-while-staying-connected-1001"}
{"category": "研究前沿", "title": "MIT研究揭示生成式AI碳足迹减排路径", "short_summary": "专家探索算法优化与绿色能源等多元策略，应对AI能耗激增带来的碳排放挑战。", "detailed_summary": "专家探索算法优化与绿色能源等多元策略，应对AI能耗激增带来的碳排放挑战。\n（1）生成式AI能耗持续飙升，国际能源署预测2030年数据中心用电量将超日本全国能耗；\n（2）MIT专家指出需同时关注数据中心运营碳排放和建造过程的隐含碳排放；\n（3）减排策略包括降低GPU能耗、采用低精度计算硬件、提前终止模型训练以节省能源；\n（4）算法架构创新带来\"negaflop\"效应，计算效率每9个月翻倍；\n（5）通过智能调度AI任务至可再生能源供电时段、部署长效储能设备、优化数据中心选址等措施最大化减排效果。", "raw_content": "In part 2 of our two-part series on generative artificial intelligence’s environmental impacts , MIT News explores some of the ways experts are working to reduce the technology’s carbon footprint. The energy demands of generative AI are expected to continue increasing dramatically over the next decade. For instance, an April 2025 report from the International Energy Agency predicts that the global electricity demand from data centers , which house the computing infrastructure to train and deploy AI models, will more than double by 2030, to around 945 terawatt-hours. While not all operations performed in a data center are AI-related, this total amount is slightly more than the energy consumption of Japan. Moreover, an August 2025 analysis from Goldman Sachs Research forecasts that about 60 percent of the increasing electricity demands from data centers will be met by burning fossil fuels, increasing global carbon emissions by about 220 million tons . In comparison, driving a gas-powered car for 5,000 miles produces about 1 ton of carbon dioxide. These statistics are staggering, but at the same time, scientists and engineers at MIT and around the world are studying innovations and interventions to mitigate AI’s ballooning carbon footprint, from boosting the efficiency of algorithms to rethinking the design of data centers. Considering carbon emissions Talk of reducing generative AI’s carbon footprint is typically centered on “operational carbon” — the emissions used by the powerful processors, known as GPUs, inside a data center. It often ignores “embodied carbon,” which are emissions created by building the data center in the first place, says Vijay Gadepally, senior scientist at MIT Lincoln Laboratory, who leads research projects in the Lincoln Laboratory Supercomputing Center. Constructing and retrofitting a data center, built from tons of steel and concrete and filled with air conditioning units, computing hardware, and miles of cable, consumes a huge amount of carbon. In fact, the environmental impact of building data centers is one reason companies like Meta and Google are exploring more sustainable building materials. (Cost is another factor.) Plus, data centers are enormous buildings — the world’s largest, the China Telecomm-Inner Mongolia Information Park, engulfs roughly 10 million square feet — with about 10 to 50 times the energy density of a normal office building, Gadepally adds. “The operational side is only part of the story. Some things we are working on to reduce operational emissions may lend themselves to reducing embodied carbon, too, but we need to do more on that front in the future,” he says. Reducing operational carbon emissions When it comes to reducing operational carbon emissions of AI data centers, there are many parallels with home energy-saving measures. For one, we can simply turn down the lights. “Even if you have the worst lightbulbs in your house from an efficiency standpoint, turning them off or dimming them will always use less energy than leaving them running at full blast,” Gadepally says. In the same fashion, research from the Supercomputing Center has shown that “turning down” the GPUs in a data center so they consume about three-tenths the energy has minimal impacts on the performance of AI models, while also making the hardware easier to cool. Another strategy is to use less energy-intensive computing hardware. Demanding generative AI workloads, such as training new reasoning models like GPT-5, usually need many GPUs working simultaneously. The Goldman Sachs analysis estimates that a state-of-the-art system could soon have as many as 576 connected GPUs operating at once. But engineers can sometimes achieve similar results by reducing the precision of computing hardware, perhaps by switching to less powerful processors that have been tuned to handle a specific AI workload. There are also measures that boost the efficiency of training power-hungry deep-learning models before they are deployed. Gadepally’s group found that about half the electricity used for training an AI model is spent to get the last 2 or 3 percentage points in accuracy. Stopping the training process early can save a lot of that energy. “There might be cases where 70 percent accuracy is good enough for one particular application, like a recommender system for e-commerce,” he says. Researchers can also take advantage of efficiency-boosting measures. For instance, a postdoc in the Supercomputing Center realized the group might run a thousand simulations during the training process to pick the two or three best AI models for their project. By building a tool that allowed them to avoid about 80 percent of those wasted computing cycles, they dramatically reduced the energy demands of training with no reduction in model accuracy, Gadepally says. Leveraging efficiency improvements Constant innovation in computing hardware, such as denser arrays of transistors on semiconductor chips, is still enabling dramatic improvements in the energy efficiency of AI models. Even though energy efficiency improvements have been slowing for most chips since about 2005, the amount of computation that GPUs can do per joule of energy has been improving by 50 to 60 percent each year, says Neil Thompson, director of the FutureTech Research Project at MIT’s Computer Science and Artificial Intelligence Laboratory and a principal investigator at MIT’s Initiative on the Digital Economy. “The still-ongoing ‘Moore’s Law’ trend of getting more and more transistors on chip still matters for a lot of these AI systems, since running operations in parallel is still very valuable for improving efficiency,” says Thomspon. Even more significant, his group’s research indicates that efficiency gains from new model architectures that can solve complex problems faster, consuming less energy to achieve the same or better results, is doubling every eight or nine months. Thompson coined the term “ negaflop ” to describe this effect. The same way a “negawatt” represents electricity saved due to energy-saving measures, a “negaflop” is a computing operation that doesn’t need to be performed due to algorithmic improvements. These could be things like “ pruning ” away unnecessary components of a neural network or employing compression techniques that enable users to do more with less computation. “If you need to use a really powerful model today to complete your task, in just a few years, you might be able to use a significantly smaller model to do the same thing, which would carry much less environmental burden. Making these models more efficient is the single-most important thing you can do to reduce the environmental costs of AI,” Thompson says. Maximizing energy savings While reducing the overall energy use of AI algorithms and computing hardware will cut greenhouse gas emissions, not all energy is the same, Gadepally adds. “The amount of carbon emissions in 1 kilowatt hour varies quite significantly, even just during the day, as well as over the month and year,” he says. Engineers can take advantage of these variations by leveraging the flexibility of AI workloads and data center operations to maximize emissions reductions. For instance, some generative AI workloads don’t need to be performed in their entirety at the same time. Splitting computing operations so some are performed later, when more of the electricity fed into the grid is from renewable sources like solar and wind, can go a long way toward reducing a data center’s carbon footprint, says Deepjyoti Deka, a research scientist in the MIT Energy Initiative. Deka and his team are also studying “smarter” data centers where the AI workloads of multiple companies using the same computing equipment are flexibly adjusted to improve energy efficiency. “By looking at the system as a whole, our hope is to minimize energy use as well as dependence on fossil fuels, while still maintaining reliability standards for AI companies and users,” Deka says. He and others at MITEI are building a flexibility model of a data center that considers the differing energy demands of training a deep-learning model versus deploying that model. Their hope is to uncover the best strategies for scheduling and streamlining computing operations to improve energy efficiency. The researchers are also exploring the use of long-duration energy storage units at data centers, which store excess energy for times when it is needed. With these systems in place, a data center could use stored energy that was generated by renewable sources during a high-demand period, or avoid the use of diesel backup generators if there are fluctuations in the grid. “Long-duration energy storage could be a game-changer here because we can design operations that really change the emission mix of the system to rely more on renewable energy,” Deka says. In addition, researchers at MIT and Princeton University are developing a software tool for investment planning in the power sector, called GenX , which could be used to help companies determine the ideal place to locate a data center to minimize environmental impacts and costs. Location can have a big impact on reducing a data center’s carbon footprint. For instance, Meta operates a data center in Lulea , a city on the coast of northern Sweden where cooler temperatures reduce the amount of electricity needed to cool computing hardware. Thinking farther outside the box (way farther), some governments are even exploring the construction of data centers on the moon where they could potentially be operated with nearly all renewable energy. AI-based solutions Currently, the expansion of renewable energy generation here on Earth isn’t keeping pace with the rapid growth of AI, which is one major roadblock to reducing its carbon footprint, says Jennifer Turliuk MBA ’25, a short-term lecturer, former Sloan Fellow, and former practice leader of climate and energy AI at the Martin Trust Center for MIT Entrepreneurship. The local, state, and federal review processes required for a new renewable energy projects can take years. Researchers at MIT and elsewhere are exploring the use of AI to speed up the process of connecting new renewable energy systems to the power grid. For instance, a generative AI model could streamline interconnection studies that determine how a new project will impact the power grid, a step that often takes years to complete. And when it comes to accelerating the development and implementation of clean energy technologies , AI could play a major role. “Machine learning is great for tackling complex situations, and the electrical grid is said to be one of the largest and most complex machines in the world,” Turliuk adds. For instance, AI could help optimize the prediction of solar and wind energy generation or identify ideal locations for new facilities. It could also be used to perform predictive maintenance and fault detection for solar panels or other green energy infrastructure, or to monitor the capacity of transmission wires to maximize efficiency. By helping researchers gather and analyze huge amounts of data, AI could also inform targeted policy interventions aimed at getting the biggest “bang for the buck” from areas such as renewable energy, Turliuk says. To help policymakers, scientists, and enterprises consider the multifaceted costs and benefits of AI systems, she and her collaborators developed the Net Climate Impact Score. The score is a framework that can be used to help determine the net climate impact of AI projects, considering emissions and other environmental costs along with potential environmental benefits in the future. At the end of the day, the most effective solutions will likely result from collaborations among companies, regulators, and researchers, with academia leading the way, Turliuk adds. “Every day counts. We are on a path where the effects of climate change won’t be fully known until it is too late to do anything about it. This is a once-in-a-lifetime opportunity to innovate and make AI systems less carbon-intense,” she says.", "release_time": "2025-09-30", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/responding-to-generative-ai-climate-impact-0930"}
{"category": "产业应用", "title": "星舰试射成功助推外太阳系科学探索", "short_summary": "星舰轨道测试成功，有望将天王星探测任务时间减半并提升载荷能力。", "detailed_summary": "星舰轨道测试成功，有望将天王星探测任务时间减半并提升载荷能力。\n（1）SpaceX星舰完成全轨道发射测试，为史上最大运载火箭，可搭载150吨载荷至近地轨道；\n（2）星舰技术或革新外太阳系探索，如将天王星旗舰任务的航行时间从13年缩短至6-8.5年；\n（3）天王星因独特倾斜、冰巨星特性及可能存在海洋卫星，被列为2022年科学调查最高优先级目标；\n（4）星舰在轨加油后可直接飞往天王星，无需行星引力辅助，并可利用气动捕获技术减速；\n（5）星舰仍需验证在轨加油能力，但其进展为深空科学任务提供了新的可能性。", "raw_content": "The successful test of SpaceX’s Starship launch vehicle, following a series of engineering challenges and failed launches, has reignited excitement over the possibilities this massive rocket may unlock for humanity’s greatest ambitions in space. The largest rocket ever built, Starship and its 33-engine “super heavy” booster completed a full launch into Earth orbit on Aug. 26, deployed eight test prototype satellites, and survived reentry for a simulated landing before coming down, mostly intact, in the Indian Ocean. The 400-foot rocket is designed to carry up to 150 tons of cargo to low Earth orbit, dramatically increasing potential payload volume from rockets currently in operation. In addition to the planned Artemis III mission to the lunar surface and proposed missions to Mars in the near future, Starship also poses an opportunity for large-scale scientific missions throughout the solar system. The National Academy of Sciences Planetary Science Decadal Survey published a recommendation in 2022 outlining exploration of Uranus as its highest-priority flagship mission. This proposed mission was envisioned for the 2030s, assuming use of a Falcon Heavy expendable rocket and anticipating arrival at the planet before 2050. Earlier this summer, a paper from researchers in MIT’s Engineering Systems Lab found that Starship may enable this flagship mission to Uranus in half the flight time. In this 3Q, Chloe Gentgen, a PhD student in aeronautics and astronautics and co-author on the recent study, describes the significance of Uranus as a flagship mission and what the current trajectory of Starship means for scientific exploration. Q: Why has Uranus been identified as the highest-priority flagship mission? A: Uranus is one of the most intriguing and least-explored planets in our solar system. The planet is tilted on its side, is extremely cold, presents a highly dynamic atmosphere with fast winds, and has an unusual and complex magnetic field. A few of Uranus’ many moons could be ocean worlds, making them potential candidates in the search for life in the solar system. The ice giants Uranus and Neptune also represent the closest match to most of the exoplanets discovered. A mission to Uranus would therefore radically transform our understanding of ice giants, the solar system, and exoplanets. What we know about Uranus largely dates back to Voyager 2’s brief flyby nearly 40 years ago. No spacecraft has visited Uranus or Neptune since, making them the only planets yet to have a dedicated orbital mission. One of the main obstacles has been the sheer distance. Uranus is 19 times farther from the sun than the Earth is, and nearly twice as far as Saturn. Reaching it requires a heavy-lift launch vehicle and trajectories involving gravity assists from other planets. Today, such heavy-lift launch vehicles are available, and trajectories have been identified for launch windows throughout the 2030s, which resulted in selecting a Uranus mission as the highest priority flagship in the 2022 decadal survey. The proposed concept, called Uranus Orbiter and Probe (UOP), would release a probe into the planet’s atmosphere and then embark on a multiyear tour of the system to study the planet’s interior, atmosphere, magnetosphere, rings, and moons. Q: How do you envision your work on the Starship launch vehicle being deployed for further development? A: Our study assessed the feasibility and potential benefits of launching a mission to Uranus with a Starship refueled in Earth’s orbit, instead of a Falcon Heavy (another SpaceX launch vehicle, currently operational). The Uranus decadal study showed that launching on a Falcon Heavy Expendable results in a cruise time of at least 13 years. Long cruise times present challenges, such as loss of team expertise and a higher operational budget. With the mission not yet underway, we saw an opportunity to evaluate launch vehicles currently in development, particularly Starship. When refueled in orbit, Starship could launch a spacecraft directly to Uranus, without detours by other planets for gravity-assist maneuvers. The proposed spacecraft could then arrive at Uranus in just over six years, less than half the time currently envisioned. These high-energy trajectories require significant deceleration at Uranus to capture in orbit. If the spacecraft slows down propulsively, the burn would require 5 km/s of delta v (which quantifies the energy needed for the maneuver), much higher than is typically performed by spacecraft, which might result in a very complex design. A more conservative approach, assuming a maximum burn of 2 km/s at Uranus, would result in a cruise time of 8.5 years. An alternative to propulsive orbit insertion at Uranus is aerocapture, where the spacecraft, enclosed in a thermally protective aeroshell, dips into the planet’s atmosphere and uses aerodynamic drag to decelerate. We examined whether Starship itself could perform aerocapture, rather than being separated from the spacecraft shortly after launch. Starship is already designed to withstand atmospheric entry at Earth and Mars, and thus already has a thermal protection system that could, potentially, be modified for aerocapture at Uranus. While bringing a Starship vehicle all the way to Uranus presents significant challenges, our analysis showed that aerocapture with Starship would produce deceleration and heating loads similar to those of other Uranus aerocapture concepts and would enable a cruise time of six years. In addition to launching the proposed spacecraft on a faster trajectory that would reach Uranus sooner, Starship’s capabilities could also be leveraged to deploy larger masses to Uranus, enabling an enhanced mission with additional instruments or probes. Q: What does the recent successful test of Starship tell us about the viability and timeline for a potential mission to the outer solar system? A: The latest Starship launch marked an important milestone for the company after three failed launches in recent months, renewing optimism about the rocket’s future capabilities. Looking ahead, the program will need to demonstrate on-orbit refueling, a capability central to both SpaceX’s long-term vision of deep-space exploration and this proposed mission. Launch vehicle selection for flagship missions typically occurs approximately two years after the official mission formulation process begins, which has not yet commenced for the Uranus mission. As such, Starship still has a few more years to demonstrate its on-orbit refueling architecture before a decision has to be made. Overall, Starship is still under development, and significant uncertainty remains about its performance, timelines, and costs. Even so, our initial findings paint a promising picture of the benefits that could be realized by using Starship for a flagship mission to Uranus.", "release_time": "2025-09-30", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/3-questions-new-mission-to-uranus-0930"}
{"category": "产业应用", "title": "日本筑波大学医院质子治疗设施更新项目投运", "short_summary": "四企联合体完成日本首例质子治疗设施PFI模式更新，支持未来20年癌症治疗。", "detailed_summary": "四企联合体完成日本首例质子治疗设施PFI模式更新，支持未来20年癌症治疗。\n（1）筑波大学医院质子治疗系统于2025年9月29日开始治疗，是日本首例质子治疗设施更新项目；\n（2）项目采用PFI模式，由日立高科技等四家公司组成的联合体负责设计、建造及未来20年运营维护；\n（3）在有限场地空间内完成设施更新，新建紧凑型加速器室和治疗室，并确保现有医疗服务不中断；\n（4）采用不依赖特殊目的公司的优化融资方案，实现高效决策和项目运营；\n（5）筑波大学自1983年引领质子治疗，已治疗约8450名患者，新设施将继续支持癌症治疗创新。", "raw_content": "Tokyo, September 30, 2025 - Hitachi High-Tech Corporation (“Hitachi High-Tech”), Toda Corporation (“Toda”), Biken Techno Corporation (“Biken Techno”), and Mitsubishi HC Capital Inc. (“Mitsubishi HC Capital”), today announced that the proton therapy system delivered through the University of Tsukuba Hospital Proton Therapy Facility Development and Operation Project (“the Project”) has commenced treatment at the Proton Beam Therapy Center, University of Tsukuba Hospital (“University of Tsukuba”) as of September 29, 2025. This project involves the first renewal of proton beam therapy facility in Japan, and is equipped with spot scanning irradiation technology, a complete proton beam cancer treatment system including an accelerator and two rotating gantry treatment rooms, and the design, construction, operation, maintenance, and management of the proton beam facility under the Private Finance Initiative (PFI) method*1. Additionally, it serves as a model case for facility renewal within a limited site space.  The consortium will continue to support the operation of the facility as partners of the University of Tsukuba, a leader in cancer treatment innovation, for the next 20 years.  *1 PFI (Private Finance Initiative): A method of utilizing private sector funds, management expertise, and technology for the construction, operation, and maintenance of public facilities.  Key Features of the Project 1. Proton therapy facility development and operation leveraging the strengths of four consortium companies A consortium of four companies, each with expertise in technology and operation of proton therapy, has delivered the facility and system under the PFI model. Going forward, the consortium will support the maintenance and operation of the facility and treatment system as a partner of the University of Tsukuba for 20 years. 2. Facility renewal while maintaining ongoing medical services in a limited space A compact accelerator room and treatment rooms were constructed adjacent to the existing facility, serving as a model for updating proton therapy systems within limited site areas. Renovation work was also carried out on parts of the existing facility during the construction of the new building, with careful planning to ensure uninterrupted medical services and a smooth transition to the new facility. 3. Promote stable and efficient business operations through optimal financing schemes. In accordance with the characteristics of the business, we have developed an optimal financing scheme that does not rely on conventional fundraising methods and does not establish a Special Purpose Company*2. This enabled consistent management by the lead company, facilitating swift decision-making and efficient project operation.  *2 SPC (Special Purpose Company): A company established for a specific project or purpose.  About the Proton Beam Therapy Center, University of Tsukuba Hospital  The University of Tsukuba has been a global pioneer in cancer treatment using proton accelerators since 1983. In 2001, the hospital introduced a proton therapy system from Hitachi, and to date, has provided proton therapy to approximately 8,450 cancer patients. Overview of the Consortium The consortium is led by Hitachi High-Tech, with each company contributing its specialized expertise to the development and operation of the facility.  Hitachi High-Tech: Procurement operations for proton beam equipment and related devices, Operation and maintenance management of proton beam equipment and related devices, and Overall management and coordination of operations Toda Corporation: Maintenance work for the new proton beam building, Renovation work for the existing proton beam building Biken Techno: Facility maintenance and management of the new proton therapy building Mitsubishi HC Capital: Overall management and coordination of operations (Financial advisory services)   Organizational structure chart  About Hitachi High-Tech  Hitachi High-Tech provides cutting-edge technologies, products and services to society and customers with its corporate vision of \"Changing the World and Future with the Power of Knowledge\" to contribute to a sustainable global environment, healthy, safe and secure lives, and the sustained development of science and industry. We manufacture and sell clinical analyzers, biotechnology products and radiation therapy systems in the healthcare field, semiconductor manufacturing and inspection equipment in the semiconductor field, as well as analytical systems and electron microscopes used in environmental fields and materials research. We are also engaged in a wide range of business areas globally, providing high added-value solutions in battery, communication infrastructure, railway inspection, digital and other industrial and social infrastructure fields. By deeply understanding the issues facing society and our customers, and utilizing the installed base (Digitalized Assets) and domain knowledge, we provide digital service through Lumada 3.0, enhanced by AI. Along with the Inspire 2027, Hitachi Group's New Management plan, we contribute to realize a harmonized society where the environment, wellbeing, and economic growth coexist in harmony. The company's consolidated revenues for FY2024 were approx. JPY 756.5 billion.  For further information, visit https://www.hitachi-hightech.com/global/en/ About Toda Corporation  Toda Corporation is a comprehensive construction company engaged in a wide range of businesses, including architecture, civil engineering, urban development, and real estate, under the brand slogan “Build the Culture. Creation from ideas, rooted in passion.” Since its founding in 1881, Toda has contributed to the development of social infrastructure, such as medical and welfare facilities, high-rise buildings, tunnels, and shield construction, aiming to realize a sustainable society. In recent years, Toda has also focused on renewable energy projects, providing high-value-added solutions that balance technological innovation and environmental consideration. Backed by sound management and a robust financial base, Toda continues to solve social and customer challenges both in Japan and overseas. (Consolidated revenue for the fiscal year ending March 2025: 586.6 billion yen)  For more information, please visit the Toda Corporation website: https://www.toda.co.jp/english/ About Biken Techno  Biken Techno is a comprehensive facility management company providing cleaning, equipment management, and security services for office buildings, commercial facilities, condominiums, government facilities, racecourses, hospitals, hotels, and logistics centers. The company also offers cleaning and sterilization of food factory production lines, facility renovation, and a wide range of facility management services. Under the key concept of “Creating Comfortable Environments,” Biken Techno also engages in architectural design, construction, and real estate management, serving as a solution provider in the fields of medical, food, and living environments, and practicing its management philosophy of “Customer First.” (Consolidated revenue for the fiscal year ending March 2025: 34.669 billion yen)  As a solution provider practicing customer-first principles, Biken Techno offers the highest quality building management and contributes to society through facility management (FM), property management (PM), and building maintenance (BM).  For more information, please visit the Biken Techno website: https://www.bikentechno.co.jp/ About Mitsubishi HC Capital  The Mitsubishi HC Capital Group has set its vision for the next decade as “Innovators Challenging the Uncharted Future Together.” In pursuit of this vision, the Group is engaged not only in its core leasing business but also in services and business management that maximize the potential value of tangible and intangible assets. With seven business segments–Customer Solutions, Overseas Customers, Environmental Energy, Aviation, Logistics, Real Estate, and Mobility–the Group has consolidated total assets exceeding 11 trillion yen and approximately 8,400 employees worldwide, operating in over 20 countries as of March 2025.  By anticipating changes in society and the business environment, Mitsubishi HC Capital Group aims to create new social value together with our customers and partners, thereby solving social issues and contributing to the realization of a sustainable and prosperous future.  For more information, please visit the Mitsubishi HC Capital website: https://www.mitsubishi-hc-capital.com/english/ Business Contact Hitachi High-Tech Corporation  Healthcare Business Group  Therapy System Business  Particle Therapy Business Development Div.  Business Promotion Dept. Toda Corporation  PPP Promotion Department, Building Sales Management Department, Construction Business Division Biken Techno Corporation  PFI Promotion Office Mitsubishi HC Capital Inc.  Corporate Communications Department  Information contained in this news release is current as of the date of the press announcement, but may be subject to change without prior notice.", "release_time": "2025-10-15", "source_institution": "日本日立", "url": "http://www.hitachi.com/New/cnews/month/2025/09/250930b.html"}
{"category": "研究前沿", "title": "吴王锁教授在沪主讲同位素分离材料学术报告", "short_summary": "上海应物所香樟讲坛举办，吴王锁教授分享同位素传质分离材料前沿研究。", "detailed_summary": "上海应物所香樟讲坛举办，吴王锁教授分享同位素传质分离材料前沿研究。\n（1）上海应用物理研究所于2025年9月24日成功举办香樟讲坛暨钍基核裂变能重点实验室学术报告。\n（2）特邀兰州大学国家级领军人才吴王锁教授作“同位素传质分离材料的设计与构筑”主旨报告。\n（3）报告深入探讨了同位素分离研究现状、材料设计与性能关联等前沿科学问题。\n（4）与会科研人员与吴教授就分离途径、辐照效应及AI技术应用等进行了深入交流。\n（5）吴教授还分享了科研教学心得，鼓励青年人员发挥榜样作用，活动促进了核科学领域学术交流。", "raw_content": "上海应物所举办香樟讲坛—兰州大学吴王锁教授作学术报告 发布日期：2025/09/30 [ 大 中 小 ] [ 打印 ] [ 关闭 ] 2025年9月24日，中国科学院上海应用物理研究所成功举办香樟讲坛暨钍基核裂变能重点实验室学术报告。本期讲坛邀请了兰州大学吴王锁教授担任主讲人，报告主题为“同位素传质分离材料的设计与构筑”。上海应物所副所长蔡翔舟、应用化学部副主任刘玉侠、科研与教育处副处长钟静、科技骨干、研究生等参加了本期讲坛。活动由科研与教育处副处长任翠兰主持。 蔡翔舟为本期讲坛致辞，他代表上海应物所对吴王锁教授及其团队表示热烈欢迎和诚挚感谢。蔡翔舟向吴王锁介绍了研究所近年来的学科建设布局及围绕国家重大科技战略需求所取得的重要科研成果等。他指出，研究所构建了多层级的学术交流平台，旨在通过学术互动激发创新思维、促进知识共享、提升科研水平，同时为人才培养提供重要支撑，对提升研究所整体学术影响力、拓宽研究生学术视野具有重要作用。希望在座的青年科技人员积极参与交流，拓展学术思路，有所收获。随后，蔡翔舟代表上海应物所向吴王锁教授颁发了“香樟讲坛”特别纪念证书，吴王锁教授为讲坛签名留念。 蔡翔舟代表上海应物所向吴王锁赠送纪念证书 吴王锁教授是国家级领军人才、国家级教学名师、第三批全国高校黄大年式教师团队负责人，长期从事核技术应用、核环境安全、核燃料循环领域相关研究。同位素在国防、能源、医疗等领域具有关键作用，其传质分离材料的设计与构筑是实现高效同位素分离的核心。本次讲坛，吴王锁教授作《同位素传质分离材料的设计与构筑》主旨报告，从同位素分离研究的现状和需求出发，探究材料设计、结构与同位素传质性能的内在关联。与会人员就同位素分离途径、辐照效应及稳定性、与AI技术结合等方面与吴王锁教授展开了深入探讨。作为国家级思政教学名师，吴王锁教授还与青年科研人员分享了自己在科研与教学中的心得体会。他秉持“讲好一门课，影响众多人”的理念，结合自己在教学道路上的不断探索与感悟，鼓励青年科研人员在深耕专业领域的同时，也要注重发挥传道授业的榜样作用。 吴王锁作学术报告并与科研人员进行交流 “香樟讲坛”是上海应物所主办的高层次学术交流平台，以研究所发展目标为指引，以弘扬科学家精神和“奋发自强、求实创新、文明团结”的核所精神为宗旨，旨在打造核科学领域具有国际影响力的学术交流平台。欢迎科研人员积极通过“香樟讲坛”开展学术交流！（钍基核裂变能全国重点实验室 供稿） 相关附件", "release_time": "2025-09-30", "source_institution": "上海应用物理研究所", "url": "http://www.sinap.cas.cn/xwzx/kydt/202509/t20250930_7983534.html"}
{"category": "研究前沿", "title": "NREL利用波浪水槽验证波浪能转换器仿真模型", "short_summary": "HERO波浪能装置完成水槽测试，验证计算机仿真准确性以优化设计。", "detailed_summary": "HERO波浪能装置完成水槽测试，验证计算机仿真准确性以优化设计。\n(1) 美国国家可再生能源实验室对其HERO波浪能转换器进行了波浪水槽测试。\n(2) 测试旨在验证WEC-Sim和计算流体动力学两种仿真工具的准确性。\n(3) 团队正将装置V2版本的外壳从充气式改为更坚固的刚性框架结构。\n(4) 水槽测试数据确认了仿真模型能准确预测装置在真实海洋中的行为。\n(5) 此举为优化波浪能装置设计、提高可靠性和降低成本提供了关键方法。", "raw_content": "HERO’s Mission: Engineering ‘Video Games’ Meet Wave Tank Latest HERO WEC Mission Status Update Examines How NREL’s Wave Tank Validates Computer-Generated Scenarios for Wave Energy Converters Sept. 30, 2025 | By Brittany Enos | Contact media relations Share NREL Researcher Thanh Toan Tran prepares the scaled-down HERO WEC V2 model for wave tank testing in NREL's Sea Wave Environmental Lab. Photo by Gregory Cooper, NREL NREL’s hydraulic and electric reverse osmosis wave energy converter (HERO WEC) surfed the laboratory’s wave tank, facing another round of trials and tribulations to advance wave energy research. Since 2024 the team has been improving the HERO WEC’s robustness, reliability, and deployability by modifying different components on the device and testing the revised design. Researchers have already upgraded the winch line, which both anchors the WEC and allows it to move freely with the waves. In December 2024, they swapped the original wire rope with a polyurethane flat belt that overperformed in initial lab testing . Now, they are focusing on the WEC’s outer body and structure. The HERO WEC, which is funded by the U.S. Department of Energy's Water Power Technologies Office (WPTO) , can operate using either a hydraulic or an electrical configuration to pump seawater through an onshore reverse osmosis system to produce fresh drinking water (a process called desalination). Text version To help bolster the HERO WEC’s robustness, reliability, and survivability, the team is replacing the inflatable body with a more rigid, shell-like frame and moving the power system components to the top of the float (instead of inside). The original HERO WEC was constrained by the Waves to Water Prize shipping requirements—devices had to fit in a 3.5 x 3.5 x 3-foot container—which is why V1 used a compact, inflatable raft-like design. This original design worked well for two-week deployments, but it would not be able to withstand six months to a year in the harsh ocean environment. That is one reason the team is changing the device’s body for V2. Changing the WEC’s outer body to a more durable material can help it withstand storms and intense wave conditions. Moving the power system components to a more accessible place can also help improve maintenance and operations. But before solidifying these changes, the team wanted to ensure the accuracy of the computer simulations they used to evaluate the new shell’s efficiency and survivability. Like video games, engineering simulations use computer-generated environments. But engineering simulations go a step further by modeling and analyzing scenarios. NREL wave energy researchers use two different simulation tools— WEC-Sim and a computational fluid dynamics model—to create computer-generated environments, which predict and analyze how the HERO WEC will behave in real-world ocean conditions. These simulation tools involve complex mathematical models, so it is important to calibrate them and ensure the simulations accurately predict and analyze the real-world scenarios. Enter: the wave tank. The research team ran these same scenarios using NREL’s wave tank—also known as the Sea Wave Environmental Lab —to track the HERO WEC’s movement, position, and force on the anchor. The tank test data validated the computer-generated simulations and confirmed their accuracy. After validation, the team does not anticipate needing to put the HERO WEC back in the wave tank. Instead, they will rely on the simulation tools to find the ideal device shape and component configuration that maximizes the WEC’s power generation and water production while minimizing force on the anchor and WEC. While the HERO WEC V2 model tested in the wave tank was a miniature version (seven times smaller than the planned prototype), it helped researchers answer some big questions, including whether a new frame and component configuration is optimal for the HERO WEC V2. The HERO WEC V2 tank-test model surfs waves that mimic the wave conditions in North Carolina’s Outer Banks—the location where HERO WEC V1 underwent in-ocean testing. The model pictured here is seven times smaller than the planned prototype. Photo by Gregory Cooper, NREL Validating HERO WEC simulations through wave tank testing also allowed NREL researchers to evaluate WEC testing procedures at large. Specifically, they highlighted how both tank testing and simulation tools can benefit marine energy technologies. Tank testing can help researchers and technology developers understand early on if their simulation tools need refinement or how sensitive a design is to small tweaks. Certain factors, like the ocean’s resistance to the WEC’s motion, are difficult to calculate but can significantly impact how a prototype performs in the water. Tank testing is a quick and cost-effective way to verify that simulation tools are accurately calculating key factors. The results of these tests can provide critical guidance for researchers and developers before they build a full-scale WEC prototype, a costly step in developing marine energy devices. The more tests that the HERO WEC team runs, the more they help uncover the best approaches for WEC testing. By developing, refining, and standardizing an efficient testing process, NREL can help guide the marine energy industry as it develops energy conversion devices that are reliable and cost competitive. With the wave tank test complete, NREL researchers will now focus on building the HERO WEC’s new shell-like body and continue to run simulation models to inform the process. Stay tuned for more HERO WEC design updates, test results, and project milestones. Learn more about NREL's research in marine energy and the HERO WEC device and its open-source data . Then, subscribe to The Current —NREL's water power newsletter—to stay up to date on the latest research.", "release_time": "2025-10-01", "source_institution": "美国能源部国家可再生能源实验室", "url": "https://www.nrel.gov/news/detail/program/2025/heros-mission-engineering-video-games-meet-wave-tank"}
{"category": "研究前沿", "title": "新型并行流算法加速海量数据分析近两个数量级", "short_summary": "研究人员开发出多流并行计算模型，显著提升海量数据流分析速度，为AI应用铺路。", "detailed_summary": "研究人员开发出多流并行计算模型，显著提升海量数据流分析速度，为AI应用铺路。\n(1) 太平洋西北国家实验室与普渡大学的研究团队开发了名为\"多流并行\"的新型计算模型。\n(2) 该模型结合数据流处理与并行计算，将大型数据分析速度提升了近两个数量级。\n(3) 算法在有限内存下处理数据流，生成高质量摘要，解决了超级计算机也难以处理的海量数据存储问题。\n(4) 该技术能对极端规模数据进行降噪和预处理，使其成为\"AI就绪\"数据，提高人工智能分析的准确性。\n(5) 此项研究成果荣获2025年欧洲算法研讨会最佳论文奖，在科学仪器数据与AI分析间架设了桥梁。", "raw_content": "Just as streaming services have replaced CDs and DVDs by letting people watch or listen without downloading the content first, data streaming lets scientists analyze raw data from tools like microscopes and drones without needing to save the entire dataset beforehand. Recent award-winning research by S. M. Ferdous at Pacific Northwest National Laboratory (PNNL) and his collaborators Ahammed Ullah and Alex Pothen at Purdue University makes analyzing large data streams significantly faster, and in the process, can make extreme-scale data AI-ready. By combining streaming with parallel computing, the team developed an algorithm that speeds up data analysis by nearly two orders of magnitude. Powering a poly-streaming model with parallel computing For algorithm design and analysis, researchers use models of computation which are agreed-upon rules for what operations an algorithm can perform and what resources it can use. Different models capture different settings. The classic random access memory (RAM) model does not impose a strict memory limit, but in a streaming model, memory is limited. A streaming algorithm processes a large dataset sequentially, often in one or a few passes, while maintaining a compact summary that fits in its limited memory. These summaries are designed to recover a high-quality solution for the entire input. The poly-streaming approach allows for massive datasets to be analyzed while using small amounts of memory. (Animation by Nathan Johnson | Pacific Northwest National Laboratory) “The poly-streaming model generalizes streaming to many processors and streams,” said Ullah. “Each processor maintains a small local summary of what it sees. Processors communicate as needed, which helps them choose summaries of good quality while limiting the number of passes. With suitably designed algorithms, the combined summaries suffice to obtain a high-quality solution.” Ullah formulated the poly-streaming model as part of his PhD thesis in collaboration with Ferdous and Pothen. Within this framework, algorithms can jointly optimize time via parallel computing and space via data summarization. The researchers demonstrated its effectiveness using the maximum weight matching problem in graphs, which is a classical optimization problem with many applications. Making large datasets manageable “The size of data is getting larger and larger,” said Ferdous, a staff scientist and past Linus Pauling Fellow at PNNL. “When the datasets get too large, we can’t easily store them on a computer. At the same time, we need to solve larger and larger problems involving these datasets.” One solution has been to use supercomputers, such as exascale computers developed by the Department of Energy (DOE). However, some problems are too large for even the supercomputers to handle, and the large number of memory accesses increases the time needed to solve them. Streaming the datasets circumvents these memory storage issues, since only a small summary of the data is saved in the streaming mode, and the amount of memory needed to analyze the dataset is much smaller. “While this doesn’t give an exact solution, we can prove that the approximations are accurate; they are a factor of two off the best solution, in the worst case,” said Pothen, professor of computer science at Purdue University and Ullah’s PhD advisor. Making extreme-scale data ready for AI Optimization problems such as the maximum weight matching problem have many applications. One such application is in the field of AI, where the data may need to be denoised and reduced in size before it can be analyzed. The maximum weight matching problem can play a crucial role in processing data for AI tasks by identifying significant subsets of the data. This preprocessing step makes the data more relevant and leads to more accuracy in reasoning tasks. Making large datasets “AI-ready” can be a challenge. Taking raw data and running it through an AI model without first denoising the data or reducing its size may lead to inaccurate results or make the computations infeasible. “The poly-streaming model has the ability to process extreme-scale data,” said Ferdous. “Our model can act as the mediator between the raw data and the AI model by processing and making sense of the data before the AI model analyzes it further.” Looking ahead, the research team sees their model being especially applicable for processing the large amounts of data from DOE’s scientific user facilities and preparing it for AI analysis, bridging the gap between AI and instrumentation. The theoretical contributions, practical performance, and the applicability of the poly-streaming model were recognized with the ‘best paper’ prize at the recent European Symposium on Algorithms , which took place in Warsaw, Poland during September 15 – 17, 2025. This work was supported by the Advanced Scientific Computing Research program of the DOE Office of Science, and by PNNL’s Linus Pauling Distinguished Postdoctoral Fellowship.", "release_time": "2025-10-02", "source_institution": "美国能源部西北太平洋国家实验室", "url": "https://www.pnnl.gov/news-media/massive-datasets-meet-their-match"}
{"category": "产业应用", "title": "实验室购入萨博飞机提升多任务技术研发能力", "short_summary": "萨博飞机作为灵活测试平台，助力雷达与情报系统技术成熟并参与国家演习。", "detailed_summary": "萨博飞机作为灵活测试平台，助力雷达与情报系统技术成熟并参与国家演习。\n(1) 萨博飞机被描述为高度多任务能力的测试平台，支持国家安全技术研发，如机载雷达测试床（ARTB）的开发与应用。\n(2) ARTB采用开放式架构和电子扫描天线，用于射频技术成熟、系统概念原型设计及情报、监视与侦察任务演示。\n(3) 飞机近期参与国家演习，演示机器间提示多情报载荷自动识别目标，展示技术集成灵活性。\n(4) 经运营效益和成本分析，实验室决定购买该飞机以永久库存，便于长期基础设施更新和多团队协作。\n(5) 此次采购是飞行测试设施十年资本重组计划的一部分，旨在更换老旧飞机，支持新兴技术发展至2026年。", "raw_content": "\"Of all our aircraft, the Saab is the most multi-mission-capable,\" says David Culbertson, manager of the Flight Test Facility. \"It's highly versatile and adaptable, like a Swiss Army knife. Researchers from across the laboratory have conducted flight tests on the Saab to develop all kinds of technologies for national security.\" For example, the Saab was modified to host the Airborne Radar Testbed (ARTB), a high-performance radar system based on a computer-controlled array of antennas that can be electronically steered (instead of physically moved) in different directions. With the ARTB, researchers have matured innovative radio-frequency technology; prototyped advanced system concepts; and demonstrated concepts of operation for intelligence, surveillance, and reconnaissance (ISR) missions. With its open-architecture design and compliance with open standards, the ARTB can easily be reconfigured to suit specific R&D needs. \"The Saab has enabled us to rapidly prototype and mature the complex system-of-systems solutions needed to realize critical warfighter capabilities,\" says Ramu Bhagavatula, an assistant leader of the laboratory's Embedded and Open Systems Group . \"Recently, the Saab participated in a major national exercise as a surrogate multi-INT [intelligence] ISR platform. We demonstrated machine-to-machine cueing of our multi-INT payload to automatically recognize targets designated by an operational U.S. Air Force platform. The Saab's flexibility was key to integrating diverse technologies to develop this important capability.\" In anticipation of the expiration of the Saab's lease, the Flight Test Facility and Financial Services Department conducted an extensive analysis of alternatives. Comparing the operational effectiveness, suitability, and life-cycle cost of various options, this analysis determined that the optimal solution for the laboratory and the government was to purchase the aircraft. \"Having the Saab in our permanent inventory allows research groups from across the laboratory to continuously leverage each other's test beds and expertise,\" says Linda McCabe, a project manager in the laboratory's Communication Networks and Analysis Group . \"In addition, we can invest in long-term infrastructure updates that will benefit a wide range of users. For instance, my group helped obtain authorizations from various agencies to equip the Saab with Link 16, a secure communications network used by NATO and its allies to share tactical information.\" The Saab acquisition is part of a larger recapitalization effort at the Flight Test Facility to support emerging technology development for years to come. This 10-year effort, slated for completion in 2026, is retiring aging, obsolete aircraft and replacing them with newer platforms that will be more cost-effective to maintain, easier to integrate rapidly prototyped systems into, and able to operate under expanded flight envelopes (the performance limits within which an aircraft can safely fly, defined by parameters such as speed, altitude, and maneuverability).", "release_time": "2025-09-30", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/saab-340-becomes-permanent-flight-test-asset-lincoln-laboratory-0930"}
{"category": "研究前沿", "title": "MIT研究中心探索BRICS与全球治理新前沿", "short_summary": "MIT国际研究中心通过BRICS实验室分析全球治理转型，聚焦气候、AI等前沿挑战。", "detailed_summary": "MIT国际研究中心通过BRICS实验室分析全球治理转型，聚焦气候、AI等前沿挑战。\n（1）麻省理工学院国际研究中心（CIS）致力于以跨学科方式应对复杂全球挑战，其研究主任Mihaela Papa概述了中心使命。\n（2）新成立的BRICS实验室分析BRICS国家（现含11国）崛起对国际规则、市场和多边主义的影响，探讨其在粮食安全、气候变化等领域的作用。\n（3）中心当前核心研究优先领域包括安全研究、核安全编程、气候变化下的环境风险、全球治理模式转变以及人工智能对国际关系的重塑。\n（4）中心通过研讨会、资助项目和区域倡议（如MIT Amazonia社区）构建研究平台，连接学术与政策。", "raw_content": "The Center for International Studies (CIS) empowers students, faculty, and scholars to bring MIT’s interdisciplinary style of research and scholarship to address complex global challenges. In this Q&A, Mihaela Papa , the center's director of research and a principal research scientist at MIT, describes her role as well as research within the BRICS Lab at MIT — a reference to the BRICS intergovernmental organization, which comprises the nations of Brazil, Russia, India, China, South Africa, Egypt, Ethiopia, Indonesia, Iran and the United Arab Emirates. She also discusses the ongoing mission of CIS to tackle the world's most complex challenges in new and creative ways. Q: What is your role at CIS, and some of your key accomplishments since joining the center just over a year ago? A: I serve as director of research and principal research scientist at CIS, a role that bridges management and scholarship. I oversee grant and fellowship programs, spearhead new research initiatives, build research communities across our center's area programs and MIT schools, and mentor the next generation of scholars. My academic expertise is in international relations, and I publish on global governance and sustainable development, particularly through my new BRICS Lab. This past year, I focused on building collaborative platforms that highlight CIS’ role as an interdisciplinary hub and expand its research reach. With Evan Lieberman , the director of CIS, I launched the CIS Global Research and Policy Seminar series to address current challenges in global development and governance, foster cross-disciplinary dialogue, and connect theoretical insights to policy solutions. We also convened a Climate Adaptation Workshop, which examined promising strategies for financing adaptation and advancing policy innovation. We documented the outcomes in a workshop report that outlines a broader research agenda contributing to MIT’s larger climate mission. In parallel, I have been reviewing CIS’ grant-making programs to improve how we serve our community, while also supporting regional initiatives such as research planning related to Ukraine. Together with the center's MIT-Brazil faculty director Brad Olsen , I secured a MITHIC [MIT Human Insight Collaboration] Connectivity grant to build an MIT Amazonia research community that connects MIT scholars with regional partners and strengthens collaboration across the Amazon. Finally, I launched the BRICS Lab to analyze transformations in global governance and have ongoing research on BRICS and food security and data centers in BRICS. Q: Tell us more about the BRICS Lab. A: The BRICS countries comprise the majority of the world’s population and an expanding share of the global economy. [Originally comprising Brazil, Russia, India, and China, BRICS currently includes 11 nations.] As a group, they carry the collective weight to shape international rules, influence global markets, and redefine norms — yet the question remains: Will they use this power effectively? The BRICS Lab explores the implications of the bloc’s rise for international cooperation and its role in reshaping global politics. Our work focuses on three areas: the design and strategic use of informal groups like BRICS in world affairs; the coalition’s potential to address major challenges such as food security, climate change, and artificial intelligence; and the implications of U.S. policy toward BRICS for the future of multilateralism. Q: What are the center’s biggest research priorities right now? A: Our center was founded in response to rising geopolitical tensions and the urgent need for policy rooted in rigorous, evidence-based research. Since then, we have grown into a hub that combines interdisciplinary scholarship and actively engages with policymakers and the public. Today, as in our early years, the center brings together exceptional researchers with the ambition to address the world’s most pressing challenges in new and creative ways. Our core focus spans security, development, and human dignity. Security studies have been a priority for the center, and our new nuclear security programming advances this work while training the next generation of scholars in this critical field. On the development front, our work has explored how societies manage diverse populations, navigate international migration, as well as engage with human rights and the changing patterns of regime dynamics. We are pursuing new research in three areas. First, on climate change, we seek to understand how societies confront environmental risks and harms, from insurance to water and food security in the international context. Second, we examine shifting patterns of global governance as rising powers set new agendas and take on greater responsibilities in the international system. Finally, we are initiating research on the impact of AI — how it reshapes governance across international relations, what is the role of AI corporations, and how AI-related risks can be managed. As we approach our 75th anniversary in 2026, we are excited to bring researchers together to spark bold ideas that open new possibilities for the future.", "release_time": "2025-09-30", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/3-questions-mihaela-papa-addressing-world-challenges-0930"}
{"category": "研究前沿", "title": "星形胶质细胞调控神经元群体视觉编码机制获揭示", "short_summary": "MIT研究揭示星形胶质细胞通过GABA调节视觉皮层神经元协同工作。", "detailed_summary": "MIT研究揭示星形胶质细胞通过GABA调节视觉皮层神经元协同工作。\n（1）MIT团队通过新型CRISPR/Cas9技术敲除小鼠视觉皮层星形胶质细胞的Gat3蛋白；\n（2）Gat3缺失导致细胞外GABA水平升高，虽未改变单个神经元视觉特征响应，但破坏神经元群体编码协调性；\n（3）群体水平分析显示神经元活动预测性下降，视觉信息解码能力显著受损；\n（4）该发现首次在活体动物中揭示Gat3对神经集群功能的影响，为理解癫痫等神经系统疾病提供新视角。", "raw_content": "Cells called astrocytes are about as abundant in the brain as neurons, but scientists have spent much less time figuring out how they contribute to brain functions. A novel study by MIT researchers at The Picower Institute for Learning and Memory shows that one function appears to be maintaining the chemical conditions necessary for groups of neurons to team up to encode information. Specifically, the neuroscientists showed that when they knocked out the ability of astrocytes in the visual cortex of mice to produce a protein called “GABA transporter 3 (Gat3),” neurons there became less able, as a group, to represent information about the movies lab mice were seeing. GABA is a common inhibitory neurotransmitter that sharpens neural activity, and astrocytes uniquely use Gat3 to regulate the ambient level of GABA in their area. In the study in eLife , knocking out Gat3 in the visual cortex left neurons stewing in a soup of excess GABA that only produced subtle effects on individual neurons, but nevertheless added up to a significant impairment on their efforts as an ensemble responsible for visual function. “Even if the changes at the level of a single neuron representing a visual stimulus do not change significantly, if a hundred neurons have some small changes, that could add up at the population level to a measurable, significant change,” says senior author Mriganka Sur , Paul and Lilah Newton Professor in the Picower Institute and MIT’s Department of Brain and Cognitive Sciences (BCS). Notably, the authors wrote in eLife , this is the first study in live mice of Gat3 at scales spanning individual cells and functional ensembles of hundreds of them. To make the discovery, BCS graduate student Jiho Park used a novel implementation of CRISPR/Cas9 gene editing to knock out Gat3, combined with statistical and computational analyses of neural activity at the population level, Sur says. Gat out As neuroscientists have studied the brain’s visual system over many decades, neurons have claimed most of their attention because they are electrically active and more easily targeted genetically, Sur says. Technology for tracking astrocyte activity and for manipulating their function hasn’t developed as quickly. But in 2019, the National Institutes of Health gave Sur a grant to develop better tools for studying astrocytes. That funding helped the lab create the variant of CRISPR/Cas9 they call MRCUTS that enabled the new study. The tool allowed them to use just one viral vector to target the gene that encodes Gat3 for multiple cuts. That multiplexed attack decisively and precisely knocked it out in visual cortex astrocytes. Once Park knocked out Gat3, she could see the effects of its absence by visually tracking the calcium activity of neurons, a proxy for their electrical activity. The consequences were more subtle than the team expected. Awash in GABA, neurons fired less robustly and less reliably. When the mice were watching only a gray screen, instead of movies, the neurons would spontaneously activate less often, too. But to the researchers’ surprise, when Gat3 was gone the neurons individually still did their jobs. Cells that in the presence of Gat3 were responsive to different features of the images the mice were seeing, such as the orientation of lines, remained responsive even after Gat3 was knocked out. Although ambient levels of GABA were higher, pairs of neurons still shared GABA through their direct connections, or “synapses,” as before, meaning their direct dialogue with each other didn’t change. “We were expecting to see changes in orientation tuning, among other things, but we didn’t see that,” Park says. “That’s why we looked into deeper levels of analysis to see if there’s any difference.” Disrupted teamwork That deeper analysis occurred at the level of broader neural ensembles, where Park used several statistical and computational methods to analyze how the collective information encoding by hundreds of neurons changed when Gat3 was knocked out. Using a statistical method called a “Generalized Linear Model” to analyze patterns of activity across the ensemble, Park discovered that when Gat3 was knocked out, the activity of neurons became less predictive of the activity of others in the group compared to when Gat3 was present. This indicated that while individual neurons might still be doing what they were supposed to, their coordination was impaired. Meanwhile using a “Support Vector Machine”-based decoder to discern the information that ensembles were representing, she found that when Gat3 was present the decoder could improve its assessment as more neurons were added to its sample. But when Gat3 was knocked out, the decoder could no longer ascertain the represented information, even as its sample size increased. “The decoding deficits following Gat3 ablation provide evidence that astrocytic regulation of ambient GABA is essential for organizing the coordinated neuronal activity patterns necessary for efficient information encoding in visual cortical networks,” the authors wrote in eLife . Clinical cases The finding that a lack of Gat3 disrupts neural coordination at the population level might help explain clinical observations that Gat3 reduction in the thalamus increases seizure risk, Gat3 increase in the striatum contribute to repetitive behaviors, and Gat3 reduction in the globus pallidus impairs motor coordination, Park says. “Because our study is the first to look at Gat3 effects on a population level, it might help tie that back to some of the behavioral phenotypes people have been seeing,” Park says. But more research is needed, Sur notes, because there are other Gat proteins, such as Gat1, that the brain might use to compensate. In addition to Park and Sur, the paper’s other authors are Grayson Sipe, Xin Tang, Prachi Ojha, Giselle Fernandes, Yi Ning Leow, Caroline Zhang, Yuma Osako, Arundhati Natesan, Gabrielle Drummond, and Rudolf Jaenisch. The National Institutes of Health, a MURI Grant, The Simons Foundation Autism Research Initiative, the Freedom Together Foundation, and The Picower Institute for Learning and Memory provided funding for the study.", "release_time": "2025-10-01", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/study-finds-key-role-non-neural-brain-cells-processing-vision-0930"}
{"category": "研究前沿", "title": "阿秒光谱研究揭示钻石虚拟载流子关键作用", "short_summary": "国际团队发现虚拟载流子主导固体超快光学响应，推动皮赫兹电子器件发展。", "detailed_summary": "国际团队发现虚拟载流子主导固体超快光学响应，推动皮赫兹电子器件发展。\n(1) 研究由筑波大学、马克斯·普朗克研究所等机构合作，利用阿秒瞬态反射光谱技术分析单晶钻石对极短光脉冲的响应。\n(2) 通过对比实验与模拟，首次分离出材料电子带间虚拟垂直跃迁的关键影响，修正了极端条件下光固相互作用的理论认知。\n(3) 证实虚拟载流子激发在阿秒尺度上决定固体光学响应，对开发皮赫兹频率超快光学开关/调制器（比现有设备快千倍）至关重要。\n(4) 研究成果为ERC AuDACE等欧州国家级项目组成部分，标志着超快电子技术发展的关键突破。", "raw_content": "The research, conducted in partnership with the University of Tsukuba, the Max Planck Institute for the Structure and Dynamics of Matter, and the Institute of Photonics and Nanotechnology (Cnr-Ifn) investigated the behavior of monocrystalline diamonds subjected to light pulses lasting a few attoseconds (billionths of a billionth of a second), using an advanced technique called attosecond-scale transient reflection spectroscopy. By comparing experimental data with state-of-the-art numerical simulations, researchers were able to isolate the effect of so-called virtual vertical transitions between the electronic bands of the material. Such an outcome changes the perspective on how light interacts with solids, even in extreme conditions hitherto attributed only to the movement of actual charges. \"Our work shows that virtual carrier excitation, which develops in a few billionths of a billionth of a second, are indispensable to correctly predict the rapid optical response in solids,\" said Matteo Lucchini, professor at the Department of Physics, senior author of the study, and associate at CNR-Ifn. \"These results mark a key step in the development of ultra-fast technologies in electronics,\" adds Rocío Borrego Varillas, researcher at CNR-IFN. The progress achieved offers new insights into the creation of ultra-fast optical devices, such as switches and modulators capable of operating at petahertz frequencies, a thousand times faster than current electronic devices. This requires a deep understanding of both the behavior of actual charges, and of virtual charges, as demonstrated by this study. Research was carried out at the Attosecond Research Center (ARC) of the Politecnico di Milano, in the framework of the European and national projects ERC AuDACE (Attosecond Dynamics in AdvanCed matErials) and MIUR FARE PHorTUNA (PHase Transition Ultrafast dyNAmics in Mott insulators).", "release_time": "2025-09-30", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250929055000.htm"}
{"category": "研究前沿", "title": "MIT加入巨型麦哲伦望远镜联盟推动前沿天文研究", "short_summary": "MIT获赠款加入巨型麦哲伦望远镜项目，增强美国在极大型望远镜领域领导地位。", "detailed_summary": "MIT获赠款加入巨型麦哲伦望远镜项目，增强美国在极大型望远镜领域领导地位。\n(1) MIT宣布加入巨型麦哲伦望远镜国际联盟，成为第16个成员，参与推动这一位于智利、总投资26亿美元的天文台建设。\n(2) 该望远镜孔径25.4米，集光面积是现有观测站的五倍，探测能力高达200倍，目前已完成40%建设。\n(3) MIT的参与由慈善家Ragon夫妇的变革性赠款促成，旨在巩固美国在天体物理学领域的领导地位，是国家极大型望远镜计划的核心部分。\n(4) 该项目将极大提升MIT在天体物理学、系外行星、黑洞等前沿领域的研究与教育能力，预计2030年代投入运行。", "raw_content": "The following article is adapted from a joint press release issued today by MIT and the Giant Magellan Telescope. MIT is lending its support to the Giant Magellan Telescope , joining the international consortium to advance the $2.6 billion observatory in Chile. The Institute’s participation, enabled by a transformational gift from philanthropists Phillip (Terry) Ragon ’72 and Susan Ragon, adds to the momentum to construct the Giant Magellan Telescope, whose 25.4-meter aperture will have five times the light-collecting area and up to 200 times the power of existing observatories. “As philanthropists, Terry and Susan have an unerring instinct for finding the big levers: those interventions that truly transform the scientific landscape,” says MIT President Sally Kornbluth. “We saw this with their founding of the Ragon Institute, which pursues daring approaches to harnessing the immune system to prevent and cure human diseases. With today’s landmark gift, the Ragons enable an equally lofty mission to better understand the universe — and we could not be more grateful for their visionary support.\" MIT will be the 16th member of the international consortium advancing the Giant Magellan Telescope and the 10th participant based in the United States. Together, the consortium has invested $1 billion in the observatory — the largest-ever private investment in ground-based astronomy. The Giant Magellan Telescope is already 40 percent under construction, with major components being designed and manufactured across 36 U.S. states. “MIT is honored to join the consortium and participate in this exceptional scientific endeavor,” says Ian A. Waitz, MIT’s vice president for research. “The Giant Magellan Telescope will bring tremendous new capabilities to MIT astronomy and to U.S. leadership in fundamental science. The construction of this uniquely powerful telescope represents a vital private and public investment in scientific excellence for decades to come.” MIT brings to the consortium powerful scientific capabilities and a legacy of astronomical excellence. MIT’s departments of Physics and of Earth, Atmospheric and Planetary Sciences, and the MIT Kavli Institute for Astrophysics and Space Research, are internationally recognized for research in exoplanets, cosmology, and environments of extreme gravity, such as black holes and compact binary stars. MIT’s involvement will strengthen the Giant Magellan Telescope’s unique capabilities in high-resolution spectroscopy, adaptive optics, and the search for life beyond Earth. It also deepens a long-standing scientific relationship: MIT is already a partner in the existing twin Magellan Telescopes at Las Campanas Observatory in Chile — one of the most scientifically valuable observing sites on Earth, and the same site where the Giant Magellan Telescope is now under construction. “Since Galileo’s first spyglass, the world’s largest telescope has doubled in aperture every 40 to 50 years,” says Robert A. Simcoe, director of the MIT Kavli Institute and the Francis L. Friedman Professor of Physics. “Each generation’s leading instruments have resolved important scientific questions of the day and then surprised their builders with new discoveries not yet even imagined, helping humans understand our place in the universe. Together with the Giant Magellan Telescope, MIT is helping to realize our generation’s contribution to this lineage, consistent with our mission to advance the frontier of fundamental science by undertaking the most audacious and advanced engineering challenges.” Contributing to the national strategy MIT’s support comes at a pivotal time for the observatory. In June 2025, the National Science Foundation (NSF) advanced the Giant Magellan Telescope into its Final Design Phase , one of the final steps before it becomes eligible for federal construction funding. To demonstrate readiness and a strong commitment to U.S. leadership, the consortium offered to privately fund this phase, which is traditionally supported by the NSF. MIT’s investment is an integral part of the national strategy to secure U.S. access to the next generation of research facilities known as “extremely large telescopes.” The Giant Magellan Telescope is a core partner in the U.S. Extremely Large Telescope Program, the nation’s top priority in astronomy . The National Academies’ Astro2020 Decadal Survey called the program “absolutely essential if the United States is to maintain a position as a leader in ground-based astronomy.” This long-term strategy also includes the recently commissioned Vera C. Rubin Observatory in Chile. Rubin is scanning the sky to detect rare, fast-changing cosmic events, while the Giant Magellan Telescope will provide the sensitivity, resolution, and spectroscopic instruments needed to study them in detail. Together, these Southern Hemisphere observatories will give U.S. scientists the tools they need to lead 21st-century astrophysics. “Without direct access to the Giant Magellan Telescope, the U.S. risks falling behind in fundamental astronomy, as Rubin’s most transformational discoveries will be utilized by other nations with access to their own ‘extremely large telescopes’ under development,” says Walter Massey, board chair of the Giant Magellan Telescope. MIT’s participation brings the United States a step closer to completing the promise of this powerful new observatory on a globally competitive timeline. With federal construction funding, it is expected that the observatory could reach 90 percent completion in less than two years and become operational by the 2030s. “MIT brings critical expertise and momentum at a time when global leadership in astronomy hangs in the balance,” says Robert Shelton, president of the Giant Magellan Telescope. “With MIT, we are not just adding a partner; we are accelerating a shared vision for the future and reinforcing the United States’ position at the forefront of science.” Other members of the Giant Magellan Telescope consortium include the University of Arizona, Carnegie Institution for Science, The University of Texas at Austin, Korea Astronomy and Space Science Institute, University of Chicago, São Paulo Research Foundation (FAPESP), Texas A&M University, Northwestern University, Harvard University, Astronomy Australia Ltd., Australian National University, Smithsonian Institution, Weizmann Institute of Science, Academia Sinica Institute of Astronomy and Astrophysics, and Arizona State University. A boon for astrophysics research and education Access to the world’s best optical telescopes is a critical resource for MIT researchers. More than 150 individual science programs at MIT have relied on major astronomical observatories in the past three years, engaging faculty, researchers, and students in investigations into the marvels of the universe. Recent research projects have included chemical studies of the universe’s oldest stars , led by Professor Anna Frebel; spectroscopy of stars shredded by dormant black holes , led by Professor Erin Kara; and measurements of a white dwarf teetering on the precipice of a black hole , led by Professor Kevin Burdge. “Over many decades, researchers at the MIT Kavli Institute have used unparalleled instruments to discover previously undetected cosmic phenomena from both ground-based observations and spaceflight missions,” says Nergis Mavalvala, dean of the MIT School of Science and the Curtis (1963) and Kathleen Marble Professor of Astrophysics. “I have no doubt our brilliant colleagues will carry on that tradition with the Giant Magellan Telescope, and I can’t wait to see what they will discover next.” The Giant Magellan Telescope will also provide a platform for advanced R&D in remote sensing, creating opportunities to build custom infrared and optical spectrometers and high-speed imagers to further study our universe. “One cannot have a leading physics program without a leading astrophysics program. Access to time on the Giant Magellan Telescope will ensure that future generations of MIT researchers will continue to work at the forefront of astrophysical discovery for decades to come,” says Deepto Chakrabarty, head of the MIT Department of Physics, the William A. M. Burden Professor in Astrophysics, and principal investigator at the MIT Kavli Institute. “Our institutional access will help attract and retain top researchers in astrophysics, planetary science, and advanced optics, and will give our PhD students and postdocs unrivaled educational opportunities.”", "release_time": "2025-09-30", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/mit-joins-constructing-giant-magellan-telescope-0930"}
{"category": "研究前沿", "title": "新型锰二硼化物合成成功，火箭燃料效能提升显著", "short_summary": "锰二硼化物较现用铝燃料能量提升超20%，兼具高安全性与多领域应用潜力。", "detailed_summary": "锰二硼化物较现用铝燃料能量提升超20%，兼具高安全性与多领域应用潜力。\n（1）美国奥尔巴尼大学团队成功合成新型化合物锰二硼化物（MnB₂），其重量能量密度比现用固体火箭助推器铝燃料高20%以上，体积能量密度高150%；  \n（2）该化合物通过电弧熔炼技术在3000℃高温下合成，其分子结构存在不对称“变形”，像被压缩的弹簧储存高能量；  \n（3）锰二硼化物安全性高，仅在与煤油等点火剂接触时燃烧，有望为火箭节省燃料空间、增加科研载荷；  \n（4）硼基结构具多功能性，同期研究显示其还可用于制造更耐用汽车催化转换器、催化塑料降解等领域；  \n（5）此项研究体现了新材料化学探索价值，为能源、环保等多领域技术革新提供新可能。", "raw_content": "\"In rocket ships, space is at a premium,\" said Assistant Professor of Chemistry Michael Yeung, whose lab led the work. \"Every inch must be packed efficiently, and everything onboard needs to be as light as possible. Creating more efficient fuel using our new compound would mean less space is needed for fuel storage, freeing up room for equipment, including instruments used for research. On the return voyage, this could mean more space is available to bring samples home.\" The newly synthesized compound, manganese diboride (MnB 2 ), is over 20% more energetic by weight and about 150% more energetic by volume compared to the aluminum currently used in solid rocket boosters. Despite being highly energetic, it is also very safe and will only combust when it meets an ignition agent like kerosene. The underlying boron-based structure is also versatile; related research in the Yeung lab has demonstrated its potential to help build more durable catalytic converters for cars and serve as a catalyst for breaking down plastics. It Takes Heat to Make Heat Manganese diboride belongs to a class of chemical compounds thought to have unusual properties, yet exploring what exactly these properties entail has been limited by an inability to actually produce the compound. \"Diborides first started getting attention in the 1960s,\" said UAlbany PhD student Joseph Doane, who works with Yeung. \"Since these initial looks, new technologies are allowing us to actually synthesize chemical compounds that were once only hypothesized to exist. \"Knowing what we do about the elements on the periodic table, we suspected that manganese diboride would be structurally asymmetrical and unstable -- factors which together would make it highly energetic -- but until recently, we couldn't test it because it couldn't be made. Successfully synthesizing pure manganese diboride is an exciting achievement in and of itself. And now, we can test it experimentally and discover new ways to put it to use.\" Synthesizing manganese diboride requires extreme heat generated using a tool called an \"arc melter.\" The first step involves pressing manganese and boron powders together into a pellet, which is placed in a small, reinforced glass chamber. The arc melter trains a narrow electrical current on the pellet, heating it to a scorching 3,000°C (over 5,000°F). The molten material is then rapidly cooled to lock the structure in place. At the atomic level, this process forces a central manganese atom to bond to too many other atoms, making for an overly crowded structure packed tight like a coiled spring. 3...2...1... Deformation! When exploring new chemical compounds, being able to physically produce the compound is critical. You also need to be able to define its molecular structure, in order to better understand why it behaves the way it does. UAlbany PhD student Gregory John, who works with computational chemist Alan Chen, built computer models to visualize manganese diboride's molecular structure. These models revealed something critical: a subtle skew, known as \"deformation,\" which gives the compound its high potential energy. \"Our model of the manganese diboride compound looks like a cross section of an ice cream sandwich, where the outer cookies are made of a lattice structure comprised of interlocking hexagons,\" said John. \"When you look closely, you can see that the hexagons aren't perfectly symmetrical; they're all a little skewed. This is what we call 'deformation.' By measuring the degree of deformation, we can use that measure as a proxy to determine the amount of energy stored in the material. That skew is where the energy is stored.\" Here's another way to picture it. \"Imagine a flat trampoline; there's no energy there when it's flat,\" said Yeung. \"If I put a gigantic weight in the center of the trampoline, it will stretch. That stretch represents energy being stored by the trampoline, which it will release when the object is removed. When our compound ignites, it's like removing the weight from the trampoline and the energy is released.\" New Materials Need New Compounds \"There's this consensus among chemists that boron-based compounds should have unusual properties that make them behave unlike any other existing compounds,\" said Associate Professor of Chemistry Alan Chen. \"There's an ongoing quest to figure out what those properties and behaviors are. This sort of pursuit is at the heart of materials chemistry, where creating harder, stronger more extreme materials requires forging brand-new chemicals. This is what the Yeung lab is doing -- with findings that could improve rocket fuel, catalytic converters and even processes for recycling plastics. \"This study is also a great example of the scientific process, where researchers pursue interesting chemical properties even when they're not certain what specific applications might emerge. Sometimes, present case included, the results are serendipitous.\" Yeung's interest in boron compounds started when he was a grad student at the University of California, Los Angeles. His project was aiming to discover compounds harder than diamond. \"I distinctly remember the first time I made a compound related to manganese diboride,\" Yeung said. \"There I was, holding this new material that was supposed to be super hard. Instead, it started to get hot and changed into a pretty orange color. I thought, 'Why is it orange? Why is it glowing? It shouldn't be glowing!' That's when I realized how energetic boron compounds can be. I put a pin in it to explore in the future, and that's exactly what we are working on now.\"", "release_time": "2025-09-30", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250929055022.htm"}
{"category": "产业应用", "title": "俄罗斯炼焦煤价创年内新高", "short_summary": "俄炼焦煤价因中国补库及澳洲供应风险支撑升至年内高点。", "detailed_summary": "俄炼焦煤价因中国补库及澳洲供应风险支撑升至年内高点。\n（1）俄罗斯远东港口炼焦煤价格在9月中下旬创年内新高，库兹巴斯炼焦煤离岸价达每吨119美元；\n（2）价格上涨主要受中国国庆前补库需求及澳大利亚供应可能减少的风险支撑；\n（3）澳大利亚多家公司因价格下跌、成本上升关闭矿井，促使中国转向俄蒙等替代供应；\n（4）俄罗斯炼焦煤主要出口中国和印度，印度因国内供应有限需求持续增长；\n（5）分析师预测全球煤炭低价周期可能持续两到三年，缺乏持续上涨基础。", "raw_content": "俄罗斯东部炼焦煤价格已达到年初以来的最高点，中国终端企业在国庆前的补库以及澳大利亚存在供应减少的风险，支撑了国际炼焦煤的价格，不过中国国内炼焦煤价格上涨乏力可能会限制价格的涨幅。 根据俄罗斯价格指数中心(PIC)的数据，截至9月中下旬，远东港口库兹巴斯炼焦煤价格上涨8.2%，至每吨119美元(离岸价)，喷吹煤(PCI LV)价格上涨10.9%，至每吨123美元(离岸价)，这些价格均创下今年以来的最高水平。PIC主任叶夫根尼·格拉乔夫表示，中国各行业的反内卷以及国庆节前夕的补库需求，支撑了俄罗斯煤炭价格。 据PIC报告，许多煤炭生产商称截至10月初，其可用煤炭采购量已全部售出。分析师称，截至9月中下旬，138家公司的普通炼焦煤库存下降5.4%，至230万吨，洗精煤库存下降6.6%，至190万吨。 与此同时，格拉乔夫先生继续说道，澳大利亚炼焦煤供应量可能会下降，几家澳大利亚大型公司已宣布在昆士兰州裁员并关闭部分矿井，主要原因是全球煤炭价格下跌、成本上升以及税负过高。分析认为澳大利亚供应量的下降支撑了价格，并使替代供应更受欢迎。 叶夫根尼·格拉乔夫表示，由于俄罗斯和蒙古的煤炭价格低于澳大利亚煤炭，中国终端企业对于澳洲炼焦煤的需求正在下降。T-Investments首席分析师阿赫迈德·阿利耶夫指出，俄罗斯90%的炼焦煤出口到中国和印度，但对俄罗斯企业来说，向中国供应煤炭也不是稳赚不赔。他指出，库兹巴斯煤矿的净回值仍然无法覆盖生产成本，目前远东地区焦煤离岸价的净回值上涨了8.3%，达到每吨5700卢布。 除了中国外，印度仍然是俄罗斯钢铁流向的主要目的地。印度对钢铁的需求不断增长，而其国内优质焦煤供应有限。有专家预测，到2030年印度的进口需求将从2025年的约8700万吨增至约1.35亿吨。此外土耳其也仍然是俄罗斯供应商的重要市场，那里的高炉产量不断增减，刺激了对焦煤的需求。 国家外汇管理局评级服务部主任谢尔盖·格里舒宁表示，总体而言尽管个别市场价格出现上涨，但近期煤炭价格缺乏持续上涨的基础。根据国家石油和天然气研究公司(NEFT Research)的预测，全球市场低迷的煤炭价格周期可能持续两到三年。 责任编辑： 张磊 标签：俄罗斯,炼焦煤价格 上一篇：陕煤澄合百良公司：党建引领聚合力，支部堡... 下一篇：1-8月全国煤炭开采和洗选业实现利润19...", "release_time": "2025-09-29", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194555-1.html"}
{"category": "产业应用", "title": "抗病花椰菜新品种发布，助力毛里求斯农业可持续发展", "short_summary": "IAEA合作推出抗病花椰菜新品，降低农药成本并提升农产品安全与农民收入。", "detailed_summary": "IAEA合作推出抗病花椰菜新品，降低农药成本并提升农产品安全与农民收入。\n（1）国际原子能机构与毛里求斯专家合作推出新型花椰菜品种\"Local Cream\"；\n（2）该品种经田间评估证实具有高抗病性并能生产高品质产品；\n（3）作为开放授粉品种，可帮助农民节省种子成本，减少对进口依赖；\n（4）种植该品种能显著降低农药使用成本，为消费者提供更安全、美味的农产品；\n（5）未来合作将致力于开发具有抗病性和高营养价值的本地卷心菜与胡萝卜新品种。", "raw_content": "Farmer Feedback The new variety has already proven its worth in the field: two highly experienced cauliflower farmers, Vikash Caleechurn and Seewan Coonjul, were involved in an on-farm evaluation and confirmed that the Local Cream variety is highly tolerant to the disease and produces a high-quality product. \"The benefits of Local Cream are clear,” explained Gashaw Wolde, IAEA Director of the TC Division for Africa, during the launch of the new variety. “The farmers cultivating this variety no longer incur heavy costs for chemical controls; consumers enjoy safer produce; and, as an open-pollinated variety, Local Cream empowers smallholders to save and exchange seed, fostering self-reliance and reducing dependency on imports.\" The launch of Local Cream is expected to bring significant benefits to the agricultural community. The availability of a disease-tolerant, open-pollinated variety of cauliflower will help farmers cut pesticide costs and improve their income, while providing consumers with a safer, high-quality, tasty product. This collaborative effort between the IAEA and Mauritian experts represents a major step forward in building a more resilient and sustainable agricultural sector for the island nation. The national IAEA technical cooperation programme for Mauritius will continue to support the work of FAREI and Mauritian experts as they work towards the development of new local cabbage and carrot varieties with tolerance for various plant diseases and with high nutritional value.", "release_time": "2025-09-30", "source_institution": "国际原子能机构", "url": "https://www.iaea.org/newscenter/news/nuclear-science-delivers-disease-resistant-cauliflower-in-mauritius"}
{"category": "研究前沿", "title": "量子传感突破海森堡不确定性原理测量极限", "short_summary": "悉尼大学团队实现粒子位置动量同步精密测量，为超灵敏量子传感器奠定基础。", "detailed_summary": "悉尼大学团队实现粒子位置动量同步精密测量，为超灵敏量子传感器奠定基础。\n（1）研究突破海森堡不确定性原理限制，首次实验实现位置与动量的同步精密测量；\n（2）采用量子计算中的网格态技术，利用囚禁离子振动模拟量子钟摆；\n（3）通过\"模块化测量\"策略将量子不确定性转移到不关注的宏观参数上；\n（4）测量精度突破标准量子极限，但未违反量子力学基本原理；\n（5）该技术有望推动导航、生物成像和基础物理等领域的超灵敏传感应用。", "raw_content": "The Heisenberg uncertainty principle, introduced in 1927, says that you can't know certain pairs of properties - such as a particle's position and momentum - with unlimited precision at the same time. In other words, there is always a trade-off in uncertainty: the more closely one property is pinned down, the less certainty there is about the other. In research published Sept. 24 in Science Advances , a team led by Dr Tingrei Tan from the University of Sydney Nano Institute and School of Physics has shown how to engineer a different trade-off to precisely measure position and momentum at the same time. \"Think of uncertainty like air in a balloon,\" said Dr Tan, a Sydney Horizon Fellow in the Faculty of Science. \"You can't remove it without popping the balloon, but you can squeeze it around to shift it. That's effectively what we've done. We push the unavoidable quantum uncertainty to places we don't care about (big, coarse jumps in position and momentum) so the fine details we do care about can be measured more precisely.\" The researchers also use the analogy of a clock to explain their findings (see image). Think of a normal clock with two hands: the hour hand and the minute hand. Now imagine the clock only has one hand. If it's the hour hand, you can tell what hour it is and roughly what minute, but the minute reading will be very imprecise. If the clock only has the minute hand, you can read the minutes very precisely, but you lose track of the larger context - specifically, which hour you're in. This 'modular' measurement sacrifices some global information in exchange for much finer detail. \"By applying this strategy in quantum systems, we can measure the changes in both position and momentum of a particle far more precisely,\" said first author Dr Christophe Valahu from the Quantum Control Laboratory team at the University of Sydney. \"We give up global information but gain the ability to detect tiny changes with unprecedented sensitivity.\" Quantum computing tools for a new sensing protocol This strategy was outlined theoretically in 2017. Here, Dr Tan's team performed the first experimental demonstration by using a technological approach they had previously developed for error-corrected quantum computers, a result recently published in Nature Physics . \"It's a neat crossover from quantum computing to sensing,\" said co-author Professor Nicolas Menicucci, a theorist from RMIT University. \"Ideas first designed for robust quantum computers can be repurposed so that sensors pick up weaker signals without being drowned out by quantum noise. The Sydney team implemented the sensing protocol using the tiny vibrational motion of a trapped ion - the quantum equivalent of a pendulum. They prepared the ion in \"grid states,\" a kind of quantum state originally developed for error-corrected quantum computing. With this, they showed that both position and momentum can be measured together with precision beyond the 'standard quantum limit' - the best achievable using only classical sensors. \"We haven't broken Heisenberg's principle. Our protocol works entirely within quantum mechanics,\" said Dr Ben Baragiola, co-author from RMIT. \"The scheme is optimised for small signals, where fine details matter more than coarse ones. Why it matters The ability to detect extremely small changes is important across science and technology. Ultra-precise quantum sensors could sharpen navigation in environments where GPS doesn't work (such as submarines, underground or spaceflight); enhance biological and medical imaging; monitor materials and gravitational systems; or probe fundamental physics. While still at the laboratory stage, the experiment demonstrates a new framework for future sensing technologies targeted towards measuring tiny signals. Rather than replacing existing approaches, it adds a complementary tool to the quantum-sensing toolbox. \"Just as atomic clocks transformed navigation and telecommunications, quantum-enhanced sensors with extreme sensitivity could enable whole new industries,\" said Dr Valahu. A collaborative effort This project united experimentalists at the University of Sydney with theorists at RMIT, the University of Melbourne, Macquarie University and the University of Bristol in Britain. It shows how collaboration across institutions and borders can accelerate progress and strengthen Australia's quantum research community. \"This work highlights the power of collaboration and the international connections that drive discovery,\" Dr Tan said.", "release_time": "2025-09-29", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250928095633.htm"}
{"category": "产业应用", "title": "全球最大108MW氢燃料电池发电厂开建", "short_summary": "韩国开建全球最大氢燃料电池厂，2028年投运以稳定电网并驱动区域经济。", "detailed_summary": "韩国开建全球最大氢燃料电池厂，2028年投运以稳定电网并驱动区域经济。\n(1) 韩国庆州市开建全球最大108MW氢燃料电池发电厂，总投资约5.8亿美元，计划2028年投运。\n(2) 项目初期使用天然气现场制取的灰色氢气发电，为电网提供基本负荷供电。\n(3) 旨在稳定庆州、浦项、蔚山等东海岸工业带的电力供需，应对数据中心激增的用电需求。\n(4) 获得地方政府65亿韩元投资及国家公共机构贷款担保，并签有长期可再生能源证书合同以确保收益。\n(5) 被视为推动当地能源转型和经济振兴的标志性项目，旨在构建可持续能源生态系统。", "raw_content": "世界上最大的氢燃料电池发电厂——韩国的108MW设施——已开始建设。 位于韩国庆尚北道省东南部城市庆州市的江东氢燃料电池发电项目耗资8191亿韩元(约合5.807亿美元)，将从2028年起利用天然气在现场生产的灰色氢气，为电网提供基本负荷供电。 该项目由当地公司ESD Holdings和江东能源公司(Gangdong Energy)共同开发，将超过目前在韩国仁川市的79MW新仁川愿景梦想氢燃料电池发电厂。 庆尚北道省认为，该发电厂将能够稳定位于庆州、浦项和蔚山等东海岸工业带的供电与需求，并应对数据中心及其他设施快速增加的电力需求。 “能源是未来产业的稻米，”省长Lee Cheol-woo在周四举行的官方奠基仪式上表示。“这座发电厂的建设不仅仅意味着发电。将丰富的电力资源与未来的产业投资联系起来非常重要，这将推动当地经济的振兴。我们还将特别关注未来的后续投资项目，使庆州成为韩国能源转型和新兴增长产业的重要枢纽。” 该项目去年11月被选入政府支持的区域振兴投资基金，将获得该省政府一笔65亿韩元的投资，该投资将保留该设施8%的股份。 此外，该项目还获得了韩国住房和城市担保公司(HUG)的贷款担保，该公司是一家全国性公共机构，已使开发商能够从私营和公共金融机构获得低于市场地位的贷款利率。 该项目还获得了私营火力发电公司的长期可再生能源供应证书(REC)合同，以确保稳定利润——尽管所消耗的氢气将由无增天然气制造，这一过程将向大气中释放大量具有地球变暖的二氧化碳。 标准蒸汽甲烷重整每生产1公斤氢气，可释放8至12千克二氧化碳。不过，燃料电池(通过反向电解方式将氢气与空气中的氧气结合产生电能)在运行过程中不会排放温室气体。 “江东绿色能源项目不仅在韩国，也在全球能源市场是一个具有象征意义的项目，”ESD控股公司首席执行官Yoo Soo-kyung表示。“它将成为通过环保燃料电池与当地社区共存，以构建可持续能源生态系统的榜样。” (素材来自：Gangdong Energy/ESD Holdings 全球氢能网、新能源网综合) 责任编辑： 张磊 标签：氢燃料电池 上一篇：27省份出台136号文细则，深刻重构储能... 下一篇：最后一页", "release_time": "2025-09-29", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194545-1.html"}
{"category": "研究前沿", "title": "研究揭示微藻H3K4表观遗传调控低碳适应机制", "short_summary": "多维表观基因组图谱解析微藻低碳适应，为碳固定效率提升提供新策略。", "detailed_summary": "多维表观基因组图谱解析微藻低碳适应，为碳固定效率提升提供新策略。\n(1) 青岛能源所团队以海洋微拟球藻为模式，构建涵盖DNA甲基化、组蛋白修饰等多维度表观基因组动态图谱；\n(2) 系统解析微藻从高CO2向低CO2环境转变过程中的表观遗传重编程；\n(3) 发现H3K4me2等激活型组蛋白修饰与43.1%差异表达基因相关，富集于光合作用等核心通路；\n(4) 基因编辑验证显示H3K4甲基转移酶敲除株生长速率下降22%，证实其关键调控作用；\n(5) 研究为提升工业微藻碳固定效率、理解海洋碳循环及人工碳汇工程提供新靶点与理论支撑。", "raw_content": "海洋微藻是全球碳循环的重要驱动力，通过光合作用每年固定约110亿吨碳，占全球初级生产力的50%以上。由于水体中CO2溶解度较低，微藻在进化过程中形成了高效的CO2浓缩机制。然而，这一机制在低CO2条件下的激活涉及多细胞器协同与代谢网络重编程，深层调控机理尚未完全阐明。近年来，DNA甲基化、组蛋白修饰等表观遗传调控逐渐被证实是光合生物适应环境胁迫的核心机制，但工业微藻的表观基因组研究却一直缺乏系统性、多维度的表观遗传调控图谱，严重限制了对其低碳适应策略的理解。针对这一问题，青岛能源所单细胞中心公衍海副研究员和王勤涛副研究员带领的研究团队以海洋微拟球藻为模式，通过涵盖DNA甲基化、组蛋白修饰、核小体占位及三维染色质结构等多维度表观基因组测序，构建了适应低CO2浓度的工业微藻多维度表观遗传调控动态图谱，系统解析了微拟球藻从高CO2（5%）向低CO2（0.01%）环境转变过程中的表观遗传动态，进而通过遗传工程的验证，揭示了H3K4组蛋白修饰在低碳适应中的重要贡献与调控机制（图1），为提升工业产油微藻碳固定效率提供了全新的改造策略与靶点。图1 多维表观基因组分析揭示H3K4组蛋白修饰调控微拟球藻适应低CO2的过程首先，研究团队通过构建多层次表观基因组图谱，并结合转录组数据进行高碳与低碳下的差异分析，研究发现微拟球藻的全基因组甲基化水平仅为0.13%，且低碳条件下无显著变化；激活型组蛋白修饰（H3K4me2、H3K9ac、H3K27ac和Kcr）与43.1%的差异表达基因显著相关，这些基因富集于核糖体的生物合成、光合作用、基因表达等核心代谢通路；低碳条件下染色体局部区室转换与基因表达变化显著相关，且H3K4me2修饰可能通过介导染色质开放状态调控靶基因转录。研究团队采用CRISPR-Cas9基因编辑技术敲除了H3K4甲基转移酶基因NO24G02310，发现H3K4me1在全基因组水平的丰度显著降低，H3K4me2发生全基因组范围的定位偏移，突变株的生长速率下降约22%，生物量积累量降低约15%，表明H3K4修饰在微拟球藻低碳适应过程中具有关键调控作用。对NoHINT与NoPMA2基因的敲除及过表达实验发现，H3K4修饰可能通过调控特定酶的互作网络及改变叶绿体跨膜pH梯度，参与微拟球藻低碳适应。该研究共构建73个表观基因组数据集，生成总量达504 Gb的高质量数据，系统揭示了微拟球藻在低碳环境下的表观遗传重编程过程，并锁定了一批具有潜力的基因改造靶点，为通过基因编辑优化微藻碳固定效率、推动生物能源开发及高附加值产物产业化提供了坚实的数据支撑。与此同时，研究阐明了微藻依靠表观遗传重编程实现快速低碳适应的分子机制，有助于深刻理解真核微藻在海洋碳循环中的作用机制，为预测海洋生态系统在气候变化背景下的响应，以及人工碳汇工程的设计与应用奠定了重要的理论基础。研究所有数据已通过NCBI和NanDeSyn数据库（https://nandesyn.single-cell.cn）向全球科研界开放共享，助力光合生物表观遗传学研究的持续发展。上述研究成果近期发表于《植物通讯》（Plant Communications），由单细胞中心徐健研究员和孙鲁阳研究员主持完成，海南师范大学魏力副教授和海南大学辛一研究员亦参与了本研究。该研究得到国家重点研发计划和国家自然科学基金等项目的支持。（文/公衍海 图/刘阳） 原文链接：https://doi.org/10.1016/j.xplc.2025.101534 Yanhai Gong#, Qintao Wang#, Li Wei, Lianhong Wang, Nana Lv, Xuefeng Du, Chen Shen, Yi Xin, Luyang Sun*, Jian Xu*. Multi-dimensional epigenomic dynamics converge on H3K4 regulation of low CO2 adaptation in Nannochloropsis oceanica. Plant Communications, 2025.", "release_time": "2025-10-17", "source_institution": "青岛生物能源与过程研究所", "url": "https://qibebt.cas.cn/news/kyjz/202509/t20250929_7982686.html"}
{"category": "产业应用", "title": "日立能源投2.7亿加元扩产变压器，助力能源转型", "short_summary": "日立能源加投2.7亿加元扩产变压器，产能近翻三倍并创造500岗位。", "detailed_summary": "日立能源加投2.7亿加元扩产变压器，产能近翻三倍并创造500岗位。\n(1) 日立能源宣布追加2.7亿加元投资，扩建其位于加拿大蒙特利尔附近瓦雷讷的大功率变压器制造工厂。\n(2) 此次扩建将使该工厂年产能提升近三倍，并创造约500个新工作岗位。\n(3) 该项目是日立能源90亿美元全球投资计划的一部分，旨在满足能源转型中对变压器日益增长的需求。\n(4) 变压器是能源价值链的关键组件，支持大规模输电、数据中心、可再生能源并网和交通电气化。\n(5) 投资将增强加拿大清洁能源制造能力，支持电网现代化和能源安全，并获得加拿大政府官员的支持。", "raw_content": "Expansion to nearly triple production capacity and create more than 500 jobs; builds on prior $140 million CAD investment ($100 million USD) Will address fast-growing demand for electricity in Canada and globally, which requires urgent investment and innovation to meet infrastructure needs Rendering of Hitachi Energy's Varennes facility, post-expansion aerial view Varennes, September 29, 2025 – Hitachi Energy, the world's leading electrification company, today announced an additional $270 million CAD ($195 million USD) investment to expand its large power transformer manufacturing facility near Montreal, Canada. This major investment, which builds on an ongoing expansion announced in 2024 , will nearly triple the site's annual production capacity, reinforcing Canada's role as a beacon of clean-energy manufacturing for the world. This effort is part of Hitachi Energy's $9 billion USD global investment program, the largest in the industry to expand manufacturing capacity, R&D, and engineering. This latest expansion will create approximately 500 new jobs and bring significant benefits to the local economy. With more than half of the value of goods sold from Varennes typically sourced locally, the investment will spur further economic development in the region. Transformers are a critical component of the energy value chain, enabling efficient transmission and distribution of electricity. They support applications such as large-scale transmission systems, data center operations, grid interconnections, integration of renewable energy, and the electrification of transportation, all of which are essential to the decarbonization of energy systems. In Canada, large power transformers are also vital in supporting energy-intensive industries such as mining, aluminum production, and steel manufacturing, which are foundational to the national economy. The Varennes expansion is a significant step in Hitachi Energy's global plan to increase transformer production capacity to meet growing mid- and long-term customer needs in the energy transition. “With this expansion, Varennes will continue to play a leading role in strengthening the region's power grid. Our team is proud to be at the forefront of delivering sustainable, reliable, and resilient energy infrastructure for decades to come,” says Bruno Melles, Managing Director of Business Unit Transformers, Hitachi Energy. “This investment will allow us to significantly increase our ability to meet the fast-growing demand for large power transformers, reactors, and HVDC technology, which are critical to achieving key energy transition goals,” added Carla Vicente, Country Managing Director, Hitachi Energy in Canada. The Varennes facility is one of the largest manufacturers of HVDC transformers in the world and is also CSA N299-certified for nuclear quality assurance. These capabilities position the site to address unprecedented demand for transformers driven by the expansion of nuclear power generation, increased interconnection between jurisdictions, the refurbishment of existing infrastructure, and surging electricity demand from data centers and continued growth in renewable sources. “Hitachi Energy Canada plays a strategic role in Quebec's energy development. It is the only company in North America that produces transformers of this magnitude. Drawing on a strong pool of Quebec expertise, it stands as one of the pillars of our energy security and will continue to be a leader in the green economy. We are proud to support its expansion project in Varennes, which will mark a new stage in its growth while creating many high-quality, well-paying jobs here in Quebec,” said Christine Fréchette, Minister of Economy, Innovation and Energy. “Clean, reliable energy is at the center of our government's plan to position Canada as an energy superpower. Investing in our domestic advanced manufacturing and research capabilities, like Hitachi Energy Canada, will strengthen Canada's energy sovereignty and create the jobs and expertise necessary to fortify our grid needs that will power Canadian prosperity and economic resiliency,” said the Honorable Mélanie Joly, Minister of Industry and Minister responsible for Canada Economic Development for Quebec Regions. “Canada is competing and winning in the race to build the strongest clean economy. By supporting Hitachi Energy's expansion in Quebec, we are shoring up our domestic manufacturing capacity, securing the supply of critical grid technologies, and creating hundreds of good-paying jobs. Projects like this are proof that Canada has the people, expertise, and the ambition to be a true energy superpower, delivering reliable electricity to Canadians and clean power solutions to the world,\" said the Honorable Tim Hodgson, Minister of Energy and Natural Resources. The project will significantly improve production flow. Planned improvements include a state-of-the-art assembly line and the addition of two flexible core and winding feeding lines, ensuring greater production continuity. The factory fully integrates Hitachi Energy's TrafoStar™ transformer technology platform, which harmonizes transformer design, manufacturing processes, and quality control measures across all power transformer factories worldwide. As the world's leading electrification company and the largest transformer manufacturer, Hitachi Energy is advancing grid modernization with industry-leading solutions and a commitment to achieving carbon-neutral operations by 2030. About Hitachi Energy Hitachi Energy is a global technology leader in electrification, powering a sustainable energy future with innovative power grid technologies with digital at the core. Over three billion people depend on our technologies to power their daily lives. With over a century in pioneering mission-critical technologies like high-voltage, transformers, automation, and power electronics, we are addressing the most urgent energy challenge of our time – balancing soaring electricity demand, while decarbonizing the power system. With an unparalleled installed base in over 140 countries, we co-create and build long-term partnerships across the utility, industry, transportation, data centers, and infrastructure sectors. Headquartered in Switzerland, we employ over 50,000 people in 60 countries and generate revenues of around $16 billion USD. https://www.hitachienergy.com https://www.linkedin.com/company/hitachienergy https://twitter.com/HitachiEnergy About Hitachi, Ltd. Through its Social Innovation Business (SIB) that brings together IT, OT (Operational Technology) and products, Hitachi contributes to a harmonized society where the environment, wellbeing, and economic growth are in balance. Hitachi operates globally in four sectors – Digital Systems & Services, Energy, Mobility, and Connective Industries – and the Strategic SIB Business Unit for new growth businesses. With Lumada at its core, Hitachi generates value from integrating data, technology and domain knowledge to solve customer and social challenges. Revenues for FY2024 (ended March 31, 2025) totaled 9,783.3 billion yen, with 618 consolidated subsidiaries and approximately 280,000 employees worldwide. Visit us at www.hitachi.com About Lumada In order to read a PDF file, you need to have Adobe Acrobat Reader installed in your computer. Information contained in this news release is current as of the date of the press announcement, but may be subject to change without prior notice.", "release_time": "2025-10-07", "source_institution": "日本日立", "url": "http://www.hitachi.com/New/cnews/month/2025/09/250930c.html"}
{"category": "研究前沿", "title": "NREL开展下一代电池安全研究，利用AI加速评估", "short_summary": "NREL聚焦下一代电池安全，通过多尺度建模与AI预测风险，推动高安全性能源存储发展。", "detailed_summary": "NREL聚焦下一代电池安全，通过多尺度建模与AI预测风险，推动高安全性能源存储发展。\n（1）NREL研究人员在《自然》发表观点文章，系统评估下一代电池（如碱金属阳极、固态电解质）的安全风险；\n（2）研究采用高速X射线成像、多尺度建模和人工智能技术，分析电池在滥用条件下的失效机制；\n（3）重点关注新材料的动力学特性、毒性、机械鲁棒性及灭火策略等差异化的安全挑战；\n（4）通过跨尺度数据评估（从材料到电池组），预测大型商用电池的安全行为；\n（5）研究成果将加速下一代电池设计，提升从消费电子到电网存储等应用场景的安全性。", "raw_content": "Safer Batteries, Reliable Power: Guiding Research for Next-Generation Energy Storage Sept. 29, 2025 | By Rebecca Martineau | Contact media relations Share NREL’s extensive portfolio of battery-safety research includes high-speed X-ray imaging to show what happens during battery failure. Image by Donal Finegan, NREL Tucked into your pocket, packed into warehouses, and embedded into critical infrastructure—lithium-ion batteries are quietly powering much of modern America. Demand for these indispensable energy storage solutions continues to skyrocket, prompting energy experts to explore next-generation (next-gen) designs for higher-performing technologies, including alkali metal anodes, solid electrolytes, and Earth-abundant cathode materials. However, safety is paramount to ensuring the successful deployment of these systems. “Over the years, battery researchers and engineers have developed a deep understanding of the factors that lead to failure in conventional lithium-ion batteries. However, the behavior of next-gen batteries is not yet well understood,” said Donal Finegan, a senior energy storage scientist at NREL. “We are seeing key differences in the kinetics, toxicity, mechanical robustness, and fire-suppression strategies for new materials. The better we understand these risks, the safer we can design and prepare battery systems of the future.” A recent Nature perspective authored by NREL researchers including Finegan takes a closer look at the current landscape of battery safety research, emphasizing new risks and opportunities of up-and-coming energy storage technologies. In addition, this perspective proposes a strategic approach to evaluating battery safety at the electrode, pack, and cell level. This rigorous process considers different conditions—such as limiting oxygen index, abuse conditions, state of charge, and cycle history—with respect to benchmark battery behavior. A Safety-First Approach to Battery Research NREL is a global leader in battery safety research , offering cutting-edge characterization, advanced machine learning , and multiscale modeling to evaluate energy storage systems. Researchers work closely with industry innovators to share knowledge and access to lab-scale capabilities, overcoming challenges to bring new technologies to the market. “Battery safety research is a cornerstone of our work at NREL and crucial to strengthening America’s energy infrastructure,” said NREL Senior Energy Storage Engineer and Manager Matt Keyser. “Safer batteries increase energy availability to power everything from consumer electronics to national security systems. However, we need a targeted strategy to expand battery safety research to support the development and adoption of new battery technologies.” NREL implements a rigorous process to evaluate the safety of battery designs, employing a holistic approach to characterize cells and materials to understand their responses to various abuse conditions throughout their lifetime. Insights from battery safety research are crucial to refining cell designs, determining safe operating systems, and standardizing practices to guide first responders in handling battery hazards. While some of these changes open the door to safer, more resilient, and lighter battery systems, they also bring challenges, such as managing rapid gas release, toxic byproducts, and extreme thermal reactions. Established methods for quantifying hazards of traditional lithium-ion batteries can be directly applied to next-gen cells, but there are other areas that require additional attention. It can take years to scale research from new materials to battery pack-level testing, but recent breakthroughs in modeling and artificial intelligence can accelerate the process and advance our understanding of new materials. These techniques uncover new insights into the safety of emerging battery designs, predicting how they will behave in different applications, such as grid-scale storage. NREL’s expertise in this area enables researchers to evaluate data across length scales, from microscopic samples to larger-format cell sizes, and explain differences in cell safety behaviors as a function of their size and abuse condition. “We’ve developed modeling strategies that bridge the gap between safety data generated at the material level and the behavior of large commercial batteries,” Finegan said. “Artificial intelligence will play a central role in quickly predicting how batteries will behave under different conditions in real-world scenarios to evaluate the safety of future battery designs.” Learn more about NREL's energy storage and transportation and mobility research. And sign up for NREL's transportation and mobility research newsletter to stay current on the latest news.", "release_time": "2025-09-30", "source_institution": "美国能源部国家可再生能源实验室", "url": "https://www.nrel.gov/news/detail/program/2025/safer-batteries-reliable-power-guiding-research-for-next-generation-energy-storage"}
{"category": "研究前沿", "title": "MIT研究证实海绵为地球最早动物", "short_summary": "MIT团队通过化学化石证据发现海绵祖先早于5.41亿年前已存在。", "detailed_summary": "MIT团队通过化学化石证据发现海绵祖先早于5.41亿年前已存在。\n(1) MIT地球化学家在超过5.41亿年前的岩石中发现特殊甾烷化学化石，证实其为古代海绵生物标志物；\n(2) 研究通过分析阿曼、印度和西伯利亚的埃迪卡拉纪岩石样本，结合现代海绵甾醇比对和实验室化学合成进行三重验证；\n(3) 发现的C30和C31甾烷证明海绵祖先在寒武纪生命大爆发前已存在，是地球最早动物之一；\n(4) 该研究建立了可靠的生物标志物认证方法，为追溯早期生命演化提供新工具。", "raw_content": "A team of MIT geochemists has unearthed new evidence in very old rocks suggesting that some of the first animals on Earth were likely ancestors of the modern sea sponge. In a study appearing today in the Proceedings of the National Academy of Sciences , the researchers report that they have identified “chemical fossils” that may have been left by ancient sponges in rocks that are more than 541 million years old. A chemical fossil is a remnant of a biomolecule that originated from a living organism that has since been buried, transformed, and preserved in sediment, sometimes for hundreds of millions of years. The newly identified chemical fossils are special types of steranes, which are the geologically stable form of sterols, such as cholesterol, that are found in the cell membranes of complex organisms. The researchers traced these special steranes to a class of sea sponges known as demosponges. Today, demosponges come in a huge variety of sizes and colors, and live throughout the oceans as soft and squishy filter feeders. Their ancient counterparts may have shared similar characteristics. “We don’t know exactly what these organisms would have looked like back then, but they absolutely would have lived in the ocean, they would have been soft-bodied, and we presume they didn’t have a silica skeleton,” says Roger Summons, the Schlumberger Professor of Geobiology Emeritus in MIT’s Department of Earth, Atmospheric and Planetary Sciences (EAPS). The group’s discovery of sponge-specific chemical fossils offers strong evidence that the ancestors of demosponges were among the first animals to evolve, and that they likely did so much earlier than the rest of Earth’s major animal groups. The study’s authors, including Summons, are lead author and former MIT EAPS Crosby Postdoctoral Fellow Lubna Shawar, who is now a research scientist at Caltech, along with Gordon Love from the University of California at Riverside, Benjamin Uveges of Cornell University, Alex Zumberge of GeoMark Research in Houston, Paco Cárdenas of Uppsala University in Sweden, and José-Luis Giner of the State University of New York College of Environmental Science and Forestry. Sponges on steroids The new study builds on findings that the group first reported in 2009 . In that study, the team identified the first chemical fossils that appeared to derive from ancient sponges. They analyzed rock samples from an outcrop in Oman and found a surprising abundance of steranes that they determined were the preserved remnants of 30-carbon (C 30 ) sterols — a rare form of steroid that they showed was likely derived from ancient sea sponges. The steranes were found in rocks that were very old and formed during the Ediacaran Period — which spans from roughly 541 million to about 635 million years ago. This period took place just before the Cambrian, when the Earth experienced a sudden and global explosion of complex multicellular life. The team’s discovery suggested that ancient sponges appeared much earlier than most multicellular life, and were possibly one of Earth’s first animals. However, soon after these findings were released, alternative hypotheses swirled to explain the C 30 steranes’ origins, including that the chemicals could have been generated by other groups of organisms or by nonliving geological processes. The team says the new study reinforces their earlier hypothesis that ancient sponges left behind this special chemical record, as they have identified a new chemical fossil in the same Precambrian rocks that is almost certainly biological in origin. Building evidence Just as in their previous work, the researchers looked for chemical fossils in rocks that date back to the Ediacaran Period. They acquired samples from drill cores and outcrops in Oman, western India, and Siberia, and analyzed the rocks for signatures of steranes, the geologically stable form of sterols found in all eukaryotes (plants, animals, and any organism with a nucleus and membrane-bound organelles). “You’re not a eukaryote if you don’t have sterols or comparable membrane lipids,” Summons says. A sterol’s core structure consists of four fused carbon rings. Additional carbon side chain and chemical add-ons can attach to and extend a sterol’s structure, depending on what an organism’s particular genes can produce. In humans, for instance, the sterol cholesterol contains 27 carbon atoms, while the sterols in plants generally have 29 carbon atoms. “It’s very unusual to find a sterol with 30 carbons,” Shawar says. The chemical fossil the researchers identified in 2009 was a 30-carbon sterol. What’s more, the team determined that the compound could be synthesized because of the presence of a distinctive enzyme which is encoded by a gene that is common to demosponges. In their new study, the team focused on the chemistry of these compounds and realized the same sponge-derived gene could produce an even rarer sterol, with 31 carbon atoms (C 31 ). When they analyzed their rock samples for C 31 steranes, they found it in surprising abundance, along with the aforementioned C 30 steranes. “These special steranes were there all along,” Shawar says. “It took asking the right questions to seek them out and to really understand their meaning and from where they come.” The researchers also obtained samples of modern-day demosponges and analyzed them for C 31 sterols. They found that, indeed, the sterols — biological precursors of the C 31 steranes found in rocks — are present in some species of contemporary demosponges. Going a step further, they chemically synthesized eight different C 31 sterols in the lab as reference standards to verify their chemical structures. Then, they processed the molecules in ways that simulate how the sterols would change when deposited, buried, and pressurized over hundreds of millions of years. They found that the products of only two such sterols were an exact match with the form of C 31 sterols that they found in ancient rock samples. The presence of two and the absence of the other six demonstrates that these compounds were not produced by a random nonbiological process. The findings, reinforced by multiple lines of inquiry, strongly support the idea that the steranes that were found in ancient rocks were indeed produced by living organisms, rather than through geological processes. What’s more, those organisms were likely the ancestors of demosponges, which to this day have retained the ability to produce the same series of compounds. “It’s a combination of what’s in the rock, what’s in the sponge, and what you can make in a chemistry laboratory,” Summons says. “You’ve got three supportive, mutually agreeing lines of evidence, pointing to these sponges being among the earliest animals on Earth.” “In this study we show how to authenticate a biomarker, verifying that a signal truly comes from life rather than contamination or non-biological chemistry,” Shawar adds. Now that the team has shown C 30 and C 31 sterols are reliable signals of ancient sponges, they plan to look for the chemical fossils in ancient rocks from other regions of the world. They can only tell from the rocks they’ve sampled so far that the sediments, and the sponges, formed some time during the Ediacaran Period. With more samples, they will have a chance to narrow in on when some of the first animals took form. This research was supported, in part, by the MIT Crosby Fund, the Distinguished Postdoctoral Fellowship program, the Simons Foundation Collaboration on the Origins of Life, and the NASA Exobiology Program.", "release_time": "2025-09-30", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/first-animals-earth-may-have-been-sea-sponges-study-suggests-0929"}
{"category": "研究前沿", "title": "MIT研发地质聚合物智能灯笼，推动可持续电子发展", "short_summary": "MIT设计实验室利用地质聚合物制造嵌入式电子灯笼，提供低碳可持续材料新方案。", "detailed_summary": "MIT设计实验室利用地质聚合物制造嵌入式电子灯笼，提供低碳可持续材料新方案。\n(1) MIT设计智能实验室主任Marcelo Coelho教授团队研发了一款名为\"Geolectric\"的定制灯笼。\n(2) 该项目的核心是使用地质聚合物作为嵌入式计算机和消费电子产品的可持续材料替代品。\n(3) 地质聚合物是一种无机材料，具有高强度、耐久性、防火和隔热性，且制造过程无需高温烧制，碳足迹低于传统陶瓷和混凝土。\n(4) 灯笼内置定制电子元件，可作为接近和触摸传感器，手放在顶部时灯光会沿玻璃管照射。\n(5) 这项研究为减少电子产品对气候的负面影响、支持循环经济提供了新的技术路径。", "raw_content": "No ordinary lantern The bespoke lantern was created by Marcelo Coelho SM ’08, PhD ’12, director of the Design Intelligence Lab and associate professor of the practice in the Department of Architecture. One of several projects in the Geoletric research at the Design Intelligence Lab, the lantern showcases the use of geopolymers as a sustainable material alternative for embedded computers and consumer electronics. “The materials that we use to make computers have a negative impact on climate, so we’re rethinking how we make products with embedded electronics — such as a lamp or lantern — from a climate perspective,” says Coelho. Consumer electronics rely on materials that are high in carbon emissions and difficult to recycle. As the demand for embedded computing increases, so too does the need for alternative materials that have a reduced environmental impact while supporting electronic functionality. The Geolectric lantern advances the formulation and application of geopolymers — a class of inorganic materials that form covalently bonded, non-crystalline networks. Unlike traditional ceramics, geopolymers do not require high-temperature firing, allowing electronic components to be embedded seamlessly during production. Geopolymers are similar to ceramics, but have a lower carbon footprint and present a sustainable alternative for consumer electronics, product design, and architecture. The minerals Coelho uses to make the geopolymers — aluminum silicate and sodium silicate — are those regularly used to make ceramics. “Geopolymers aren’t particularly new, but are becoming more popular,” says Coelho. “They have high strength in both tension and compression, superior durability, fire resistance, and thermal insulation. Compared to concrete, geopolymers don’t release carbon dioxide. Compared to ceramics, you don’t have to worry about firing them. What’s even more interesting is that they can be made from industrial byproducts and waste materials, contributing to a circular economy and reducing waste.” The lantern is embedded with custom electronics that serve as a proximity and touch sensor. When a hand is placed over the top, light shines down the glass tubes. The timeless design of the Geoelectric lantern — minimalist, composed of natural materials — belies its future-forward function. Coelho’s academic background is in fine arts and computer science. Much of his work, he says, “bridges these two worlds.” Working at the Design Intelligence Lab with Coelho on the lanterns are Jacob Payne, a graduate architecture student, and Jean-Baptiste Labrune, a research affiliate. A light for MIT A few weeks before commencement, Sarkis saw the Geoelectric lantern in Palazzo Diedo Berggruen Arts and Culture in Venice, Italy . The exhibition, a collateral event of the Venice Biennale’s 19th International Architecture Exhibition, featured the work of 40 MIT architecture faculty. The sustainability feature of Geolectric is the key reason Sarkis regarded the lantern as the perfect gift for Robinson. After her career in politics, Robinson founded the Mary Robinson Foundation — Climate Justice, an international center addressing the impacts of climate change on marginalized communities. The third iteration of Geolectric for Sarkis’ office is currently underway. While the lantern was a technical prototype and an opportunity to showcase his lab’s research, Coelho — an immigrant from Brazil — was profoundly touched by how Sarkis created the perfect symbolism to both embody the welcoming spirit of the school and honor President Robinson. “When the world feels most fragile, we need to urgently find sustainable and resilient solutions for our built environment. It’s in the darkest times when we need light the most,” says Coelho.", "release_time": "2025-09-30", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/beacon-of-light-geolectric-lantern-0929"}
{"category": "产业应用", "title": "全球冶金煤需求分析：2025年挑战与趋势", "short_summary": "冶金煤市场面临价格低迷与供应受限，印度需求成关键增长驱动力。", "detailed_summary": "冶金煤市场面临价格低迷与供应受限，印度需求成关键增长驱动力。\n(1) 当前冶金煤价格处于四年低位，新加坡基准期货在173-188美元/吨区间波动；\n(2) 澳大利亚主导全球供应链，但新矿开发有限，仅三座计划2030年前投产；\n(3) 印度成为最重要增长市场，计划十年内钢铁产量翻番至3亿吨；\n(4) 绿色钢铁转型速度低于预期，因技术障碍和基础设施限制；\n(5) 长期价格受供应有限和亚洲需求支撑，预计2025年底开始复苏。", "raw_content": "澳大利亚Discovery Alert网站9月25日发布报告，标题为“全球冶金煤需求：2025年的挑战与未来趋势”(Global Metallurgical Coal Demand: Challenges and Future Trends in 2025)。 全球冶金煤需求如何演变? 冶金煤面临一个由短期挑战和长期结构性变化组成的复杂市场格局。当前的市场指标显示，价格徘徊在四年来的最低点，新加坡交易所的基准期货在2025年3月降至每吨173.50美元，随后在9月稳定在188.25美元左右。这种价格弱势已经促使一些生产暂停，例如，澳大利亚昆士兰州的必和必拓集团最近关闭了其Saraji South矿井。 尽管面临这些短期挑战，从中长期来看，由于发展中国家对钢铁生产需求的增加、冶金煤供应有限以及向绿色钢铁技术转型的速度比预期的慢，前景呈现出不同的画面。最近的南非煤炭增产只是在当前市场压力下，该行业继续投资的一个例子。 当前市场动态和价格趋势 2025年的冶金煤需求由于2025年前七个月全球钢铁产量下降1.9%，主要产国供应充足，以及全球经济逆风影响全球工业活动而面临显著的下行压力。 这为生产者创造了一个具有挑战性的环境，特别是那些运营成本较高的或面临税收增加的生产者，正如昆士兰州的特许权使用费增加到煤炭价格超过每吨175澳元(117美元)时为20%，超过300澳元时为40%所证明的那样。此外，关税对市场的影响为国际煤炭贸易商增加了另一层复杂性。 谁控制全球冶金煤供应链? 海运冶金煤市场仍然高度集中在少数几个主要出口国家： 澳大利亚的主导地位源于其高质量的储备、已建立的基础设施以及靠近亚洲市场。这种集中可能导致潜在的供应漏洞，特别是因为全球范围内计划的新矿很少。加拿大在这个市场上的地位越来越受到能源转型挑战的影响，对其 broader 资源部门造成影响。 供应约束与发展前景 供应前景似乎越来越受到限制，只有三座新的冶金煤矿计划在2030年前开始运营： 1. 彭布罗克资源公司在澳大利亚昆士兰州的橄榄谷项目 2. 另一个项目在澳大利亚昆士兰州 3. 美国的一个项目 有限的新开发项目与一些现有生产活动即将结束的计划生产寿命重合，这可能在未来几年造成供应缺口。 为什么印度对冶金煤需求变得至关重要? 印度是冶金煤最重要的增长市场，计划在未来十年内将钢铁产量翻一番，达到3亿多吨。与中国逐渐转向替代钢铁制造技术不同，印度继续扩大基本氧气炉(BOF)产能，这需要冶金煤作为关键输入。 印度钢铁产能扩张计划 印度钢铁行业的增长规模相当大： 对BOF技术的这种强烈关注表明，印度对冶金煤进口的需求将持续增长，因为印度主要依赖国内生产热煤，并且必须进口大部分的冶金煤需求。正如国际能源署的煤炭市场更新中所述，印度的钢铁产能扩张将成为未来十年冶金煤消费的关键驱动力。 绿色钢铁雄心如何影响冶金煤市场? 钢铁行业向低排放生产方法的转变对冶金煤需求构成了重大的长期挑战。然而，最近的发展表明，这一转变的速度比最初预期的要慢。 挑战阻碍绿色钢的采用 几个因素导致对快速绿色钢铁实施的热情减弱： 1. 经济障碍：为直接还原铁(DRI)生产建造绿色氢气工厂所需的高资本成本 2. 基础设施限制：可再生能源容量不足，无法大规模生产氢气 3. 技术障碍：在将基于氢的还原技术扩展到商业可行性方面的持续挑战 4. 市场现实：继续在发展中的亚洲建设传统的顶吹转炉钢铁设施 这些挑战导致许多钢铁制造商在短期内减少了他们对绿色钢铁的雄心，这表明冶金煤将在未来几十年内继续成为全球钢铁生产中的关键组成部分。正在进行的采矿业演变可能会在传统煤炭开采与新技术之间取得平衡。 冶金煤的长期价格影响是什么? 尽管当前市场疲软，受限的供应和传统钢铁制造的持续需求为冶金煤生产商创造了潜在的长期有利价格环境。 价格支持因素 几个结构性因素表明中长期内冶金煤价格将走强： 1. 有限的新供应：很少的新矿在开发中，以取代逐渐枯竭的矿山 2. 亚洲钢铁增长：印度和其他亚洲发展中国家的钢铁生产持续扩张 3. 高昂的开发成本：新项目需要持续的高价格才能实现经济可行性 4. 行业整合：主要生产商如必和必拓优化生产，专注于高毛利率的业务 这些因素表明， 冶金煤metallurgical coal 价格可能需要从当前水平大幅上涨，以激励开发新的供应能力，以满足未来的需求。 根据最新 Fastmarkets 分析，这种价格复苏可能最早在 2025 年底开始。 监管和政策变化如何影响该行业? 政府政策和监管框架显著影响冶金煤市场的供应和需求双方。最近的发展突显了经济、环境和财政考虑之间的复杂互动。 税收和特许权使用费制度 澳大利亚昆士兰州政府在2022年大幅提高了煤炭特许权使用费，实施了一档阶梯结构，对于每吨超过300澳元的价格，税率可高达40%。这一政策变化受到了包括必和必拓首席执行官迈克·英厄姆在内的行业领导人的批评，他们将其视为公司决定暂停其萨拉吉南矿 operations的原因之一。 这些更高的税收水平可能会影响现有业务和未来开发项目的经济可行性，可能会限制澳大利亚——该市场的主要出口国——的供应增长。 环境政策和碳减排目标 虽然环境政策旨在减少钢铁生产中的碳排放，但替代煤炭钢铁生产的方法在实际实施中面临重大障碍： 1. 技术成熟度：基于氢的直接还原技术及其他替代方案仍处于早期商业部署阶段 2. 成本竞争力：传统转炉炼钢在许多市场保持经济优势 3. 基础设施要求：绿色钢铁技术需要大量的支持基础设施 4. 地区差异：不同的气候政策在市场之间造成了不均衡的转型压力 这些因素导致钢铁行业中从冶金煤使用向非冶金煤使用的转型速度比许多政策框架最初设想的要缓慢。尽管面临这些挑战，行业仍在继续探索采矿脱碳的好处，并在各个方面进行探索。 冶金煤市场未来会怎样? 冶金煤市场似乎有望从当前的价格低迷中复苏，这得益于超越短期市场疲软的基本供应-需求动态。 需要关注的关键趋势 1. 印度钢铁扩张：印度钢铁生产和冶金煤进口的持续增长 2. 供应合理化：如果价格持续低迷，高成本运营将进一步减产 3. 新项目开发：目前在途的有限的新矿项目的时机和规模 4. 绿色钢铁进展：替代钢铁制造方法的技术进步和商业化进展 5. 中国钢铁生产：中国经济结构改革和环保政策中的中国钢铁行业演变 这些相互关联的因素将决定未来十年冶金煤需求和定价的轨迹，供应限制可能会在绿色钢铁制造技术的长期转型继续进行的同时，形成价格支撑。 责任编辑： 张磊 标签：全球冶金煤 上一篇：九月份煤炭市场情况分析及后期走势判断 下一篇：中国中煤：向智向新 坚定做好煤炭清洁高效...", "release_time": "2025-09-29", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194562-1.html"}
{"category": "研究前沿", "title": "我国全超导磁体创35.1特斯拉稳态磁场世界纪录", "short_summary": "我国研制全超导磁体实现35.1特斯拉稳态磁场，突破国际关键技术瓶颈。", "detailed_summary": "我国研制全超导磁体实现35.1特斯拉稳态磁场，突破国际关键技术瓶颈。\n（1）中国科学院等离子体所牵头联合团队研制全超导磁体实现35.1特斯拉中心稳态磁场，创造新的世界纪录；\n（2）采用高温超导内插磁体技术，解决了低温高场下应力集中、屏蔽电流效应等关键难题；\n（3）磁体稳定运行30分钟后安全退磁，验证了技术可靠性，为高场科学研究提供实验平台；\n（4）实现了关键材料、工艺、制备100%自主可控，推动高温超导材料产业技术升级；\n（5）成果为核磁共振成像、航天电磁推进、超导磁悬浮等多领域产业化应用提供关键技术支撑。", "raw_content": "等离子体所研制全超导磁体实现35.1特斯拉稳态磁场 2025-09-28 | 作者：等离子体所应用超导研究室团队 |【 大 中 小 】 【打印】 【关闭】 近日，由中国科学院合肥物质院等离子体物理研究所牵头，联合合肥国际应用超导中心、合肥综合性国家科学中心能源研究院、清华大学共同研制的全超导磁体，实现了35.1特斯拉中心稳态磁场，创造新的世界纪录。 该磁体采用高温超导内插磁体技术，与低温超导磁体同轴嵌套构建，其中高温超导材料由上海超导科技股份有限公司提供。团队运用万匝级高场磁体多物理场协同优化方法与高应力调控工艺，有效解决了低温高场下的应力集中、屏蔽电流效应、多场耦合效应等难题，大幅提升磁体在极端工况下的力学稳定性与电磁性能。该磁体励磁至35.1特斯拉，稳定运行30分钟后安全退磁，充分验证了技术方案的可靠性，为在全超导磁体35.1特斯拉条件下开展各类样品实验提供了强有力平台。 等离子体所深耕全超导托卡马克技术研究，布局高温超导材料在聚变磁体中的应用研究。聚焦强场高载流磁体技术验证，突破电缆绕制、导体集成、接头制备等核心技术瓶颈，攻克聚变高温超导百千安级电流引线、数万安级CICC导体、纳欧级导体低阻接头、亚米级线圈制备系列关键技术及关键装备平台搭建。2024年高温超导CICC导体在国际上首次实现80千安@10.85特斯拉背景磁场稳定运行，并一次性通过国际权威机构测试。在低温超导导体及接头等磁体关键技术领域也取得突破性进展，攻克接头电阻纳欧级批量化稳定制备技术，实现大尺寸磁体毫米级高精度成型，为托卡马克装置工程化奠定了基础。 本次成果实现了超高场全超导稳态磁体领域国际共同面临的关键技术突破，推动了“核心技术+材料国产化”深度协同，实现了关键材料、工艺、制备100%自主可控，为高场科学仪器的研发提供核心技术支撑，助力强场科学研究领域的创新发展。等离子体所开展的超导技术研究，不仅有效带动国内高温超导材料产业技术升级，更为核磁共振成像、航天电磁推进、超导感应加热、超导磁悬浮、高效电力传输等多领域的产业化应用提供了关键技术支撑，彰显了我国在前沿聚变科技领域的创新实力与国际引领力。 图1 全超导磁体测试曲线 图2 测试现场 附件：", "release_time": "2025-09-28", "source_institution": "等离子体物理研究所", "url": "http://www.ipp.ac.cn/xwdt/ttxw/202509/t20250928_779819.html"}
{"category": "研究前沿", "title": "新型4D地震成像技术提升石油勘探精度", "short_summary": "研究利用超级计算机分析多维地震数据，创建4D模型以准确预测石油储量。", "detailed_summary": "研究利用超级计算机分析多维地震数据，创建4D模型以准确预测石油储量。\n(1) 研究背景：传统3D地震成像仅依赖声波传播时间，常导致钻井后实际产油量远低于预估，出现“干井”问题。\n(2) 研究方法：宾州州立大学团队在Bridges-2超级计算机上，对地震数据增加时间维度（多次测量）和信号振幅分析，构建4D动画模型。\n(3) 技术突破：高计算力和大内存支持复杂数据分析，识别出储层内部被忽略的地质结构（如致密岩层），这些结构会阻挡石油开采。\n(4) 初步成果：方法在北海9平方英里区域验证有效，证明简单加深钻井即可获取被阻挡的石油，相关成果发表于《Geophysics》期刊。\n(5) 未来方向：团队正扩展计算规模，计划将方法应用于数十平方英里的大区域，并探索使用超内存节点进一步提升能力。", "raw_content": "Why It's Important Given all the complexity of finding oil in more remote and deeper locations, we need to drill smarter . Waste was always expensive, but today it's particularly important to be as clean and efficient as oil and gas extraction can be. Experts use the movement of sound through the Earth to spot where oil deposits should be. Those measurements also tell us the approximate size of a given reserve. Still, it's common for a well to go dry after only a fraction of its suspected oil has been pumped out. Penn State's Tieyuan Zhu and his students and postdoctoral fellows wanted to understand why that is -- and to develop more accurate measurements of how much oil a given well will actually produce. \"We actually tested … data from the North Sea. You know, they started drilling in 2008 and based on their estimation … they could produce oil for 20 years, 30 years. But unfortunately, after two years, there was nothing. Their well is dry. They just got confused. Where is the oil? Gone? The big issue actually is the complexity of the geology in the reservoir.\" -- Tieyuan Zhu, Penn State The team's approach, studying more aspects of the data from sound measurements than previously employed, would require more computing power. Also, they would need large memory to store parts of the problem in the computer's processors without time-costly trips back to data storage. PSC's NSF-funded Bridges-2 was the answer to this problem, thanks to an allocation from ACCESS, the NSF network of computing sites. How PSC Helped Oil doesn't sit in pools underground. When it's present, it's soaked into porous rock. Solid rock transmits sound more readily than oil-drenched rock. So experts can spot oil reserves by the way they slow down sound traveling through them. Much like a medical ultrasound, these seismic methods produce 3D images of where that oil-sodden rock sits. Despite those sophisticated maps, though, wells drilled based on those images often come up short. Zhu's team reasoned that there were literally parts of the picture that the 3D imaging wasn't capturing. They suspected that obtaining images of the same reserves on different dates -- adding time to create a kind of 4D animation -- would help build a more accurate picture. Another piece of the puzzle would be to include more features of the seismic data in the analysis. Previously, oil reserves were spotted by the longer amount of time it takes sound to move through them. To this time data, the Penn State scientists added the amplitude of the signal -- how oil damped out its loudness. This all posed computational problems. The computer would need lots of fast processors to crunch the calculations in a reasonable amount of time. But it would also need to temporarily store parts of the problem in its memory -- like RAM in a laptop -- so that it didn't need to keep going back to read the stored data, which slows everything down. Bridges-2, with over a thousand powerful central processing units (CPUs) in its regular memory nodes , could provide the speed. It could also provide the memory, as its CPU nodes each feature between 256 and 512 gigabytes of RAM -- eight to 16 times as much as a high-end gaming laptop. \"We have two postdocs and also one graduate student using Bridges-2 … the first phase of using Bridges-2 was to parallelize our research code … and make it more practical … The second phase is really to implement the code to the field data … PSC guaranteed me a hundred thousand computing hours, and also the memory to store my data, my field data … That just cannot be achieved with our local [resources].\" -- Tieyuan Zhu, Penn State The team's repeated measurements and expanded analysis yielded paydirt. They found that the images mapped out by time alone, in a single measurement, missed structures within the oil reserve. Some of these structures, such as a layer of more solid rock within the reserve, wouldn't affect the speed of the sound enough to be detected. But it would prevent a well from sucking up the oil below it. The solution, in some cases, was simple. Drill a little deeper, and the rest of the oil would be accessible. The scientists reported their results in the journal Geophysics in September, 2024, with a more extensive result in the same journal in April, 2025. The current report was just a proof of concept for their approach in a limited geological area, about 9 square miles. Currently, the team is expanding their computations to more nodes, so that the method can produce accurate maps for much larger areas, dozens of square miles. Another option Zhu's group may explore in scaling up their work is using Bridges-2's extreme memory nodes, which have 4,000 gigabytes of RAM apiece.", "release_time": "2025-09-28", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250927031239.htm"}
{"category": "产业应用", "title": "全球首座百兆瓦时级数字储能电站通过验收", "short_summary": "全球首座数字储能电站验收，标志技术从科研迈向规模化应用。", "detailed_summary": "全球首座数字储能电站验收，标志技术从科研迈向规模化应用。\n（1）50兆瓦/100兆瓦时数字储能示范工程在内蒙古三峡乌兰察布电站通过验收；\n（2）该项目为全球首座百兆瓦时级数字储能电站，由三峡科研院与清华大学联合研发；\n（3）核心技术为毫秒级数字能量交换装置与电池网络智能重构算法，实现电池网络动态重构；\n（4）由46个储能集装箱构成，包含数字能量交换、集成系统及智能运维平台三大核心组件；\n（5）项目已安全稳定运行一年余，入选国家能源局转型案例与示范项目。", "raw_content": "9月24日，大规模先进电力储能关键技术研究与示范项目——50兆瓦/100兆瓦时数字储能示范工程，在内蒙古自治区三峡乌兰察布新一代电网友好绿色电站项目2#场站通过验收。该工程为全球首座百兆瓦时级数字储能电站，其验收标志着我国数字储能技术从科研攻关迈向规模化工程应用。据了解，50兆瓦/100兆瓦时数字储能示范工程项目由三峡科研院牵头，联合清华大学共同研发，通过研究毫秒级数字能量交换装置与电池网络智能重构算法，将传统储能系统中电池固定串并组合的连接方式，转变为数字化柔性、可动态重构的电池网络结构，为低成本、长寿命数字储能技术规模化应用提供支撑。该项目由46个容量为1.075兆瓦/2.15兆瓦时的储能集装箱构成，包含数字能量交换系统、数字储能集成系统、能量管理与智能运维平台三大核心组件，可实现毫秒级动态投切，电池组件迅速接入或退出电网，实现故障或异常模组快速隔离;基于一定算法，动态平衡模组间的电量、温度;采用优化策略，延长电池簇及整个储能电站的循环寿命;挖掘电池实时运行数据，匹配智能分析算法与执行策略，实现储能电站不同层级精准管控和智能运维。项目早在2024年6月通过并网测试并正式投运，目前已安全稳定运行一年有余，入选“国家能源局能源绿色低碳转型典型案例”“国家能源局新型储能试点示范项目”。", "release_time": "2025-11-11", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/zhdt/202510/t20251028_792167.html"}
{"category": "产业应用", "title": "印尼动力煤出口复苏，新政与航运市场分化", "short_summary": "印尼煤出口8月反弹，政策松绑与航运需求推动市场复苏，运费走势分化。", "detailed_summary": "印尼煤出口8月反弹，政策松绑与航运需求推动市场复苏，运费走势分化。\n（1）印尼动力煤出口自6月低点3500万吨反弹至8月4800万吨，同比转正，预示下半年可能抵消上半年下滑。\n（2）印尼政府8月底解除煤炭销售基准价限制，赋予定价灵活性，新基准价和即将签署的欧盟-印尼CEPA协定有望提升竞争力。\n（3）出口流向多元化，除中印外，菲律宾保持稳定进口，多艘船舶从印尼港口运抵菲律宾。\n（4）航运市场分化：好望角型船费率坚挺；巴拿马型船部分航线走软；大灵便型船需求增长推动运费攀升。\n（5）供应端空驶船舶区域分布不均，需求增长疲软，港口拥堵呈现美洲缓解而远东加剧的分化态势。", "raw_content": "航运界网消息，经历2025年第一季度的低迷后，印尼动力煤出口量自6月起逐步复苏。6月出货量一度跌至年内低点约3500万吨，但8月已反弹至4800万吨，同比实现正增长。尽管上半年总出货量同比下滑至2.364亿吨，低于去年同期的2.63亿吨 ，但8月的强劲表现预示下半年或可部分抵消前期收缩。 印尼政府于8月底解除煤炭及矿物销售必须遵循政府基准价底线的规定，赋予出口商更大定价灵活性。税收机制仍与基准价挂钩，而9月新公布的基准价有望提升印尼煤相对于澳煤和俄煤的竞争力。此外，欧盟-印尼全面经济伙伴关系协定(CEPA)计划于9月23日签署，将进一步打通贸易通道，强化印尼在全球能源贸易中的地位。 航行数据显示，印尼煤炭出口流向正逐步多元化。除传统目的地中国和印度外，菲律宾持续保持稳定进口。8月期间，多艘巴拿马型和大灵便型船舶从印尼巴厘巴板、塔博内奥等港口出发，抵达菲律宾苏阿尔、利迈、达沃等港口。尽管菲律宾能源结构正向液化天然气转型，但其仍是印尼煤炭的长期稳定需求方。 运费市场：大型船型坚挺，中小型船分化 1)好望角型船：供需紧平衡支撑费率 9月下旬，巴西至中国(C3)和澳大利亚至中国(C5)航线运费维持高位。巴西至中国航线稳定在24美元/吨，澳大利亚至中国航线接近11美元/吨。与此同时，前往南大西洋和西澳大利亚的好望角型空驶船舶数量持续下降(7日移动平均值分别接近250艘和160艘)，反映市场供需结构偏紧。 2)巴拿马型船：南美及美湾至远东航线走软 南美东岸(ECSA)至远东航线周环比下降3%，美湾至中国航线下降4%，但同比仍保持7%涨幅。8月中旬以来，ECSA区域巴拿马型船每日装载量持续低于80万吨，空驶船舶数量处于低位，表明短期需求动能不足。 3)大灵便型船：需求增长推动运费攀升 ECSA至远东航线运费升至37美元/吨(月增10%)，美湾至远东航线涨至47美元/吨(月增8%)。尽管ECSA区域每日装载量稳定在30万吨以下，但空驶船舶数量逼近130艘，创近期新高，需关注后续对运价的传导效应。 供应端：空驶船舶分布区域分化明显 好望角型空驶船舶数量概况：大西洋区域南跌北涨，其中南大西洋空驶船舶数量减少6%，北大西洋环比增长13%。太平洋区域空驶船舶吸收情况持续改善，澳大拉西亚增长12%，印度洋和远东/NOPAC区域基本保持稳定。 巴拿马型空驶船舶数量概况：太平洋区域空驶船舶数量仍高于大西洋。具体而言，太平洋印度洋区域显著增长19%，而大西洋的南大西洋区域较南方呈现更高上行趋势。 大灵便型空驶船舶数量概况：太平洋盆地过剩持续，澳大拉西亚空驶船舶增长20%，印度洋/南非区域增长39%。大西洋亦显著上升，南方增长39%，北方增长10%。 灵便型空驶船舶数量概况：太平洋和大西洋盆地均呈现显著增长。太平洋远东/NOPAC区域增长7%，澳大拉西亚增长9%;大西洋北方增长16%，南方增长7%。 需求与拥堵：需求增长疲软，区域拥堵分化 据了解，今年二季度远东航线煤炭吨日需求增长弱于往年。尽管9月开局优于7月，但受上半年印尼对华出口收缩影响，全年恐难恢复至2023年水平。未来需重点关注印尼新政对下半年货量的实际拉动效果。 美洲大西洋港口拥堵水平降至900艘以下，2023-2024年同期超1000艘，接近2022年低点。相反，远东天津港拥堵加剧。美洲大西洋区域平均港口停留时间约11天，显著低于2023年9月初的16天峰值。(资料来源：Signal Group) 责任编辑： 张磊 标签：东南亚,煤炭贸易 上一篇：进口动力煤市场外涨内稳，后期上行空间或有... 下一篇：最后一页", "release_time": "2025-09-28", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194504-1.html"}
{"category": "产业应用", "title": "韩国首个商用电解制氢基地竣工 年产绿氢400吨", "short_summary": "现代建设韩国首座商用电解制氢厂竣工，日产绿氢1吨助力氢能城市发展。", "detailed_summary": "现代建设韩国首座商用电解制氢厂竣工，日产绿氢1吨助力氢能城市发展。\n（1）现代建设在全北扶安郡新再生能源园区建成韩国首个商用电解制氢生产基地，占地5000平方米；  \n（2）采用电解水技术生产绿氢，计划2026年投产，日产氢气超1吨（年产能约400吨），可满足150辆乘用车日需；  \n（3）项目整合太阳能、风能等可再生能源，实现零碳排放制氢；  \n（4）现代建设同步参与氢能城市规划，并开展多项氢能技术实证项目；  \n（5）项目将推动韩国氢能产业链发展，助力现代集团构建氢生态系统。", "raw_content": "韩国的绿氢项目有点慢啊。 今天(9月24日)，现代建设(HDEC)在全北扶安郡的新再生能源园区为电解制氢生产基地举行了竣工仪式。 现代建设和现代汽车都是现代集团旗下企业。 这个氢气生产基地被韩国产业通商资源部，在2022年定为\"电解制氢生产基地建设项目\"公开项目。 整个工程占地约5000平方米，就在扶安郡新再生能源主题公园内。工厂采用电解技术分解水制氢，配备了氢气生产、储存、供应的全套设备。 项目合作方包括全北道、扶安郡、全北技术园区、韩国水力核电、Techcross水务能源、Techcross环境服务等多家机构。 现代建设派出了氢气工厂领域的专业团队，全面负责设计、采购、施工等各个环节。 按照计划，工厂将在今年年底前完成试运行和系统调试，2026年正式投产。 届时日产氢气将超过1吨，这在韩国商用电解氢气生产中规模最大。1吨氢气大概能给150辆乘用车加满氢。生产出来的氢气主要供应扶安郡内的氢气研究机构和加氢站使用。 电解制氢的技术原理是用电力分解水，如果用的是可再生能源发的电，整个过程完全不产生温室气体，这种氢气被叫作\"绿氢\"，业内普遍认为这是未来氢能社会的关键技术。 扶安郡的地理位置很有优势。这里有西南区海上风电、新万金水上太阳能等韩国最大的可再生能源项目，新再生能源园区内还集中了太阳能、风能、氢能相关的研发和生产设施，发展绿氢产业条件得天独厚。 氢气生产基地建成后，现代建设还承接了\"扶安氢气城市建设项目总体规划及详细设施计划制定\"的咨询服务，要在全北及扶安地区打造氢能源驱动的环保能源自立城市。 除了扶安这个项目，现代建设在氢能基础设施方面还有不少动作：韩国首个高温电解100kW级系统模块实证、大容量5MW级工厂型PEM电解系统开发、蔚珍氢气城市建设项目总体规划，以及核电站连接的10MW级清洁氢气生产实证等等。 公司同时还在海上风电、太阳能、碳捕获利用(CCUS)、生物气体、小型模块反应堆(SMR)等新能源技术上加大投入，要在全球清洁能源市场站稳脚跟。 现代建设的相关负责人表示：\"能够成功建成韩国首个商用电解制氢生产基地，我们感到非常自豪。现代建设会继续深耕氢气生产、运输、储存等产业链各个环节，为现代汽车集团的氢气生态系统建设贡献力量。\" 每天1吨氢燃料电池汽车用氢，一年也不到400吨，在中国只能算个小项目。 责任编辑： 张磊 标签：韩国 ,电解制氢 上一篇：氢能，本该如此——荣程新能打造氢能产业新... 下一篇：最后一页", "release_time": "2025-09-28", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194500-1.html"}
{"category": "研究前沿", "title": "铜冶炼实验催生铁技术，考古研究改写冶金史", "short_summary": "新研究揭示格鲁吉亚古铜冶炼场使用氧化铁助熔，为铁冶炼起源提供关键证据。", "detailed_summary": "新研究揭示格鲁吉亚古铜冶炼场使用氧化铁助熔，为铁冶炼起源提供关键证据。\n(1) 研究重新分析了格鲁吉亚南部3000年历史的Kvemo Bolnisi冶炼作坊的冶金遗迹。\n(2) 推翻了1950年代认为该遗址是早期铁冶炼场的结论，证实其实际是铜冶炼场。\n(3) 关键发现是古代工匠在铜冶炼中使用氧化铁作为助熔剂以提高铜产量。\n(4) 这一发现支持了铁冶炼技术可能起源于铜冶炼工匠实验的理论，是迈向铁冶炼的关键一步。\n(5) 研究由克兰菲尔德大学考古科学家主导，强调了分析炉渣等废弃物对理解古代技术起源的重要性。", "raw_content": "The work reanalyzed metallurgical remains from a site in southern Georgia: a 3000-year-old smelting workshop called Kvemo Bolnisi. During the original analysis in the 1950s, piles of hematite (an iron oxide mineral) and slag (a waste product of the metal production) were found in the workshop. Finding those iron oxides, the original excavators thought the workshop was an early iron smelting site. However, new research shows that those assumptions were wrong. Rather than iron, workers at Kvemo Bolnisi were smelting copper using iron oxide as a flux -- a substance added into the furnace to increase the resulting copper yield. These discoveries give weight to a long-discussed theory that iron was invented by copper smelters. This evidence shows that ancient copper metalworkers experimented with iron-bearing materials in a metallurgical furnace, which was a crucial step towards iron smelting. The importance of iron While the Iron Age marked the beginnings of widespread iron production, the metal itself wasn't a new discovery. Iron artifacts have been found dating from the Bronze Age, most famously an iron dagger with a gold and rock crystal hilt from the tomb of Egyptian king Tutankhamun. But the earliest iron objects were forged from naturally occurring metallic iron found in meteorites, not extracted from iron ore through smelting. That rarity meant iron was, at that point in history, more valuable than gold. The development of extractive iron metallurgy changed all this. Iron is one of the most abundant elements on Earth, even though naturally occurring iron metal is very rare. The ability to extract iron from iron ore and work it into useful materials such as tools or weapons is one of the defining technological transformations in human history. The transition into the Iron Age was far from instantaneous, but it gave rise to the iron-wielding armies of Assyria and Rome and later the railroads and steel-frame buildings of the industrial revolution. Dr Nathaniel Erb-Satullo, Visiting Fellow in Archaeological Science at Cranfield University, said: \"Iron is the world's quintessential industrial metal, but the lack of written records, iron's tendency to rust, and a lack of research on iron production sites has made the search for its origins challenging. \"That's what makes this site at Kvemo Bolnisi so exciting. It's evidence of intentional use of iron in the copper smelting process. That shows that these metalworkers understood iron oxide -- the geological compounds that would eventually be used as ore for iron smelting -- as a separate material and experimented with its properties within the furnace. Its use here suggests that this kind of experimentation by copper-workers was crucial to development of iron metallurgy. \"There's a beautiful symmetry in this kind of research, in that we can use the techniques of modern geology and materials science to get into the minds of ancient materials scientists. And we can do all this through the analysis of slag -- a mundane waste material that looks like lumps of funny-looking rock.\" The research was supported by grants from the British Institute of Ankara, the Gerda Henkel Foundation, and the American Research Institute of the South Causcasus. The research paper Iron in copper metallurgy at the dawn of the Iron Age: Insights on iron invention from a mining and smelting site in the Caucasus is published in the Journal of Archaeological Science .", "release_time": "2025-09-28", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250927031245.htm"}
{"category": "政策计划", "title": "前8月全国发电装机容量同比增18%", "short_summary": "全国发电装机容量达36.9亿千瓦，太阳能与风电新增装机合计超2.8亿千瓦。", "detailed_summary": "全国发电装机容量达36.9亿千瓦，太阳能与风电新增装机合计超2.8亿千瓦。\n(1) 截至8月底，全国累计发电装机容量36.9亿千瓦，同比增长18.0%。\n(2) 太阳能发电装机容量11.2亿千瓦，同比增长48.5%；风电装机容量5.8亿千瓦，同比增长22.1%。\n(3) 1—8月全国新增发电装机容量达34516万千瓦，比上年同期多投产13520万千瓦。\n(4) 其中，风电新增装机5784万千瓦，太阳能发电新增装机23061万千瓦。\n(5) 太阳能与风电新增装机合计超2.8亿千瓦，显示可再生能源快速发展。", "raw_content": "本报北京9月26日电（记者廖睿灵）国家能源局26日发布1—8月份全国电力工业统计数据显示，截至8月底，全国累计发电装机容量36.9亿千瓦，同比增长18.0%。其中，太阳能发电装机容量11.2亿千瓦，同比增长48.5%；风电装机容量5.8亿千瓦，同比增长22.1%。数据显示，1—8月，全国新增发电装机容量达34516万千瓦，比上年同期多投产13520万千瓦。其中风电新增装机5784万千瓦，比上年同期多投产2424万千瓦；太阳能发电新增装机23061万千瓦，比上年同期多投产9062万千瓦。1至8月，太阳能、风电新增装机合计超2.8亿千瓦。", "release_time": "2025-11-11", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/zhdt/202510/t20251028_792170.html"}
{"category": "研究前沿", "title": "生物焦油变废为宝：新型生物碳材料研究突破", "short_summary": "生物焦油可转化为高价值生物碳，助力清洁能源与环境修复。", "detailed_summary": "生物焦油可转化为高价值生物碳，助力清洁能源与环境修复。\n（1）中国农科院团队提出将生物质能源产生的有害副产品生物焦油转化为高附加值\"生物碳\"材料；\n（2）通过调控温度、反应时间和添加剂，利用焦油内含羰基化合物等物质的自然聚合反应生成定制化生物碳；\n（3）生物碳相比普通生物炭具有更高碳含量、更低灰分和特殊结构优势；\n（4）其应用涵盖水净化吸附剂、超级电容器电极、绿色工业催化剂和低排放清洁燃料；\n（5）技术虽具经济环保双重效益，但大规模生产和反应控制仍是未来研究重点。", "raw_content": "When biomass such as crop residues, wood, or other organic matter is heated to produce clean energy and biochar, it also generates a thick liquid known as bio-tar. This tar easily clogs pipelines, damages equipment, and poses environmental risks if released into the atmosphere. For decades, researchers have sought ways to eliminate or neutralize it. Now, a team led by scientists at the Chinese Academy of Agricultural Sciences argues that instead of being treated as waste, bio-tar can be converted into \"bio-carbon\" -- a novel material with applications ranging from water purification to clean energy storage. \"Our review highlights how turning bio-tar into bio-carbon not only solves a technical problem for the bioenergy industry, but also opens the door to producing advanced carbon materials with high economic value,\" said senior author Dr. Zonglu Yao. The review examines how chemical reactions inside bio-tar, particularly those involving oxygen-rich compounds like carbonyls and furans, naturally promote polymerization -- processes where small molecules link together to form larger, more stable carbon structures. By carefully adjusting temperature, reaction time, and additives, researchers can harness this process to produce bio-carbon with tailored properties. The resulting material, the authors note, is distinct from ordinary biochar. Bio-carbon typically has higher carbon content, lower ash, and unique structural features that make it especially suited for advanced uses. Early studies suggest that bio-carbon could serve as: Adsorbents to clean polluted water and air by trapping heavy metals and organic contaminants. Electrode materials for next-generation supercapacitors, which are vital for renewable energy storage. Catalysts that speed up industrial chemical reactions more sustainably than traditional fossil-based options. Clean-burning fuels with lower emissions of harmful nitrogen and sulfur oxides. Importantly, recent economic and life-cycle assessments suggest that converting bio-tar into bio-carbon can deliver net-positive energy, financial, and environmental benefits. For example, replacing coal with bio-carbon fuels could cut carbon dioxide emissions by hundreds of millions of tons annually, while also generating profits for biomass processing plants. Still, challenges remain. The chemical complexity of bio-tar makes it difficult to fully control the polymerization process, and large-scale production has not yet been achieved. The authors recommend combining laboratory experiments with computer simulations and machine learning to optimize reaction pathways and design bio-carbon with specific functions. \"Bio-tar polymerization is not just about waste treatment -- it represents a new frontier for creating sustainable carbon materials,\" said first author Yuxuan Sun. \"With further research, this approach could significantly improve the efficiency of biomass energy systems while providing new tools for environmental protection and clean technology.\" The study provides a roadmap for scientists and industry partners to turn one of bioenergy's biggest obstacles into a powerful resource for the future.", "release_time": "2025-09-28", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250926035016.htm"}
{"category": "产业应用", "title": "直接空气捕集技术助力实现净零排放目标", "short_summary": "直接空气捕集技术可从大气中移除二氧化碳，助力达成净零排放。", "detailed_summary": "直接空气捕集技术可从大气中移除二氧化碳，助力达成净零排放。\n（1）直接空气捕集技术能够直接从空气中捕获二氧化碳。\n（2）捕获的二氧化碳可被压缩后进行封存或资源化利用。\n（3）该技术是实现净零排放目标的重要途径之一。", "raw_content": "July 20, 2022  Direct air capture technology removes carbon dioxide from the air and compresses it for sequestration or utilization and promises to help us meet net-zero emissions goals. However, the process of ...", "release_time": "2025-09-28", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250926035019.htm"}
{"category": "研究前沿", "title": "科学家发现超导希格斯回波，开辟量子信息新路径", "short_summary": "研究团队利用太赫兹光谱在超导铌材料中发现新型量子希格斯回波，有望推动量子计算发展。", "detailed_summary": "研究团队利用太赫兹光谱在超导铌材料中发现新型量子希格斯回波，有望推动量子计算发展。\n（1）研究团队在超导铌材料中发现新型“希格斯回波”量子现象；\n（2）该回波源于希格斯模式与准粒子间的复杂相互作用，具有独特信号特征；\n（3）通过精确时序太赫兹辐射脉冲可观测回波，并能编码、存储和检索量子信息；\n（4）此项发现为控制和观测超导体量子相干性提供新方法；\n（5）研究成果有望推动实用量子计算和先进量子传感技术的发展。", "raw_content": "Superconductors are materials that carry electricity without resistance. Within these superconductors are collective vibrations known as \"Higgs modes.\" A Higgs mode is a quantum phenomenon that occurs when its electron potential fluctuates in a similar way to a Higgs boson. They appear when a material is undergoing a superconducting phase transition. Observing these vibrations has been a long-time challenge for scientists because they exist for a very short time. They also have complex interactions with quasiparticles, which are electron-like excitations that emerge from the breakdown of superconductivity. However, using advanced terahertz (THz) spectroscopy techniques, the research team discovered a novel type of quantum echo, called the \"Higgs echo,\" in superconducting niobium materials used in quantum computing circuits. \"Unlike conventional echoes observed in atoms or semiconductors, the Higgs echo arises from a complex interaction between the Higgs modes and quasiparticles, leading to unusual signals with distinct characteristics,\" explained Jigang Wang, a scientist at Ames Lab and lead of the research team. According to Wang, the Higgs echo can remember and reveal hidden quantum pathways within the material. By using precisely timed pulses of THz radiation, his team was able to observe these echoes. Using these THz radiation pulses, they can also use the echoes to encode, store, and retrieve quantum information embedded within this superconducting material. This research demonstrates the ability to control and observe quantum coherence in superconductors and paves the way for potential new methods of quantum information storage and processing. \"Understanding and controlling these unique quantum echoes brings us a step closer to practical quantum computing and advanced quantum sensing technologies,\" said Wang. This project was partially supported through the Superconducting Quantum Materials and Systems Center (SQMS).", "release_time": "2025-09-28", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250926035059.htm"}
{"category": "研究前沿", "title": "MIT揭示大脑视觉信息跨半球无缝传递机制", "short_summary": "MIT研究发现脑波频率协调视觉信息在左右脑半球间的交接，实现感知统一。", "detailed_summary": "MIT研究发现脑波频率协调视觉信息在左右脑半球间的交接，实现感知统一。\n（1）MIT皮考尔研究所神经科学家通过测量动物大脑神经活动，研究物体跨越视野中线时的大脑处理机制；\n（2）研究发现不同频率脑波（如伽马、贝塔、阿尔法和西塔波）在信息转移中起关键作用，阿尔法波在交接前激活双半球，西塔波在接收半球确认完成；\n（3）神经活动显示，目标物体在跨越中线前，发送和接收半球会同时编码信息，确保感知无缝过渡；\n（4）该机制类似于接力赛交接或手机信号塔切换，揭示了大脑如何实现视觉感知的统一性；\n（5）研究可能为精神分裂症、自闭症等神经疾病提供新见解，因为这些疾病中半球协调机制可能出现问题。", "raw_content": "The brain divides vision between its two hemispheres — what’s on your left is processed by your right hemisphere, and vice versa — but your experience with every bike or bird that you see zipping by is seamless. A new study by neuroscientists at The Picower Institute for Learning and Memory at MIT reveals how the brain handles the transition. “It’s surprising to some people to hear that there’s some independence between the hemispheres, because that doesn’t really correspond to how we perceive reality,” says Earl K. Miller , Picower Professor in the Picower Institute and MIT’s Department of Brain and Cognitive Sciences. “In our consciousness, everything seems to be unified.” There are advantages to separately processing vision on either side of the brain, including the ability to keep track of more things at once, Miller and other researchers have found , but neuroscientists have been eager to fully understand how perception ultimately appears so unified in the end. Led by Picower Fellow Matthew Broschard and Research Scientist Jefferson Roy, the research team measured neural activity in the brains of animals as they tracked objects crossing their field of view. The results reveal that different frequencies of brain waves encoded and then transferred information from one hemisphere to the other in advance of the crossing, and then held on to the object representation in both hemispheres until after the crossing was complete. The process is analogous to how relay racers hand off a baton, how a child swings from one monkey bar to the next, and how cellphone towers hand off a call from one to the next as a train passenger travels through their area. In all cases, both towers or hands actively hold what’s being transferred until the handoff is confirmed. Witnessing the handoff To conduct the study, published Sept. 19 in the Journal of Neuroscience , the researchers measured both the electrical spiking of individual neurons and the various frequencies of brain waves that emerge from the coordinated activity of many neurons. They studied the dorsal and ventrolateral prefrontal cortex in both hemispheres, brain areas associated with executive brain functions. The power fluctuations of the wave frequencies in each hemisphere told the researchers a clear story about how the subject’s brains transferred information from the “sending” to the “receiving” hemisphere whenever a target object crossed the middle of their field of view. In the experiments, the target was accompanied by a distractor object on the opposite side of the screen to confirm that the subjects were consciously paying attention to the target object’s motion, and not just indiscriminately glancing at whatever happened to pop up on to the screen. The highest-frequency “gamma” waves, which encode sensory information, peaked in both hemispheres when the subjects first looked at the screen and again when the two objects appeared. When a color change signaled which object was the target to track, the gamma increase was only evident in the “sending” hemisphere (on the opposite side as the target object), as expected. Meanwhile, the power of somewhat lower-frequency “beta” waves, which regulate when gamma waves are active, varied inversely with the gamma waves. These sensory encoding dynamics were stronger in the ventrolateral locations compared to the dorsolateral ones. Meanwhile, two distinct bands of lower-frequency waves showed greater power in the dorsolateral locations at key moments related to achieving the handoff. About a quarter of a second before a target object crossed the middle of the field of view, “alpha” waves ramped up in both hemispheres and then peaked just after the object crossed. Meanwhile, “theta” band waves peaked after the crossing was complete, only in the “receiving” hemisphere (opposite from the target’s new position). Accompanying the pattern of wave peaks, neuron spiking data showed how the brain’s representation of the target’s location traveled. Using decoder software, which interprets what information the spikes represent, the researchers could see the target representation emerge in the sending hemisphere’s ventrolateral location when it was first cued by the color change. Then they could see that as the target neared the middle of the field of view, the receiving hemisphere joined the sending hemisphere in representing the object, so that they both encoded the information during the transfer. Doing the wave Taken together, the results showed that after the sending hemisphere initially encoded the target with a ventrolateral interplay of beta and gamma waves, a dorsolateral ramp up of alpha waves caused the receiving hemisphere to anticipate the handoff by mirroring the sending hemisphere’s encoding of the target information. Alpha peaked just after the target crossed the middle of the field of view, and when the handoff was complete, theta peaked in the receiving hemisphere as if to say, “I got it.” And in trials where the target never crossed the middle of the field of view, these handoff dynamics were not apparent in the measurements. The study shows that the brain is not simply tracking objects in one hemisphere and then just picking them up anew when they enter the field of view of the other hemisphere. “These results suggest there are active mechanisms that transfer information between cerebral hemispheres,” the authors wrote. “The brain seems to anticipate the transfer and acknowledge its completion.” But they also note, based on other studies, that the system of interhemispheric coordination can sometimes appear to break down in certain neurological conditions including schizophrenia, autism, depression, dyslexia, and multiple sclerosis. The new study may lend insight into the specific dynamics needed for it to succeed. In addition to Broschard, Roy, and Miller, the paper’s other authors are Scott Brincat and Meredith Mahnke. Funding for the study came from the Office of Naval Research, the National Eye Institute of the National Institutes of Health, The Freedom Together Foundation, and The Picower Institute for Learning and Memory.", "release_time": "2025-09-27", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/how-brain-splits-vision-without-you-even-noticing-0926"}
{"category": "产业应用", "title": "山西新能源三箭齐发：光伏风电氢能重塑能源版图", "short_summary": "山西光伏装机破千万千瓦，风电乡村振兴项目落地，氢能电解槽技术突破，能源转型加速。", "detailed_summary": "山西光伏装机破千万千瓦，风电乡村振兴项目落地，氢能电解槽技术突破，能源转型加速。\n（1）光伏发电实现跨越式发展，分布式光伏装机容量达1053.61万千瓦，年发电量106.62亿千瓦时；\n（2）创新农村光伏\"集中汇流\"模式，南张河村试点实现整村屋顶光伏全覆盖，村民获得稳定收益；\n（3）风电乡村振兴项目规划200万千瓦，首批33个试点项目总规模151.74万千瓦，2026年底建成；\n（4）氢能技术取得突破，首台碱性水电解槽\"晋华槽\"投产，每小时产氢1000标准立方米；\n（5）政策体系完善，通过\"风光火储一体化\"等模式推进能源革命，目标\"十四五\"末新能源装机占比超50%。", "raw_content": "“借风”“迎光”“燃氢”而上，山西新能源装机规模和发电量屡创新高，煤炭由“按吨卖”，变为“论克卖”，近年来，山西能源产业向“绿”而行，向“新”发力。从光伏全产业链的技术突破，到绿电制氢的成本革命、“风光火储一体化”，再到全国首个分布式光伏管理细则的制度创新……我省能源结构不断重塑，推进动能转换。山西正以“绿能”为笔，在传统能源基地的版图上，勾勒出高质量发展的新图景，为全国能源转型提供可复制的“山西动力”。山西“光”破局近日，在晋能控股光伏发电公司天镇旭升电站举办的“开放周”活动中，来参观的群众纷纷议论，“原来太阳能板是这样把阳光变成电!”周边居民们走进这个平日里只可见其轮廓的“光明工厂”。电站人员化身讲解员，从硅晶片的光电转换原理，到智能跟踪系统如何让电池板追光而动;从年发电量可满足25万户家庭用电的环保效益，到相当于每年减少二氧化碳排放41万吨的生态价值……电站工作人员用通俗易懂的语言揭示着光伏发电的秘密。这并非孤例，只是我省光伏发电的一个缩影。放眼省内，大型地面光伏电站正成为能源绿色转型的“佼佼者”。根据公开数据，截至今年1月底，山西省分布式光伏装机容量突破1000万千瓦，达到1053.61万千瓦，创历史新高。山西省拥有得天独厚的光照条件，年日照时数约2200-3000小时，2024年全省分布式光伏发电量达106.62亿千瓦时，同比增长49%。随后，山西晚报·山河+记者在潞安太阳能公司厂区看到，建筑物的屋顶和闲置空地上，一排排高效太阳能电池板整齐排列。这是自产自建的分布式光伏发电项目的一部分，充分利用屋顶和闲置空地资源，将太阳能转化为电能，为厂区日常生产运营提供了源源不断的绿色动力。据了解，潞安太阳能公司厂区已建成的40MW光伏实验电站年发电量达5200万度，相当于替代标准煤6.39万吨，减少二氧化碳排放17.06万吨、二氧化硫排放1533吨。工作人员介绍，这一转变不仅降低了煤炭消耗，还使二氧化碳、二氧化硫等的排放大幅减少。针对山西农村地区电网基础薄弱的现状，我省还鼓励非自然人户用分布式光伏以行政村(社区)为单元，优先采用“集中汇流、升压并网”方式接入。在山西省长治市长子县慈林镇南张河村，这一试点工程已显现成效。面对整村58户居民仅靠200千伏安供电台区的困境，创新建设了低压汇流网络、升压变压器、并网线路及控制终端，将分散的屋顶光伏电力统一升压至10千伏后集中并网。村民与光伏开发企业签订了25年屋顶租赁合同，除去当下每户可以拿到初装费外，以后每年每户还能拿到2100余元的屋顶租赁收益。当前，该村试点工程分两期推进，一期工程覆盖17户，总装机容量达320千瓦，目前已并网运行;二期工程完工后，将实现整村屋顶光伏全覆盖，总装机容量跃升至1200千瓦。这个创新模式为我省农村分布式光伏规模化开发提供了可复制的技术路径。从大型地面电站到分布式光伏发电项目，从工业应用领域到民用领域，从全黑组件到小微型发电系统，从光伏制造到“光伏+多场景融合”，我省的光伏产品正以更加高效、智能、环保的姿态走进千家万户，为更多用户提供了优质的绿色能源。“弃风”到“纳风”的储能行动据省能源局、省农业农村厅此前印发的《山西省驭风行动助力乡村振兴工程总体方案》，我省将在各市选取2—5个农村居民人均可支配收入较低的县，建成一批就地就近开发利用的乡村振兴风电项目，每个市不超过20万千瓦，每个县不超过5万千瓦，每个行政村不超过2万千瓦，全省规划下达乡村振兴风电项目规模200万千瓦左右，力争2026年底建成。山西晚报·山河+记者了解到，去年，我省首批确定了33个风电项目作为试点项目，总规模151.74万千瓦，力争于2026年底建成。其中忻州、长治和临汾规模最大，均为20万千瓦;其余城市规模分别是晋中市19.75万千瓦、吕梁市17万千瓦、大同市16万千瓦、运城市14.99万千瓦、阳泉市14万千瓦、太原市5万千瓦、朔州市5万千瓦。山西省农业农村厅相关负责人介绍，山西省农村地区风能资源丰富、分布广泛;而风电项目具有经济性高、占地少、环境友好等优势，可以在推动乡村振兴中发挥重要作用。根据相关规划，山西将在每个地级市选取2至5个农村居民人均可支配收入较低的县，建成一批就地就近开发利用的风电项目。同时，我省要求，各地明确收益分配机制。有关县政府督促指导村集体、项目单位按照“村企合作”模式建立长期稳定的利益共享机制，县级农业农村主管部门要及时了解和掌握本地乡村振兴风电试点项目的收益共享落实情况，协调发挥项目收益在壮大村集体经济和助力乡村振兴中的作用。然而，光伏发电“看天吃饭”，风电“随风而动”，这种不稳定性是新能源大规模并网的世界性难题。如何将不稳定的“绿电”变成稳定可靠的“主力电”?山西的答案是：打好“组合拳”。山上，风车成列;山下，光伏板点缀村庄。山西晚报·山河+记者从忻州市获悉，忻州聚焦打造山西省重要绿色能源产业基地的目标，充分发挥新能源品种全、结构优、规模大等优势，统筹推进“风光水火储”一体化发展，一批投资规模大、带动能力强的新能源项目相继落地投产，新能源和清洁能源装机总量连续6年位居全省第一。从“弃风”的无奈到“纳风”的自信，我省的探索为全国乃至全球新能源发展提供了宝贵经验。这背后是政策红利的精准滴灌，是储能技术的硬核支撑，更是“一体化”发展模式的系统创新。当风车在山间从容转动，当储能电站智能调峰，当绿色电力点亮万家灯火，山西不仅是在构建一个清洁低碳的新型能源体系，更是在一个资源型地区以“绿”转型、向“新”而生的不断突破。氢能改写行业规则氢是宇宙中最为丰富的元素，但大多存在于化合物中，如水、甲烷、碳水化合物等，只有少数以氢气的方式存在。作为清洁能源的“生力军”，氢被认为是第三次能源革命中的重要载体，而要想制造出氢气，离不开关键设备电解槽。潞安化工作为重点产业链链主企业，是全省制造业行业先锋。长期以来，一直强化科技创新引领，不断提高企业核心竞争力、打造拳头产品，取得了一系列璀璨耀眼且令人瞩目的丰硕成果。去年底，由潞安化工机械集团联合清华大学、碳能科技(北京)有限公司研发制造的全省首台碱性水电解槽(晋华槽)正式亮相，这个长约5米、直径约3米的“电解槽”，是我省又一个能源技术革命的重大标志性成果。“晋华槽”应用范围广且灵活性强，工作状态产氢量每小时达1000标准立方米，可用于消纳陆上风电、海上风电及光伏新能源发出的绿色电力，转化为绿氢产品，广泛应用于石油炼化加氢、氢冶金、电厂掺氨燃烧、加氢站等多个领域，为用户提供高效率、高可靠性、低成本的电解水制氢解决方案。“近年来山西省积极布局氢能产业，潞安化工机械集团作为‘先行者’在发展氢能技术上不断突破。此次研发主要围绕低能耗、强波动碱性电解水制氢集成系统开展联合攻关，同时与国内知名智能化装备设计制造企业合作，融合自动控制、声光电检测、AI算法、云平台和MES管理系统，建设了山西省首条GW级(100台/年)自动化生产线，最终成功研制‘晋华槽’。”潞安化工机械集团党委书记、董事长任金锁介绍道。山西晚报·山河+记者了解到，此前，省发展改革委、省工信厅联合出台的《山西省氢能产业链2024年行动方案》提出，要开展氢能关键核心技术攻关、推进氢能创新平台建设、建立多元氢能供应体系、有序推进加氢站建设、有序开展氢能在交通领域示范应用、探索开展氢能在工业领域示范应用、打造氢能产业集聚区、推进氢能产业重大项目建设、开展氢能产业链招商、强化氢能行业交流合作、加强氢能全产业链安全管理等11项重点任务，明确3项保障措施，推动氢能“制、储、运、加、用”全产业链发展，加快形成新质生产力。与此同时，全省各地加快氢能基础设施布局，大力开发氢能应用场景，尤其是围绕工业园区、钢铁冶炼、新型农场、专业运输等，有序推进氢能在交通、工业等领域的示范应用，加快推进氢能资源化、规模化利用。按照规划，我省将力争今年基本构建起较为完备的氢能产业链体系，为氢能产业的高质量发展和山西能源的低碳转型注入澎湃动力。勇当能源革命“排头兵”从“煤都”到“绿都”，从“黑色黄金”到“绿色动能”，山西的能源转型之路，是一场深刻的自我革命，更是一次面向未来的主动求变。风、光、氢“三箭齐发”，不仅是能源供给结构的优化，更是发展理念、产业形态和区域竞争力的全面重塑。这背后是山西作为国家资源型经济转型综合配套改革试验区的使命担当，也是其为全国能源革命先行探路的坚定决心。根据规划，到“十四五”末，全省新能源和清洁能源装机容量占比将达到50%以上，力争建成全国重要的新能源综合基地。为此，我省正构建起一套系统完备的政策支持体系：在顶层设计上，持续深化能源革命综合改革试点，出台《山西省“十四五”新能源和可再生能源发展规划》，为产业发展提供清晰路径;在项目推进上，大力推进“风光火储一体化”“源网荷储一体化”等重大项目建设，提升能源系统的灵活性和稳定性;在技术创新上，设立专项资金，鼓励企业、高校和科研院所围绕高效光伏电池、低成本绿氢制备、长时储能等关键核心技术进行联合攻关，抢占产业发展制高点;在市场机制上，积极探索绿电交易、碳普惠等新模式，让绿色能源的价值得到充分体现。我省将绿色发展的理念深植于每一项政策、每一个项目、每一次创新之中。这不仅为山西自身的高质量发展注入了澎湃的“绿色动能”，更以其丰富的实践经验和可复制的“山西方案”，为全国构建清洁低碳、安全高效的能源体系贡献着不可或缺的智慧与力量，呈现一个“风光无限、氢能涌动”的新山西。", "release_time": "2025-11-11", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/zhdt/202510/t20251028_792146.html"}
{"category": "研究前沿", "title": "弗劳恩霍夫研究所建立燃料电池与电解槽生产研究平台", "short_summary": "研究所开发膜电极组件连续生产工艺，助力燃料电池与电解槽规模化降本。", "detailed_summary": "研究所开发膜电极组件连续生产工艺，助力燃料电池与电解槽规模化降本。\n（1）重型商用车辆零排放转型推动燃料电池需求，电解技术是低碳能源经济关键。\n（2）弗劳恩霍夫ISE研究所建立膜电极组件生产研究平台，支持部件制造商及设备工程师。\n（3）研究聚焦创新连续生产工艺，如卷对卷制造，以实现高生产率和成本降低。\n（4）生产研究涵盖从催化剂粉末到七层膜电极组件的全价值链，包括质量控制。", "raw_content": "The transition of the heavy-duty and commercial vehicle sector to zero-emission engines is driving the expected production volume of fuel cells. At the same time, electrolysis is gaining importance as a building block for a low-emission energy economy. New production methods are needed to ramp up the market for both technologies. In this context, Fraunhofer ISE has established a versatile platform for research on the production of membrane electrode assemblies to support component manufacturers as well as machinery and plant engineers in addressing production challenges associated with fuel cells and electrolyzers. The focus is on innovative, continuous processes that enable high throughput rates and cost reductions, such as roll-to-roll manufacturing. Furthermore, pro-duction research considers the entire value chain from catalyst powder to 7-layer MEA, including quality control.", "release_time": "2025-09-26", "source_institution": "德国弗劳恩霍夫协会太阳能系统研究所", "url": "http://www.ise.fraunhofer.de/en/press-media/press-releases/2025/innovative-production-processes-for-the-core-components-of-fuel-cells-and-electrolyzers.html"}
{"category": "研究前沿", "title": "新型无透镜红外成像技术实现大景深宽视场探测", "short_summary": "华东师大团队研发无透镜非线性针孔成像技术，实现高灵敏度中红外探测与3D成像。", "detailed_summary": "华东师大团队研发无透镜非线性针孔成像技术，实现高灵敏度中红外探测与3D成像。\n(1) 华东师范大学研究团队开发出一种新型无透镜非线性针孔成像技术，用于中红外波段探测。\n(2) 该技术利用强激光在非线性晶体内部形成“光学针孔”，并将红外图像转换为可见光，由标准硅相机记录。\n(3) 系统实现了超过35厘米的景深和超过6厘米的视场，成像清晰无畸变，并具有高灵敏度及固有噪声抑制能力。\n(4) 研究人员成功演示了两种无透镜3D成像方法：基于飞行时间的三维形状重建和双快照深度成像。\n(5) 此项技术有望提升夜间安全、工业质检和环境监测水平，未来通过材料与光源改进可实现系统小型化和更广泛应用。", "raw_content": "\"Many useful signals are in the mid-infrared, such as heat and molecular fingerprints, but cameras working at these wavelengths are often noisy, expensive or require cooling,\" said research team leader Heping Zeng from East China Normal University. \"Moreover, traditional lens-based setups have a limited depth of field and need careful design to minimize optical distortions. We developed a high-sensitivity, lens-free approach that delivers a much larger depth of field and field of view than other systems.\" In Optica , Optica Publishing Group's journal for high-impact research, the researchers describe how they use light to form a tiny \"optical pinhole\" inside a nonlinear crystal, which also turns the infrared image into a visible one. Using this setup, they acquired clear mid-infrared images with a depth of field of over 35 cm and a field of view of more than 6 cm. They were also able to use the system to acquire 3D images. \"This approach can enhance night-time safety, industrial quality control and environmental monitoring,\" said research team member Kun Huang from East China Normal University. \"And because it uses simpler optics and standard silicon sensors, it could eventually make infrared imaging systems more affordable, portable and energy efficient. It can even be applied with other spectral bands such as the far-infrared or terahertz wavelengths, where lenses are hard to make or perform poorly.\" Pinhole imaging reimagined Pinhole imaging is one of the oldest image-making methods, first described by the Chinese philosopher Mozi in the 4th century BC. A traditional pinhole camera works by letting light pass through a tiny hole in a lightproof box, projecting an inverted image of the outside scene onto the opposite surface inside. Unlike lens-based imaging, pinhole imaging avoids distortion, has an infinite depth of field and works across a wide range of wavelengths. To bring these advantages to a modern infrared imaging system, the researchers used an intense laser to form an optical hole, or artificial aperture, inside a nonlinear crystal. Because of its special optical properties, the crystal converts the infrared image into visible light, so that a standard silicon camera can record it. The researchers say that the use of a specially designed crystal with a chirped-period structure, which can accept light rays from a broad range of directions, was key to achieving a large field of view. Also, the upconversion detection method naturally suppresses noise, which allows it to work even in very low light conditions. \"Lensless nonlinear pinhole imaging is a practical way to achieve distortion-free, large-depth, wide-field-of-view mid-infrared imaging with high sensitivity,\" said Huang. \"The ultrashort synchronized laser pulses also provide a built-in ultrafast optical time gate that can be used for sensitive, time-of-flight depth imaging, even with very few photons.\" After figuring out that an optical pinhole radius of about 0.20 mm produced sharp, well-defined details, the researchers used this aperture size to image targets that were 11 cm, 15 cm and 19 cm away. They achieved sharp imaging at the mid-infrared wavelength of 3.07 μm, across all the distances, confirming a large depth range. They were also able to keep images sharp for objects placed up to 35 cm away, demonstrating a large depth of field. 3D imaging without lenses The investigators then used their setup for two types of 3D imaging. For 3D time-of-flight imaging, they imaged a matte ceramic rabbit by using synchronized ultrafast pulses as an optical gate and were able to reconstruct the 3D shape with micron-level axial precision. Even when the input was reduced to about 1.5 photons per pulse -- simulating very low-light conditions -- the method still produced 3D images after correlation-based denoising. They also performed two-snapshot depth imaging by taking two pictures of a stacked \"ECNU\" target at slightly different object distances and using those to calculate the true sizes and depths. With this method, they were able to measure the depth of the objects over a range of about 6 centimeters, without using complex pulsed timing techniques. The researchers note that the mid-infrared nonlinear pinhole imaging system is still a proof-of-concept that requires a relatively complex and bulky laser setup. However, as new nonlinear materials and integrated light sources are developed, the technology should become far more compact and easier to deploy. They are now working to make the system faster, more sensitive and adaptable to different imaging scenarios. Their plans include boosting conversion efficiency, adding dynamic control to reshape the optical pinhole for different scenes, and extending the camera's operation across a wider mid-infrared range.", "release_time": "2025-09-26", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250926035048.htm"}
{"category": "研究前沿", "title": "超重带电引力微子或为暗物质 JUNO探测器有望探寻", "short_summary": "理论修正预言超重带电引力微子可作暗物质，中国JUNO实验具备独特探测潜力。", "detailed_summary": "理论修正预言超重带电引力微子可作暗物质，中国JUNO实验具备独特探测潜力。\n(1) 研究基于对N=8超引力理论的修正，成功解释了标准模型粒子电荷问题，并预言存在带电荷（±1/3或±2/3）的超重引力微子。\n(2) 提出这些质量接近普朗克尺度的引力微子，因其极重且稳定无法衰变，可作为一类新型带电暗物质候选者，其极低丰度使其符合观测约束。\n(3) 重点分析了中国江门地下中微子观测站（JUNO）等大型液体探测器探测此类粒子的可行性，通过精密模拟确定了其穿过探测器时产生的独特信号，可与已知粒子背景区分。\n(4) 此项研究深度融合理论物理与量子化学，为在JUNO（预计2025年下半年运行）和美国的DUNE等未来实验中寻找统一引力与粒子物理的证据开辟了新途径。", "raw_content": "In 1981 Murray Gell-Mann, Nobel Prize laureate for the introduction of quarks as fundamental constituents of matter, noticed the intriguing fact that the particles of the Standard Model, quarks and leptons, are contained in a theory formulated purely mathematically 2 years earlier, N=8 supergravity, distinguished by its maximal symmetry. N=8 supergravity contains, besides Standard Model matter particles of spin 1/2, also gravitational part: graviton (of spin 2) and 8 gravitinos of spin 3/2. If the Standard Model is indeed related to N=8 supergravity, the relation may possibly point to a path to solve the most difficult problem of fundamental theoretical physics -- unifying gravity with particle physics. N=8 supergravity in the spin ½ sector contains exactly 6 quarks (u,d,c,s,t,b) and 6 leptons (electron, muon, taon and neutrinos) and forbids the presence of any other matter particles. After 40 years of intensive accelerator research failing to discover any new matter particles the N=8 supergravity matter content is not only consistent with our knowledge but remains the only known theoretical explanation of the number of quarks and leptons in the Standard Model! However, direct connection of N=8 supergravity with the Standard Model had several drawbacks, the main one being that the electric charges of quarks and leptons were shifted by ±1/6 with respect to the known values, for example electron had charge -5/6 instead of -1. Several years ago Krzysztof Meissner from the Faculty of Physics at the University of Warsaw, Poland and Hermann Nicolai from the Max Planck Institute for Gravitational Physics (Albert Einstein Institute/AEI), Potsdam, Germany returned to the Gell-Mann's idea and were able to go beyond N=8 supergravity and modify the original proposal obtaining correct electric charges of the Standard Model matter particles. The modification is very far reaching pointing to an infinite symmetry K(E10), little known mathematically and replacing the usual symmetries of the Standard Model. One of the surprising outcomes of the modification, described in papers in Physical Review Letters and Physical Review, is the fact that the gravitinos, presumably of the extremely large mass close to the Planck scale i.e. billion billion proton masses, are electrically charged: 6 of them have charge ±1/3 and 2 of them ±2/3. The gravitinos, even though they are extremally massive, cannot decay since there are no particles they could decay into. Meissner and Nicolai proposed therefore that 2 gravitinos of charge ±2/3 (the other 6 have much lower abundance) could be Dark Matter particles of very different kind than anything proposed so far. Namely, the widely advertized usual candidates, either extremely light like axions or intermediate (proton) mass like WIMPs (weakly interacting massive particles) were electrically neutral, in compatibility with the name 'Dark Matter'. However, after more than 40 years of intensive search by many different methods and devices no new particles beyond the Standard Model were detected. However, gravitinos present a new alternative. Even though they are electrically charged, they can be Dark Matter candidates because being so massive they are extremely rare and therefore observationally 'do not shine on the sky' and avoid the very tight constraints on the charge of Dark Matter constituents. Moreover, the electric charge of gravitinos suggested a completely different way of trying to prove their existence. The original paper in 2024 in Eur. Phys. J. by Meissner and Nicolai pointed out that neutrino detectors, based on scintillators different from water, could be suitable for the detection of Dark Matter gravitinos. However, the search is made enormously difficult by their extreme rarity (presumably only one gravitino per 10,000 km3 in the Solar System), which is why there is no prospect of detection with currently available detectors. However, new giant, oil or liquid argon underground detectors, are either constructed or planned and realistic possibilities for searching for these particles are now opening up. Among all detectors, the Chinese Jiangmen Underground Neutrino Observatory (JUNO) now under construction, seems predestined for such a search. It aims to determine the properties of neutrinos (actually antineutrinos) but since neutrinos interact extremely weakly with matter the detectors must have very large volumes. In the case of the JUNO detector, this means 20,000 tons of an organic, synthetic oil-like liquid, commonly used in chemical industry, with special additions, in a spherical vessel with a diameter of approximately 40 meters with more than 17 thousand photomultipliers around the sphere. JUNO is scheduled to begin measurements in the second half of 2025. The recently published paper in Physical Review Research by Meissner and Nicolai, with collaborators Adrianna Kruk and Michal Lesiuk from the Faculty of Chemistry at the University of Warsaw, presents a detailed analysis of the specific signatures that events caused by gravitinos could produce at JUNO and in future liquid argon detectors such as the Deep Underground Neutrino Experiment (DUNE) in the United States. The paper describes not only the theoretical background both on the physics and chemistry sides but also very detailed simulation of the possible signatures as a function of the velocity and track of a gravitino traveling through the oil vessel. It required very advanced knowledge of quantum chemistry and intensive CPU-time consuming calculations. The simulations had to take into account many possible backgrounds - decay of radioactive C14 present in the oil, dark count rate and efficiency of photomultipliers, absorption of photons in oil etc. The simulations show that, with the appropriate software, passage of a gravitino through the detector will leave a unique signal impossible to be wrongly identified with a passage of any of the presently known particles. The analysis sets new standards in terms of interdisciplinarity by combining two different areas of research: theoretical and experimental elementary particle physics on one hand and very advanced methods of modern quantum chemistry on the other. The detection of the superheavy gravitinos would be a major step forward in the search for a unified theory of gravity and particles. Since gravitinos are predicted to have masses on the order of the Planck mass, their detection would be the first direct indication of physics near the Planck scale and could thus provide valuable experimental evidence for a unification of all forces of nature.", "release_time": "2025-09-26", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250925025403.htm"}
{"category": "政策计划", "title": "GWEC呼吁全球落实可再生能源承诺", "short_summary": "GWEC支持各国NDCs可再生能源目标，强调风能成本与就业优势，呼吁COP30采取行动。", "detailed_summary": "GWEC支持各国NDCs可再生能源目标，强调风能成本与就业优势，呼吁COP30采取行动。\n(1) 全球风能理事会（GWEC）欢迎联合国气候行动中近100个国家更新NDCs，其中78%重申三倍可再生能源承诺。\n(2) 风能作为核心可再生能源，已为124个国家供电，年发电超1.1TWh，创造150万个就业岗位，且成本低于化石燃料。\n(3) GWEC呼吁COP30聚焦行动：消除部署障碍（如审批慢、电网投资不足）、确保政策稳定性、扩大新兴市场融资。\n(4) 驳斥美国总统特朗普的错误信息，强调可再生能源投资创新高（2025年上半年达3860亿美元），而化石燃料补贴仍占主导。\n(5) 将COP30视为实现NDCs的关键，推动能源转型以促进经济增长和就业。", "raw_content": "26 September, Lisbon, Portugal | GWEC welcomes the endorsement of renewable energy demonstrated at the United Nations this week. With almost 100 countries signalling new climate targets and numerous countries submitting or announced new and updated NDCs, the commitment to the Paris Agreement remains strong. Around 78% of new NDCs referenced renewable energy, with governments across the world reaffirming their commitment to the tripling renewables pledge. Renewable energy, with wind at its core, is now recognized not only as a climate necessity, but as the foundation of energy security and economic growth. GWEC calls on governments to ignore the noise and focus on the facts: wind energy delivers more than 1.1TWh of electricity – equivalent to more than 500 million homes - and is responsible for 1.5m jobs around the world. Wind turbines are generating clean and secure renewable energy in 124 countries, and countries are delivering new plans, policies and action to install new capacity. And moreover, wind is cheap. Last year, over 90% of newly added renewable power capacity was cheaper than new fossil fuel alternatives, with onshore wind leading the way - costing less than half the price of the lowest-cost fossil option. Ben Backwell, CEO of the Global Wind Energy Council and Chair of the Global Renewables Alliance, said: “The renewables sector welcomes the recognition of renewable energy’s crucial role in the future global economy. NDCs are much more than climate plans, they are a roadmap for delivering clean jobs, reinvigorated economies and shared global growth. As the energy transition continues to gain momentum, the noise from those that aim to slow global progress must not deter those working for a cleaner, fairer future. These roadmaps must now be backed up with concrete measures to deliver, so that countries and communities can realise the enormous benefits of renewable energy.” COP30 The world will now turn its attention to COP30 in Belem, Brazil. In New York, President Lula described NDCs as ‘the road maps’ guiding countries through an energy transition that ‘opens the door to a productive and technological transformation comparable to the Industrial Revolution’. This year’s COP must be focused on driving decisive action that delivers on the NDCs. That means: Remove the barriers that hold back deployment, including slow planning and permitting, underinvestment in transmission, and bottlenecks in grid connection. Maintain policy certainty and investment security by setting out pipelines for wind energy deployment, embedding renewable goals into national strategies, avoiding sudden policy changes, and providing stable frameworks for investors. Scale finance in emerging and developing economies. 89 percent of 2035 NDCs are conditional on finance or technical assistance. Lowering the cost of capital, scaling public investment and unlocking blended finance are essential. Plan for a future proof energy system by prioritising implementation of the COP29 Grids and Storage Pledge, making these solutions central to national energy strategies, so renewable energy targets translate into real-world delivery. Advancing action on fossil fuel phase-out, with an honest dialogue at COP to accelerate the shift. Facts over misinformation It is also important to call out the misinformation delivered by US President Donald Trump at the UN General Assembly. While the false claims are too many to address, the facts spell out reality: wind energy is well established as one of the most competitive and fastest to deploy source of new power and is being adopted by growing numbers of countries every year. Wind and other renewables are an important catalyst for investment and job creation. Investment momentum around the world is also strong; global investment in new renewable energy development reached a record $386 billion in the first half of 2025, according to Bloomberg New Energy Finance (BNEF).  BNEF’s data shows that investment is shifting from the US to Europe and other regions, due to a hostile policy environment, undermining the US’s position in the global renewable energy market and making it more difficult to meet growing power demand.  President Trump also missed the target on his analysis of subsidies, which the UN Secretary-General accurately detailed at the General Assembly, explaining that ‘public subsidies - taken from taxpayer money - still flow to fossil fuels over clean energy by a factor of nine to one.’", "release_time": "2025-09-26", "source_institution": "全球风能理事会", "url": "https://www.gwec.net/gwec-news/global-support-for-tripling-goal-sets-course-for-cop30-to-accelerate-transformative-energy-transition"}
{"category": "研究前沿", "title": "第十届重元素化学国际研讨会在敦煌成功举办", "short_summary": "敦煌举办重元素化学国际研讨会，80余位专家探讨超重元素研究前沿。", "detailed_summary": "敦煌举办重元素化学国际研讨会，80余位专家探讨超重元素研究前沿。\n（1）第十届重元素化学国际研讨会于9月7日至11日在甘肃敦煌成功举办；\n（2）会议由中科院近代物理研究所主办，以\"超重元素的化学理论与实验研究\"为主题；\n（3）来自中、美、俄、德等国的80余位顶尖专家学者参会，32位专家作学术报告；\n（4）会议探讨了重元素化学性质实验装置、理论进展及相对论效应影响；\n（5）有效促进了学科交叉融合，下一届会议将于2029年在瑞士召开。", "raw_content": "9 月 7 日至 11 日，“第十届重元素化学国际研讨会”（ 10 th Workshop on the Chemistry of the Heaviest Elements-CHE10 ）在甘肃省敦煌市成功举办。 本次会议由中国科学院近代物理研究所主办，中国化学会、中国核学会核化学与放射化学分会协办，以“超重元素的化学理论与实验研究”为主题，以响应国家“一带一路”倡议，增强与合作伙伴的科技文化交流、增强文化自信，进一步促进我单位在相关研究领域的国际科技合作。 来自中、美、俄、德、瑞士、捷克、日本等国内外著名科研院所的 80 余位国际顶尖专家学者参加了本次会议， 32 位专家和学者做了精彩的学术报告，围绕总结重元素化学性质实验装置、理论研究方面的最新进展以及讨论相对论效应对重元素化学性质的影响等方面进行了分享交流。此次会议有效促进了重元素化学在不同领域的应用发展，深化了学科交叉融合，助力重元素化学研究迈向新高度。 本次会议受到了敦煌市人民政府、中共敦煌市委巡查工作领导小组办公室、敦煌市科学技术局、敦煌市科学技术协会等当地单位的热情支持，敦煌市副市长王得文出席了开幕式并致辞，科技局局长闫峰、科协主席吴红艳等领导全程参与了研讨会，为敦煌从古老的历史文化走向现代的前沿科技搭建了深度对话的平台。 重元素化学国际研讨会每四年举办一次，下一届会议将于 2029 年在瑞士召开。 会议相关信息链接： https://indico.impcas.ac.cn/event/70/ 图1：会议交流掠影 图2：参会人员合影 （核化学室   供稿）", "release_time": "2025-09-26", "source_institution": "近代物理研究所", "url": "http://www.imp.cas.cn/sndt2017/202509/t20250925_7979689.html"}
{"category": "产业应用", "title": "日立联手英伟达建立全球AI工厂加速物理AI应用", "short_summary": "日立基于英伟达架构建全球AI工厂，加速交通能源等领域物理AI方案部署。", "detailed_summary": "日立基于英伟达架构建全球AI工厂，加速交通能源等领域物理AI方案部署。\n（1）日立公司宣布建立基于NVIDIA AI Factory参考架构的全球AI工厂；\n（2）该工厂采用日立iQ系统与NVIDIA Blackwell GPU等硬件，提供统一AI计算基础设施；\n（3）旨在加速开发能与物理世界交互的AI解决方案，支持数字孪生等应用；\n（4）将重点应用于交通、能源、工业等领域的HMAX系列AI解决方案；\n（5）工厂分布美日欧三地，助力日立实现Lumada 3.0愿景，推动产业数字化转型。", "raw_content": "Santa Clara, September 25th, 2025, Hitachi, Ltd. (TSE:6501, \"Hitachi\"), today announced the establishment of a global Hitachi AI Factory based on NVIDIA AI Factory reference architecture, yielding a centralized infrastructure designed to accelerate the development and deployment of physical AI solutions across Hitachi's core business sectors. The AI Factory is powered by Hitachi iQ with NVIDIA HGX B200 systems featuring NVIDIA Blackwell GPUs; Hitachi iQ M Series with NVIDIA RTX PRO 6000 Server Edition GPUs; and NVIDIA Spectrum-X Ethernet networking platform. This strategic initiative directly supports Hitachi's ambition to create and deploy AI that interacts with the real world. The AI Factory will also enable Hitachi to further expand HMAX–the company's family of AI-enabled solutions solving a wide-range of complex problems in the Mobility, Energy, Industrial and Technology sectors.     The centralized AI Factory provides Hitachi's global teams with a powerful unified AI computing infrastructure to run applications and AI workflows developed on the NVIDIA full-stack AI platform, which includes NVIDIA AI Enterprise for production-grade AI as well as NVIDIA Omniverse libraries for simulation, industrial scale, and physically accurate digital twins. This infrastructure allows for the rapid development and deployment of advanced physical AI models. These models will acquire and interpret information from physical environments via cameras and sensors; determine the next steps to take; and execute actions based on that data.     Today's announcement builds on Hitachi, Ltd. President and CEO Toshiaki Tokunaga's recent comment on the Hitachi-NVIDIA partnership wherein he stated that, by leveraging Hitachi iQ built on NVIDIA RTX PRO Servers, Hitachi will further accelerate AI innovation. Mr. Tokunaga specified that through the NVIDIA RTX PRO Servers' ability to accelerate AI reasoning and physical AI, digital twin development and physical asset optimization (including social infrastructure) is augmented while new possibilities such as productivity improvement across all business activities are unlocked.      The Hitachi AI Factory is strategically distributed across the United States, EMEA, and Japan ensuring that Hitachi's engineers can collaborate seamlessly and access powerful computing resources with low latency, no matter where they are. This interconnected network will support the creation of a wide range of physical AI applications, driving new levels of efficiency, productivity, and safety across industries.     The initiative reinforces Hitachi's commitment to using cutting-edge technology to drive both social and business innovation.     \"The strategic collaboration between Hitachi and NVIDIA is becoming a key engine for solving complex real-world problems, accelerating social innovation,\" said Jun Abe, General Manager of the Digital Systems & Services Division. \"Our work together leverages NVIDIA AI infrastructure to achieve both DX (Digital Transformation) and GX (Green Transformation) with solutions like Hitachi Rail's HMAX, which is currently transforming railway operations and maintenance; Hitachi Vantara's AI solution portfolio Hitachi iQ; and Hitachi's liquid-cooled AI data centers supporting our generative AI foundation. By establishing a global NVIDIA AI Factory, we can now operate as a true 'One Hitachi' across regions and organizations. A synergy that will accelerate physical AI innovations, as exemplified by HMAX.\"    Operationalizing the Corporate Vision    Hitachi views the AI Factory as a fundamental step toward achieving its Lumada 3.0 vision. Lumada is Hitachi's operating model that helps enterprises solve business and societal problems through co-created digital transformation. It harnesses Hitachi's extensive domain knowledge and technical expertise, combined with AI technologies to convert data into value while reducing operational costs and inefficiencies.      Hitachi is unique in its ability to integrate IT, OT, and hardware expertise as illustrated by the engineering design capabilities, products, and consultative services making up Lumada 3.0. The company leads the Industrial AI market with disruptive solutions that redefine what's possible.      \"AI factories are the engines of a new industrial revolution, converting enterprise data into autonomous intelligence for both software and the physical world,\" said Justin Boitano, Vice President, Enterprise AI Products, NVIDIA. \"With NVIDIA accelerated computing and software, Hitachi's AI factory infrastructure provides a transformative platform for building and deploying enterprise and physical AI.\"   About Hitachi, Ltd.  Through its Social Innovation Business (SIB) that brings together IT, OT(Operational Technology) and products, Hitachi contributes to a harmonized society where the environment, wellbeing, and economic growth are in balance. Hitachi operates globally in four sectors – Digital Systems & Services, Energy, Mobility, and Connective Industries – and the Strategic SIB Business Unit for new growth businesses. With Lumada at its core, Hitachi generates value from integrating data, technology and domain knowledge to solve customer and social challenges. Revenues for FY2024 (ended March 31, 2025) totaled 9,783.3 billion yen, with 618 consolidated subsidiaries and approximately 280,000 employees worldwide. Visit us at  www.hitachi.com.  Information contained in this news release is current as of the date of the press announcement, but may be subject to change without prior notice.", "release_time": "2025-10-15", "source_institution": "日本日立", "url": "http://www.hitachi.com/New/cnews/month/2025/09/250926b.html"}
{"category": "政策计划", "title": "云南“十四五”生态文明建设成果显著 绿电装机全国居首", "short_summary": "云南“十四五”绿色转型成效卓著，绿电装机及多项绿色指标位居全国前列。", "detailed_summary": "云南“十四五”绿色转型成效卓著，绿电装机及多项绿色指标位居全国前列。\n(1) 云南省举行新闻发布会，通报“十四五”生态文明建设排头兵专场成果。\n(2) 能源绿色化显著：新增绿电装机超6000万千瓦，总规模达1.5亿千瓦居全国第一；绿电发电量占比超90%。\n(3) “西电东送”累计送电超2万亿千瓦时，为国家节约标煤6.65亿吨、减排二氧化碳17.3亿吨。\n(4) 产业绿色化加速：“绿色铝谷”崛起，创建136家国家级绿色工厂、10个绿色工业园区及15个省级零碳园区。\n(5) 农业与服务业的绿色品牌影响力提升，如咖啡产量占全国95%，旅游业成为万亿级产业。", "raw_content": "云南省人民政府新闻办公室于2025年9月24日(星期三)上午，举行云南省“高质量完成‘十四五’规划”系列主题新闻发布会·生态文明建设排头兵专场。云南省发展和改革委员会二级巡视员  宋予表示，“十四五”以来，云南坚定不移走生态优先、绿色发展之路，持续推动能源、产业、交通运输、城乡建设等重点领域绿色转型，绿色已经成为云南经济社会发展最鲜明的底色。能源发展更加绿色化。持续巩固和扩大绿电优势，大力推进“风光水火储”多能互补和“源网荷储”一体化发展，建设全国重要清洁能源基地。“十四五”以来，新增绿色能源装机超6000万千瓦，绿色能源装机规模达1.5亿千瓦、居全国第1位。绿色能源产业产值从2020年的不足3000亿元增长到4000亿元以上，成为云南产业“顶梁柱”。电力碳排放因子全国最低，绿电装机及发电量占比超过90%、非化石能源占一次能源消费比重达46%，均居全国前列。“西电东送”累计送电量超过2万亿千瓦时、居全国第1位，相当于为东部地区节约标准煤6.65亿吨、减排二氧化碳17.3亿吨，为国家能源安全和碳达峰碳中和作出积极贡献。产业发展更加绿色化。加快推进农业结构调整，“云茶”“云花”“云果”“云药”享誉国内外，2024年，全省咖啡产量占全国的95%，鲜切花产量位居世界第1位、出口规模居全国第1位。有机产品认证证书数量居全国第1位，创建5个农业绿色发展先行区。工业发展新动能不断增强，“绿电+先进制造业”新优势持续放大，云南“绿色铝谷”正在崛起，打造产业绿色低碳转型载体，启动建设15个省级零碳园区，累计创建国家级绿色工厂136家、绿色工业园区10个，培育绿色供应链管理企业7家。现代服务业快速发展，2024年生产性服务业营业收入规模达1.4万亿元，积极推动农文旅融合发展，旅游业成为万亿级产业，“有一种叫云南的生活”叫响全国，“旅居云南”成为大IP、大市场、大生态。", "release_time": "2025-11-11", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/zhdt/202510/t20251028_792140.html"}
{"category": "研究前沿", "title": "科学家首次发现冰晶具有惊人柔韧性", "short_summary": "PNNL团队首次实现液态水结冰分子级观测，揭示冰晶容纳气泡的独特柔性。", "detailed_summary": "PNNL团队首次实现液态水结冰分子级观测，揭示冰晶容纳气泡的独特柔性。\n(1) 美国太平洋西北国家实验室首次实现液态水到冰转变的分子级实时观测，成果发表于《自然-通讯》。\n(2) 研究发现冰晶六方晶格具有非凡柔韧性，能轻松容纳气体气泡并允许其移动合并，而不会导致晶体破裂。\n(3) 这一发现通过新型低温液相透射电镜技术实现，颠覆了对冰晶体刚性的传统认知。\n(4) 研究对冰川运动预测、生物低温保存及航空防冰等领域具有重要应用价值。\n(5) 机器学习分子动力学模型验证了实验观察，确认冰在容忍缺陷方面是独一无二的固体。", "raw_content": "RICHLAND, Wash.—You’d think there’s nothing surprising left to discover about water. After all, researchers have been studying its properties for centuries. But today researchers at Department of Energy’s Pacific Northwest National Laboratory report a new finding. Even though ice forms in a perfectly hexagonal lattice, it is surprisingly flexible and malleable, which explains why ice so often has trapped gas bubbles. The findings come from the first-ever molecular-resolution observations of nanoscale samples of ice frozen from liquid water, which appear today in the journal Nature Communications . Why do ice cubes so often trap air bubbles? Now we know, thanks to researchers at Pacific Northwest National Laboratory, who captured the first-ever nanoscale images of ice crystals formed from liquid water. (Animation by Sara Levine | Pacific Northwest National Laboratory) “We observed dissolved gas not only generate cavities in ice crystals, but also migrate, merge with other gas bubbles and dissolve—behavior that is only possible due to the unusual nature of bonding in ice,” said James De Yoreo, principal investigator of the work and a Battelle Fellow at PNNL. “This work opens up an entirely new opportunity to explore ice crystallization and melting behavior at scales unimaginable only a few years ago.” The research could have profound implications for preserving deeply frozen (cryogenic) biological tissue samples, forecasting ice behavior for aviation and vehicle safety and understanding the movement of glaciers, among other areas of research. “There have been a lot of mysteries about ice,” said PNNL materials scientist Jingshan Du, lead author of the work. “We want to understand how ice tolerates structural imperfections in the crystal and how trapped bubbles affect the mechanical properties of the crystal. Now we have a way to understand that.” What’s new with ice Until now, no one has been able to directly observe molecules of water undergoing the shift from liquid water to ice. That’s because the techniques scientists use to view individual atoms involve harsh conditions, including using high-energy radiation and removal of all air (vacuum sealing). While researchers have generated some images of ice at the molecular scale, that ice doesn’t reflect the normal freeze-thaw cycles on Earth. It’s generated by flash freezing directly from vapor to solid. To avoid those issues, the research team sandwiched liquid water between thin carbon membranes, which turned out to be the critical factor that led to this imaging breakthrough. Then they developed a new technique, cryogenic liquid-cell transmission electron microscopy, to follow the freezing process. “The membranes protect the ice crystals from high vacuum and radiation, allowing us to acquire images with atomic-level information,” said Du. They watched gas bubbles form, move through the lattice, merge with other bubbles and dissolve. The study results showed that when liquid water turns to solid ice, defects in its crystal structure or trapped gas bubbles don’t cause much strain to the ice crystal, which could cause fracturing. It adapts to the presence of the defect with surprising ease compared with other solids, like metal or minerals. The nature of water’s chemical bonds makes it extraordinarily flexible and malleable, even as solid ice. This new observation, combined with the crucial fact that ice is less dense than liquid water, are properties that support life on Earth, and especially in the sea. The researchers also made direct observations of the geometries and forces that guide ice crystal formation at all scales, including the formation of snowflakes. While snow forms from water vapor, not liquid water, the same underlying forces are at work. Watch how the same nanoscale forces shape both ice cubes and snowflakes. PNNL researchers just recorded the first-ever molecular scale video of ice formed from liquid water over a century after this snowflake was photographed. (Composite image by Sara Levine | Pacific Northwest National Laboratory) To confirm their experimental observations, the PNNL scientists collaborated with researchers from Argonne National Laboratory and the University of Illinois-Chicago who had used machine learning to develop a highly accurate molecular dynamics model for ice. The comparisons between experiment and what was predicted by theoretical models confirmed that ice is unique among solids in its tolerance for defects without compromising the integrity of the ice crystal structure. Why trapped air bubbles in ice matter While the PNNL team is studying ice dynamics on a nanoscale, other researchers are discovering that the presence of air bubbles in glaciers greatly affects their behavior. Recently, scientists showed that glaciers melt more than two times faster if they contain bubbles, compared with bubble-free ice . Other scientists are trying to avoid having ice form in delicate tissue samples or on aircraft in flight. Next steps for this research include studying melting and working with more complicated samples, including water with dissolved materials. In addition to Du and DeYoreo, PNNL researcher Ajay S. Karakoti; Argonne National Laboratory scientists Suvo Banik, Henry Chan and Subramanian K. R. S. Sankaranarayanan; Helmholtz Institute Erlangen-Nürnberg for Renewable Energy scientists Birk Fritsch and Andreas Hutzler; as well as University of Washington scientist Ying Xia, also contributed to the research. The study was supported by the DOE Office of Science, Basic Energy Sciences, Division of Materials Science and Engineering. Molecular dynamics simulations were supported by the Data, Artificial Intelligence, and Machine Learning at Scientific User Facilities program under the Digital Twin Project at Argonne National Laboratory. A portion of the work was conducted at the Environmental Molecular Sciences Laboratory, a scientific user facility at PNNL, at the Molecular Foundry and the National Energy Research Scientific Computing Center DOE-supported user facilities located at Lawrence Berkeley National Laboratory.", "release_time": "2025-09-26", "source_institution": "美国能源部西北太平洋国家实验室", "url": "https://www.pnnl.gov/news-media/chilling-discovery-surprising-flexibility-ice"}
{"category": "研究前沿", "title": "PNNL加入太空信息共享中心推动前沿研究", "short_summary": "美国PNNL国家实验室加入太空信息共享与分析中心，贡献核能及网络安全技术助力太空探索。", "detailed_summary": "美国PNNL国家实验室加入太空信息共享与分析中心，贡献核能及网络安全技术助力太空探索。\n(1) 美国能源部太平洋西北国家实验室加入太空信息共享与分析中心，成为首个加入该组织的能源部下属国家实验室。\n(2) PNNL在核推进系统、太空环境对材料影响及网络安全方面拥有专业知识，将助力应对太空资产安全威胁。\n(3) 当前太空探索活动激增，轨道卫星数量已超1.1万颗，需公私合作进行科学协调与风险管理。\n(4) 实验室具体贡献包括与Zeno Power公司合作验证锶-90热源设计，以及开展OHSNAP项目研究太空辐射对材料的影响。\n(5) PNNL还为美国太空军运营太空网络测试靶场，并通过CHIRP项目培养太空网络安全人才。", "raw_content": "RICHLAND, Wash.—Researchers at the Department of Energy’s Pacific Northwest National Laboratory are bringing their knowledge of nuclear power, space governance, cybersecurity and technology test beds to the space domain by joining an organization that facilitates collaboration across the global space industry. PNNL is the first DOE national laboratory to join the Space Information Sharing and Analysis Center , or Space ISAC. The organization serves as a source for data, facts and analysis on space security and threats to space assets. Space ISAC facilitates collaboration across the global space industry, enhancing the ability to prepare for and respond to vulnerabilities, incidents and threats. Members include U.S. agencies, universities and industry partners as well as several international organizations. Strengths that PNNL brings to the domain of space include expertise in nuclear propulsion systems, the effects of the space environment on materials, and cybersecurity. (Animation by Sara Levine | Pacific Northwest National Laboratory) The development comes at a time when space exploration is taking off. A growing number of companies are developing launch vehicles, spacecraft and payloads. Missions to space, some carrying civilians, are being funded and launched both by governments and by companies. Four countries in addition to the United States have landed spacecraft on the moon. Every day, space is becoming more congested: more than 11,000 satellites are now in orbit, and tens of thousands more are projected by the end of the decade. Managing all that activity and the risks involved requires careful coordination and scientific collaboration involving both public and private actors. “Joining the Space ISAC puts us squarely with the leaders exploring space technology and governance,” said Sarah Frazar, a national security analyst at PNNL. “We have a lot to offer federal and industry partners interested in using nuclear technology for space power and propulsion systems. We have a long tradition of helping partners test new technologies as well as understanding and managing the risks involved.” PNNL also has extensive knowledge about the legal and regulatory challenges of introducing new technologies into space. Challenges include new launch regulations, development of international governance and new performance standards. “We are thrilled to welcome Pacific Northwest National Laboratory to Space ISAC,” said Erin Miller, executive director of Space ISAC. “Their expertise in national security and cutting-edge research strengthens our collective mission to secure the global space ecosystem.” Expertise in space research, cybersecurity and nuclear materials PNNL brings 60 years of experience working with the nuclear materials and technologies needed for advanced space exploration. PNNL researchers have supported a variety of space reactor development activities, including the SP-100 and Project Prometheus programs dating back to the late 1980s. While those programs were ultimately cancelled, the question of how to provide more energy in space continues to loom large as planned missions to the moon and Mars proceed. Challenges include environments that are very dark, very cold and very remote. Heat and power from nuclear fission and radioactive decay provide energy-dense options to surmount these challenges. In recent years, public-private partnerships have become a staple of successful space exploration, and working with industrial and federal partners has flourished at PNNL. Laboratory researchers are collaborating with industry to develop and deploy new types of space nuclear power systems to keep critical components warm and provide electrical energy for years or even decades. In one effort, a team led by PNNL engineer Jeff Katalenich tapped the unique resources of PNNL’s nuclear research and development facility, the Radiochemical Processing Laboratory . The PNNL team worked closely with Zeno Power , a company that is developing commercial radioisotope heat and power systems, to fabricate and validate its strontium-90 heat source design. Two scientists work in the Shallow Underground Laboratory at Pacific Northwest National Laboratory. The lab is shielded from cosmic rays and other background radiation, allowing scientists to do unique studies of materials that have been exposed to the space environment. (Photo by Andrea Starr | Pacific Northwest National Laboratory) Last year, PNNL worked with the Polaris Program , a commercial spaceflight program headed by entrepreneur Jared Isaacman, to study the effects of space radiation on materials and human health. The experiment, dubbed OHSNAP —the Orbital High-Energy Space Neutron Activation Project—explored the effects of galactic cosmic rays and the high-energy neutrons created when the cosmic rays hit a spacecraft. Samples were returned to PNNL, where they were analyzed using ultra-low-background radiation detection capabilities in the Shallow Underground Laboratory . The Laboratory’s work includes research done through the Space Cyber Test Range, a virtual test bed that PNNL operates for the U.S. Space Force. The virtual range supports space cyber development, testing and training across the full spectrum of space-related activities—ground activity, communications, launches and satellites. In addition, PNNL teams with the Space Force to increase the pipeline of students who are trained to protect space-based technologies from cyber threats. The Cyber Halo Innovation Research Program provides college students with a two-year pathway to a cybersecurity career at Space Systems Command or an industry partner.", "release_time": "2025-10-01", "source_institution": "美国能源部西北太平洋国家实验室", "url": "https://www.pnnl.gov/news-media/pnnl-joins-space-research-group-bringing-its-nuclear-and-cybersecurity-expertise-new"}
{"category": "政策计划", "title": "全国碳市场成交额创新高 三行业将纳入管理", "short_summary": "全国碳市场累计成交近480亿元，钢铁等三行业将纳入，民航业加速准备。", "detailed_summary": "全国碳市场累计成交近480亿元，钢铁等三行业将纳入，民航业加速准备。\n（1）全国碳市场累计成交量近7亿吨，成交额约480亿元，2024年成交额181.14亿元创年度新高；\n（2）钢铁、水泥、铝冶炼行业配额分配方案加快推进，1334家新纳入单位名录已公布；\n（3）中国民用航空局正研究制定民航业参与碳市场工作方案；\n（4）2023年度配额清缴完成率达99.98%，28个省级地区100%完成履约；\n（5）市场运行平稳有序，交易主体参与意愿增强，碳减排意识持续加强。", "raw_content": "中国证券报记者从9月24日在上海举行的“2025年中国碳市场大会”上获悉，截至8月底，全国碳排放权交易市场累计成交量近7亿吨，成交额约480亿元人民币。2024年全年成交额创2021年市场启动上线交易以来年度新高。会议同期发布的《全国碳市场发展报告（2025）》显示，2024年以来，纳入全国碳排放权交易市场的重点排放单位有序开展市场交易，交易规模创历史新高。2024年，碳排放配额年度成交金额达到181.14亿元，创2021年市场启动上线交易以来年度新高。截至2025年8月底，全国碳排放权交易市场配额累计成交量6.96亿吨，累计成交额478.26亿元。此外，交易价格反映供需关系，交易主体参与意愿增强，交易产品和方式逐步丰富升级。报告介绍，目前，生态环境部正按程序加快推进钢铁、水泥、铝冶炼行业配额分配方案编制工作。新纳入3个行业的1334家重点排放单位名录已公布，碳排放相关数据月度信息化存证全面启动，企业账户开立工作稳步推进。此外，中国民用航空局也积极组织编制民航业碳排放核算核查指南，研究制定民航业参与全国碳市场工作方案，推动将民航业及早纳入全国碳排放权交易市场管理。2024年，全国碳市场配额分配和清缴圆满完成。报告提出，截至2024年年底，2023年度配额清缴完成率为99.98％，较第二个履约周期进一步提升，创历史新高。其中，全国共有28个省级地区100％完成履约工作，较前两个履约周期明显增加，仅4家重点排放单位未按时足额履约。报告显示，在各方的共同努力下，全国碳市场运行平稳有序，制度体系不断健全，市场活力进一步提升，重点排放单位碳减排意识持续加强、配额清缴完成情况全面趋好，各类经营主体踊跃参与，自愿开发和实施减排项目，碳市场功能不断显现。", "release_time": "2025-11-11", "source_institution": "中国新能源网", "url": "http://www.newenergy.org.cn/zhdt/202510/t20251028_792143.html"}
{"category": "政策计划", "title": "印尼强调煤炭能源安全并承诺公正转型", "short_summary": "印尼官员重申煤炭对能源安全的重要性，并规划下游加工与清洁技术以实现公正转型。", "detailed_summary": "印尼官员重申煤炭对能源安全的重要性，并规划下游加工与清洁技术以实现公正转型。\n（1）印尼能源官员在“煤炭亚洲2025”活动上强调煤炭对维护国家能源安全的重要作用；\n（2）印尼煤炭资源储量达979.6亿吨，2024年产量创8.36亿吨新高，前8月产量已超5.09亿吨；\n（3）煤炭部门2024年贡献非税收入142.89万亿印尼盾，占矿业能源部门总额超70%；\n（4）印尼致力于煤炭下游加工，如生产二甲醚、甲醇，并推广超临界锅炉等清洁煤技术以减少排放；\n（5）政府计划到2040年逐步淘汰燃煤电厂，通过公平利用策略平衡能源供应、工业增长与减排目标。", "raw_content": "据印度尼西亚媒体9月23日报道的消息，印尼能源和矿产资源部(Ministry of Energy and Mineral Resources)矿业和煤炭总局局长(Director General of Mining and Coal)特里·维纳尔诺(Tri Winarno)周一(9月22日)在巴厘岛举行的“亚洲煤炭2025”(Coaltrans Asia -CT Asia)活动开幕式上讲话强调，煤炭在维护印尼国家能源安全方面的重要性，同时重申了印尼对公正能源转型的承诺。 Tri局长演讲中表示，全球煤炭消费量仍处于高水平，亚洲是主要支撑地区。印度尼西亚凭借其979.6亿吨资源储量和319.5亿吨储量，继续成为该地区的重要供应国。 2024年，印度尼西亚煤炭产量达到8.36亿吨，创历史新高。截至今年8月，煤炭产量已超过5.09亿吨，占全年目标的68.81%。凭借这一成就，如果第四季度的表现得以维持，今年全年的煤炭生产目标可以实现。 煤炭对印尼经济的贡献也非常重要。2024年，煤炭部门为国家非税收入(PNBP)贡献了142.89万亿印尼盾，超过矿业和能源部门PNBP总额的70%。 Tri局长强调，印度尼西亚不仅专注于煤炭生产，还致力于煤炭的下游加工以创造附加值。下游转化计划旨在生产作为液化石油气的替代品的二甲醚(DME)和作为化工和能源行业原料的甲醇。 此外，清洁煤技术(Clean Coal Technology - CCT)也已成为减少排放的主要议程，包括使用超临界和超超临界锅炉以及开发煤的气化。这项技术使煤炭能够转化为合成气，可用于发电、液体燃料、氢气和化工原料。 在此期间，所有在禁令前批准的PLN新电厂必须使用超临界技术或更高级的技术，一些为工业服务的独立电厂也采用了更高效的循环流化床锅炉。 印尼政府计划到2040年逐步淘汰燃煤电厂，从而调整煤炭在未来的作用，采用公平利用策略，并支持减少碳排放。 他补充道，一方面，煤炭仍然需要维持能源供应和推动工业增长，特别是冶炼。然而，另一方面，我们也必须规范煤炭的使用，促进下游加工，减少其环境影响。 “煤炭亚洲2025”(CT Asia) 对印度尼西亚来说是一个重要的平台，用于重申国家能源政策的方向，即保持煤炭消费平衡、加强国内市场、冶炼行业与脱碳和上下游产业的协调，并为后代的可持续发展做出贡献。 责任编辑： 张磊 标签：印尼,煤炭产量 上一篇：1-8月份宁夏规上原煤销量同比增长12.... 下一篇：最后一页", "release_time": "2025-09-25", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194395-1.html"}
{"category": "研究前沿", "title": "CRESt系统实现人工智能驱动的自动化材料发现", "short_summary": "CRESt结合AI与机器人技术，通过主动学习加速材料研发，成功开发出高性能燃料电池催化剂。", "detailed_summary": "CRESt结合AI与机器人技术，通过主动学习加速材料研发，成功开发出高性能燃料电池催化剂。\n（1）CRESt系统整合主动学习、贝叶斯优化和机器人设备，实现材料发现的自动化工作流程；\n（2）系统能够处理多模态实验数据，并利用文献知识指导材料配方设计；\n（3）通过计算机视觉监控实验过程，自动识别并建议解决可重复性问题；\n（4）在燃料电池催化剂开发中，仅用三个月筛选900多种配方，发现八元素催化剂；\n（5）新催化剂将功率密度成本效率提升9.3倍，且仅需四分之一贵金属用量。", "raw_content": "A smarter system Materials science experiments can be time-consuming and expensive. They require researchers to carefully design workflows, make new material, and run a series of tests and analysis to understand what happened. Those results are then used to decide how to improve the material. To improve the process, some researchers have turned to a machine-learning strategy known as active learning to make efficient use of previous experimental data points and explore or exploit those data. When paired with a statistical technique known as Bayesian optimization (BO), active learning has helped researchers identify new materials for things like batteries and advanced semiconductors. “Bayesian optimization is like Netflix recommending the next movie to watch based on your viewing history, except instead it recommends the next experiment to do,” Li explains. “But basic Bayesian optimization is too simplistic. It uses a boxed-in design space, so if I say I’m going to use platinum, palladium, and iron, it only changes the ratio of those elements in this small space. But real materials have a lot more dependencies, and BO often gets lost.” Most active learning approaches also rely on single data streams that don’t capture everything that goes on in an experiment. To equip computational systems with more human-like knowledge, while still taking advantage of the speed and control of automated systems, Li and his collaborators built CRESt. CRESt’s robotic equipment includes a liquid-handling robot, a carbothermal shock system to rapidly synthesize materials, an automated electrochemical workstation for testing, characterization equipment including automated electron microscopy and optical microscopy, and auxiliary devices such as pumps and gas valves, which can also be remotely controlled.  Many processing parameters can also be tuned. With the user interface, researchers can chat with CRESt and tell it to use active learning to find promising materials recipes for different projects. CRESt can include up to 20 precursor molecules and substrates into its recipe. To guide material designs, CRESt’s models search through scientific papers for descriptions of elements or precursor molecules that might be useful. When human researchers tell CRESt to pursue new recipes, it kicks off a robotic symphony of sample preparation, characterization, and testing. The researcher can also ask CRESt to perform image analysis from scanning electron microscopy imaging, X-ray diffraction, and other sources. Information from those processes is used to train the active learning models, which use both literature knowledge and current experimental results to suggest further experiments and accelerate materials discovery. “For each recipe we use previous literature text or databases, and it creates these huge representations of every recipe based on the previous knowledge base before even doing the experiment,” says Li. “We perform principal component analysis in this knowledge embedding space to get a reduced search space that captures most of the performance variability. Then we use Bayesian optimization in this reduced space to design the new experiment. After the new experiment, we feed newly acquired multimodal experimental data and human feedback into a large language model to augment the knowledgebase and redefine the reduced search space, which gives us a big boost in active learning efficiency.” Materials science experiments can also face reproducibility challenges. To address the problem, CRESt monitors its experiments with cameras, looking for potential problems and suggesting solutions via text and voice to human researchers. The researchers used CRESt to develop an electrode material for an advanced type of high-density fuel cell known as a direct formate fuel cell. After exploring more than 900 chemistries over three months, CRESt discovered a catalyst material made from eight elements that achieved a 9.3-fold improvement in power density per dollar over pure palladium, an expensive precious metal. In further tests, CRESTs material was used to deliver a record power density to a working direct formate fuel cell even though the cell contained just one-fourth of the precious metals of previous devices. The results show the potential for CRESt to find solutions to real-world energy problems that have plagued the materials science and engineering community for decades. “A significant challenge for fuel-cell catalysts is the use of precious metal,” says Zhang. “For fuel cells, researchers have used various precious metals like palladium and platinum. We used a multielement catalyst that also incorporates many other cheap elements to create the optimal coordination environment for catalytic activity and resistance to poisoning species such as carbon monoxide and adsorbed hydrogen atom. People have been searching low-cost options for many years. This system greatly accelerated our search for these catalysts.” A helpful assistant Early on, poor reproducibility emerged as a major problem that limited the researchers’ ability to perform their new active learning technique on experimental datasets. Material properties can be influenced by the way the precursors are mixed and processed, and any number of problems can subtly alter experimental conditions, requiring careful inspection to correct. To partially automate the process, the researchers coupled computer vision and vision language models with domain knowledge from the scientific literature, which allowed the system to hypothesize sources of irreproducibility and propose solutions. For example, the models can notice when there’s a millimeter-sized deviation in a sample’s shape or when a pipette moves something out of place. The researchers incorporated some of the model’s suggestions, leading to improved consistency, suggesting the models already make good experimental assistants. The researchers noted that humans still performed most of the debugging in their experiments. “CREST is an assistant, not a replacement, for human researchers,” Li says. “Human researchers are still indispensable. In fact, we use natural language so the system can explain what it is doing and present observations and hypotheses. But this is a step toward more flexible, self-driving labs.”", "release_time": "2025-09-26", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/ai-system-learns-many-types-scientific-information-and-runs-experiments-discovering-new-materials-0925"}
{"category": "研究前沿", "title": "MIT新算法提升3D打印材料设计精准度", "short_summary": "MIT研发设计方法，通过预置打印限制实现材料性能与理论模型高度吻合。", "detailed_summary": "MIT研发设计方法，通过预置打印限制实现材料性能与理论模型高度吻合。\n（1）MIT研究团队开发新型设计方法，解决3D打印制造精度与拓扑优化设计之间的脱节问题；\n（2）该方法在设计算法中预置打印头尺寸和层间弱粘合等制造限制参数，并自动生成打印路径；\n（3）实验显示新材料性能偏差显著低于传统设计方法，在70%以下密度时优势尤为明显；\n（4）该技术可降低对3D打印专家的依赖，为水泥、陶瓷等材料的精确制造开辟新途径；\n（5）研究成果发表于《Materials and Design》期刊，有望推动更多材料的可靠应用。", "raw_content": "People are increasingly turning to software to design complex material structures like airplane wings and medical implants. But as design models become more capable, our fabrication techniques haven’t kept up. Even 3D printers struggle to reliably produce the precise designs created by algorithms. The problem has led to a disconnect between the ways a material is expected to perform and how it actually works. Now, MIT researchers have created a way for models to account for 3D printing’s limitations during the design process. In experiments, they showed their approach could be used to make materials that perform much more closely to the way they’re intended to. “If you don’t account for these limitations, printers can either over- or under-deposit material by quite a lot, so your part becomes heavier or lighter than intended. It can also over- or underestimate the material performance significantly,” says Gilbert W. Winslow Associate Professor of Civil and Environmental Engineering Josephine Carstensen. “With our technique, you know what you’re getting in terms of performance because the numerical model and experimental results align very well.” The approach is described in the journal Materials and Design , in an open-access paper co-authored by Carstensen and PhD student Hajin Kim-Tackowiak. Matching theory with reality Over the last decade, new design and fabrication technologies have transformed the way things are made, especially in industries like aerospace, automotive, and biomedical engineering, where materials must reach precise weight-to-strength ratios and other performance thresholds. In particular, 3D printing allows materials to be made with more complex internal structures. “3D printing processes generally give us more flexibility because we don’t have to come up with forms or molds for things that would be made through more traditional means like injection molding,” Kim-Tackowiak explains. As 3D printing has made production more precise, so have methods for designing complex material structures. One of the most advanced computational design techniques is known as topology optimization. Topology optimization has been used to generate new and often surprising material structures that can outperform conventional designs, in some cases approaching the theoretical limits of certain performance thresholds. It is currently being used to design materials with optimized stiffness and strength, maximized energy absorption, fluid permeability, and more. But topology optimization often creates designs at extremely fine scales that 3D printers have struggled to reliably reproduce. The problem is the size of the print head that extrudes the material. If the design specifies a layer to be 0.5 millimeters thick, for instance, and the print head is only capable of extruding 1-millimeter-thick layers, the final design will be warped and imprecise. Another problem has to do with the way 3D printers create parts, with a print head extruding a thin bead of material as it glides across the printing area, gradually building parts layer by layer. That can cause weak bonding between layers, making the part more prone to separation or failure. The researchers sought to address the disconnect between expected and actual properties of materials that arise from those limitations. “We thought, ‘We know these limitations in the beginning, and the field has gotten better at quantifying these limitations, so we might as well design from the get-go with that in mind,” Kim-Tackowiak says. In previous work, Carstensen developed an algorithm that embedded information about the print nozzle size into design algorithms for beam structures. For this paper, the researchers built off that approach to incorporate the direction of the print head and the corresponding impact of weak bonding between layers. They also made it work with more complex, porous structures that can have extremely elastic properties. The approach allows users to add variables to the design algorithms that account for the center of the bead being extruded from a print head and the exact location of the weaker bonding region between layers. The approach also automatically dictates the path the print head should take during production. The researchers used their technique to create a series of repeating 2D designs with various sizes of hollow pores, or densities. They compared those creations to materials made using traditional topology optimization designs of the same densities. In tests, the traditionally designed materials deviated from their intended mechanical performance more than materials designed using the researchers’ new technique at material densities under 70 percent. The researchers also found that conventional designs consistently over-deposited material during fabrication. Overall, the researchers’ approach led to parts with more reliable performance at most densities. “One of the challenges of topology optimization has been that you need a lot of expertise to get good results, so that once you take the designs off the computer, the materials behave the way you thought they would,” Carstensen says. “We’re trying to make it easy to get these high-fidelity products.” Scaling a new design approach The researchers believe this is the first time a design technique has accounted for both the print head size and weak bonding between layers. “When you design something, you should use as much context as possible,” Kim-Tackowiak says. “It was rewarding to see that putting more context into the design process makes your final materials more accurate. It means there are fewer surprises. Especially when we’re putting so much more computational resources into these designs, it’s nice to see we can correlate what comes out of the computer with what comes out of the production process.” In future work, the researchers hope to improve their method for higher material densities and for different kinds of materials like cement and ceramics. Still, they said their approach offered an improvement over existing techniques, which often require experienced 3D printing specialists to help account for the limitations of the machines and materials. “It was cool to see that just by putting in the size of your deposition and the bonding property values, you get designs that would have required the consultation of somebody who’s worked in the space for years,” Kim-Tackowiak says. The researchers say the work paves the way to design with more materials. “We’d like to see this enable the use of materials that people have disregarded because printing with them has led to issues,” Kim-Tackowiak says. “Now we can leverage those properties or work with those quirks as opposed to just not using all the material options we have at our disposal.”", "release_time": "2025-09-25", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/technique-makes-complex-3d-printed-parts-more-reliable-0925"}
{"category": "研究前沿", "title": "MIT研发多语境医学图像分割AI工具", "short_summary": "MIT新AI工具MultiverSeg实现高效医学图像分割，大幅减少人工标注需求。", "detailed_summary": "MIT新AI工具MultiverSeg实现高效医学图像分割，大幅减少人工标注需求。\n(1) MIT研究人员开发了名为MultiverSeg的人工智能系统，用于加速医学图像中感兴趣区域的标注（分割）过程。\n(2) 该系统结合了交互式和自动分割方法的优点，用户通过点击、涂鸦或画框进行初始标注，模型利用已分割图像上下文进行预测。\n(3) 核心优势包括：无需为每个新任务重新训练模型、无需机器学习专业知识、用户交互次数随使用递减直至为零。\n(4) 与现有工具相比，MultiverSeg达到90%准确率所需的人工交互（点击和涂鸦）减少约三分之一到四分之一。\n(5) 该工具有望加速医学研究和临床试验，降低成本，并可用于临床应用如放射治疗规划。", "raw_content": "Annotating regions of interest in medical images, a process known as segmentation, is often one of the first steps clinical researchers take when running a new study involving biomedical images. For instance, to determine how the size of the brain’s hippocampus changes as patients age, the scientist first outlines each hippocampus in a series of brain scans. For many structures and image types, this is often a manual process that can be extremely time-consuming, especially if the regions being studied are challenging to delineate. To streamline the process, MIT researchers developed an artificial intelligence-based system that enables a researcher to rapidly segment new biomedical imaging datasets by clicking, scribbling, and drawing boxes on the images. This new AI model uses these interactions to predict the segmentation. As the user marks additional images, the number of interactions they need to perform decreases, eventually dropping to zero. The model can then segment each new image accurately without user input. It can do this because the model’s architecture has been specially designed to use information from images it has already segmented to make new predictions. Unlike other medical image segmentation models, this system allows the user to segment an entire dataset without repeating their work for each image. In addition, the interactive tool does not require a presegmented image dataset for training, so users don’t need machine-learning expertise or extensive computational resources. They can use the system for a new segmentation task without retraining the model. In the long run, this tool could accelerate studies of new treatment methods and reduce the cost of clinical trials and medical research. It could also be used by physicians to improve the efficiency of clinical applications, such as radiation treatment planning. “Many scientists might only have time to segment a few images per day for their research because manual image segmentation is so time-consuming. Our hope is that this system will enable new science by allowing clinical researchers to conduct studies they were prohibited from doing before because of the lack of an efficient tool,” says Hallee Wong, an electrical engineering and computer science graduate student and lead author of a paper on this new tool . She is joined on the paper by Jose Javier Gonzalez Ortiz PhD ’24; John Guttag, the Dugald C. Jackson Professor of Computer Science and Electrical Engineering; and senior author Adrian Dalca, an assistant professor at Harvard Medical School and MGH, and a research scientist in the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL). The research will be presented at the International Conference on Computer Vision. Streamlining segmentation There are primarily two methods researchers use to segment new sets of medical images. With interactive segmentation, they input an image into an AI system and use an interface to mark areas of interest. The model predicts the segmentation based on those interactions. A tool previously developed by the MIT researchers, ScribblePrompt , allows users to do this, but they must repeat the process for each new image. Another approach is to develop a task-specific AI model to automatically segment the images. This approach requires the user to manually segment hundreds of images to create a dataset, and then train a machine-learning model. That model predicts the segmentation for a new image. But the user must start the complex, machine-learning-based process from scratch for each new task, and there is no way to correct the model if it makes a mistake. This new system, MultiverSeg , combines the best of each approach. It predicts a segmentation for a new image based on user interactions, like scribbles, but also keeps each segmented image in a context set that it refers to later. When the user uploads a new image and marks areas of interest, the model draws on the examples in its context set to make a more accurate prediction, with less user input. The researchers designed the model’s architecture to use a context set of any size, so the user doesn’t need to have a certain number of images. This gives MultiverSeg the flexibility to be used in a range of applications. “At some point, for many tasks, you shouldn’t need to provide any interactions. If you have enough examples in the context set, the model can accurately predict the segmentation on its own,” Wong says. The researchers carefully engineered and trained the model on a diverse collection of biomedical imaging data to ensure it had the ability to incrementally improve its predictions based on user input. The user doesn’t need to retrain or customize the model for their data. To use MultiverSeg for a new task, one can upload a new medical image and start marking it. When the researchers compared MultiverSeg to state-of-the-art tools for in-context and interactive image segmentation, it outperformed each baseline. Fewer clicks, better results Unlike these other tools, MultiverSeg requires less user input with each image. By the ninth new image, it needed only two clicks from the user to generate a segmentation more accurate than a model designed specifically for the task. For some image types, like X-rays, the user might only need to segment one or two images manually before the model becomes accurate enough to make predictions on its own. The tool’s interactivity also enables the user to make corrections to the model’s prediction, iterating until it reaches the desired level of accuracy. Compared to the researchers’ previous system, MultiverSeg reached 90 percent accuracy with roughly 2/3 the number of scribbles and 3/4 the number of clicks. “With MultiverSeg, users can always provide more interactions to refine the AI predictions. This still dramatically accelerates the process because it is usually faster to correct something that exists than to start from scratch,” Wong says. Moving forward, the researchers want to test this tool in real-world situations with clinical collaborators and improve it based on user feedback. They also want to enable MultiverSeg to segment 3D biomedical images. This work is supported, in part, by Quanta Computer, Inc. and the National Institutes of Health, with hardware support from the Massachusetts Life Sciences Center.", "release_time": "2025-09-25", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/new-ai-system-could-accelerate-clinical-research-0925"}
{"category": "研究前沿", "title": "NIH资助削减恐影响超半数新药研发", "short_summary": "研究显示超半数FDA批准新药与NIH资助相关，大幅预算削减或危及未来医疗进展。", "detailed_summary": "研究显示超半数FDA批准新药与NIH资助相关，大幅预算削减或危及未来医疗进展。\n（1）MIT等机构研究量化NIH预算削减影响，发现超50%的2000年后FDA批准小分子药物专利引用NIH资助研究；\n（2）若NIH预算削减40%，这些引用\"风险\"类别研究的药物开发可能受阻；\n（3）研究区分直接与间接链接，间接链接显示NIH资助构建了药物研发的科学基础；\n（4）以抗癌药Gleevec为例，说明NIH资助对靶向药物开发的关键作用；\n（5）学者警告削减资金可能延缓医学进步，影响未来二十年新药问世。", "raw_content": "Gleevec, a cancer drug first approved for sale in 2001, has dramatically changed the lives of people with chronic myeloid leukemia. This form of cancer was once regarded as very difficult to combat, but survival rates of patients who respond to Gleevec now resemble that of the population at large. Gleevec is also a medicine developed with the help of federally funded research. That support helped scientists better understand how to create drugs targeting the BCR-ABL oncoprotein, the cancer-causing protein behind chronic myeloid leukemia. A new study co-authored by MIT researchers quantifies how many such examples of drug development exist. The current administration is proposing a nearly 40 percent budget reduction to the National Institutes of Health (NIH), which sponsors a significant portion of biomedical research. The study finds that over 50 percent of small-molecule drug patents this century cite at least one piece of NIH-backed research that would likely be vulnerable to that potential level of funding change. “What we found was quite striking,” says MIT economist Danielle Li, co-author of a newly published paper outlining the study’s results. “More than half of the drugs approved by the FDA since 2000 are connected to NIH research that would likely have been cut under a 40 percent budget reduction.” Or, as the researchers write in the paper: “We found extensive connections between medical advances and research that was funded by grants that would have been cut if the NIH budget was sharply reduced.” The paper, “ What if NIH funding had been 40% smaller? ” is published today as a Policy Article in the journal Science . The authors are Pierre Azoulay, the China Program Professor of International Management at the MIT Sloan School of Management; Matthew Clancy, an economist with the group Open Philanthropy; Li, the David Sarnoff Professor of Management of Technology at MIT Sloan; and Bhaven N. Sampat, an economist at Johns Hopkins University. (Biomedical researchers at both MIT and Johns Hopkins could be affected by adjustments to NIH funding.) To conduct the study, the researchers leveraged the fact that the NIH uses priority lists to determine which projects get funded. That makes it possible to discern which projects were in the lower 40 percent of NIH-backed projects, priority-wise, for a given time period. The researchers call these “at-risk” pieces of research. Applying these data from 1980 through 2007, the scholars examined the patents of the new molecular entities — drugs with a new active ingredient — approved by the U.S. Food and Drug Administration since 2000. There is typically a time interval between academic research and subsequent related drug development. The study focuses on small-molecule drugs — compact organic compounds, often taken orally as medicine — whereas NIH funding supports a wider range of advancements in medicine generally. Based on how many of these FDA-approved small-molecule medicines were linked to at-risk research from the prior period, the researchers estimated what kinds of consequences a 40 percent cut in funding would have generated going forward. The study distinguishes between two types of links new drugs have to NIH funding. Some drug patents have what the researchers call “direct” links to new NIH-backed projects that generated new findings relevant to development of those particular drugs. Other patents have “indirect “ links to the NIH, when they cite prior NIH-funded studies that contributed to the overall body of knowledge used in drug development. The analysis finds that 40 of the FDA-approved medications have direct links to new NIH-supported studies cited in the patents — or 7.1 percent. Of these, 14 patents cite at-risk pieces of NIH research. When it comes to indirect links, of the 557 drugs approved by the FDA from 2000 to 2023, the study found that 59.4 percent have a patent citing at least one NIH-supported research publication. And, 51.4 percent cite at least one NIH-funded study from the at-risk category of projects. “The indirect connection is where we see the real breadth of NIH's impact,” Li says. “What the NIH does is fund research that forms the scientific foundation upon which companies and other drug developers build.” As the researchers emphasize in the paper, there are many nuances involved in the study. A single citation of an NIH-funded study could appear in a patent for a variety of reasons, and does not necessarily mean “that the drug in question could never have been developed in its absence,” as they write in the paper. To reckon with this, the study also analyzes how many patents had at least 25 percent of their citations fall in the category of at-risk NIH-backed research. By this metric, they found that 65 of the 557 FDA-approved drugs, or 11.7 percent, met the threshold. On the other hand, as the researchers state in the paper, it is possible the study “understates the extent to which medical advances are connected to NIH research.” For one thing, as the study’s endpoint for examining NIH data is 2007, there could have been more recent pieces of research informing medications that have already received FDA approval. The study does not quantify “second-order connections,” in which NIH-supported findings may have led to additional research that directly led to drug development. Again, NIH funding also supports a broad range of studies beyond the type examined in the current paper. It is also likely, the scholars suggest, that NIH cuts would curtail the careers of many promising scientists, and in so doing slowdown medical progress. For a variety of these reasons, in addition to the core data itself, the scholars say the study indicates how broadly NIH-backed research has helped advance medicine. “The worry is that these kinds of deep cuts to the NIH risk that foundation and therefore endanger the development of medicines that might be used to treat us, or our kids and grandkids, 20 years from now,” Li says. Azoulay and Sampat have received past NIH funding. They also serve on an NIH working group about the empirical analysis of the scientific enterprise.", "release_time": "2025-09-26", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/how-federal-research-support-has-helped-create-life-changing-medicines-0925"}
{"category": "研究前沿", "title": "澳院士访穗作海洋新能源装备学术报告", "short_summary": "昆士兰大学院士访问广州能源所，探讨海上新能源与大型装备协同创新。", "detailed_summary": "昆士兰大学院士访问广州能源所，探讨海上新能源与大型装备协同创新。\n(1) 澳大利亚昆士兰大学Chien Ming Wang院士应邀访问广州能源所并作学术报告。\n(2) 报告主题涉及超大型海上渔场与可再生能源岛等新型海洋装备前沿研究。\n(3) 双方就海洋装备研发的技术挑战、解决方案及合作模式进行了深入交流。\n(4) 访问促进了学术思想碰撞，为研究所海洋装备科研攻关提供参考。\n(5) 下一步将推进与昆士兰大学等机构的国际合作，重点拓展海上新能源领域。", "raw_content": "澳大利亚昆士兰大学Chien Ming Wang院士访问广州能源所并作学术报告 文章来源：海上能源中心海洋能科研团队  |  发布时间： 2025-09-25 |  【 打印 】 【 关闭 】 9月23日上午，应广州能源所海上能源中心邀请，澳大利亚工程院院士、新加坡工程院院士、欧洲科学与艺术院院士、昆士兰大学讲席教授Chien Ming Wang一行访问广州能源所，并作题为 HEXAGON ： Ultra-Large Offshore Fish Farm and Renewable Energy Island 等的学术报告。广州能源所科技处处长白羽、海上能源中心副主任王坤林等参加了交流。 Chien Ming Wang教授以典型海洋装备案例为切入点，系统阐述了新型海洋装备研发过程中面临的环境挑战与设计难点，并提出了创新解决方案，展示了其团队最新研究成果。随后，白羽介绍了广州能源所的发展概况、国际合作现状以及未来规划。 在互动环节，双方就海洋装备研发的技术挑战、潜在解决方案、合作模式等重点合作领域展开了深入探讨和交流。本次报告不仅促进了学术层面的思想碰撞，也为研究所在海洋装备方向的科研攻关提供了有益参考。下一步，中心将积极推进与澳大利亚昆士兰大学等国际知名机构的全方位合作，重点拓展海上新能源等前沿领域的协同创新，不断提升科研影响力与国际合作水平。 部分与会人员合影 附件下载：", "release_time": "2025-09-25", "source_institution": "广州能源研究所", "url": "http://www.giec.cas.cn/xshd2016/202509/t20250925_7979624.html"}
{"category": "产业应用", "title": "日立与ELITech合作开发全自动PCR检测系统", "short_summary": "日立与ELITech签署协议，联合开发全自动PCR检测系统，提升传染病诊断效率。", "detailed_summary": "日立与ELITech签署协议，联合开发全自动PCR检测系统，提升传染病诊断效率。\n（1）日立高科技与ELITechGroup签署合作协议，共同开发全自动分子检测系统；  \n（2）系统具备连续样本加载、随机访问功能，实现从样本制备到测量的全自动化；  \n（3）专注于传染病诊断与治疗监测，旨在提升微生物学和病毒学实验室的操作效率；  \n（4）日立将在日本JACLaS EXPO 2025展出该系统，命名为“LABOSPECT GA-5”；  \n（5）合作基于双方技术优势，日立提供光度分析和自动化技术，ELITech提供PCR系统和试剂。", "raw_content": "Tokyo, September 25, 2025 Hitachi High-Tech Corporation (\"Hitachi High-Tech\"), and ELITechGroup S.p.A. (Head Office: Italy, \"ELITech\") have entered a Collaboration, Manufacturing and Supply Agreement (the \"Agreement\") in the field of molecular testing for infectious disease. Hitachi High-Tech has development and technical capabilities such as photometric analysis and automation utilized for its life sciences and in-vitro diagnostics products. ELITech offers fully automated PCR *1 testing systems and reagents for the European market, with a particular strength in reagents for a wide range of test items. Both companies have been jointly developing fully automated PCR testing system (the \"System\") primarily for the diagnosis and monitoring treatment of infectious diseases. This Agreement governs that Hitachi High-Tech supplies of the System to ELITech. The System offers continuous sample and reagent loading as well as random-access capabilities in accordance with the needs of the laboratory, together with fully automated functions from sample preparation to measurement. The joint development efforts will focus on creating innovative and flexible PCR platform that enhances operational efficiency in microbiology and virology laboratories, ultimately contributing to improved patient care. In Japan, Hitachi High-Tech will exhibit the System under the name “LABOSPECT GA-5” at the JACLaS EXPO 2025 in Yokohama, Japan, from October 3 through October 5, 2025. *1 Polymerase Chain Reaction (PCR): A method of amplifying very small samples of DNA fragments from cells. Background In the field of healthcare, molecular testing is used to figure out the risks of diseases and constitution and to diagnose diseases based on their genetic information. The PCR method was also used during the COVID-19 pandemic and has become more widely used. As such, there is a need to improve the efficiency of testing operations through automation and reduction of testing times for multiple test items. Hitachi High-Tech and ELITech have been jointly developing a fully automated molecular testing system that can detect viruses and bacteria at an early stage. In addition, this system utilizes the technologies of Precision System Science Co., Ltd., with whom Hitachi High-Tech has a business alliance with respect to the genetic testing business. Future Development Going forward, Hitachi High-Tech will continue to foster innovation in the area of infectious diseases with ELITech, and through this partnership and others, we will build strong and long-term relationships with our partners. Hitachi High-Tech support offering of personalized medical care for each and every patient by “Diagnosis x Therapy x Digital,” providing Lumada solution through the installed base (Digitalized Assets) and domain knowledge. We aim to “make patient smile with frontline healthcare workers” and “create a society without fear of cancer” for realizing a harmonized society where environment, wellbeing and economic growth are in balance. About Hitachi High-Tech Hitachi High-Tech provides cutting-edge technologies, products and services to society and customers with its corporate vision of \"Changing the World and Future with the Power of Knowledge\" to contribute to a sustainable global environment, healthy, safe and secure lives, and the sustained development of science and industry. We manufacture and sell clinical analyzers, biotechnology products and radiation therapy systems in the healthcare field, semiconductor manufacturing and inspection equipment in the semiconductor field, as well as analytical systems and electron microscopes used in environmental fields and materials research. We are also engaged in a wide range of business areas globally, providing high added-value solutions in battery, communication infrastructure, railway inspection, digital and other industrial and social infrastructure fields. By deeply understanding the issues facing society and our customers, and utilizing the installed base (Digitalized Assets) and domain knowledge, we provide digital service through Lumada 3.0, enhanced by AI. Along with the Inspire 2027, Hitachi Group's New Management plan, we contribute to realize a harmonized society where the environment, wellbeing, and economic growth coexist in harmony. The company's consolidated revenues for FY2024 were approx. JPY 756.5 billion. For further information, visit https://www.hitachi-hightech.com/global/en/ About ELITech ELITechGroup is a global leader in in-vitro diagnostics, serving hospitals and diagnostic laboratories in over 100 countries through a direct sales network and trusted distribution partners. The company develops, manufactures, and markets a comprehensive range of diagnostic products and solutions, including instruments, reagents, and software. With a global team of about 600 professionals, ELITechGroup is proud to be a part of Bruker Corporation. Alongside Bruker's other businesses in the Bruker Microbiology & Infection Diagnostics division (BMID), ELITechGroup remains deeply committed to fully meeting the evolving needs of its customers. The company continues to develop state-of-the-art technologies and innovative solutions that address the challenges faced by today's–and tomorrow's–laboratories. For more information, visit the ELITech website ( https://www.elitechgroup.com/ ). Business Contact Molecular Systems Marketing Dept., Sales & Marketing Div., Diagnostic System Business, Healthcare Business Group, Hitachi High-Tech Corporation Contact form In order to read a PDF file, you need to have Adobe Acrobat Reader installed in your computer. Information contained in this news release is current as of the date of the press announcement, but may be subject to change without prior notice.", "release_time": "2025-09-25", "source_institution": "日本日立", "url": "http://www.hitachi.com/New/cnews/month/2025/09/250925.html"}
{"category": "研究前沿", "title": "广岛大学提出观测昂鲁效应新方法", "short_summary": "研究利用超导电路圆周运动实现昂鲁效应观测，突破传统加速度极限。", "detailed_summary": "研究利用超导电路圆周运动实现昂鲁效应观测，突破传统加速度极限。\n（1）昂鲁效应是相对论与量子理论交叉的重要预测，加速观测者会感知真空波动为热粒子；\n（2）传统实验需极大加速度（10^20 m/s²），远超当前技术能力；\n（3）新方法利用耦合环形约瑟夫森结中通量子-反通量子对的圆周运动产生高有效加速度；\n（4）量子涨落引发通量子对分裂，产生可测量的宏观电压跳变信号；\n（5）该方法为首次实验验证昂鲁效应提供可行路径，有望推动量子传感与基础物理统一理论发展。", "raw_content": "The work was recently published in Physical Review Letters . The Fulling-Davies-Unruh effect, or simply the Unruh effect, is a striking theoretical prediction at the profound intersection of Albert Einstein's Theory of Relativity and Quantum Theory. \"In quantum theory, even the vacuum seethes with tiny energy fluctuations, where particles and antiparticles briefly appear and vanish. Remarkably, the Unruh effect shows how these 'vacuum ripples' are perceived depends on the observer's motion. A stationary observer sees nothing, but an observer undergoing acceleration perceives them as real particles with a thermal energy distribution -- a 'quantum warmth',\" said Noriyuki Hatakenaka, professor emeritus at Hiroshima University. The counterintuitive result emphasizes the important connection between these two pillars of modern physics. If scientists could experimentally verify the Unruh effect, it would not only bridge the gap between general relativity and quantum mechanics but also provide profound insights into the nature of spacetime itself. Yet the experimental verification of the Unruh effect has been a long-standing and significant challenge in fundamental physics. \"The core problem has been the extraordinarily large accelerations -- on the order of 10 20 m/s 2 -- required to make this effect detectable, rendering its observation practically impossible with current technology at least in linear acceleration systems,\" said Haruna Katayama, assistant professor at Hiroshima University. The researchers at Hiroshima University have proposed a promising approach to observe the Unruh effect. \"Our work aims to overcome this fundamental hurdle by proposing a novel and feasible experimental method. We utilize the circular motion of metastable fluxon-antifluxon pairs within coupled annular Josephson junctions,\" said Hatakenaka. Advances in superconducting microfabrication allow the creation of circuits with extremely small radii, enabling immensely high effective accelerations and producing an Unruh temperature of a few kelvin -- high enough to be experimentally detectable with current technology. \"We have proposed a realistic, highly sensitive, and unambiguous method to detect the elusive Unruh effect. Our proposed system offers a clear pathway to experimentally observe this 'phantom heat' of acceleration for the first time,\" said Katayama. In their innovative setup, the \"quantum warmth\" induced by the circular acceleration causes fluctuations that trigger the splitting of the metastable fluxon-antifluxon pairs. Crucially, this splitting event manifests as a clear, macroscopic voltage jump across the superconducting circuit. This voltage jump serves as an undeniable and easily measurable signal, providing a direct and robust signature of the Unruh effect's presence. By statistically analyzing the distribution of these voltage jumps, the researchers can precisely measure the Unruh temperature with high accuracy. \"One of the most surprising aspects is that microscopic quantum fluctuations can induce sudden, macroscopic voltage jumps, making the elusive Unruh effect directly observable. Even more striking, the switching distribution shifts solely with acceleration while all other parameters remain fixed -- a clear statistical fingerprint of the Unruh effect itself,\" said Hatakenaka. Looking ahead, Katayama said, \"Our immediate next step is to conduct a detailed analysis of the decay processes of the fluxon-antifluxon pairs. This includes thoroughly investigating the role of macroscopic quantum tunneling, a quantum-mechanical phenomenon where particles can pass through potential barriers, which was not extensively explored in this initial work. Understanding these intricate decay mechanisms will be crucial for refining the experimental detection of the Unruh effect.\" Their ultimate goal in this research is multifaceted. Beyond the immediate detection, they aim to investigate potential connections between this phenomenon and other quantum fields coupled to their detector. \"By deepening our understanding of these novel quantum phenomena, we hope to contribute significantly to the search for a unified theory of all physical laws,\" said Hatakenaka. The researchers note that the highly sensitive and broad-range detection capabilities developed in this research hold immense promise for paving the way for future applications, particularly in the field of advanced quantum sensing technologies. \"We aspire for this work to open new avenues in fundamental physics and to inspire further exploration into the true nature of spacetime and quantum reality,\" said Katayama. The research team includes Noriyuki Hatakenaka, professor emeritus in the Graduate School of Advanced Science and Engineering at Hiroshima University, and Haruna Katayama, assistant professor in the Graduate School of Advanced Science and Engineering at Hiroshima University. This work was supported by JSPS KAKENHI Grants and by the HIRAKU-Global Program, which is funded by MEXT's \"Strategic Professional Development Program for Young Researchers.\"", "release_time": "2025-09-25", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250924012234.htm"}
{"category": "政策计划", "title": "美国对欧盟征收15%汽车关税", "short_summary": "美国正式对欧盟进口汽车等商品征收15%关税，部分商品获豁免。", "detailed_summary": "美国正式对欧盟进口汽车等商品征收15%关税，部分商品获豁免。\n（1）美国特朗普政府9月24日发布公告，正式实施与欧盟达成的贸易协议；\n（2）自8月1日起对欧盟进口汽车及汽车产品征收15%关税；\n（3）同时对某些药物化合物、飞机零部件等进口商品给予关税豁免；\n（4）该协议于7月27日由特朗普宣布，欧盟委员会主席冯德莱恩称15%税率为最佳结果。", "raw_content": "当地时间9月24日，美国特朗普政府发布正式公告，实施美国与欧盟达成的贸易协议，确认自8月1日起，对欧盟进口汽车及汽车产品征收15%的关税。此外，文件还列出了对某些药物化合物、飞机零部件及其他进口商品的关税豁免。 当地时间7月27日，美国总统特朗普表示，美国已与欧盟达成新贸易协议，对欧盟输美商品征收15%的关税。欧盟委员会主席冯德莱恩称，15%税率是欧委会能够达成的最佳结果。", "release_time": "2025-09-25", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194356-1.html"}
{"category": "研究前沿", "title": "高能缪子散射物理研讨会在惠州召开", "short_summary": "惠州研讨会聚焦高能缪子物理前沿，推动HIAF装置相关实验国际合作。", "detailed_summary": "惠州研讨会聚焦高能缪子物理前沿，推动HIAF装置相关实验国际合作。\n（1）9月19日至21日，“高能缪子散射物理研讨会”在广东惠州成功召开；\n（2）由中科院近代物理所等七家单位联合主办，多位院士及50余位国内外专家参会；\n（3）会议围绕高能缪子束物理前沿，研讨理论探索与实验设计；\n（4）重点介绍了强流重离子加速器装置（HIAF）工程进展及可提供的高能缪子束流；\n（5）专家学者提出了PKMu、DREAMuS、LUNE、CANTON-μ等多个新型实验方案；\n（6）会议有助于加强该领域国际交流合作，提升我国研究影响力，为未来依托HIAF开展研究提供重要参考。", "raw_content": "9月19日至21日，“高能缪子散射物理研讨会”在广东省惠州市成功召开。本次研讨会由中国科学院近代物理研究所、先进能源科学与技术广东省实验室、北京大学、上海交通大学、华中师范大学、山东大学、中山大学联合主办。中国科学院近代物理研究所所长孙志宇研究员在开幕式上致辞。赵光达、詹文龙、张肇西、马余刚、赵红卫、邹冰松等多位院士以及来自国内外多家科研机构的50余位专家学者通过线上或线下方式参会。与会代表围绕高能缪子束物理的前沿进展与发展趋势，从理论探索与实验设计等角度展开深入交流和讨论。 本次会议围绕“高能缪子束物理”主题安排了多个邀请报告。近代物理所申国栋副研究员介绍了强流重离子加速器装置（ HIAF ）的工程进展；徐宇博士介绍了基于 HIAF-HIRIBL 的高能缪子束流的能量和流强情况；华中师范大学计晨教授详述了原子光谱学与轻子散射在核子及原子核结构高精度研究中的最新进展；密歇根州立大学谢可平博士展望了高能缪子研究在标准模型精确检验与新物理探索等方面的巨大潜力；中山大学韩成成教授介进一步介绍了缪子在检验味道依赖的 B-L 模型、类轴子及最小超对称等新物理模型方面的独特价值。这些报告为与会者提供了丰富的学术视角。 图1：专题报告现场 基于 HIAF 可提供的高能缪子束流，与会的专家学者提出了多个新型的实验方案，涵盖了标准模型精确测量和新物理寻找等多个重要研究领域。北京大学李强教授报告了缪子电子散射实验（ PKMu ）；上海交通大学李亮教授介绍了基于先进缪子源的暗物质研究实验（ DREAMuS ）；华中师范大学尹航教授分享了低能缪子 - 核子散射实验（ LUNE ）的相关情况；利物浦大学张策博士提出了中国负缪子反常磁矩实验（ CANTON-μ ）的设想方案。这些实验方案的分享，引发了线上线下与会专家学者的热烈讨论。 相关会议链接： https://indico.impcas.ac.cn/event/175/ ‍ 图2：交流讨论现场 图3：与会人员参观HIAF 此次会议的成功举办，有助于推动和加强国内外学者在高能缪子物理前沿与实验技术领域的交流与合作，提升我国相关研究的国际影响力，为未来依托 HIAF 的 GeV 缪子源开展粒子物理与核物理研究提供了重要参考。 图4：人员合影 （放射性束物理室、南方核科学理论研究中心 、先进核能物理室   供稿）", "release_time": "2025-09-26", "source_institution": "近代物理研究所", "url": "http://www.imp.cas.cn/sndt2017/202509/t20250925_7979686.html"}
{"category": "研究前沿", "title": "MIT研究发现黏液蛋白MUC2可抑制沙门氏菌感染", "short_summary": "黏液蛋白MUC2能关闭沙门氏菌毒力基因，有望开发成预防腹泻的合成黏液素。", "detailed_summary": "黏液蛋白MUC2能关闭沙门氏菌毒力基因，有望开发成预防腹泻的合成黏液素。\n(1) MIT研究发现肠道黏液中的MUC2蛋白能关闭沙门氏菌的毒力基因，阻止其感染宿主细胞。\n(2) MUC2通过阻断细菌调控蛋白HilD来抑制沙门氏菌III型分泌系统（T3SS）相关基因的表达。\n(3) 胃部黏液蛋白MUC5AC也具有类似抑制沙门氏菌及其他食源性病原体的功能。\n(4) 研究团队计划开发合成黏液素，通过口服补液盐或咀嚼片形式用于预防旅行者腹泻等疾病。\n(5) 该策略旨在增强人体天然防御，为全球腹泻这一重大健康挑战提供低成本预防方案。", "raw_content": "Mucus is more than just a sticky substance: It contains a wealth of powerful molecules called mucins that help to tame microbes and prevent infection. In a new study, MIT researchers have identified mucins that defend against Salmonella and other bacteria that cause diarrhea. The researchers now hope to mimic this defense system to create synthetic mucins that could help prevent or treat illness in soldiers or other people at risk of exposure to Salmonella . It could also help prevent “traveler’s diarrhea,” a gastrointestinal infection caused by consuming contaminated food or water. Mucins are bottlebrush-shaped polymers made of complex sugar molecules known as glycans, which are tethered to a peptide backbone. In this study, the researchers discovered that a mucin called MUC2 turns off genes that Salmonella uses to enter and infect host cells. “By using and reformatting this motif from the natural innate immune system, we hope to develop strategies to preventing diarrhea before it even starts. This approach could provide a low-cost solution to a major global health challenge that costs billions annually in lost productivity, health care expenses, and human suffering,” says Katharina Ribbeck, the Andrew and Erna Viterbi Professor of Biological Engineering at MIT and the senior author of the study. MIT Research Scientist Kelsey Wheeler PhD ’21 and Michaela Gold PhD ’22 are the lead authors of the paper, which appeared Tuesday in the journal Cell Reports . Blocking infection Mucus lines much of the body, providing a physical barrier to infection, but that’s not all it does. Over the past decade, Ribbeck has identified mucins that can help to disarm Vibrio cholerae , as well as Pseudomonas aeruginosa , which can infect the lungs and other organs, and the yeast Candida albicans . In the new study, the researchers wanted to explore how mucins from the digestive tract might interact with Salmonella enterica , a foodborne pathogen that can cause illness after consuming raw or undercooked food, or contaminated water. To infect host cells, Salmonella must produce proteins that are part of the type 3 secretion system (T3SS), which helps bacteria form needle-like complexes that transfer bacterial proteins directly into host cells. These proteins are all encoded on a segment of DNA called Salmonella pathogenicity island 1 (SPI-1). The researchers found that when they exposed Salmonella to a mucin called MUC2, which is found in the intestines, the bacteria stopped producing the proteins encoded by SPI-1, and they were no longer able to infect cells. Further studies revealed that MUC2 achieves this by turning off a regulatory bacterial protein known as HilD. When this protein is blocked by mucins, it can no longer activate the T3SS genes. Using computational simulations, the researchers showed that certain monosaccharides found in glycans, including GlcNAc and GalNAc, can attach to a specific binding site of the HilD protein. However, their studies showed that these monosaccharides can’t turn off HilD on their own — the shutoff only occurs when the glycans are tethered to the peptide backbone of the mucin. The researchers also discovered that a similar mucin called MUC5AC, which is found in the stomach, can block HilD. And, both MUC2 and MUC5AC can turn off virulence genes in other foodborne pathogens that also use HilD as a gene regulator. Mucins as medicine Ribbeck and her students now plan to explore ways to use synthetic versions of these mucins to help boost the body’s natural defenses and protect the GI tract from Salmonella and other infections. Studies from other labs have shown that in mice, Salmonella tends to infect portions of the GI tract that have a thin mucus barrier, or no barrier at all. “Part of Salmonella ’s evasion strategy for this host defense is to find locations where mucus is absent and then infect there. So, one could imagine a strategy where we try to bolster mucus barriers to protect those areas with limited mucin,” Wheeler says. One way to deploy synthetic mucins could be to add them to oral rehydration salts — mixtures of electrolytes that are dissolved in water and used to treat dehydration caused by diarrhea and other gastrointestinal illnesses. Another potential application for synthetic mucins would be to incorporate them into a chewable tablet that could be consumed before traveling to areas where Salmonella and other diarrheal illnesses are common. This kind of “pre-exposure prophylaxis” could help prevent a great deal of suffering and lost productivity due to illness, the researchers say. “Mucin mimics would particularly shine as preventatives, because that’s how the body evolved mucus — as part of this innate immune system to prevent infection,” Wheeler says. The research was funded by the U.S. Army Research Office, the U.S. Army Institute for Collaborative Biotechnologies, the U.S. National Science Foundation, the U.S. National Institute of Health and Environmental Sciences, the U.S. National Institutes of Health, and the German Research Foundation.", "release_time": "2025-09-25", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/study-shows-mucus-contains-molecules-that-block-salmonella-infection-0925"}
{"category": "研究前沿", "title": "环保量子点实现低成本红外探测技术突破", "short_summary": "NYU研发无重金属量子点红外探测器，解决环保法规与市场需求矛盾。", "detailed_summary": "NYU研发无重金属量子点红外探测器，解决环保法规与市场需求矛盾。\n（1）研究背景：环保法规限制汞/铅等材料使用，制约红外探测器在自动驾驶、医疗成像等领域的普及；\n（2）技术突破：采用胶体量子点溶液合成技术，替代传统原子级精密组装工艺，实现类似印刷的规模化涂层制造；\n（3）性能优势：微秒级响应速度、纳瓦级弱光检测能力，溶液配体交换技术提升导电性与薄膜均匀度；\n（4）应用前景：结合银纳米线透明电极技术，为大规模红外成像阵列提供环保低成本解决方案，推动消费电子等领域应用。", "raw_content": "This regulatory pressure is slowing the broader adoption of infrared detectors across civilian applications, just as demand in fields like autonomous vehicles, medical imaging and national security is accelerating. In a paper published in ACS Applied Materials & Interfaces, researchers at NYU Tandon School of Engineering reveal a potential solution that uses environmentally friendly quantum dots to detect infrared light without relying on mercury, lead, or other restricted materials. The researchers use colloidal quantum dots which upends the age-old, expensive, and tedious processing of infrared detectors. Traditional devices are fabricated through slow, ultra-precise methods that place atoms almost one by one across the pixels of a detector -- much like assembling a puzzle piece by piece under a microscope. Colloidal quantum dots are instead synthesized entirely in solution, more like brewing ink, and can be deposited using scalable coating techniques similar to those used in roll-to-roll manufacturing for packaging or newspapers. This shift from painstaking assembly to solution-based processing dramatically reduces manufacturing costs and opens the door to widespread commercial applications. \"The industry is facing a perfect storm where environmental regulations are tightening just as demand for infrared imaging is exploding,\" said Ayaskanta Sahu, associate professor in the Department of Chemical and Biomolecular Engineering (CBE) at NYU Tandon and the study's senior author. \"This creates real bottlenecks for companies trying to scale up production of thermal imaging systems.\" Another challenge the researchers addressed was making the quantum dot ink conductive enough to relay signals from incoming light. They achieved this using a technique called solution-phase ligand exchange, which tailors the quantum dot surface chemistry to enhance performance in electronic devices. Unlike traditional fabrication methods that often leave cracked or uneven films, this solution-based process yields smooth, uniform coatings in a single step -- ideal for scalable manufacturing. The resulting devices show remarkable performance: they respond to infrared light on the microsecond timescale -- for comparison, the human eye blinks at speeds hundreds of times slower -- and they can detect signals as faint as a nanowatt of light. \"What excites me is that we can take a material long considered too difficult for real devices and engineer it to be more competitive,\" said graduate researcher Shlok J. Paul, lead author on the study. \"With more time this material has the potential to shine deeper in the infrared spectrum where few materials exist for such tasks.\" This work adds to earlier research from the same lead researchers that developed new transparent electrodes using silver nanowires. Those electrodes remain highly transparent to infrared light while efficiently collecting electrical signals, addressing one component of the infrared camera system. Combined with their earlier transparent electrode work, these developments address both major components of infrared imaging systems. The quantum dots provide environmentally compliant sensing capability, while the transparent electrodes handle signal collection and processing. This combination addresses challenges in large-area infrared imaging arrays, which require high-performance detection across wide areas and signal readout from millions of individual detector pixels. The transparent electrodes allow light to reach the quantum dot detectors while providing electrical pathways for signal extraction. \"Every infrared camera in a Tesla or smartphone needs detectors that meet environmental standards while remaining cost-effective,\" Sahu said. \"Our approach could help make these technologies much more accessible.\" The performance still falls short of the best heavy-metal-based detectors in some measurements. However, the researchers expect continued advances in quantum dot synthesis and device engineering could reduce this gap. In addition to Sahu and Paul, the paper's authors are Letian Li, Zheng Li, Thomas Kywe, and Ana Vataj, all from NYU Tandon CBE. The work was supported by the Office of Naval Research and the Defense Advanced Research Projects Agency.", "release_time": "2025-09-25", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250925025356.htm"}
{"category": "研究前沿", "title": "研究揭示金伯利岩喷发关键机制", "short_summary": "新模型量化二氧化碳对金伯利岩喷发的驱动作用，解释钻石如何到达地表。", "detailed_summary": "新模型量化二氧化碳对金伯利岩喷发的驱动作用，解释钻石如何到达地表。\n(1) 金伯利岩是源自地幔深处（>150公里）的火山岩管，其快速喷发能将钻石带至地表。\n(2) 研究针对加拿大杰里科金伯利岩，通过化学建模和分子动力学模拟分析熔体浮力。\n(3) 首次量化关键参数：熔体需含至少8.2%二氧化碳才能获得足够浮力穿透克拉通地壳。\n(4) 水增加熔体流动性，二氧化碳在高压下稳定熔体结构，近地表时脱气驱动喷发。\n(5) 该研究为理解深部地球过程和钻石形成运输提供了重要化学约束。", "raw_content": "Kimberlites -- carrot-shaped volcanic pipes that erupt from mantle depths greater than 150 km -- have long fascinated geologists as windows into the deep Earth. Their mantle-derived melt ascends rapidly through the mantle and crust, with some estimates suggesting ascent rates of up to 80 miles per hour before kimberlites erupt violently at the surface. Along the way, the magma captures xenoliths and xenocrysts, fragments of the rocks encountered on its path. \"They're very interesting and still very enigmatic rocks,\" despite being well-studied, says Ana Anzulović, a doctoral research fellow at the University of Oslo's Centre for Planetary Habitability. In a study published this month in the journal Geology , Anzulović and colleagues from the University of Oslo have taken a major step toward solving the puzzle. By modelling how volatile compounds like carbon dioxide and water influence the buoyancy of proto-kimberlite melt relative to surrounding materials, they quantified for the first time what it takes to erupt a kimberlite. Diamonds make it to the surface in kimberlites because their rapid ascent prevents them from reverting to graphite, which is more stable at shallow pressures and temperatures. But the composition of the kimberlite's original melt -- and how it rises so fast -- has remained mysterious. \"They start off as something that we cannot measure directly,\" says Anzulović. \"So we don't know what a proto-kimberlite, or parental, melt would be like. We know approximately but everything we know basically comes from the very altered rocks that get emplaced.\" To constrain the composition of these parental melts, the team focused on the Jericho kimberlite, which erupted into the Slave craton of far northwest Canada. Using chemical modelling, they tested different original mixtures of carbon dioxide and water. \"Our idea was, well, let's try to create a chemical model of a kimberlite, then vary CO 2 and H 2 O,\" says Anzulović. \"Think of it as trying to sample a kimberlite as it ascends at different pressure and temperature points.\" The researchers used molecular dynamics software to simulate atomic forces and track how atoms in a kimberlite melt move under varying depths. From these calculations, they determined the density of the melt at different conditions and whether it remained buoyant enough to rise. \"The most important takeaway from this study is that we managed to constrain the amount of CO 2 that you need in the Jericho kimberlite to successfully ascend through the Slave craton,\" Anzulović says. \"Our most volatile-rich composition can carry up to 44% of mantle peridotite, for example, to the surface, which is really an impressive number for such a low viscosity melt.\" The study also shows how volatiles play distinct roles. Water increases diffusivity, keeping the melt fluid and mobile. Carbon dioxide helps structure the melt at high pressures but, near the surface, it degasses and drives the eruption upward. For the first time, researchers demonstrated that the Jericho kimberlite needs at least 8.2% CO 2 to erupt; without it, diamonds would remain locked in the mantle. \"I was actually pretty surprised that I can take such a small scale system and actually observe, 'Okay, if I don't put any carbon in, this melt will be denser than the craton, so this will not erupt,'\" says Anzulović. \"It's great that modeling kimberlite chemistry can have implications for such a large-scale process.\"", "release_time": "2025-09-25", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250924012229.htm"}
{"category": "研究前沿", "title": "富含神经酸微藻提升海水鱼养殖效益研究获进展", "short_summary": "麦可藻可显著促进海水鱼生长繁殖并增强其抗逆性，展现新型饲料潜力。", "detailed_summary": "麦可藻可显著促进海水鱼生长繁殖并增强其抗逆性，展现新型饲料潜力。\n(1) 研究聚焦富含神经酸的新型微藻麦可藻在海水鱼养殖中的应用潜力。\n(2) 饲喂麦可藻显著提升海水青鳉的生长率、多不饱和脂肪酸含量及繁殖能力。\n(3) 麦可藻优化鱼类肠道微生物群，增加有益菌并降低致病菌丰度。\n(4) 麦可藻能延长仔鱼耐饥饿时间，并有效缓解重金属对胚胎的毒性影响。\n(5) 研究成果发表于《Algal Research》，为开发新型水产饲料提供科学依据。", "raw_content": "近年来，我国已快速发展成为全球最大的海水养殖国，海水鱼养殖作为其重要组成部分，产值持续领先。2024年统计数据显示，我国海水鱼养殖产值高达5034亿元，约占全国海水养殖总产值的53%，占据了绝对主导地位。在此背景下，微藻因其在海水鱼养殖饲料中的应用价值备受关注。微藻不仅能增强鱼类的免疫能力、改善生长表现，还可减轻养殖污染、减少碳足迹。国际上新发现的麦可藻（Mychonastes afer）因含有较高比例的神经酸而引人注目。神经酸是一种超长链单不饱和脂肪酸，具有修复脑神经组织和促进神经再生的能力，在预防和治疗阿尔茨海默病、抑郁症及帕金森症等疾病方面展现潜力，本研究旨在探究麦克藻在海水渔业养殖方面的应用潜力。研究团队选取了海洋模式鱼种海水青鳉（Oryzias melastigma）作为模型，重点开展了三方面研究（图1）：图1 Mychonastes afer对海水青鳉生长、营养、肠道微生物、繁殖、畸形和死亡的影响实验示意图首先，分析了麦可藻对海水青鳉生长表现、营养组成变化、肠道微生物及繁殖的影响。研究结果显示，饲喂微藻组的鱼体表现均优于对照组。麦克藻可显著提高海水青鳉的增重率和特定生长率；鱼体多不饱和脂肪酸含量，尤其α-亚麻酸等关键脂肪酸含量显著高于小球藻组和人工饲料组。此外，麦克藻的EAA/NEAA＞60%，符合FAO/WHO推荐的优质蛋白质特征。研究还发现，麦可藻可显著增强海水青鳉肠道微生物群的多样性，拟杆菌属等有益菌相对丰度升高，弧菌等致病菌相对丰度降低（图2）；麦可藻组海水青鳉的受精率高达90.67%，显著高于其他实验组。图2 M. afer对海水青鳉肠道微生物群的影响分析其次，研究团队还特别关注了仔鱼的摄食与耐饥饿能力。开口期，即内源营养吸收转化为外源营养摄入的关键期，亦是仔鱼死亡率最高的时期。通过评估开口不可逆点（Point of No Return）这项仔鱼摄食和耐饥饿能力的关键指标，研究发现，人工饲料组和小球藻组仔鱼的不可逆点集中在11日—12日龄，而麦可藻组则可延迟至13日—14日龄，且与摄食率的变化趋势保持一致。此外，为评估麦可藻对鱼胚胎的保护作用，研究人员构建了镍（Ni）致畸模型。结果显示，麦可藻组海水青鳉胚胎死亡率为51.99%，低于小球藻组的60.20%和人工饲料组的66.27%；胚胎孵化率为48.01%，显著高于小球藻组的39.80%和人工饲料组的33.73%（图3）。研究推测，麦可藻富含神经酸，可通过促进神经细胞修复、提供关键营养物质等途径，有效减轻不利环境因素对胚胎发育的负面影响。图3 在重金属环境暴露条件下，微藻对鱼胚胎存活和孵化的影响综上所述，麦可藻不仅能提供均衡的营养物质，改善鱼类肠道微生物组成，提升鱼类生长性能、繁殖力和耐受力，还可缓解重金属等污染物对鱼类胚胎的毒性影响，展现出作为新型水产饲料原料的潜力。上述研究成果近期发表于Algal Research期刊，一碳生物技术研究中心李福利、范勇研究团队联合山东省海洋科学研究院海洋生态环境研究所共同发表，孙璐和刘凯凯为论文共同第一作者，范勇副研究员和宋静静副研究员为共同通讯作者。（文/图 范勇）原文链接：https://doi.org/10.1016/j.algal.2025.104305Lu Sun#, Kaikai Liu#, Xiaoyi Shi, Xia Fang, Daode Yu, Yongjiang Xu, Hui Wang, Jingjing Song*, Yong Fan*, Fuli Li, (2025), Effects of the nervonic acid-rich microalga Mychonastes afer on the growth and reproductive processes of Oryzias melastigma, Algal Research. 91.104305", "release_time": "2025-10-13", "source_institution": "青岛生物能源与过程研究所", "url": "https://qibebt.cas.cn/news/kyjz/202509/t20250924_7977725.html"}
{"category": "研究前沿", "title": "青岛能源所开发热纤梭菌嗜热型基因诱导系统", "short_summary": "研究人员成功开发适用于热纤梭菌的高性能l-阿拉伯糖诱导表达系统ThermoARAi。", "detailed_summary": "研究人员成功开发适用于热纤梭菌的高性能l-阿拉伯糖诱导表达系统ThermoARAi。\n(1) 研究背景：基因表达的精准调控对非模式微生物热纤梭菌的代谢工程开发至关重要，但现有诱导系统存在动态范围低、诱导剂昂贵等限制。\n(2) 系统开发：成功开发了嗜热型l-阿拉伯糖诱导表达系统ThermoARAi，采用嗜热地芽孢杆菌的阻遏蛋白和启动子元件。\n(3) 性能优化：通过启动子优化等手段，将系统动态范围从约5倍显著提升至最高175倍，并具备低泄露、高特异性、低毒性等优点。\n(4) 应用验证：该系统成功实现了热纤梭菌中纤维素糖化和PET塑料降解过程的可诱导调控。\n(5) 研究意义：为热纤梭菌的深入改造提供了关键工具，推动了其在生物质能源领域的应用，并为其他非模式微生物的系统开发提供了范例。", "raw_content": "随着代谢工程复杂性的增加，基因表达的精准调控在生物制造中变得愈发关键。相较于组成型表达系统，诱导型系统能够动态控制基因的表达，在遗传电路设计、活细胞调控以及重组蛋白、生物聚合物和平台化学品等工业产品的生产等方面展现出重要价值。尽管现有的诱导表达系统在模式生物中已有广泛应用，但适用于非模式微生物和嗜热微生物的仍然较少。热纤梭菌是一种嗜热厌氧的木质纤维素分解细菌，最适生长温度为60℃。它能通过独特的代谢途径将纤维素生物转化为乙醇、氢气和多种有机酸等能源化合物，在整合生物加工（CBP, consolidated bioprocessing）和整合生物糖化（CBS, consolidated bio-saccharification）方面极具潜力。研究人员致力于对热纤梭菌进行遗传与代谢工程改造，以获得既能高效降解植物生物质又能高产工业相关化学品的菌株。但热纤梭菌现有的诱导表达系统动态范围较低，诱导剂昂贵或不稳定，限制了热纤梭菌的代谢工程开发。针对这一问题，青岛能源所先进生物炼制与合成研究组成功开发了适用于热纤梭菌的嗜热型l-阿拉伯糖诱导表达系统ThermoARAi。该系统具有高动态范围、低泄露表达、高诱导剂特异性、对宿主无毒性、诱导剂成本低廉等优点。通过使用来自于生长温度相同的嗜热地芽孢杆菌阿拉伯聚糖利用基因簇中的阻遏蛋白和启动子元件，并引入来自超嗜热古菌的β葡萄糖醛酸酶基因作为报告基因，准确测定了诱导系统的泄露表达情况。经过系统的启动子优化、诱导剂浓度和诱导时间优化，ThermoARAi系统的本底泄露显著降低，动态范围从初始的约5倍提升至最高可达175倍。同时，ThermoARAi还展现出高度的诱导剂特异性、持续稳定性以及对宿主低毒性等优良特性。基于该系统，研究人员成功在热纤梭菌中实现了可诱导调控的纤维素全细胞糖化和无定形PET塑料薄片的降解过程。该研究为热纤梭菌的基因表达精准调控与深入代谢工程改造提供了关键工具，将有助于推动热纤梭菌在生物质能源与生物技术中的应用，同时也为其他非模式微生物的诱导表达系统开发提供了新的范例。图1 热纤梭菌嗜热诱导表达系统ThermoARAi的开发、优化与应用相关研究成果以“Development of a thermophilic l-arabinose-inducible system in Acetivibrio thermocellus (Clostridium thermocellum)”为题发表于Metabolic Engineering，博士研究生刘凤华为文章第一作者，冯银刚研究员为论文的通讯作者，相关技术已申请国家发明专利一项。该工作得到国家重点研发计划、国家自然科学基金、中国科学院国际合作项目等的支持。（文/图 刘凤华）原文链接：https://doi.org/10.1016/j.ymben.2025.09.008Liu, F., Chen, C., Liu, Y.-J., Bayer, E.A., Mizrahi, I., Feng, Y., Development of a thermophilic l-arabinose-inducible system in Acetivibrio thermocellus (Clostridium thermocellum), Metabolic Engineering (2025) DOI: 10.1016/j.ymben.2025.09.008.", "release_time": "2025-10-13", "source_institution": "青岛生物能源与过程研究所", "url": "https://qibebt.cas.cn/news/kyjz/202509/t20250924_7977991.html"}
{"category": "研究前沿", "title": "张研究者探索AI生产力与劳动力市场前沿议题", "short_summary": "研究揭示AI提升写作生产力，并探讨非规律排班及远程工作对劳工影响。", "detailed_summary": "研究揭示AI提升写作生产力，并探讨非规律排班及远程工作对劳工影响。\n（1）与Shakked Noy合作的研究发现ChatGPT显著提升写作任务生产力，对初始表现较差者效果尤甚；\n（2）\"非规律工作排班决定因素\"研究利用薪资数据探讨排班不可预测性对低薪员工生活质量的影响；\n（3）与Arjun Ramani合作项目考察远程工作技术是否促进离岸外包及其对美外工人的影响；\n（4）研究获美国国家科学基金会研究生研究奖学金计划等资助；\n（5）张研究者通过跨学科合作，致力于将技术、经济政策与劳动者福祉相结合。", "raw_content": "The intersection of tech and labor policy Zhang began investigating employee productivity, artificial intelligence, and related economic and labor market phenomena early in her time as a doctoral student, collaborating frequently with fellow PhD students in the department. A collaboration with economics doctoral student Shakked Noy yielded the 2023 study investigating ChatGPT as a tool to improve productivity. Their research found it substantially increased workers’ productivity on writing tasks, most so for workers who initially performed the worst on the tasks. “This was one of the earliest pieces of evidence on the productivity effects of generative AI, and contributed to providing concrete data on how impactful these types of tools might be in the workplace and on the labor market,” Zhang says. In other ongoing research — “Determinants of Irregular Worker Schedules” — Zhang is using data from a payroll provider to examine scheduling unpredictability, investigating why companies employ unpredictable schedules and how these schedules affect low-wage employees’ quality of life. The scheduling project, conducted with MIT economics PhD student Nathan Lazarus, is motivated, in part, by existing sociological evidence that low-wage workers’ unpredictable schedules are associated with worse sleep and well-being. “We’ve seen a relationship between higher turnover and inconsistent, inadequate schedules, which suggests workers dis-prefer these kinds of schedules,” Zhang says. At an academic roundtable, Zhang presented her results to Starbucks employees involved in scheduling and staffing. The attendees wanted to learn more about how different scheduling practices impacted workers and their productivity. “These are the kinds of questions that could reveal useful information for small businesses, large corporations, and others,” she says. By conducting this research, Zhang hopes to better understand whether or not scheduling regulations can improve affected employees’ quality of life, while also considering potential unintended consequences. “Why are these schedules set the way they’re set?” she asks. “Do businesses with these kinds of schedules require increased regulation?” Another project, conducted with MIT economics doctoral student Arjun Ramani, examines the linkages between offshoring, remote work, and related outcomes. “Do the technological and managerial practices that have made remote work possible further facilitate offshoring?” she asks. “Do organizations see significant gains in efficiency? What are the impacts on U.S. and offshore workers?” Her work is being funded through the National Science Foundation Graduate Research Fellowship Program and the Washington Center for Equitable Growth . Putting people at the center Zhang has observed the different kinds of people economics and higher education could bring together. She followed a dual enrollment track in high school, completing college-level courses with students from across a variety of demographic identities. “I enjoyed centering people in my work,” she says. “Taking classes with a diverse group of students, including veterans and mothers returning to school to complete their studies, made me more curious about socioeconomic issues and the policies relevant to them.” She later enrolled at MIT, where she participated in the Undergraduate Research Opportunities Program ( UROP ). She also completed an internship at the World Bank, worked as a summer analyst at the Federal Reserve Bank of New York, and worked as an assistant for a diverse faculty cohort including MIT economists David Autor , Jon Gruber , and Nina Roussille . Autor is her primary advisor on her doctoral research, a mentor she cites as a significant influence. “[Autor’s] course, 14.03 (Microeconomics and Public Policy), cemented connections between theory and practice,” she says. “I thought the class was revelatory in showing the kinds of questions economics can answer.” Doctoral study has revealed interesting pathways of investigation for Zhang, as have her relationships with her student peers and other faculty. She has, for example, leveraged faculty connections to gain access to hourly wage data in support of her scheduling and employee impacts work. “Generally, economists have had administrative data on earnings, but not on hours,” she notes. Zhang’s focus on improving others’ lives extends to her work outside the classroom. She’s a mentor for the Boston Chinatown Neighborhood Center College Access Program and a member of MIT’s Graduate Christian Fellowship group. When she’s not enjoying spicy soups or paddling on the Charles, she takes advantage of opportunities to decompress with her art at W20 Arts Studios . “I wanted to create time for myself outside of research and the classroom,” she says. Zhang cites the benefits of MIT’s focus on cross-collaboration and encouraging students to explore other disciplines. As an undergraduate, Zhang minored in computer science, which taught her coding skills critical to her data work. Exposure to engineering also led her to become more interested in questions around how technology and workers interact. Working with other scholars in the department has improved how Zhang conducts inquiries. “I’ve become the kind of well-rounded student and professional who can identify and quantify impacts, which is invaluable for future projects,” she says. Exposure to different academic and research areas, Zhang argues, helps increase access to ideas and information.", "release_time": "2025-09-24", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/improving-workplace-future-whitney-zhang-0924"}
{"category": "产业应用", "title": "日立收购德国AI咨询公司synvert以加速AI战略部署", "short_summary": "日立收购德国synvert公司，整合数据与AI能力，加速Agentic AI和Physical AI解决方案的全球部署。", "detailed_summary": "日立收购德国synvert公司，整合数据与AI能力，加速Agentic AI和Physical AI解决方案的全球部署。\n（1）日立公司通过其美国子公司GlobalLogic收购德国数据与AI咨询公司synvert，交易预计在2026年3月财年结束前完成。\n（2）收购旨在加速日立HMAX解决方案套件的部署，该套件专注于通过Agentic AI和Physical AI推动运营自主和商业模式创新。\n（3）synvert拥有超过550名数据与AI专家，擅长数据治理、平台工程和高级分析，服务超过200家客户。\n（4）此次整合将结合synvert的数据咨询能力与GlobalLogic的数字工程平台，增强企业数据价值链的端到端服务能力。\n（5）收购将帮助日立利用synvert在德国、瑞士、西班牙、葡萄牙和中东的市场存在，拓展能源、零售、金融等行业的AI解决方案业务。", "raw_content": "Santa Clara, Münster, September 23rd, Tokyo 24th 2025, Hitachi, Ltd. (TSE:6501, \"Hitachi\") is advancing the realization of a “Harmonized Society” where environment, wellbeing, and economic growth coexist in balance. As One Hitachi, the company is strengthening its portfolio to harness domain expertise and accelerate AI-driven innovations that transform social infrastructure. The Hitachi Group has agreed to acquire synvert, a company headquartered in Germany, as a wholly owned subsidiary of its U.S. subsidiary GlobalLogic Inc. (“GlobalLogic”) from Maxburg, a leading private equity fund focusing on founder-led technology companies in the German-speaking region. This acquisition aims to accelerate the deployment of HMAX, Hitachi's solution suite advancing operational autonomy and business model innovation through Agentic and Physical AI, solving customer and societal challenges in the AI era. synvert is a leading consulting firm in the data and AI space, delivering advanced expertise in AI-driven business design, data access and governance, integration, and operations. With a portfolio of over 200 clients, synvert helps enterprises unlock value and drive intelligent, data-powered transformation. synvert maintains advanced partnerships with leading cloud and data platform vendors, including Databricks and Snowflake, alongside major public cloud vendors (AWS, Microsoft Azure, Google Cloud). Once the acquisition is completed, synvert will complement GlobalLogic's deep capabilities in AI and digital engineering, while adding end-to-end strength across the enterprise data value chain and accelerating the development of Agentic and Physical AI. synvert's strong presence in Germany, Switzerland, Spain, Portugal, and the Middle East will help expand markets for HMAX through collaboration with Hitachi Rail and Hitachi Energy. The acquisition is expected to close in the fiscal year ending March 2026 (April 1, 2025 to March 31, 2026), subject to regulatory approval. Advancing Hitachi's AI Vision Led by the Digital Systems & Services Sector Hitachi's Digital Systems & Services sector, leading the company's AI strategy under Lumada 3.0, is driving the evolution from Generative AI to Agentic AI–which autonomously coordinates multiple tools to perform complex tasks–and now to Physical AI, where intelligent systems interact with and control the physical world through robotics and IoT-enabled devices. The Hitachi AI Center of Excellence (AI CoE) has led the development and deployment of over 1,000 generative AI use cases, including mission-critical applications. Agentic AI is actively in use across executive, engineering, and frontline layers to enhance risk analysis, predictive maintenance, and system integrator efficiency, with over 200 global operational implementations.    Relevance of the synvert Acquisition Customers gain immediate advantages from a platform-first architecture and industrialized MLOps, resulting in faster AI time-to-value, responsible scaling with built-in AI guardrails, and the ability to add managed services that improve resilience and reduce total cost of ownership. As Agentic AI evolves to orchestrate intelligent decision-making and task execution across vast, dynamic datasets, a modern, enterprise-grade data foundation becomes mission-critical. synvert brings over 550 highly skilled specialists in data governance, data platform engineering, and advanced analytics–with deep expertise in data warehouse and lakehouse architectures. Their capabilities enable the seamless ingestion, management, and activation of data needed to power autonomous agents and real-time decision systems. By integrating synvert's proven data and AI consulting strengths with GlobalLogic's VelocityAI platform and digital engineering leadership, we extend our end-to-end value across the enterprise data lifecycle–positioning Hitachi to deliver scalable, secure, and production-ready Agentic and Physical AI solutions across industries.    Comment from Jun Abe, Executive Vice President of Hitachi, Ltd., General Manager of the Digital Systems & Services Division “Hitachi is accelerating social innovation by addressing urgent societal challenges–such as labor shortages and knowledge transfer among frontline workers in transportation, energy, gas, and railway sectors–through the advancement of its own AI-driven transformation and the delivery of its outcomes to customers. By integrating synvert's outstanding data analytics and consulting capabilities with GlobalLogic's digital engineering expertise, we will enhance competitiveness through Agentic AI and accelerate HMAX deployment. We aim to deliver digital value to all and realize a safe, secure, and sustainable Harmonized Society.” Comment from Srini Shankar, President and CEO, GlobalLogic “Integrating synvert into GlobalLogic will play a key role in accelerating our global strategy. It will strengthen our data and consulting capabilities and expand our presence in Europe and the Middle East across industries like energy, retail, financial services, and insurance. Once the acquisition is completed, we expect to rapidly deliver innovation through end-to-end development of data-driven AI services, and accelerate efforts in Agentic and Physical AI.” Comment from André Holhozinskyj, CEO, synvert “Joining the Hitachi Group, which has strengths in OT and products, is an ideal step in synvert's growth story. GlobalLogic's capabilities and regional strategy align well with synvert, and we believe this partnership will drive further growth. synvert's identity resonates with Hitachi's purpose-driven culture, and we look forward to what we can achieve together.” Company Overview     Company Name synvert   Headquarter and Office Headquarter: Münster, Germany  Offices: Europe, U.S., and Middle East   Business Provides sustainable data value chains from strategy to analytics platform operations; over 3,000 projects across finance, manufacturing, insurance, public sector, and energy   Employees Over 550 (as of June 2025)   Founded 1991   Website    CEO André Holhozinskyj (CEO)     As a private equity fund focusing on founder-led technology companies, Maxburg's successful partnership with synvert concludes with a strategic transaction with the Hitachi Group. Over the past five years, synvert has grown into one of the leading data and AI service providers in EMEA, increasing sales and profitability by a factor of eight through disciplined execution and strong leadership. The terms of the acquisition are not disclosed. About Hitachi, Ltd.  Through its Social Innovation Business (SIB) that brings together IT, OT(Operational Technology) and products, Hitachi contributes to a harmonized society where the environment, wellbeing, and economic growth are in balance. Hitachi operates globally in four sectors – Digital Systems & Services, Energy, Mobility, and Connective Industries – and the Strategic SIB Business Unit for new growth businesses. With Lumada at its core, Hitachi generates value from integrating data, technology and domain knowledge to solve customer and social challenges. Revenues for FY2024 (ended March 31, 2025) totaled 9,783.3 billion yen, with 618 consolidated subsidiaries and approximately 280,000 employees worldwide. Visit us at www.hitachi.com. About GlobalLogic  GlobalLogic (www.globallogic.com) is a leading digital engineering partner that helps the world's most forward-thinking companies design and build innovative, AI-powered products, platforms, and digital experiences. Since 2000, we've been at the forefront of the digital revolution, now accelerating clients' transitions into tomorrow's AI-driven businesses by integrating experience design, complex engineering, AI, and data expertise. Headquartered in Silicon Valley, GlobalLogic is a Hitachi Group Company operating under Hitachi, Ltd. (TSE: 6501), which contributes to a sustainable society with a higher quality of life by driving innovation through AI and technology as the Social Innovation Business. Visit us at www.globallogic.com. About Maxburg  Maxburg is a Munich-based private equity fund with capital commitments of more than €1bn. Maxburg is a growth investor, supporting exceptional businesses built and led by strong founders. Maxburg focusses on technology and software, business services and consumable products (B2B and B2C) sectors in the GSA region. synvert is Maxburg's fifth exit in the technology sector after having successfully invested in Maltego, KGS, Starface and Tenado. For more information about Maxburg visit maxburg.com/en/  Information contained in this news release is current as of the date of the press announcement, but may be subject to change without prior notice.", "release_time": "2025-10-11", "source_institution": "日本日立", "url": "http://www.hitachi.com/New/cnews/month/2025/09/250924.html"}
{"category": "产业应用", "title": "日立能源获评全球电网自动化市场领导者", "short_summary": "日立能源被ARC咨询集团评为全球电网自动化产品和服务的市场份额第一。", "detailed_summary": "日立能源被ARC咨询集团评为全球电网自动化产品和服务的市场份额第一。\n(1) ARC咨询集团2025年研究报告确认日立能源为全球电网自动化市场领导者。\n(2) 公司在电网控制管理、停电管理和AI应用等关键软件类别市场份额领先。\n(3) 在无线/有线网络、测量设备和RTU等硬件类别也处于市场领先地位。\n(4) 报告指出电网自动化市场因能源结构变化、新储能资产等因素正经历显著增长。\n(5) 公司致力于通过数字化和AI解决方案助力电网现代化，加速清洁能源转型。", "raw_content": "No. 1 position in ARC study underscores company's vital role in the global transformation of the electric power grid for a sustainable energy future Zurich, September 24, 2025 - Hitachi Energy was recognized as the global market share leader in grid automation for electric power transmission and distribution utilities by ARC Advisory Group , a leading technology research and advisory firm for industry, energy, and infrastructure. The findings are part of ARC's comprehensive market and technology study titled “Grid Automation Global Market Study 2024-2029” (June 2025). According to the report , Hitachi Energy is the No. 1 provider of grid automation products and services worldwide. The company was also recognized as the market share leader in key software categories, including Grid Control & Management, Outage Management, and AI Applications. ARC's study also revealed Hitachi Energy leads the market in a number of hardware categories, including Wireless and Wired Networks, Measurement devices, and RTUs. “Grid automation is essential to operating and maintaining the modern grid,” said Richard Rys, director of consulting at ARC Advisory and lead researcher for grid automation. “Our extensive market share analysis of suppliers in this highly competitive space shows Hitachi Energy at the top of the leaderboard. We believe this company's deep-rooted heritage in energy, extensive domain expertise, the breadth and depth of their integrated solutions, and strong focus on digitalization and AI/ML capabilities will continue to drive their leadership in the industry.” The report points to substantial growth in grid automation software, hardware and services due to a changing mix of generation, new grid-storage assets, and new market structures such as virtual power plants and support for demand response. In particular, the report states growth is strongest in regions building new electric grids or making major system upgrades or repairs due to weather events or wars that target and damage electric distribution systems. “The grid automation market is at an inflection point, with rapid global electrification and the urgency of the energy transition placing unprecedented demands on the grid. The future of the power grid depends on accelerating digital innovation and new capabilities,” said Massimo Danieli, Managing Director, Business Unit Grid Automation at Hitachi Energy. “As the market leader, we're proud to work closely with our customers and the industry to deliver the advanced solutions that modernize grid infrastructure, enhance resilience, and speed the transition to cleaner energy systems.” Hitachi Energy offers a comprehensive portfolio of grid automation solutions designed to modernize and optimize the electricity grid. The company helps electric utilities worldwide transform the traditional power grid into a more reliable, efficient, and resilient system, capable of handling the challenges of the evolving energy landscape. The company's grid automation solutions enable customers to navigate today's energy challenges with a unified, data-driven approach. From planning and building to real-time monitoring, control and protection, as well as maintenance and trading operations, Hitachi Energy's technologies enable safer, more reliable, and sustainable grid performance – connecting customers to what's next across the energy lifecycle. Published annually since 2021, ARC's Grid Automation Global Market Study combines current market analysis with a five-year market and technology forecast, as well as detailed market share analysis of the world's leading suppliers. The study focuses on electric utilities in the transmission and distribution sector providing power to commercial, industrial, and residential customers. It examines the key hardware, software, and services used to automate the grid – from the central control centers of the grid operators down to the edge of the distribution network. Founded in 1986, ARC Advisory Group is a leading technology research and advisory firm for industrial, energy, and infrastructure markets. Visit www.arcweb.com . About Hitachi Energy Hitachi Energy is a global technology leader in electrification, powering a sustainable energy future with innovative power grid technologies with digital at the core. Over three billion people depend on our technologies to power their daily lives. With over a century in pioneering mission-critical technologies like high-voltage, transformers, automation, and power electronics, we are addressing the most urgent energy challenge of our time – balancing soaring electricity demand, while decarbonizing the power system. With an unparalleled installed base in over 140 countries, we co-create and build long-term partnerships across the utility, industry, transportation, data centers, and infrastructure sectors. Headquartered in Switzerland, we employ over 50,000 people in 60 countries and generate revenues of around $16 billion USD. https://www.hitachienergy.com https://www.linkedin.com/company/hitachienergy https://twitter.com/HitachiEnergy About Hitachi, Ltd. Through its Social Innovation Business (SIB) that brings together IT, OT (Operational Technology) and products, Hitachi contributes to a harmonized society where the environment, wellbeing, and economic growth are in balance. Hitachi operates globally in four sectors – Digital Systems & Services, Energy, Mobility, and Connective Industries – and the Strategic SIB Business Unit for new growth businesses. With Lumada at its core, Hitachi generates value from integrating data, technology and domain knowledge to solve customer and social challenges. Revenues for FY2024 (ended March 31, 2025) totaled 9,783.3 billion yen, with 618 consolidated subsidiaries and approximately 280,000 employees worldwide. Visit us at www.hitachi.com . About Lumada In order to read a PDF file, you need to have Adobe Acrobat Reader installed in your computer. Information contained in this news release is current as of the date of the press announcement, but may be subject to change without prior notice.", "release_time": "2025-10-06", "source_institution": "日本日立", "url": "http://www.hitachi.com/New/cnews/month/2025/09/250925b.html"}
{"category": "产业应用", "title": "美国煤炭出口格局生变，亚洲成最大买家", "short_summary": "2024年美国出口近亿吨煤炭，印度中国日本为前三大进口国。", "detailed_summary": "2024年美国出口近亿吨煤炭，印度中国日本为前三大进口国。\n(1) 2024年美国煤炭出口量近1亿吨，亚洲取代欧洲成为主要出口目的地。\n(2) 印度是美国最大煤炭进口国，占比23.4%，其次是中国(11.5%)和日本(8.4%)。\n(3) 印度需求旺盛源于其能源安全需求、国内生产缺口及超70%电力依赖燃煤。\n(4) 欧洲进口量下降，因欧盟推动淘汰煤炭，现多进口用于钢铁制造而非发电。\n(5) 巴西、摩洛哥等拉丁美洲、非洲国家也是美国煤炭的重要买家。", "raw_content": "据美国VISUAL CAPITALIST 网站9月17日发布的信息，尽管美国国内能源结构在向天然气和可再生能源转变，但煤炭仍是主要的出口商品。 2024年，美国向世界各地出口了近1亿吨煤炭，主要买家集中在亚洲。这个可视化图表分解了去年美国煤炭出口的主要目的地。该图表的数据来自美国能源信息署(EIA)，显示了2024年按目的地划分的煤炭出口量，单位为百万吨。 亚洲：煤炭需求增长中心 印度是进口美国煤炭数量最多的国家，以占美国煤炭出口总量的23.4%份额遥遥领先，其次是中国(11.5%)和日本(8.4%)。这三个亚洲国家合计占美国煤炭出口总量的近43%。 自2017年以来，亚洲就取代欧洲成为美国煤炭出口的主要目的地。2024年，仅印度一国就购买了2290万吨的美国煤炭。印度对美国煤炭的高需求是由其能源安全需求、国内生产缺口和基础设施限制共同驱动的。目前，该国严重依赖煤炭发电——超过70%的电力来自燃煤电厂。 欧洲：美国煤炭进口角色的减弱 尽管一些欧洲国家仍然进口美国煤炭，但其总体份额已下降。荷兰仍然是主要买家(占7.4%)，但德国、意大利和波兰等其他国家的进口量较小。欧盟推动淘汰煤炭并尽早实现气候目标，导致该地区煤炭需求大幅减少。 值得注意的是，现在许多欧洲买家主要是为了钢铁制造而不是电力生产而进口美国煤炭。 新兴市场和利基市场(Niche Markets) 除了亚洲和欧洲，拉丁美洲、非洲和中东的一些国家2024年也进口了少量的美国煤炭。巴西(7.8%)和摩洛哥(5.6%)是非亚洲的美国煤炭主要买家。 责任编辑： 张磊 标签：美国 ,出口煤炭 上一篇：山东济宁梁山港煤炭“铁水直连”新模式落地 下一篇：最后一页", "release_time": "2025-09-23", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194268-1.html"}
{"category": "研究前沿", "title": "MIT与INL合作推动核能前沿技术创新", "short_summary": "MIT与INL深化合作，开发新型核燃料与小型反应堆，提升核能安全性与经济性。", "detailed_summary": "MIT与INL深化合作，开发新型核燃料与小型反应堆，提升核能安全性与经济性。\n（1）MIT与INL通过联合研究、人员交流等形式长期合作，共同应对美国核能产业关键挑战。\n（2）合作开发新型铬涂层核燃料，提升反应堆安全性与效率，已在美国电厂应用。\n（3）研究小型模块化反应堆（SMRs）成本与设计，开发开源工具评估可行性。\n（4）探索太空核反应堆材料与燃料制造新方法，支持月球表面能源系统。\n（5）通过CRISP联合中心聚焦仪器与控制技术，推动核电站远程自主运行。", "raw_content": "At the center of nuclear reactors across the United States, a new type of chromium-coated fuel is being used to make the reactors more efficient and more resistant to accidents. The fuel is one of many innovations sprung from collaboration between researchers at MIT and the Idaho National Laboratory (INL) — a relationship that has altered the trajectory of the country’s nuclear industry. Amid renewed excitement around nuclear energy in America, MIT’s research community is working to further develop next-generation fuels, accelerate the deployment of small modular reactors (SMRs), and enable the first nuclear reactor in space. Researchers at MIT and INL have worked closely for decades, and the collaboration takes many forms, including joint research efforts, student and postdoc internships, and a standing agreement that lets INL employees spend extended periods on MIT’s campus researching and teaching classes. MIT is also a founding member of the Battelle Energy Alliance, which has managed the Idaho National Laboratory for the Department of Energy since 2005. The collaboration gives MIT’s community a chance to work on the biggest problems facing America’s nuclear industry while bolstering INL’s research infrastructure. “The Idaho National Laboratory is the lead lab for nuclear energy technology in the United States today — that’s why it’s essential that MIT works hand in hand with INL,” says Jacopo Buongiorno, the Battelle Energy Alliance Professor in Nuclear Science and Engineering at MIT. “Countless MIT students and postdocs have interned at INL over the years, and a memorandum of understanding that strengthened the collaboration between MIT and INL in 2019 has been extended twice.” Ian Waitz, MIT’s vice president for research, adds, “The strong collaborative history between MIT and the Idaho National Laboratory enables us to jointly contribute practical technologies to enable the growth of clean, safe nuclear energy. It’s a clear example of how rigorous collaboration across sectors, and among the nation’s top research facilities, can advance U.S. economic prosperity, health, and well-being.” Research with impact Much of MIT’s joint research with INL involves tests and simulations of new nuclear materials, fuels, and instrumentation. One of the largest collaborations was part of a global push for more accident-tolerant fuels in the wake of the nuclear accident that followed the 2011 earthquake and tsunami in Fukushima, Japan. In a series of studies involving INL and members of the nuclear energy industry, MIT researchers helped identify and evaluate alloy materials that could be deployed in the near term to not only bolster safety but also offer higher densities of fuel. “These new alloys can withstand much more challenging conditions during abnormal occurrences without reacting chemically with steam, which could result in hydrogen explosions during accidents,” explains Buongiorno, who is also the director of science and technology at MIT’s Nuclear Reactor Laboratory and the director of MIT’s Center for Advanced Nuclear Energy Systems. “The fuels can take much more abuse without breaking apart in the reactor, resulting in a higher safety margin.” The fuels tested at MIT were eventually adopted by power plants across the U.S., starting with the Byron Clean Energy Center in Ogle County, Illinois. “We’re also developing new materials, fuels, and instrumentation,” Buongiorno says. “People don’t just come to MIT and say, ‘I have this idea, evaluate it for me.’ We collaborate with industry and national labs to develop the new ideas together, and then we put them to the test,  reproducing the environment in which these materials and fuels would operate in commercial power reactors. That capability is quite unique.” Another major collaboration was led by Koroush Shirvan, MIT’s Atlantic Richfield Career Development Professor in Energy Studies. Shirvan’s team analyzed the costs associated with different reactor designs, eventually developing an open-source tool to help industry leaders evaluate the feasibility of different approaches. “The reason we’re not building a single nuclear reactor in the U.S. right now is cost and financial risk,” Shirvan says. “The projects have gone over budget by a factor of two and their schedule has lengthened by a factor of 1.5, so we’ve been doing a lot of work assessing the risk drivers. There’s also a lot of different types of reactors proposed, so we’ve looked at their cost potential as well and how those costs change if you can mass manufacture them.” Other INL-supported research of Shirvan’s involves exploring new manufacturing methods for nuclear fuels and testing materials for use in a nuclear reactor on the surface of the moon. “You want materials that are lightweight for these nuclear reactors because you have to send them to space, but there isn’t much data around how those light materials perform in nuclear environments,” Shirvan says. People and progress Every summer, MIT students at every level travel to Idaho to conduct research in INL labs as interns. “It’s an example of our students getting access to cutting-edge research facilities,” Shirvan says. There are also several joint research appointments between the institutions. One such appointment is held by Sacit Cetiner, a distinguished scientist at INL who also currently runs the MIT and INL Joint Center for Reactor Instrumentation and Sensor Physics (CRISP) at MIT’s Nuclear Reactor Laboratory. CRISP focuses its research on key technology areas in the field of instrumentation and controls, which have long stymied the bottom line of nuclear power generation. “For the current light-water reactor fleet, operations and maintenance expenditures constitute a sizeable fraction of unit electricity generation cost,” says Cetiner. “In order to make advanced reactors economically competitive, it’s much more reasonable to address anticipated operational issues during the design phase. One such critical technology area is remote and autonomous operations. Working directly with INL, which manages the projects for the design and testing of several advanced reactors under a number of federal programs, gives our students, faculty, and researchers opportunities to make a real impact.” The sharing of experts helps strengthen MIT and the nation’s nuclear workforce overall. “MIT has a crucial role to play in advancing the country’s nuclear industry, whether that’s testing and developing new technologies or assessing the economic feasibility of new nuclear designs,” Buongiorno says.", "release_time": "2025-09-23", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/mit-work-with-idaho-national-laboratory-advances-america-nuclear-industry-0923"}
{"category": "研究前沿", "title": "研究揭示宇宙网磁性源于大爆炸初期", "short_summary": "国际团队通过模拟证实宇宙网磁性源自早期宇宙，并确立原初磁场强度新上限。", "detailed_summary": "国际团队通过模拟证实宇宙网磁性源自早期宇宙，并确立原初磁场强度新上限。\n(1) 研究旨在解释宇宙网（连接星系的纤维状结构）在稀疏区域也存在磁性的起源之谜。\n(2) 假设磁场源于宇宙诞生初期的物理过程，如暴胀或相变，并通过超过25万次计算机模拟进行验证。\n(3) 模拟结果显示，包含强度约0.2纳高斯的微弱原初磁场的模型与观测数据更为吻合。\n(4) 研究确立了原初磁场强度的新上限，该数值比先前估计低数倍，与宇宙微波背景研究结果一致。\n(5) 此发现有助于理解早期宇宙事件，并可能通过詹姆斯·韦伯空间望远镜的观测得到进一步验证。", "raw_content": "A magnetic cosmic web \"The cosmic web, of which much remains to be discovered, is a filamentary structure connecting the galaxies that permeates the Universe. One of its many unsolved mysteries is why it is magnetized, not only near galaxies, where this might be expected, but also in distant regions that are sparsely populated and constitute the bulk of the cosmic web. This is harder to explain.\" These comments come from Mak Pavičević, a SISSA PhD student and lead author of the research, and Matteo Viel, his supervisor and co-author of the study. \"Our hypothesis was that this could be a legacy of events occurring in cosmic epochs during the birth of the Universe, and that magnetism was linked essentially to physical processes in the primordial Universe. For example, the filaments would have become magnetized during the inflation process before the so-called \"Big Bang\" or through events in later epochs, called phase transitions. This is what we sought to ascertain with our work. We also wished to assess the magnitude of these primordial magnetic fields through our investigations, establishing an upper limit and attempting to measure their strengths.\" At the origin of the Universe with a quarter of a million simulations The international team used over 250,000 computer simulations to study the cosmic web and better understand the influence of primordial magnetic fields. Vid Iršič from University of Hertfordshire, and a co-author of the study, emphasizes that \"these are the most realistic and largest suite state-of-the-art simulations of the influence of primordial magnetic field on the intergalactic cosmic web.\" Pavičević and Viel explain: \"By comparing these simulations with observational data, we saw that our hypotheses were correct. When the influence of primordial fields is included in the picture, the cosmic web looks different and more in agreement with observed data. In particular, we can say that a standard model of the Universe with a very weak magnetic field of around 0.2 nano-gauss actually fits experimental data much better.\" The magnitude of primordial magnetic fields: a new upper limit The scientists have derived a particularly low value for the magnitude of the primordial magnetic fields, establishing a new upper limit several times lower than previously estimated. Pavičević and Viel continue: \"Our research thus places strict limits on the intensity of magnetic fields formed in the very early moments of the Universe and is consistent with recent results obtained in independent data and studies on the cosmic microwave background. The two scientists explain: \"This evidence will help us to improve our understanding of events in the early Universe. The magnetic field would have increased the density of the cosmic web, in turn accelerating the process of star and galaxy formation. It will be possible to further validate our results through observations made by the James Webb Space Telescope.\" Vid Iršič concludes: \"Not only will these new limits help us understand the impact of the primordial magnetic fields on the evolution of the Cosmo, but they also hold important implications for other theoretical models that enhance structure formation.\"", "release_time": "2025-09-23", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250923021158.htm"}
{"category": "政策计划", "title": "印尼处罚190家未缴保证金矿企并责令停产", "short_summary": "印尼对190家未缴复垦保证金矿企实施停产处罚，同时关注中国煤炭市场动态与三峡洪水。", "detailed_summary": "印尼对190家未缴复垦保证金矿企实施停产处罚，同时关注中国煤炭市场动态与三峡洪水。\n（1）印尼能源部对190家未缴纳复垦保证金的矿业公司实施行政处罚，责令其业务暂时停产，最长期限60天。\n（2）处罚原因是企业未响应此前三次行政警告，若企业提交获批复垦计划并补缴保证金，处罚可解除，否则采矿许可证可能被永久撤销。\n（3）国内北方港口煤价涨幅缩窄，下游需求偏弱，产地市场情绪降温，出现降价和流拍现象。\n（4）受华西秋雨影响，三峡水库迎来2025年最大洪水过程，入库流量超40000立方米每秒。", "raw_content": "2025 年 9 月 18 日，印尼能源与矿产资源部通过矿产与煤炭总局发布编号 1533/MB.07/DJB.T/2025 的函件，对 190 家未缴纳 复垦保证金 的矿业公司实施行政处罚，责令其业务 暂时停产。 在此之前，因为这些公司没有按照适用的规定提供索赔和退款担保，已经受到了三次行政警告，此次处罚是为未响应此前三次行政警告的后续措施。 停产期限最长期限为 60 天，若企业能提交并获批复垦计划文件，并缴纳 2025 年前的复垦保证金，处罚可被解除。同时，矿产与煤炭总局相关负责人 强调，若企业在规定时间内仍未履行义务，其采矿许可证可能被永久撤销。 国内方面，今日，北方港口煤价涨幅缩窄，贸易商出货意愿增加，但下游需求依然偏弱。 9月22日北方港口具体煤价参考如下： 5500大卡：707元/吨(+3) 5000大卡：616元/吨(+3) 4500大卡：543元/吨(+3) 同时，产地方面，阶段性补库告一段落，贸易商及下游均减缓采购节奏，产地情绪开始降温，市场观望情绪渐起，个别煤矿出现降价、流拍现象。 中国三峡集团官网消息，受华西秋雨影响，长江上游嘉陵江及三峡区间出现多轮次降雨过程，三峡水库入库流量从9月17日开始逐步上涨，9月20日迎来入库流量超过40000立方米每秒的洪水，为2025年最大洪水过程。截至今日，长江三峡水位167米，去年同期水位为161米。 责任编辑： 张磊 标签：印尼 上一篇：煤价站稳700元关口!九月动力煤走出“淡... 下一篇：最后一页", "release_time": "2025-09-23", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194261-1.html"}
{"category": "研究前沿", "title": "科学家首次揭示纳米受限水的预熔态特性", "short_summary": "东京理科大学团队通过氘核磁共振技术，首次观测到纳米孔中水分子分层结构及固液共存预熔态。", "detailed_summary": "东京理科大学团队通过氘核磁共振技术，首次观测到纳米孔中水分子分层结构及固液共存预熔态。\n（1）东京理科大学团队使用静态固态氘核磁共振技术，研究1.6纳米亲水孔道中重水的动力学行为；\n（2）首次确认受限水存在三层分层结构，各层水分子具有不同的运动模式和氢键相互作用；\n（3）发现预熔态新相：不完全氢键结合的水分子先熔化，与冻结水层共存，形成固液混合态；\n（4）预熔态水分子位置固定如固体，但旋转运动速度接近液态水，表现出独特动力学特性；\n（5）该发现有助于理解生物膜水渗透机制，并为开发人工气体水合物等新型水基材料提供理论基础。", "raw_content": "One intriguing yet poorly understood state of confined water is called the 'premelting state.' In this unique phase, water behaves as if it were on the cusp of freezing and melting at the same time, thus defying simple liquid or solid classifications. However, it has proven difficult to study the premelting state and other confined water dynamics in detail. While techniques such as diffraction methods (example: X-ray analysis) are useful for pinpointing the positions of atoms other than hydrogen, they are not sensitive enough to capture the picosecond-scale rotational motion of hydrogen and the motion of individual water molecules. In a recent study, a research team led by Professor Makoto Tadokoro alongside Lecturer Fumiya Kobayashi and first-year PhD student Mr. Tomoya Namiki, from the Department of Chemistry, Tokyo University of Science, Japan, shed new light on the mysteries of confined water. Their paper, published online in the Journal of the American Chemical Society on August 27, 2025, reports how they used static solid-state deuterium nuclear magnetic resonance (NMR) spectroscopy to observe the hierarchical dynamics of water confined within the hydrophilic nanopores of a molecular crystal and characterized the premelting state, which is a new phase observed in water. To perform their experiments, the team produced hexagonal rod-like crystals, with quasi-one-dimensional channels containing a nanopore approximately 1.6 nm in diameter and filled them with heavy water (D 2 O). By measuring the NMR spectra of a single crystal of {[Co(D 2 bim) 3 ](TMA).20D 2 O} n at room temperature, the researchers were able to confirm the existence of a hierarchical, three-layered structure in the contained water molecules. The unique peaks observed in the spectra corresponded to every layered structures with distinct movements and hydrogen-bonding interactions with one another of the confined water, providing clear evidence of multi-layered organization. Furthermore, water confined in the nanopores freezes in a different structure from bulk ice and first melts through a distorted hydrogen-bonded structure, leading to the formation of a premelting state. To gain insights into the premelting state, the researchers heated the crystal gradually from low temperature to get the water from a frozen state to a liquid state. They observed distinct changes in the NMR spectra that confirmed a phase transition into the premelting state, and their measurements revealed the presence of two seemingly contradictory states. \" The premelting state involves the melting of incompletely hydrogen-bonded H 2 O before the completely frozen ice structure starts melting during the heating process. It essentially constitutes a novel phase of water in which frozen H 2 O layers and slowly moving H 2 O coexist ,\" explains Prof. Tadokoro. The researchers measured the spin-lattice relaxation time to quantify the rotational mobility of the heavy water molecules in this new phase. While the activation energy for the premelting state was far from that of bulk ice, the correlation time was remarkably close to that of bulk liquid water. Simply put, this means that while the water molecules' positions were relatively fixed as one would expect of a solid, their rotational motions were extremely fast and liquid-like. Taken together, these findings build toward a more comprehensive understanding of how water behaves in extreme confinement. They clarify crucial structural and dynamic aspects, which are important for understanding how water and ions permeate through biological proteins and membranes. Looking ahead, these insights could also lead to practical innovations. \" By creating new ice network structures, it may be possible to store energetic gases such as hydrogen and methane and develop water-based materials such as artificial gas hydrates ,\" says Prof. Tadokoro. Controlling the freezing properties of water based on the structure of ice could lead to the creation of new, inexpensive, and safe hydrosphere materials. Overall, this study ultimately demonstrates that even a substance as common as water still holds fundamental secrets waiting to be unlocked. This work was supported by JSPS KAKENHI Grant-in-Aid for Scientific Research (B) JP23K26672 and JSPS KAKENHI Grant-in-Aid for Early-Career Scientists JP23K13767 from the Ministry of Education, Culture, Sports, Science, and Technology, Japan.", "release_time": "2025-09-23", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250922074936.htm"}
{"category": "研究前沿", "title": "紫外线新技术可快速灭活空气中过敏原", "short_summary": "研究发现222纳米紫外线能改变过敏原结构，快速降低其致敏性。", "detailed_summary": "研究发现222纳米紫外线能改变过敏原结构，快速降低其致敏性。\n(1) 科罗拉多大学博尔德分校研究发现，使用222纳米波长的紫外线可快速灭活空气中的过敏原。\n(2) 该技术通过改变过敏原蛋白质的三维结构，使其无法被免疫系统识别，从而避免过敏反应。\n(3) 实验表明，在30分钟内可使过敏原的免疫识别率平均降低20%至25%，效果显著快于传统清洁方法。\n(4) 222纳米紫外线被认为在 occupied 空间内使用相对安全，不会深入穿透细胞。\n(5) 该技术有望开发成便携设备，帮助过敏患者在家庭、工作场所等环境中预防过敏和哮喘发作。", "raw_content": "For people with allergies, even a brief whiff of the airborne allergens these organisms produce can lead to swollen eyes, itchy skin and impaired breathing. Such allergens can persist indoors for months after the original source is gone, and repeated exposure can exacerbate, and even lead to, asthma. What if you could just flip a switch and disable them? You can, according to new University of Colorado Boulder research. \"We have found that we can use a passive, generally safe ultraviolet light treatment to quickly inactivate airborne allergens,\" said study author Tess Eidem, a senior research associate in the Department of Civil, Environmental and Architectural Engineering. \"We believe this could be another tool for helping people fight allergens in their home, schools or other places where allergens accumulate indoors.\" The findings were published in August in the journal ACS ES&T Air . Why you can't kill an allergen Walk into a room with a cat and, if you sneeze, it's not actually the cat you are reacting to. It's likely airborne flecks of a protein called Fel d1 produced in their saliva. The protein spreads when they lick themselves and ends up in microscopic flakes of dead skin floating in the air, a.k.a. dander. When we inhale these particles, our immune system produces antibodies that bind to the protein's unique 3D structure, kicking off an allergic reaction. Dogs, mice, dust mites, mold and plants all emit their own unique proteins, with their own unique structure. Unlike bacteria and viruses, these allergens can't be killed because they were never alive. \"After those dust mites are long gone, the allergen is still there,\" said Eidem. \"That's why, if you shake out a rug, you can have a reaction years later.\" Standard methods of reducing allergens -- like vacuuming, washing walls, using an air filter and regularly bathing pets -- can work OK but are hard to maintain long-term studies show. Eidem and co-authors Mark Hernandez, a professor of Civil, Environmental and Architectural Engineering, and Kristin Rugh, a microbiologist in the lab, sought a simpler way. Instead of eliminating the proteins that cause allergies, they sought to change their structure -- much like unfolding an origami animal -- so the immune system wouldn't recognize them. \"If your immune system is used to a swan and you unfold the protein so it no longer looks like a swan, you won't mount an allergic response,\" explained Eidem. UV light, their study suggests, can do that. Let there be light Previous research has shown that UV light can kill airborne microorganisms, including the virus that causes COVID-19. It's already used widely to disinfect equipment in hospitals, airports and elsewhere, but the bandwidth is typically so strong (a wavelength of 254 nanometers) that users must wear protective equipment to prevent damage to skin and eyes. Eidem used 222-nanometer-wavelength lights, a less-intense alternative considered safe for occupied spaces because it doesn't penetrate deep into cells. (It does not come entirely without risks, including ozone production, she notes, so exposure should be limited.) The team pumped microscopic aerosolized allergens from mites, pet dander, mold and pollen into an unoccupied and sealed 350-cubic-foot chamber. Then they switched on four lunchbox-sized UV222 lamps on the ceiling and floor. When they sampled the air at 10-minute intervals and compared it to untreated, allergen-filled air via laboratory tests, they saw significant differences. In the treated samples, immunorecognition was reduced, meaning the antibodies no longer recognized many of the proteins and stuck to them. After just 30 minutes, airborne allergen levels effectively decreased by about 20% to 25% on average, the study showed. \"Those are pretty rapid reductions when you compare them to months and months of cleaning, ripping up carpet, and bathing your cat,\" said Eidem. A portable allergy buster? UV222 lights are already commercially available, mostly for industrial antimicrobial uses. But Eidem envisions a day when companies could engineer portable versions for people to switch on when they visit a friend with a pet or clean out a dusty basement. UV222 systems could also potentially protect workers frequently exposed to allergens, such as those who work around live animals or in cannabis grow houses where, her own research shows, allergic reactions can be deadly. One-in-three adults and children in the United States have allergies, according to the Centers for Disease Control. Eidem hopes her research, and more to come, can provide them with some relief -- or even save lives. \"Asthma attacks kill about 10 people every day in the United States, and they are often triggered by airborne allergies,\" she said. \"Trying to develop new ways to prevent that exposure is really important.\"", "release_time": "2025-09-23", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250922074945.htm"}
{"category": "产业应用", "title": "亚洲动力煤价现近两年最长涨势后回落", "short_summary": "亚洲动力煤价经历近两年最长上涨，主因中国进口激增，随后因需求减弱价格回落。", "detailed_summary": "亚洲动力煤价经历近两年最长上涨，主因中国进口激增，随后因需求减弱价格回落。\n（1）亚洲动力煤价格在2024年8月出现自2023年10月以来近两年最长的持续上涨行情。\n（2）价格上涨主要受中国进口需求激增推动，原因包括国内煤矿安检推高本地煤价、夏季热浪增加用电需求。\n（3）中国煤炭进口连续两月增长，7月进口3561万吨，8月增至4274万吨；同时7月国内原煤产量同比下降3.8%。\n（4）涨势在8月下旬逆转，因夏季需求减弱、水电改善及港口库存增加，价格回落。\n（5）未来展望显示，9月中国需求可能进一步减弱，供需缺口扩大或继续压制煤价。", "raw_content": "据标普全球(S&P Globle)9月10日发布的信息，亚洲动力煤价格在上个月经历了自2023年10月以来的近两年来最长的复苏上涨时段，各等级煤炭的价格在夏季持续上涨。 普氏(Platts)评估价格显示，从8月1日结束的那一周到8月22日结束的那一周，最活跃等级的加里曼丹4200千卡/千克GAR价格持续每周上涨，而中等CV等级的加里曼丹5000千卡/千克GAR则从7月11日结束的那一周连续七周上涨，直到截至8月22日的那一周。 这是自2023年9月和10月亚洲动力煤价格上涨连续8周以来最长的上涨行情，当时中国的电力公司和交易商在黄金周假期前以及为满足冬季补库需求，而大量采购煤炭。 在今年经历了大部分时间的逐步下跌后，煤炭价格保持了在2024年大部分时间里的区间波动，而仅因中国间歇性购买和南亚及东南亚地区需求不均出现小幅波动。 最近的市场反弹是由中国进口复苏购买量激增推动的。国内矿山更严格的安检措施推高了当地煤炭价格，使得海运进口价格相对便宜。中国各地夏季热浪进一步增加了煤炭消耗，使得海运市场即时供应表现有些趋紧。 新加坡的一位交易员表示，由于中国国内现货价格快速上涨，公用事业部门在7月和8月初不得不更加依赖进口。“这让印尼和澳大利亚的供应商在定价上占据了一些优势。” 中国海关总署最新数据显示，中国煤炭和褐煤进口量连续两个月增长，7月份环比增长7.8%，达到3561万吨，8月份进一步增至4274万吨。 7月份，中国原煤产量总计3.8099亿吨，同比下降3.8%，为2024年4月以来的最低产量水平。 亚洲动力煤市场价格上涨势头在8月22日结束的那一周发生逆转，价格又再次出现回落。 主要原因是，随着夏季需求的减弱，中国国内煤炭价格趋于稳定，而水电发电量的改善减少了对燃煤发电的需求。主要港口煤炭库存开始增加，缓解了即时的购买压力。 标普全球海运大宗商品(S&P Global Commodities at Sea)数据显示，迄今为止，印度尼西亚是中国最大的煤炭进口来源供应国，其次是澳大利亚和俄罗斯。 普氏评估9月10日中国到岸3800千卡/千克NAR价格仅为每吨50.70美元。 与此同时，印尼的供应变得更加稳健，因为几家生产商获得了额外的年度产量配额，即当地称为RKAB的配额，这有助于缓解现货市场的紧张局势。 一位印尼矿商表示，“由于RKAB修订后，本季度我们获得了额外的生产配额批准，因此出口将更加稳定。” 随着中国国内供应保持强劲，能源转型加速，煤炭进口的动态变化越来越受到价格竞争力的影响。买家可能会采取机会主义的态度，寻找最具有成本效益的供应商来满足即时需求并解决短期供应短缺问题。 通常在春节或秋假等长假前，因为国内煤矿因假期而暂停部分运营，中国的购买力度会得到一定支持。 “标普全球商品洞察”(S&P Global Commodity Insights)分析师在最新的国际动力煤市场预测报告中表示，“9月份，中国的煤炭产区降雨量可能将比8月份减少;此外，随着气温下降，煤炭消耗量也会减少。预计煤炭供需之间不匹配的差距扩大，将削弱国内市场煤炭价格，并降低对进口动力煤的需求。” 责任编辑： 张磊 标签：亚洲动力煤 上一篇：从资金、现货流动看四季度焦煤走势 下一篇：最后一页", "release_time": "2025-09-23", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194266-1.html"}
{"category": "研究前沿", "title": "自驱动轨道车结合ALTRIOS优化技术提升短途货运竞争力", "short_summary": "新型自驱动轨道车通过优化调度策略可将集装箱交付时间缩短70%，助力小型铁路竞争短途货运市场。", "detailed_summary": "新型自驱动轨道车通过优化调度策略可将集装箱交付时间缩短70%，助力小型铁路竞争短途货运市场。\n（1）Parallel Systems在乔治亚州启动自驱动轨道车试点，每个轨道车配备电池和传感器系统实现自主运行；\n（2）NREL研究人员使用ALTRIOS软件进行系统优化，包括电池容量配置、编队长度和调度策略模拟；\n（3）创新终端调度模块LIFTS可减少货物堆积，使轨道车在装载20-30个集装箱后数小时内即可出发；\n（4）优化后的系统使集装箱交付时间减少70%，有望帮助小型铁路在短途运输市场与卡车竞争；\n（5）该技术可降低终端占地面积需求，为农村地区提供新的铁路接入机会，预计2026年完成商业化验证。", "raw_content": "ALTRIOS Software Helps Launch Next-Generation Railcars in Heart of Georgia Parallel Systems’ Self-Propelled Railcars and a New Dispatching Strategy Could Help Smaller Railroads Compete in Short-Haul Delivery Market Sept. 24, 2025 | By Anna Squires | Contact media relations Share After analyzing Parallel Systems rail vehicles and freight train terminal operations, NREL researchers found the next-generation vehicles—combined with an optimized dispatching strategy—could reduce container delivery times by 70%. This could help smaller railroads compete with the trucking industry for short-haul deliveries. Photo from Parallel Systems A new kind of freight train has hit the tracks outside of Savannah, Georgia—and researchers at NREL, a U.S. Department of Energy national laboratory, helped put it there. With approval from the Federal Railroad Association, U.S. manufacturer Parallel Systems launched a seven-phase pilot of its self-propelling railcars this summer along the Heart of Georgia railroad, which is operated by the short-line railroad Genesee & Wyoming. Traditional freight trains haul large portions of the nation’s long-distance cargo: roughly 1.5 billion tons of raw materials and finished goods every year, or about 118,000 pounds of cargo per American. Yet they struggle to complete in the short-haul delivery market, where they carry just 4% of shipments , compared to the trucking industry’s 75%. Parallel, a newcomer to the well-established world of freight trains, could change those proportions with railcars that mimic the flexibility and speed of trucks. Unlike a traditional freight train, which typically uses a group of diesel locomotives to haul 100 railcars or more, each Parallel railcar powers and controls itself using a battery, onboard control system, and a suite of sensors. The vehicles are capable of “platooning”—connecting themselves using a spring-damper bumper system—to form small 20- to 30-car convoys that travel closely together to reduce aerodynamic drag. These smaller, lighter platoons have the potential to flow through freight facilities far more quickly than traditional trains, reducing bottlenecks and lag time and ultimately getting deliveries to their final destinations faster. It could help make freight trains competitive, for the first time, in the short-haul delivery market. Text version Parallel’s disruptive concept requires precise engineering, deep understanding of railcar dynamics, and a lot of optimization. That is where NREL researchers come in. “We want to bring miles back to railroads so railroads can make more money,” said Suzi An, a Parallel project manager. “What NREL has helped us do is put structure and data behind that idea.” NREL’s Train and Terminal Optimization Tools Identify New Efficiencies In 2024, NREL commercial vehicle researchers journeyed to MxV Rail’s test facility in Pueblo, Colorado, to observe Parallel rail vehicles on the tracks: watching as the railcars braked, curved, and equalized their weight, then finally zoomed around a high-speed loop track. These evaluations helped ensure Parallel’s railcars met industry standards for train dynamics before demonstrations began along the Heart of Georgia rail line. In the meantime, NREL researchers could begin optimizing Parallel’s operations. Using data gathered during the evaluations, along with vehicle specifications, the research team built Parallel’s railcars into their open-source Advanced Locomotive Technology and Rail Infrastructure Optimization System , called ALTRIOS. ALTRIOS operates, in some ways, like a very high-resolution camera. Researchers can use it to see a crisp operational rendering of an entire rail system, including the movements of multiple fleets. Or they can use it to zoom into the fine details of a single train’s operation and even individual components like a powertrain or a set of brakes. “A very multidisciplinary team built ALTRIOS, and it was important to us that industry partners had a strong voice in its development,” said Jason Lustbader, NREL’s principal investigator for the project. “We combined fine-grained details of individual component and powertrain performance with a system-level perspective, which is what allows us to model rail traffic, infrastructure constraints, and now terminal operations,” he said. “It enables ALTRIOS to operate at a high fidelity for single trains and entire rail networks and makes it useful to railroads and manufacturers.” ALTRIOS operates like a high-resolution camera, giving researchers a crisp big-picture view of train fleet operations or a zoomed-in understanding of single trains and components. Illustration by Cameron Nelson, NREL To optimize Parallel’s operations, NREL researchers first simulated Parallel railcars traveling along multiple U.S. routes. Then, they narrowed in on specific interactions. Researchers determined the right battery size to allow vehicles to haul cargo 500 miles on a single charge without adding excess weight or cost. They identified the best platoon length to allow for fast, low-energy deliveries of as many containers as possible. And they determined how many platoons Parallel could dispatch without saturating the rail network. Next, researchers turned their focus to Parallel’s operations within freight terminals. Parallel’s freight terminal concept could dramatically decrease the required footprint by nearly eliminating container bottlenecks. Image from Parallel Systems Traditionally, a freight train is “built” by physically coupling railcars together, then using cranes and yard tractors to load them with containers. To reduce the cost of shipping, these trains can stretch over two miles in length—and assembling a train can take hours. Logistics can slow even further due to a dispatching pattern NREL researchers describe as a “sawtooth.” While shipments that arrive just before a train departs can make it onto a train quickly, shipments that arrive afterward may sit for 24 hours or more before being loaded onto the next train. Parallel and NREL aim to turn that concept on its head. Together with researchers from the University of Texas at Austin, the NREL team built a brand-new ALTRIOS module called the Line-haul Intermodal Freight Terminal Simulator, or LIFTS. The module allows researchers to understand even the tiniest movements of containers and equipment inside a freight terminal’s gates. Using ALTRIOS-LIFTS, researchers studied the number of times a crane might lift a container, how much energy it takes to move that container through each step of its journey, and where bottlenecks in the process occurred. Because every unneeded movement costs energy—and money—more efficient operations can quickly create cost savings. Then, they were able to simulate how Parallel’s railcars would function using either a traditional dispatching strategy or a new, optimized approach. NREL analysis showed that, by reducing bottlenecks, Parallel’s system could slash freight train delivery times by nearly 70%. Image by NREL “Automated vehicles, like Parallel railcars, can be essentially scheduled to leave a terminal on demand,” Lustbader said. “As soon as you have enough railcars to create an aerodynamically efficient platoon—say, 20—you can send them out. It gives you a lot of flexibility in how you dispatch and how you optimize your dispatching.” And that optimized strategy, researchers determined, would allow Parallel railcars to keep up with demand: arriving at a terminal, taking on 20 to 30 shipping containers, and departing within hours. By reducing bottlenecks, Parallel’s system can slash freight train delivery times by nearly 70%. Fast, Flexible Deliveries Could Help Small Railroads Compete The benefits of faster cargo delivery stretch far beyond companies and consumers getting their goods more quickly. First, reducing the amount of storage needed at freight terminals can help create new opportunities to build smaller freight terminals in areas with no existing rail access. “When you’re intelligently dispatching railcars as fast as possible, you hardly have any cargo buildup at a freight terminal, so you need very little storage space on-site,” said NREL’s Matt Bruchon, another member of the research team. “You can build a less expensive terminal because it doesn’t need a large footprint. That can potentially unlock new locations for freight terminals in areas that have good rail access but don’t have a lot of space.” It can also help smaller freight terminals, often located in rural areas, compete with larger facilities. “In rural communities that have lower demand, the traditional dispatching model is a lot more challenging,” Lustbader explained. “Freight trains need to be big in order to be cost-effective, and you end up seeing trains running less frequently into rural areas.” But automating and optimizing small platoons in the way Parallel intends to can help rural freight terminals maintain steady operations, even if they have a low volume of cargo. “Right now, the rail industry tends to focus on high-volume areas because they can build and dispatch large trains, and it’s very cost-effective,” Lustbader said. “In my mind, Parallel’s technologies could really open opportunities for areas that have lower and less consistent volume and expand rail access across the United States.” The Cordele Train Terminal, pictured here in 1938, used to be a bustling resource for middle Georgia. It shut down in 2017 due to low freight train volume and high competition from trucks but could have an opportunity for revitalization. Photo from Getty Images Indeed, revitalizing rural rail lines is a stated goal of Parallel’s operations. The final phase of their Heart of Georgia trial aims to show that Parallel vehicles can successfully deliver revenue-generating containers along the 160 miles of track between Pooler, Georgia, and Cordele, Georgia—an area of the state largely served by trucking companies. Yet with faster, more flexible dispatching to more areas in the United States, freight trains could become more competitive with trucks. Shifting more freight from trucks to trains can also create benefits, like reducing traffic and collisions on highways and lowering the cost of deliveries. NREL’s Optimization Tools Stretch Beyond the Tracks Parallel’s pilot is slated for completion in 2026. After verifying that the technology works safely and is ready for commercialization, the manufacturer will be able to apply for regulatory approval and bring in its first customers. “It’s been exciting to use our models to inform real-world decisions and exciting to see Parallel take their next step towards commercialization,” Lustbader said. “It shows how the physics-based modeling tools we build can help make technology development and implementation successful.” And this is not the end of the line for NREL’s ALTRIOS or ALTRIOS-LIFTS software. The tools open possibilities for analyzing advanced technologies, such as automation and cutting-edge powertrains, at seaport and inland port terminals—including the railroads and highways that lead there. “Optimizing freight operations, whether it’s within a rail terminal or a port or even along our freight networks, can be a huge boon for our global competitiveness,” Bruchon said. “Improving cost, speed, and reliability could really give the U.S. a leg up.” Learn more about NREL's transportation and mobility research and its specific focus on advanced commercial vehicles . And sign up for NREL's transportation and mobility research newsletter to stay current on the latest news.", "release_time": "2025-09-24", "source_institution": "美国能源部国家可再生能源实验室", "url": "https://www.nrel.gov/news/detail/features/2025/altrios-software-helps-launch-next-generation-railcars-in-heart-of-georgia"}
{"category": "研究前沿", "title": "AI加速生物制造：从实验室到工业应用的新路径", "short_summary": "PNNL利用AI模型优化微生物菌株性能，显著提升生物产品产出并缩短研发周期。", "detailed_summary": "PNNL利用AI模型优化微生物菌株性能，显著提升生物产品产出并缩短研发周期。\n（1）生物制造面临核心挑战：实验室成功的工程菌株在工业放大时常失败，传统试错法效率低下；\n（2）PNNL采用AI解决方案：结合机器学习模型（如自动推荐工具ART）与基因组规模模型，实现精准预测；\n（3）应用案例验证：使用ART优化Lipomyces starkeyi酵母的培养基，使苹果酸产量提升20%；\n（4）技术优势：AI模型隐含捕捉基因-环境互作复杂性，耦合机制模型提升可解释性；\n（5）未来潜力：加速生物燃料、医药等产品开发，推动实验室成果向工业转化。", "raw_content": "Biodiesel, bioplastics, penicillin: “If you look at important industrial bioprocesses, most of them use organisms that naturally make a product,” said Jeff Czajka , a bioprocess scientist and Linus Pauling Fellow at the Department of Energy’s (DOE’s) Pacific Northwest National Laboratory (PNNL). “There hasn’t been as much success engineering strains for bioprocesses to make new or better products—instead, people just optimize what nature has started.” The reason for that is an all-too-familiar story for many researchers: as they aim to improve a bioproduct, they spend years meticulously engineering a promising microbial strain. It works perfectly in the laboratory, but when it’s scaled up for industrial application, it suddenly fails. Accurately predicting how organisms’ characteristics respond to not only their genes, but also their environments (a nascent field called “predictive phenomics”) is extraordinarily challenging. Even for microbes, a staggering number of factors influence their traits; for bioproduct innovation, that means that when a strain fails, it’s often almost impossible for researchers to isolate the problem and course correct. “It’s a huge challenge facing synthetic biology researchers and companies,” Czajka said. At PNNL, researchers are using AI to tackle that challenge. The arts and sciences of AI-accelerated bioprocesses Often, bioproducts researchers want to engineer bioprocesses to increase their outputs. Higher outputs mean more biofuel and more antibiotics at lower costs. In one case, PNNL researchers had already engineered Lipomyces starkeyi: a yeast commonly used in biofuel production to produce malic acid which is a platform chemical with a wide range of applications. The next task: increasing the output. “We were trying to optimize the media—what the yeast was growing in—to produce as much malic acid as possible,” Czajka said. “But there are a lot of parameters: these yeasts are sensitive to all sorts of environmental conditions, and it would have taken a very long time to explore all the options.” “Currently, the main approach to optimization is trial and error,” he said. “Which leads a lot of people to say that the bioprocess field is an art more than a science.” But Czajka and his colleagues applied a different kind of art: a machine learning model called the Automated Recommendation Tool (ART). The model was developed by researchers at Lawrence Berkeley National Laboratory and Sandia National Laboratories through the Joint BioEnergy Institute (a DOE Bioenergy Research Center) and DOE’s Agile BioFoundry (a consortium of national laboratories dedicated to accelerating biomanufacturing). PNNL is a member of both groups. “ART basically designed the experiment for us,” Czajka said. “As we iterated the experiment, ART would learn from the results and suggest which conditions to test next and which conditions it expected would produce the most malic acid.” “In the end, we improved production by around 20 percent in a short time, which was very exciting.” The best of both worlds While AI models can excel at predicting strains’ performance, they are often limited by low availability of the precise molecular measurements that inform them—a phenomenon known as sparse data. Furthermore, even highly predictive AI models often produce “black box” solutions: lots of “what,” but not much “why.” In these cases, PNNL researchers apply a combination of AI and more traditional genome-scale models, which incorporate researchers’ scientific and mechanistic understandings of an organism’s functions. “Informing machine learning models with mechanistic insights helps them perform better and improves explainability,” Czajka said. Machine learning, in turn, offers advantages over genome-scale models. “It’s challenging to build accurately predictive genome-scale models because of the complexity of gene-environment interactions—and because there are a lot of genes that we simply don’t know what they do,” Czajka said. “Machine learning models can implicitly capture all that complexity.” By coupling them, researchers get the best of both worlds: the mechanistic precision of genome-scale modeling and the predictive punch of machine learning. Czajka and his colleagues, for instance, applied this combined approach to predict outputs from various strains of Yarrowia lipolytica , a yeast with a wide range of applications in the production of biofuels and other bioproducts. The team first used a genome-scale model to fill in the gaps of the sparse data, then used the resulting dataset to train a machine learning model that accurately predicted output concentrations. A brighter future for bioproduct development “Right now, you can spend years going through and picking out targets, learning or engineering the strain, seeing how it performs, and trying to go back through with those insights to engineer them,” Czajka said. “Ideally, these AI-boosted modeling efforts will help shorten those cycles, producing new and improved bioproducts while saving time and reducing costs.” The AI-accelerated processes and tools being developed at PNNL have broad potential to enhance development of bioenergy molecules and countless other bioproducts. Better-engineered strains could lead to better medicine, better fuels, better materials, and more. But for Czajka, it’s not about any individual bioproduct. “In my mind, this is all under one umbrella: transitioning strains from the lab to industry,” he said. PNNL’s work in AI-accelerated bioproducts development is supported by the Department of Energy, Office of Energy Efficiency and Renewable Energy’s Bioenergy Technologies Office and by PNNL’s internally funded Predictive Phenomics Initiative , which is focused on understanding the inner workings of complex biological systems.", "release_time": "2025-10-01", "source_institution": "美国能源部西北太平洋国家实验室", "url": "http://www.pnnl.gov/news-media/pnnl-ai-accelerating-us-bioeconomy"}
{"category": "产业应用", "title": "蒙古炼焦煤进口创新高，8月中国进口结构生变", "short_summary": "8月中国炼焦煤进口环比增5.8%，蒙古单月突破600万吨创年内新高。", "detailed_summary": "8月中国炼焦煤进口环比增5.8%，蒙古单月突破600万吨创年内新高。\n（1）2025年8月中国炼焦煤进口量1016.2万吨，环比增长5.8%但同比下降5.0%；\n（2）1-8月累计进口7264.3万吨，较2024年同期下降7.5%，整体呈收缩态势；\n（3）蒙古炼焦煤8月进口601.5万吨创年内新高，环比大增20.8%，占总进口量49.2%；\n（4）俄罗斯进口环比回落23.7%，加拿大创年内新高环比增45.9%，澳大利亚和美国进口显著萎缩；\n（5）进口来源结构变化反映市场竞争格局调整，蒙古供应优势凸显。", "raw_content": "2025年8月，中国炼焦煤进口量达到 1016.2万吨，环比增5.8%，但同比仍低于2024年同期水平，同比降5.0%。纵观2025年1-8月，进口总量为 7264.3万吨，较2024年同期的7853.9万吨下降约7.5%，整体进口规模呈现收缩态势。然而，从结构上看，蒙古炼焦煤进口8月表现尤为突出，成为本期数据最大亮点。 一、蒙古炼焦煤进口量单月突破600万吨，创年内新高 2025年8月，中国从蒙古进口炼焦煤601.5万吨，不仅环比大幅增长20.8%，更创下2025年单月进口量最高记录。这一数据显著高于7月的497.9万吨，显示出蒙古对中国炼焦煤供应的强劲动力。 从累计数据看，1-8月从蒙古进口总量达 3574.6万吨，占总进口量的49.2%，较2024年同期总量下降9.0%。 二、其他国家进口表现不一 俄罗斯：8月进口256.7万吨，较7月(336.6万吨)明显回落，环比降23.7%;累计进口2081.1万吨，累计同比增2.6%，占比28.6%，仍是中国第二大炼焦煤进口来源国。 加拿大：8月进口102.8万吨，创年内新高，环比大增45.9%，累计709.4万吨，占比9.8%，同比有明显增长，累计同比增20.8%。 澳大利亚：8月仅进口37.3万吨，环比降13.6%，;累计进口460.1万吨，占比6.3%。 美国：2025年以来进口大幅萎缩，1-8月仅290.5万吨，5月份起美国炼焦煤进口量持续为0，反映其因关税问题在中国市场竞争力下降。 表：2025年中国炼焦煤进口分国别月度数据表(万吨) 责任编辑： 张磊 标签：蒙古炼焦煤 上一篇：进口贸易商采购成本延续高位 下一篇：最后一页", "release_time": "2025-09-23", "source_institution": "中国能源网china5e", "url": "https://www.china5e.com/news/news-1194259-1.html"}
{"category": "研究前沿", "title": "多层超透镜设计突破波长聚焦限制", "short_summary": "新型多层超透镜实现多波长聚焦，有望用于无人机成像系统。", "detailed_summary": "新型多层超透镜实现多波长聚焦，有望用于无人机成像系统。\n（1）研究团队开发多层超材料透镜设计，克服单层超透镜的物理限制；\n（2）采用逆向设计算法优化形状，实现偏振不敏感和更大制造容差；\n（3）设计支持多波长同时聚焦，结构易于通过半导体平台规模化制造；\n（4）目前最多支持5种波长，适用于无人机和地球观测卫星等便携成像系统。", "raw_content": "The design uses layers of metamaterials to simultaneously focus a range of wavelengths from an unpolarized source and over a large diameter, overcoming a major limitation of metalenses, said the first author of the paper reporting the design, Mr Joshua Jordaan, from the Research School of Physics at the Australian National University and the ARC Centre of Excellence for Transformative Meta-Optical Systems (TMOS). \"Our design has a lot of nice features that make it applicable to practical devices.\" \"It's easy to manufacture because it has a low aspect ratio and each layer can be fabricated individually and then packaged together, it's also polarisation insensitive, and is potentially scalable through mature semiconductor nanofabrication platforms,\" Mr Jordaan said. The project was led by researchers from the Friedrich Schiller University Jena in Germany as part of the International Research Training Group Meta-ACTIVE. The paper reporting their design is published in Optics Express . Metalenses have thickness mere fractions of the width of a hair, which is orders of magnitude thinner than conventional lenses. They can be designed to have properties such as focal lengths that would be impossibly short for conventional optics. Initially the team attempted to focus multiple wavelengths with a single layer, but they hit up against some fundamental constraints, Mr Jordaan said. \"It turns out the maximum group-delay attainable in a single-layer metasurface has physical limitations, and these in turn set upper bounds on the product of the numerical aperture, physical diameter and operating bandwidth.\" \"To work at the wavelength range we needed, a single layer would either have to have a very small diameter, which would defeat the purpose of the design, or basically have such a low numerical aperture that it's hardly focusing the light at all,\" he said. \"We realized we needed a more complex structure, which then led to a multi-layer approach.\" With the design shifted to incorporating several metalens layers, the team approached the problem with an inverse design algorithm based on shape optimization, with parameterization that meant a lot of degrees of freedom. They guided the software to search for metasurface shapes that, for a single wavelength, created simple resonances in both the electric and magnetic dipole, known as Huygens resonances. By employing resonances, the team were able to improve on previous designs by other groups, and develop metalens designs that were polarization independent, and had greater tolerances in manufacturing specifications - crucial in the quest to scale fabrication to industrial quantities. The optimization routine came up with a library of metamaterial elements in a surprising range of shapes, such as rounded squares, four-leaf clovers and propellers. These tiny shapes, around 300 nm tall and 1000 nm wide, spanned the full range of phase shifts, from zero to two pi, enabling the team to create a phase gradient map to achieve any arbitrary focusing pattern - although they were initially just aiming for a simple ring structure of a conventional lens. \"We could, for example, focus different wavelengths into different locations to create a colour router,\" Mr Jordaan said. However, the multilayer approach is limited to a maximum of around five different wavelengths, Mr Jordaan said. \"The problem is you need structures large enough to be resonant at the longest wavelength, without getting diffraction from the shorter wavelengths,\" he said. Within these constraints, Mr Jordaan said the ability to make metalenses to collect a lot of light will be a boon for future portable imaging systems. \"The metalenses we have designed would be ideal for drones or earth-observation satellites, as we've tried to make them as small and light as possible,\" he said.", "release_time": "2025-09-22", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250921090853.htm"}
{"category": "研究前沿", "title": "研究揭示冰比水更能释放铁元素", "short_summary": "新研究发现冰在零下环境反能高效释放铁，挑战传统认知并影响生态系统。", "detailed_summary": "新研究发现冰在零下环境反能高效释放铁，挑战传统认知并影响生态系统。\n（1）研究发现冰在零下十摄氏度时比四摄氏度液态水释放更多铁元素，颠覆冰冻环境减缓化学反应的传统认知；\n（2）机制在于冰晶间形成微观液态水袋，成为浓缩酸性化学反应器，可在零下30度与铁矿物反应；\n（3）实验以针铁矿和天然有机酸为对象，发现冻融循环通过释放有机物进一步促进铁溶解；\n（4）盐度是关键因素：淡水和微咸水增强溶解，海水则抑制，主要适用于酸性冻土等环境；\n（5）气候变暖使冻融循环更频繁，可能将大量铁释放至水体，影响水质和生态系统。", "raw_content": "The study, recently published in the scientific journal PNAS , shows that ice at minus ten degrees Celsius releases more iron from common minerals than liquid water at four degrees Celsius. This challenges the long-held belief that frozen environments slow down chemical reactions. \"It may sound counterintuitive, but ice is not a passive frozen block,\" says Jean-François Boily, Professor at Umeå University and co-author of the study. \"Freezing creates microscopic pockets of liquid water between ice crystals. These act like chemical reactors, where compounds become concentrated and extremely acidic. This means they can react with iron minerals even at temperatures as low as minus 30 degrees Celsius.\" To understand the process, the researchers studied goethite - a widespread iron oxide mineral - together with a naturally occurring organic acid, using advanced microscopy and experiments. They discovered that repeated freeze-thaw cycles make iron dissolve more efficiently. As the ice freezes and thaws, organic compounds that were previously trapped in the ice are released, fuelling further chemical reactions. Salinity also plays a crucial role: fresh and brackish water increase dissolution, while seawater can suppress it. The findings apply mainly to acidic environments, such as mine drainage sites, frozen dust in the atmosphere, acid sulfate soils along the Baltic Sea coast, or in any acidic frozen environment where iron minerals interact with organics. The next step is to find out if the same is true for all iron-bearing ice. This is what ongoing research in the Boily laboratory will soon reveal. \"As the climate warms, freeze-thaw cycles become more frequent,\" says Angelo Pio Sebaaly, doctoral student and first author of the study. \"Each cycle releases iron from soils and permafrost into the water. This can affect water quality and aquatic ecosystems across vast areas.\" The findings show that ice is not a passive storage medium, but an active player. As freezing and thawing increase in polar and mountain regions, for the impact on ecosystems. and the natural cycling of elements could be significant.", "release_time": "2025-09-22", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250922074938.htm"}
{"category": "研究前沿", "title": "MIT开发AI新方法突破量子材料设计瓶颈", "short_summary": "MIT团队提出SCIGEN技术，引导AI生成具有特定几何结构的量子材料候选物。", "detailed_summary": "MIT团队提出SCIGEN技术，引导AI生成具有特定几何结构的量子材料候选物。\n(1) MIT研究人员开发SCIGEN技术，通过几何约束引导生成式AI模型设计具有量子特性的新材料；\n(2) 该方法针对现有生成模型难以设计超导、量子自旋液体等特殊量子材料的瓶颈问题；\n(3) 成功生成超1000万候选材料，从中合成出两种具有奇异磁性的新材料TiPdBi和TiPbSb；\n(4) 实验验证表明AI预测与实际材料属性高度吻合，相关成果发表于《自然·材料》；\n(5) 该技术将加速量子计算机材料、拓扑超导体等关键材料的发现进程。", "raw_content": "The artificial intelligence models that turn text into images are also useful for generating new materials. Over the last few years, generative materials models from companies like Google, Microsoft, and Meta have drawn on their training data to help researchers design tens of millions of new materials. But when it comes to designing materials with exotic quantum properties like superconductivity or unique magnetic states, those models struggle. That’s too bad, because humans could use the help. For example, after a decade of research into a class of materials that could revolutionize quantum computing, called quantum spin liquids, only a dozen material candidates have been identified. The bottleneck means there are fewer materials to serve as the basis for technological breakthroughs. Now, MIT researchers have developed a technique that lets popular generative materials models create promising quantum materials by following specific design rules. The rules, or constraints, steer models to create materials with unique structures that give rise to quantum properties. “The models from these large companies generate materials optimized for stability,” says Mingda Li, MIT’s Class of 1947 Career Development Professor. “Our perspective is that’s not usually how materials science advances. We don’t need 10 million new materials to change the world. We just need one really good material.” The approach is described today in a paper published by Nature Materials . The researchers applied their technique to generate millions of candidate materials consisting of geometric lattice structures associated with quantum properties. From that pool, they synthesized two actual materials with exotic magnetic traits. “People in the quantum community really care about these geometric constraints, like the Kagome lattices that are two overlapping, upside-down triangles. We created materials with Kagome lattices because those materials can mimic the behavior of rare earth elements, so they are of high technical importance.” Li says. Li is the senior author of the paper. His MIT co-authors include PhD students Ryotaro Okabe, Mouyang Cheng, Abhijatmedhi Chotrattanapituk, and Denisse Cordova Carrizales; postdoc Manasi Mandal; undergraduate researchers Kiran Mak and Bowen Yu; visiting scholar Nguyen Tuan Hung; Xiang Fu ’22, PhD ’24; and professor of electrical engineering and computer science Tommi Jaakkola, who is an affiliate of the Computer Science and Artificial Intelligence Laboratory (CSAIL) and Institute for Data, Systems, and Society. Additional co-authors include Yao Wang of Emory University, Weiwei Xie of Michigan State University, YQ Cheng of Oak Ridge National Laboratory, and Robert Cava of Princeton University. Steering models toward impact A material’s properties are determined by its structure, and quantum materials are no different. Certain atomic structures are more likely to give rise to exotic quantum properties than others. For instance, square lattices can serve as a platform for high-temperature superconductors, while other shapes known as Kagome and Lieb lattices can support the creation of materials that could be useful for quantum computing. To help a popular class of generative models known as a diffusion models produce materials that conform to particular geometric patterns, the researchers created SCIGEN (short for Structural Constraint Integration in GENerative model). SCIGEN is a computer code that ensures diffusion models adhere to user-defined constraints at each iterative generation step. With SCIGEN, users can give any generative AI diffusion model geometric structural rules to follow as it generates materials. AI diffusion models work by sampling from their training dataset to generate structures that reflect the distribution of structures found in the dataset. SCIGEN blocks generations that don’t align with the structural rules. To test SCIGEN, the researchers applied it to a popular AI materials generation model known as DiffCSP. They had the SCIGEN-equipped model generate materials with unique geometric patterns known as Archimedean lattices, which are collections of 2D lattice tilings of different polygons. Archimedean lattices can lead to a range of quantum phenomena and have been the focus of much research. “Archimedean lattices give rise to quantum spin liquids and so-called flat bands, which can mimic the properties of rare earths without rare earth elements, so they are extremely important,” says Cheng, a co-corresponding author of the work. “Other Archimedean lattice materials have large pores that could be used for carbon capture and other applications, so it’s a collection of special materials. In some cases, there are no known materials with that lattice, so I think it will be really interesting to find the first material that fits in that lattice.” The model generated over 10 million material candidates with Archimedean lattices. One million of those materials survived a screening for stability. Using the supercomputers in Oak Ridge National Laboratory, the researchers then took a smaller sample of 26,000 materials and ran detailed simulations to understand how the materials’ underlying atoms behaved. The researchers found magnetism in 41 percent of those structures. From that subset, the researchers synthesized two previously undiscovered compounds, TiPdBi and TiPbSb, at Xie and Cava’s labs. Subsequent experiments showed the AI model’s predictions largely aligned with the actual material’s properties. “We wanted to discover new materials that could have a huge potential impact by incorporating these structures that have been known to give rise to quantum properties,” says Okabe, the paper’s first author. “We already know that these materials with specific geometric patterns are interesting, so it’s natural to start with them.” Accelerating material breakthroughs Quantum spin liquids could unlock quantum computing by enabling stable, error-resistant qubits that serve as the basis of quantum operations. But no quantum spin liquid materials have been confirmed. Xie and Cava believe SCIGEN could accelerate the search for these materials. “There’s a big search for quantum computer materials and topological superconductors, and these are all related to the geometric patterns of materials,” Xie says. “But experimental progress has been very, very slow,” Cava adds. “Many of these quantum spin liquid materials are subject to constraints: They have to be in a triangular lattice or a Kagome lattice. If the materials satisfy those constraints, the quantum researchers get excited; it’s a necessary but not sufficient condition. So, by generating many, many materials like that, it immediately gives experimentalists hundreds or thousands more candidates to play with to accelerate quantum computer materials research.” “This work presents a new tool, leveraging machine learning, that can predict which materials will have specific elements in a desired geometric pattern,” says Drexel University Professor Steve May, who was not involved in the research. “This should speed up the development of previously unexplored materials for applications in next-generation electronic, magnetic, or optical technologies.” The researchers stress that experimentation is still critical to assess whether AI-generated materials can be synthesized and how their actual properties compare with model predictions. Future work on SCIGEN could incorporate additional design rules into generative models, including chemical and functional constraints. “People who want to change the world care about material properties more than the stability and structure of materials,” Okabe says. “With our approach, the ratio of stable materials goes down, but it opens the door to generate a whole bunch of promising materials.” The work was supported, in part, by the U.S. Department of Energy, the National Energy Research Scientific Computing Center, the National Science Foundation, and Oak Ridge National Laboratory.", "release_time": "2025-09-22", "source_institution": "麻省理工学院能源计划", "url": "https://news.mit.edu/2025/new-tool-makes-generative-ai-models-likely-create-breakthrough-materials-0922"}
{"category": "研究前沿", "title": "研究发现冰具挠曲电性，或解闪电成因", "short_summary": "冰受机械变形可发电，新发现关联闪电形成机制并具技术应用前景。", "detailed_summary": "冰受机械变形可发电，新发现关联闪电形成机制并具技术应用前景。\n（1）国际研究首次证实普通冰是挠曲电材料，机械变形时可产生电荷，且在低于-113°C时表面呈现铁电性。\n（2）该发现揭示了冰粒子在云层碰撞中因弯曲变形产生电荷，可能解释雷暴中闪电形成的 electrification 机制。\n（3）研究通过实验测量弯曲冰块产生的电势，结果与雷暴观测相符，为解决长期未明的冰带电机制提供了新解释。\n（4）冰的挠曲电性使其与二氧化钛等电陶瓷材料性能相当，为在寒冷环境中开发新型电子器件开辟了潜在路径。", "raw_content": "Frozen water is one of the most abundant substances on Earth. It is found in glaciers, on mountain peaks and in polar ice caps. Although it is a well-known material, studying its properties continues to yield fascinating results. An international study involving ICN2, at the UAB campus, Xi'an Jiaotong University (Xi'an) and Stony Brook University (New York), has shown for the first time that ordinary ice is a flexoelectric material. In other words, it can generate electricity when subjected to mechanical deformation. This discovery could have significant implications for the development of future technological devices and help to explain natural phenomena such as the formation of lightning in thunderstorms. The study, published in the journal Nature Physics , represents a significant step forward in our understanding of the electromechanical properties of ice. \"We discovered that ice generates electric charge in response to mechanical stress at all temperatures. In addition, we identified a thin 'ferroelectric' layer at the surface at temperatures below -113ºC (160K). This means that the ice surface can develop a natural electric polarization, which can be reversed when an external electric field is applied -- similar to how the poles of a magnet can be flipped. The surface ferroelectricity is a cool discovery in its own right, as it means that ice may have not just one way to generate electricity but two: ferroelectricity at very low temperatures, and flexoelectricity at higher temperatures all the way to 0 °C \" explains Dr Xin Wen, a member of the ICN2 Oxide Nanophysics Group and one of the study's lead researchers. This property places ice on a par with electroceramic materials such as titanium dioxide, which are currently used in advanced technologies like sensors and capacitors. Ice, flexoelectricity and thunderstorms One of the most surprising aspects of this discovery is its connection to nature. The results of the study suggest that the flexoelectricity of ice could play a role in the electrification of clouds during thunderstorms, and therefore in the origin of lightning. It is known that lightning forms when an electric potential builds up in clouds due to collisions between ice particles, which become electrically charged. This potential is then released as a lightning strike. However, the mechanism by which ice particles become electrically charged has remained unclear, since ice is not piezoelectric -- it cannot generate charge simply by being compressed during a collision. However, the study shows that ice can become electrically charged when it is subjected to inhomogeneous deformations, i.e. when it bends or deforms irregularly. \"During our research, the electric potential generated by bending a slab of ice was measured. Specifically, the block was placed between two metal plates and connected to a measuring device. The results match those previously observed in ice-particle collisions in thunderstorms,\" explains ICREA Prof. Gustau Catalán, leader of the Oxide Nanophysics Group at ICN2. Thus, the results suggest that flexoelectricity could be one possible explanation for the generation of the electric potential that leads to lightning during storms. Future perspectives The researchers in the group are already exploring new lines of investigation aimed at exploiting these properties of ice for real-world applications. Although it is still a bit early to discuss potential solutions, this discovery could pave the way for the development of new electronic devices that use ice as an active material, which could be fabricated directly in cold environments.", "release_time": "2025-09-22", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250921090846.htm"}
{"category": "产业应用", "title": "美军基地能源韧性演习提升电网中断应对能力", "short_summary": "林肯实验室通过模拟断电演习测试军事基地备用系统，发现漏洞并推动政策立法。", "detailed_summary": "林肯实验室通过模拟断电演习测试军事基地备用系统，发现漏洞并推动政策立法。\n（1）林肯实验室开展能源弹性准备演习（ERRE），模拟断电事件测试军事基地备用电源系统和人员响应能力；  \n（2）演习持续长达15小时，已在33个基地实施，覆盖80万人，暴露出备用系统脆弱、发电机故障等共性问题；  \n（3）项目推动美国会立法要求各军种每年进行5次演习，并拓展至微电网设计和水资源韧性分析领域；  \n（4）演习成果帮助基地优化基础设施政策，提升关键任务在电网中断期间的持续运行能力。", "raw_content": "In recent years, power outages caused by extreme weather or substation attacks have exposed the vulnerability of the electric grid. For the nation’s military bases, which are served by the grid, being ready for outages is a matter of national security. What better way to test readiness than to cut the power? Lincoln Laboratory is doing just that with its Energy Resilience Readiness Exercises (ERREs). During an exercise, a base is disconnected from the grid, testing the ability of backup power systems and service members to work through failure. Lasting up to 15 hours, each exercise mimics a real outage event with limited forewarning to the base population. “No one thought that this kind of real-world test would be accepted. We’ve now done it at 33 installations, impacting over 800,000 people,” says Jean Sack ’13, SM ’15, who leads the program with Christopher Lashway and Annie Weathers in the laboratory's Energy Systems Group . According to a Department of Energy report , 70 percent of the nation’s transmission lines are approaching end of life. This aging infrastructure, combined with increasing power demands and interdependencies, threatens cascading failures. In response, the Department of Defense (DoD) has sharpened its focus on energy resilience, or the ability to anticipate, withstand, and recover from outages. On a base, an outage could disrupt critical missions, open the door to physical or cyberattacks, and cut off water supplies. “Threats to this already-fragile system are increasing. That's why this work is so important,” Sack says. Safely cutting power Before an exercise, the laboratory team works closely with base leadership and infrastructure personnel to carefully plan how it will safely disconnect from utility power. Over multiple site visits, they study each building and mission to understand power capabilities, ensure health and safety, and develop contingency plans. “We get people together who may never have spoken before, but depend on one another. We like to say ‘connecting mission owners to their utility providers,’” says Lashway, a former electrician turned energy-systems researcher. “The planning process is a huge learning opportunity, and a chance to fix issues ahead of the outage.” On the day of the outage, laboratory staff are on site to ensure the process runs smoothly, but the base is meant to run the exercise. Since beginning in 2018, the ERRE campaign has reached huge installations, including Fort Bragg, a U.S. Army base in North Carolina that sees nearly 150,000 people daily, and sites as far away as England and Japan. The key is to not limit its scope. All facilities and missions, especially those that are critical, should be included, and service members are tasked with working through issues. To make exercises even more useful as an evaluation of readiness, some are modified with scripted scenarios simulating real-world incidents. These scenarios might challenge personnel to handle a cyberattack to control systems, shutdown of a backup power plant, or a rocket launch during an outage. “We can do all the tabletop exercises in the world, but when you actually pull the plug, the question is, what actually goes on?” former assistant secretary of defense for sustainment Robert McMahon said at a joint House Armed Services subcommittee hearing about initial exercises. “Perhaps the most important lesson that I've seen is a lack of appreciation and understanding by our senior leaders at the installation level, all the way up to my level, of what we thought was going to happen versus what actually occurred, and then being able to apply those lessons learned.” Illuminating issues The ERREs have brought to light common issues across bases. One of them is a reliance on fragile or faulty backup systems. For example, electronic equipment experiences a hard shutdown if it isn't supported by a backup battery to bridge power transitions. In some instances, these battery systems failed or unexpectedly depleted due to age or generator issues. “We see a giant comms room drop out, and then phones and computers don’t work. It emphasizes the need for redundancies,” Lashway says. Generators also present issues. Some fail because they aren’t regularly serviced or refueled through the long outage. Sometimes, personnel mistakenly assumed a generator would support their entire building, requiring reconfigurations after the fact. Air conditioning systems are often excluded from generator-supported emergency circuits, but rooms with a large number of computers generate a lot of heat, and overheated equipment quickly shuts down. The exercises also unveiled interdependencies and chain reactions. In one case, a fire-suppression system accidentally went off, dousing a hangar in foam. The cause was a pressure drop at the same exact moment a switch reset. “Executing an operation at this scale stresses how each of these factors need to work harmoniously and efficiently to ensure that the base, and ultimately missions, remain functional,” Lashway says. Beyond resolving technical issues, the exercises have been valuable for practicing coordination and following chains of command. They’ve also revealed social challenges of operating through outages. For instance, some DoD guidance restricts the use of generators at daycare centers, so parents needed to coordinate care while maintaining their mission. After an exercise, the laboratory compiles all findings in a report for the base. It provides time stamps of significant events by building, identifies links between issues, and summarizes common problems site-wide. It then provides recommendations to address vulnerabilities. “Our goal is to provide as much justification as possible for the base to get the resources they need to fix a problem,” Sack says. The researchers also want to help bases prevent issues and avoid costly repairs. Recently, they’ve been using power meters to capture electrical data before, during, and after an exercise. These monitoring tools reveal power-quality issues that are otherwise hidden. “Not all power is created equal, and standards must be followed to ensure equipment, especially specialized military equipment, operates properly and doesn’t get damaged over the long term. Power metering provides a view into that,” says Lashway. Sparking resiliency ahead Lincoln Laboratory’s ERRE campaign has resulted in legislation. In 2021, Congress passed a law requiring each military branch to perform at least five ERREs, or \"Black Start Exercises,\" per year through 2027. That law was recently reauthorized until 2032. The team has transitioned the ERRE process to two private companies, as well as within the Air Force and Army, to conduct exercises in the coming years. “It's very exciting that this got Congress' attention and has scaled across the DoD,” says Nick Judson, who leads the portfolio of energy, water, and natural hazard resilience efforts within the Energy Systems Group. “This idea started out as a way to enable change on DoD installations, and included a lot of difficult conversations about turning the power off to critical missions, and now we're seeing significant improvements to the readiness of bases and their missions.” It may even be encouraging some healthy competition across the services, Lashway says. At a recent regional event in Colorado, three U.S. Space Force installations each vied to push the scope and duration of their exercises. The team’s focus is now turning to related analysis, such as water resiliency. Water and wastewater systems are vulnerable to disruptions beyond power outages, including equipment failure, sabotage, or water source depletion. “We are conducting tabletop exercises and workshops uniting stakeholders around the importance of water and wastewater systems to enable missions,” says Amelia Servi, who leads this work. “So far, we’ve seen great engagement from groups managing water systems who have been seeking funds to fix these aging systems, and from missions who have previously taken water for granted.” They are also working on long-term energy planning, including ways for installations to be less dependent on the grid. One way is to install microgrids, which are self-sufficient systems that can tap into stored energy. According to Sack, microgrids are highly customized and complicated to operate, so one goal is to design a standardized system. The team's recent power-metering data is providing useful initial inputs into such a design. The researchers are also considering how this work could improve energy resiliency for civilians. Large-scale exercises might not be feasible for the public, but they could be conducted in areas important to public safety, or in places that rely on military resources. During one exercise in Georgia, city residents partially depended upon a base's power plant, so that exercise included working with the city to ensure its resiliency to the outage. “Striking that balance of testing readiness without causing harm is a big challenge in this field and a huge motivation for us,” Sack says. “We are encouraged by the outcomes. Our work is impacting the services at the highest level, rewriting infrastructure policy, and making sure people can better sustain operations during grid disruptions.”", "release_time": "2025-09-22", "source_institution": "麻省理工学院能源计划", "url": "http://news.mit.edu/2025/power-outage-exercises-strengthen-resilience-us-bases-0922"}
{"category": "研究前沿", "title": "科学家研制首个钙钛矿伽马射线探测器 突破核医学成像精度", "short_summary": "新型钙钛矿探测器实现单光子伽马射线成像，有望提升核医学扫描清晰度并降低成本。", "detailed_summary": "新型钙钛矿探测器实现单光子伽马射线成像，有望提升核医学扫描清晰度并降低成本。\n（1）中美科学家合作研制出首个基于钙钛矿晶体的SPECT伽马射线探测器；\n（2）该探测器实现记录级能量分辨率，能区分不同能量的伽马射线并感知极微弱信号；\n（3）相比现有探测器具有成本低、成像清晰、稳定性好等优势；\n（4）可缩短扫描时间、降低辐射剂量，使高质量核医学成像更普及；\n（5）研究成果发表于《自然·通讯》，已启动商业化进程。", "raw_content": "Now, scientists led by Northwestern University and Soochow University in China have built the first perovskite-based detector that can capture individual gamma rays for SPECT imaging with record-breaking precision. The new tool could make common types of nuclear medicine imaging sharper, faster, cheaper and safer. For patients, that could mean shorter scan times, clearer results and lower doses of radiation. The study was published on Aug. 30 in the journal Nature Communications . \"Perovskites are a family of crystals best known for transforming the field of solar energy,\" said Northwestern's Mercouri Kanatzidis, the study's senior author. \"Now, they are poised to do the same for nuclear medicine. This is the first clear proof that perovskite detectors can produce the kind of sharp, reliable images that doctors need to provide the best care for their patients.\" \"Our approach not only improves the performance of detectors but also could lower costs,\" said co-corresponding author Yihui He, a professor at Soochow University. \"That means more hospitals and clinics eventually could have access to the best imaging technologies.\" Kanatzidis is a Charles E. and Emma H. Morrison Professor of Chemistry at Northwestern's Weinberg College of Arts and Sciences and a senior scientist at Argonne National Laboratory. Yihui He is a former postdoctoral fellow from Kanatzidis' laboratory. Nuclear medicine, like SPECT (single-photon emission computing tomography) imaging, works like an invisible camera. Physicians implant a tiny, safe, short-lived radiotracer in a specific part of a patient's body. The tracer emits gamma rays, which pass outward through tissues and eventually hit a detector outside of the body. Each gamma ray is like a pixel of light. After collecting millions of these pixels, computers can construct a 3D image of working organs. Today's detectors, which are either made from cadmium zinc telluride (CZT) or sodium iodide (NaI), have several disadvantages. CZT detectors are incredibly expensive, sometimes reaching into the price range of hundreds of thousands to millions of dollars for a whole camera. Because CZT crystals are brittle and prone to cracking, these detectors also are difficult to manufacture. While cheaper than CZT detectors, NaI detectors are bulky and produce blurrier images -- like taking a photo through a foggy window. To overcome these issues, the scientists turned to perovskite crystals, a material that Kanatzidis has studied for more than a decade. In 2012, his group built the first solid-film solar cells made from perovskites. Then, in 2013, Kanatzidis discovered that single perovskite crystals were highly promising for detecting X-rays and gamma rays. This breakthrough, enabled by his group's growth of high-quality single crystals, sparked a worldwide surge of research and effectively launched a new field in hard radiation detection materials. \"This work demonstrates how far we can push perovskite detectors beyond the laboratory,\" Kanatzidis said. \"When we first discovered in 2013 that perovskite single crystals could detect X-rays and gamma rays, we could only imagine their potential. Now, we're showing that perovskite-based detectors can deliver the resolution and sensitivity needed for demanding applications like nuclear medicine imaging. It's exciting to see this technology moving closer to real-world impact.\" Building on this foundation, Kanatzidis and He led the crystal growth, surface engineering and device design for the new study. By carefully growing and shaping these crystals, the researchers created a pixelated sensor -- just like the pixels in a smartphone camera -- that delivers record-breaking clarity and stability. Leading the design and development of the prototype gamma-ray detector, He developed the camera's pixelated architecture, optimized the multi-channel readout electronics and carried out the high-resolution imaging experiments that validated the device's capabilities. He, Kanatzidis and their team demonstrated that perovskite-based detectors can achieve record energy resolutions and unprecedented single-photon imaging performance, paving the way for practical integration into next-generation nuclear medicine imaging systems. \"Designing this gamma-ray camera and demonstrating its performance has been incredibly rewarding,\" He said. \"By combining high-quality perovskite crystals with a carefully optimized pixelated detector and multi-channel readout system, we were able to achieve record-breaking energy resolution and imaging capabilities. This work shows the real potential of perovskite-based detectors to transform nuclear medicine imaging.\" In experiments, the detector was able to differentiate among gamma rays of different energies with the best resolution reported thus far. It also sensed extremely faint signals from a medical radiotracer (technetium-99m) commonly used in clinical practice and distinguished incredibly fine features, producing crisp images that could separate tiny radioactive sources spaced just a few millimeters apart. The detector also remained highly stable, collecting nearly all the tracer's signal without loss or distortion. Because these new detectors are more sensitive, patients potentially could require shorter scan times or smaller doses of radiation. Northwestern spinout company Actinia Inc. is commercializing this technology -- working with partners in the medical device field to bring it out of the lab and into hospitals. Because they are easier to grow and use simpler components, perovskites offer a far less expensive alternative to CZT and NaI detectors without sacrificing quality. Perovskite-based detectors also offer a realistic pathway to imaging using a lower dose of a radiotracer than can be used with a NaI detector but at a price that ensures widespread patient access. \"Demonstrating that perovskites can deliver single-photon gamma-ray imaging is a milestone,\" He said. \"It shows these materials are ready to move beyond the laboratory and into technologies that directly benefit human health. From here, we see opportunities to refine the detectors further, scale up production and explore entirely new directions in medical imaging.\" \"High-quality nuclear medicine shouldn't be limited to hospitals that can afford the most expensive equipment,\" Kanatzidis said. \"With perovskites, we can open the door to clearer, faster, safer scans for many more patients around the world. The ultimate goal is better scans, better diagnoses and better care for patients.\" The study, \"Single photon γ-ray imaging with high energy and spatial resolution perovskite semiconductor for nuclear medicine,\" was supported by the Defense Threat Reduction Agency (award number HDTRA12020002), the Consortium for Interaction of Ionizing Radiation with Matter University Research Alliance, the National Key R&D Program of China (award number 2021YFF0502600), the National Natural Science Foundation of China (award number U2267211) and the Jiangsu Natural Science Foundation (award number BK20240822).", "release_time": "2025-09-22", "source_institution": "每日科学", "url": "http://www.sciencedaily.com/releases/2025/09/250921090850.htm"}
